ID_Article,communityId,ID_RelatedVenue,title,year,abstract
1817755,22457,9475,Robust Network Routing under Cascading Failures,2014,"We propose a dynamical model for cascading failures in single-commodity network flows. In the proposed model, the network state consists of flows  and  activation status of the links. Network dynamics is determined by a, possibly state-dependent and adversarial, disturbance process that reduces flow capacity on the links, and routing policies at the nodes that have access to the network state, but are oblivious to the presence of disturbance. Under the proposed dynamics, a link becomes irreversibly inactive either due to overload condition on itself or on all of its immediate downstream links. The coupling between link activation and flow dynamics implies that links to become inactive successively are not necessarily adjacent to each other, and hence the pattern of cascading failure under our model is qualitatively different than standard cascade models. The magnitude of a disturbance process is defined as the sum of cumulative capacity reductions across time and links of the network, and the margin of resilience of the network is defined as the infimum over the magnitude of all disturbance processes under which the links at the origin node become inactive. We propose an algorithm to compute an upper bound on the margin of resilience for the setting where the routing policy only has access to information about the local state of the network. For the limiting case when the routing policies update their action as fast as network dynamics, we identify sufficient conditions on network parameters under which the upper bound is tight under an appropriate routing policy. Our analysis relies on making connections between network parameters and monotonicity in network state evolution under proposed dynamics."
1928909,22457,20358,Accelerating instant question search with database techniques,2011,"Distributed question answering services, like Yahoo Answer and Aardvark, are known to be useful for end users and have also opened up numerous topics ranging in many research fields. In this paper, we propose a user-support tool for composing questions in such services. Our system incrementally recommends similar questions while users are typing their question in a sentence, which gives the users opportunities to know that there are similar questions that have already been solved. A question database is semantically analyzed and searched in the semantic space by boosting the performance of similarity searches with database techniques such as server/client caching and LSH (Locality Sensitive Hashing). The more text the user enters, the more similar the recommendations will become to the ultimately desired question. This unconscious editing-as-a-sequence-of-searches approach helps users to form their question incrementally through interactive supplementary information. Not only askers nor repliers, but also service providers have advantages such as that the knowledge of the service will be autonomously refined by avoiding for novice users to repeat questions which have been already solved."
2075109,22457,20358,Knowledge sharing and yahoo answers: everyone knows something,2008,"Yahoo Answers (YA) is a large and diverse question-answer forum, acting not only as a medium for sharing technical knowledge, but as a place where one can seek advice, gather opinions, and satisfy one's curiosity about a countless number of things. In this paper, we seek to understand YA's knowledge sharing and activity. We analyze the forum categories and cluster them according to content characteristics and patterns of interaction among the users. While interactions in some categories resemble expertise sharing forums, others incorporate discussion, everyday advice, and support. With such a diversity of categories in which one can participate, we find that some users focus narrowly on specific topics, while others participate across categories. This not only allows us to map related categories, but to characterize the entropy of the users' interests. We find that lower entropy correlates with receiving higher answer ratings, but only for categories where factual expertise is primarily sought after. We combine both user attributes and answer characteristics to predict, within a given category, whether a particular answer will be chosen as the best answer by the asker."
2519509,22457,20348,One meter to find them all: water network leak localization using a single flow meter,2014,"Leak localization is a major issue faced by water utilities worldwide. Leaks are ideally detected and localized by a network-wide metering infrastructure. However, in many utilities, in-network metering is minimally present at just the inlets of sub-networks called District Metering Area (DMA). We consider the problem of leak localization using data from a single flow meter placed at the inlet of a DMA. We use standard time-series based modeling to detect if a current meter reading is a leak or not, and if so, to estimate the excess flow. Conventional approaches use an a-priori fully calibrated hydraulic model to map the excess flow back to a set of candidate leak locations. However, obtaining an accurate hydraulic model is expensive and hence, beyond the reach of many water utilities.   We present an alternate approach that exploits the network structure and static properties in a novel way. Specifically, we extend the use of centrality metrics to infrastructure domains and use these metrics to map from the excess leak flow to the candidate leak location(s). We evaluate our approach on benchmark water utility network topologies as well as on real data obtained from an European water utility. On benchmark topologies, the localization obtained by our method is comparable to that obtained from a complete hydraulic model. On a real-world network, we were able to localize two out of the three leaks whose data we had access to. Of these two cases, we find that the actual leak location was in the candidate set identified by our approach; further, the approach pruned as much as 78% of the DMA locations, indicating a high degree of localization."
955488,22457,9896,(How) will the revolution be retweeted?: information diffusion and the 2011 Egyptian uprising,2012,"This paper examines microblogging information diffusion activity during the 2011 Egyptian political uprisings. Specifically, we examine the use of the retweet mechanism on Twitter, using empirical evidence of information propagation to reveal aspects of work that the crowd conducts. Analysis of the widespread contagion of a popular meme reveals interaction between those who were on the ground in Cairo and those who were not. However, differences between information that appeals to the larger crowd and those who were doing on-the-ground work reveal important interplay between the two realms. Through both qualitative and statistical description, we show how the crowd expresses solidarity and does the work of information processing through recommendation and filtering. We discuss how these aspects of work mutually sustain crowd interaction in a politically sensitive context. In addition, we show how features of this retweet-recommendation behavior could be used in combination with other indicators to identify information that is new and likely coming from the ground."
2655235,22457,20561,Venture Signals and Social Media Buzz in Crowdfunding: Are Buzzworthy Projects Worth the Hype?,2016,"Entrepreneurs signal the worth of their ventures using the technological capabilities of their crowdfunding platforms. Additionally, social media allows others to create buzz about the venture, which can also influence funding outcomes. Moreover, these two antecedents can interact with each other, whereby venture signals are either amplified or diluted by buzz about the project. Our study examined how the effects of technological cues and social media buzz about a crowdfunded venture affect its success. Our results indicate a differential effect of buzz -- depending on the social media platform and the type of signal conveyed -- on crowdfunding success."
1214360,22457,9896,Limber: exploring motivation in a workplace exergame,2013,"Limber, in its current iteration, is a vision-based application that introduces gamification into the workplace. This ongoing effort to incentivize good posture, and regular body movements implements several changes to include; full body stretches (figure 2), team gaming elements, and an ambient display (figure 1). With increased intra and inter team competition our field study of twelve players in a work place aims to better understand the most popular motivators, and answer the question, can gamification promote more healthy behaviour among office workers? What forms of motivation are most effective: personal, intra or inter-group?"
293216,22457,20358,Subgraph frequencies: mapping the empirical and extremal geography of large graph collections,2013,"A growing set of on-line applications are generating data that can be viewed as very large collections of small, dense social graphs --- these range from sets of social groups, events, or collaboration projects to the vast collection of graph neighborhoods in large social networks. A natural question is how to usefully define a domain-independent 'coordinate system' for such a collection of graphs, so that the set of possible structures can be compactly represented and understood within a common space. In this work, we draw on the theory of graph homomorphisms to formulate and analyze such a representation, based on computing the frequencies of small induced subgraphs within each graph. We find that the space of subgraph frequencies is governed both by its combinatorial properties --- based on extremal results that constrain all graphs --- as well as by its empirical properties --- manifested in the way that real social graphs appear to lie near a simple one-dimensional curve through this space.   We develop flexible frameworks for studying each of these aspects. For capturing empirical properties, we characterize a simple stochastic generative model, a single-parameter extension of Erdos-Renyi random graphs, whose stationary distribution over subgraphs closely tracks the one-dimensional concentration of the real social graph families. For the extremal properties, we develop a tractable linear program for bounding the feasible space of subgraph frequencies by harnessing a toolkit of known extremal graph theory. Together, these two complementary frameworks shed light on a fundamental question pertaining to social graphs: what properties of social graphs are 'social' properties and what properties are 'graph' properties?   We conclude with a brief demonstration of how the coordinate system we examine can also be used to perform classification tasks, distinguishing between structures arising from different types of social graphs."
2659308,22457,20561,Mobbing and Burnout in Emerging Knowledge Economies: An Exploratory Study in Poland,2016,"Many transition countries, known as emerging knowledge economies, can not to catch up with more advanced, matured economies. Low salaries, job insecurity, pressure to keep low cost create a work environment in many transitions economies where mobbing and burnout is common place. This paper examines the relationship between mobbing and professional burnout syndroms among knowledge workers in Poland. The study is based on a preliminary survey among 160 Polish respondents. The results of this study confirm that phenomena of mobbing and professional burnout are very common in emerging knowledge economies. Knowledge workers, female and employees of small firms are especially impacted by mobbing and burnout. Mobbing has an influence on job burnout of knowledge workers. Managers and politicians in emerging knowledge economies can benefit from our findings, by the use our conclusions, by changing regulations and companies polices."
2650542,22457,20561,Benchmark characterization,1991,"The design of experimental systems usually employ some form of simulation. The inputs to the simulation are typically standard benchmarks. This paper presents a method for finding a cost-effective design for each benchmark. This method is called benchmark characterization. Benchmark characterization is possible in part due to the advent of high-performance architecture-independent compiler technology. To demonstrate the method, seven benchmarks are characterized. Five of the benchmarks are from the SPEC benchmark set (gcc, espresso, spice, li and matrix300) and two are popular synthetic benchmarks (dhrystone and whetstone). Benchmark characteristics are reported for the processor, memory system, and operating system. >"
3227846,22457,9896,Augmenting Media Literacy with Automatic Characterization of News along Pragmatic Dimensions,2017,"Media literacy allows individuals to better interpret the information they need to absorb to contribute to our democratic, knowledge-based society. I propose that by automatically notifying readers of an article's problematic pragmatic characteristics, an application could augment their media literacy. I describe two characteristics for which I have been building automatic classifiers -- factiness and tropes as narrative frames -- and discuss the status of each project."
2813418,22457,20561,Inheritance of synchronization and recovery properties in Avalon/C++,1988,"The inheritance mechanism of object-oriented languages is used in the new domain of fault-tolerant distributed systems. Inheritance in Avalon/C++ is used to transmit properties, such as serializability and crash resilience, that are of specific interest in distributed applications. Three base classes are presented: resilient, atomic, and dynamic. They are arranged in a linear hierarchy. Examples of derived classes with objects that guarantee desirable fault-tolerance properties are given. >"
1571348,22457,9896,MoCoMapps: mobile collaborative map-based applications,2012,"This video demonstrates an experiment in crowdsourcing both map-based data and also the applications that provide the maps, and also presents scenarios of use."
2435264,22457,9475,Novel switched model reference adaptive control for continuous piecewise affine systems,2008,"This paper is concerned with the derivation of a novel model reference adaptive control (MRAC) scheme for piecewise-affine (PWA) continuous systems. A novel version of the minimal control synthesis algorithm, originally developed as a MRAC for smooth systems, is presented. The resulting adaptive algorithm is a switched feedback controller able to cope with uncertain continuous PWA systems. The proof of stability, based on the newly developed passivity theory for hybrid systems, is provided and the effectiveness of the new proposed control strategy is numerically tested."
2881997,22457,20561,SEGUE: support for distributed graphical interfaces,1988,"A description is given of SEGUE, a system for the specification and generation of structured graphical interfaces for distributed systems. The user interface resides on as raster-graphics workstation, but the application program may execute on one or more other machines connected to that workstation by a local area network. SEGUE is based on standard editor technology, but extends it to provide a general interface to arbitrary application programs and to allow the interface to be remote from the application program. It is based on the specification of two tree structures and a mapping between them. One tree corresponds to data structures in the application program, while the other defines the user display. A prototype version of SEGUE has been built on a SUN workstation and has been used to build a number of interfaces, including one for an Ada structured editor. >"
2290676,22457,10228,Experimental evaluation of timing bounds for clustering protocols in wireless sensor networks,2011,"In recent years a flurry of research activity has produced many suggested schemes for clustering wireless sensor networks, but no hard numbers for real-world implementations. This lack of guidance for developers makes it very difficult to effectively and confidently build working networks. This paper partially addresses these concerns by deriving minimal timing bounds on the clustering process in a typical and recently suggested clustering schemes. This is achieved through low-level network simulation in NS –2. We present detailed results that provide insight to timings involved in different phases of cluster set up. Results show ideal clusters can be constructed within 0.5 s for expected node densities (≤ 0.04 nodes/m 2 )."
1088577,22457,9896,A blog considered from the perspectives of social practice theory,2012,The focus of this study is a group blog site of  special librarians  who work at the library department in a large geographically dispersed corporation. We examined the field data through the framework of history in person in order to understand the relation of the blog with the historical aspects of librarians and the library and information science (LIS) field. This blog serves as a mediator among librarians with diverse viewpoints and also between them and the relentlessly changing LIS field.
2658487,22457,20561,Introducing Avatarification: An Experimental Examination of How Avatars Influence Student Motivation,2016,"While gamification has been studied, applied, and sometimes contested within a variety of contexts (especially education and business), the concept of avatarification -- the utilization of virtual self-representations within a mediated environment -- is relatively new and has great potential for enhancing learning contexts. Building on previous work which suggests that people behave consistently with their avatars' characteristics, the present research aims to develop an understanding of how avatars can be integrated into student communication in ways that increase performance motivation. In a field experiment conducted with an undergraduate class, 229 participants used avatars to communicate over a 15-week period about class material. Results suggest that using an ideal-self avatar or superhero-student avatar augmented student performance motivation during the avatar-use task, but the superhero-student avatar unexpectedly hindered performance motivation in a task unrelated to avatar use. This suggests novel theoretical and practical implications for avatar use in education."
2702169,22457,20561,Towards the Construction of Smart City Index for Analytics (SM-CIA): Pilot-Testing with Major Cities in China Using Publicly Available Data,2016,"The smart city concept is becoming increasingly important in recent years, but no universally agreed index has been developed to assess smartness in urban cities. This study proposed the construction of an index, we call Smart City Index for Analytics (SM-CIA), to objectively measure the degree of smartness in urban cities in six domain areas. We then conducted a pilot testing of SM-CIA on major cities in China. Publicly available data were collected from 2008 to 2012 and time trend analysis was conducted to detect changes of the cities in various smart city domains. A significant increasing trend was found in smart living, mobility, economy and governance domains. Cross-sectional analysis was conducted to rank the cities. The top three cities were Xiamen, Shenzhen and Shanghai. To validate the proposed index, the findings were compared with the Lien Public Service Excellence Index, one of the recent indices developed for China's cities. The results suggested that the cities' scores based on our proposed SM-CIA were correlated with the business perspective of Lien's Index, but not with the citizen's perspective. This is on-going work towards the construction of a global smart city index."
2958696,22457,20561,Robust Reconfiguration of A Distribution System,2017,"In this paper, a robust reconfiguration approach based on Mixed Integer Programming (MIP) is proposed to minimize loss in distribution systems. A Depth-First Search (DFS) algorithm to enumerate possible loops provides radiality constraint. This provides a general solution to the radiality constraint for distribution system reconfiguration/expansion problems. Still, imprecision and ambiguity in net loads, i.e. load minus renewable generation, due to lack of sufficient measurements and high utilization of demand response programs and renewable resources, creates challenges for effective reconfiguration. Deterministic optimization of reconfiguration may no lead to optimal/feasible results. Two methods to address these uncertainties are introduced in this paper: one, based on a stochastic MIP (SMIP) formulation and two, based on a fuzzy MIP (FMIP) formulation. Case studies demonstrate the robustness and efficiency of the proposed reconfiguration methods."
3032458,22457,20561,"Agile Research for Cybersecurity: Creating Authoritative, Actionable Knowledge When Speed Matters",2017,"Securing information systems from attack and com-promise is a problem of massive scope and global scale. Traditional, long-term research provides a deep understanding of the foundations for protecting systems, networks, and infrastructures. But sponsors often need applied research that will create results for immediate application to unforeseen cybersecurity events. The Agile Research process is a new approach to provide this type of rapid, authoritative, applied research. It is designed to be fast, transparent, and iterative, with each iteration producing results that can be applied quickly. The idea is to engage subject-matter experts fast enough to make a difference. Agile Research requires new levels of collaboration and performance, plus adaptive organizational structures that support this new way of working. In addition to its application in Government, Agile Research is being employed in academic settings, and is influencing how research requirements and researchers are identified and matched, and research traineeship."
1498544,22457,8806,"Empirical evaluation of OpenCCM for Java-based distributed, real-time, and embedded systems",2005,"Component technology can overcome many limitations of conventional Object Request Brokers (ORBs) in developing distributed, real-time, and embedded (DRE) applications. Component technology has particular advantages for building large-scale DRE systems. The CORBA Component Model (CCM) enables the composition and reuse of software components and the configuration of key non-functional aspects of DRE systems such as timing, fault-tolerance, and security. However, the CCM can introduce additional overhead to the runtime performance and code size of middleware. Hence, the overhead for using the CCM needs to be evaluated to determine if the CCM can be effectively employed in the design of high-reliability DRE applications. In this paper, we empirically evaluated the performance of OpenCCM, a Java-based implementation of the CCM standard, when configured with two Java ORBs: with ZEN, a real-time Java ORB, and with OpenORB, a desktop Java ORB. We measured throughput, latency, and jitter of method invocations for both ORBs configured with and without OpenCCM. We also measured the additional memory requirement introduced by the CCM implementation. We concluded that OpenCCM adds some overhead to both Java ORBs, affecting OpenORB's performance more than ZEN's. More development of the CCM may be necessary to bring its advantages to high-performance DRE systems."
2020428,22457,9896,Flash forums and forumReader: navigating a new kind of large-scale online discussion,2004,"We describe a popular kind of large, topic-centered, transient discussion, which we term a  flash forum . These occur in settings ranging from web-based bulletin boards to corporate intranets, and they display a conversational style distinct from Usenet and other online discussion. Notably, authorship is more diffuse, and threads are less deep and distinct. To help orient users and guide them to areas of interest within flash forums, we designed ForumReader, a tool combining data visualization with automatic topic extraction. We describe lessons learned from deployment to thousands of users in a real world setting. We also report a laboratory experiment to investigate how interface components affect behavior, comprehension, and information retrieval. The ForumReader interface is well-liked by users, and our results suggest it can lead to new navigation patterns. We also find that, while both visualization and text analytics are helpful individually, combining them may be counterproductive."
1730166,22457,9896,Environmental jolts: impact of exogenous factors on online community participation,2011,"Few studies of online communities take exogenous factors into account while explaining community participation. We present preliminary results from a study investigating the impact of steward companies' actions on online community participation. We identified two events: (1) open sourcing of Java by Sun and (2) acquisition of Sun (and consequently of Java) by Oracle, and examined participation in their developer online communities. We found significant change in participation levels around each event with both significant increases and decreases. We conjecture that participation increased if the action was perceived as supportive by developers (e.g. Sun's open sourcing of Java) whereas it decreased if the action was perceived as detrimental by developers (e.g. Oracle's acquisition of Sun)."
1518160,22457,9896,The work of sustaining order in wikipedia: the banning of a vandal,2010,"In this paper, we examine the social roles of software tools in the English-language Wikipedia, specifically focusing on autonomous editing programs and assisted editing tools. This qualitative research builds on recent research in which we quantitatively demonstrate the growing prevalence of such software in recent years. Using trace ethnography, we show how these often-unofficial technologies have fundamentally transformed the nature of editing and administration in Wikipedia. Specifically, we analyze vandal fighting as an epistemic process of distributed cognition, highlighting the role of non-human actors in enabling a decentralized activity of collective intelligence. In all, this case shows that software programs are used for more than enforcing policies and standards. These tools enable coordinated yet decentralized action, independent of the specific norms currently in force."
3048037,22457,20561,Three Roles for Statistical Significance and the Validity Frontier in Theory Testing,2017,"This study offers a method for empirically testing theories operationalized in the form of multivariate statistical models. An innovation of the method is that it distinguishes testing into three separate forms, “effect testing,” “prediction testing,” and “theory testing,”where statistical significance plays a separate role in each one. In another innovation, the researcher specifies not only his or her desired level of statistical significance, but also his or her desired level of practical significance. Statistical significance and practical significance each serve as a dimension in a two-dimensional table that specifies the rejection region– the region where the researcher can justify the decision to reject the theory being tested. The boundary of the rejection region is the “validity frontier,” which ongoing research may advance so as to reduce the sizeof the rejection region."
2892953,22457,20561,FolioPub: A publication management system,1988,"FolioPub supports publication definition, version and access control, and publication processing. The system is based on a distributed architecture, maintaining a distributed database that stores the contents as well as the logical structure of publications. It records publication history, including changes to the content and modifications to the logical structure. The database also contains a hierarchical processing description that can be applied to the publication. Each processing operation at a given level involves two steps; control processing and file processing. Control processing schedules the processing of lower-level operations and controls the information flow between levels. File processing performs the actual processing at a given level. Attributes are used to describe publication data and constraints on the information flow. >"
2725099,22457,20561,"Triple Helix in Smart Cities: A Literature Review about the Vision of Public Bodies, Universities, and Private Companies",2016,"Smart city is a recent topic, aiming at improving the quality of life of citizens in urban areas. Born like a bottom-up trend, it is now becoming crucial in urban planning in large cities all over the world. The smart city success depends on the synergic action by the triple helix key actors: public bodies, universities, and private companies. However, not ever these actors share the same smart city vision. This paper aims at individuating similarities and differences in key actors smart city vision, by a large and deep literature review on both scientific papers and practitioner or institutional reports."
2486021,22457,9896,Should your MOOC forum use a reputation system,2014,"Massive open online courses (MOOCs) rely primarily on discussion forums for interaction among students. We investigate how forum design affects student activity and learning outcomes through a field experiment with 1101 participants on the edX platform. We introduce a reputation system, which gives students points for making useful posts. We show that, as in other settings, use of forums in MOOCs is correlated with better grades and higher retention. Reputation systems additionally produce faster response times and larger numbers of responses per post, as well as differences in how students ask questions. However, reputation systems have no significant impact on grades, retention, or the students' subjective sense of community. This suggests that forums are essential for MOOCs, and reputation systems can improve the forum experience, but other techniques are needed to improve student outcomes and community formation. We also contribute a set of guidelines for running field experiments on MOOCs."
2690315,22457,20561,Convex Optimization for Joint Expansion Planning of Natural Gas and Power Systems,2016,"Within the energy sector, two of the most tightly coupled systems are natural gas and electric power. The recent advent of cheap gas extraction technologies have only driven these systems more tightly together. Despite their interconnections, in many areas of the world these systems are operated and managed in isolation. This separation is due to a number of reasons and challenges, ranging from technological (problems involving connected systems are difficult to solve) to political and commercial (prevention of monopolies, lack of communication, market forces, etc.). However, this separation can lead to a number of undesirable outcomes, such as what the northeastern United States experienced during the winter of 2013/2014. In this paper, we develop approaches to address the technological reasons for separation. We consider the problem of expanding and designing coupled natural gas and electric power systems to meet increased coincident demand on both systems. Our approach utilizes recent advances in convex modeling of gas and power systems to develop a computationally tractable optimization formulation."
2665648,22457,20561,The Inter-Organizational Dynamics of a Platform Ecosystem: Exploring Stakeholder Boundaries,2016,"The Internet of Things (IoT) creates a myriad of new business opportunities that focus on collecting, transmitting, and analyzing product data. IoT collaborations bring together diverse firms with separate skill-sets that both produce and utilize digitized data to co-create value. While previous research has explored the technical implications of IoT in great detail, it has largely ignored the business implications of such endeavors. In this paper, we focus on the early stages of the emerging inter-organizational relationships that IoT enables and ask the question: How can the inter-organizational dynamics between disparate actors in an IoT ecosystem be perceived and understood? By conducting a qualitative case study and tracing four types of organizational boundaries: efficiency, power, competence and identity, we show how firm boundaries are emergent, dynamic, and constantly negotiated between firms. Allowing for and understanding this relational interplay is crucial in order for IoT ecosystems to thrive and grow."
2704288,22457,20561,Introduction to the Minitrack on Mobile Applications and Emerging Technologies for Health Management and Wellness,2016,The minitrack comprises two sessions. A set of presentations focuses on theoretical concepts as well as application scenarios of wearable and mobile devices for health and fitness. The physician's perspective as well as the patient-centric view will be addressed. Exemplary solutions and prototypical systems will be introduced. Another group of papers exhibits results of empirical studies conducted in clinical and ambient environments. Taken together they serve to illustrate the potentials and limits of mobile applications for health and wellness. The minitrack comprises two sessions. A set of presentations focuses on theoretical concepts as well as application scenarios of wearable and mobile devices for health and fitness. The physician's perspective as well as the patient-centric view will be addressed. Exemplary solutions and prototypical systems will be introduced. Another group of papers exhibits results of empirical studies conducted in clinical and ambient environments. Taken together they serve to illustrate the potentials and limits of mobile applications for health and wellness.
2330414,22457,9896,VidWiki: enabling the crowd to improve the legibility of online educational videos,2014,"Videos are becoming an increasingly popular medium for communicating information, especially for online education. Recent efforts by organizations like Coursera, edX, Udacity and Khan Academy have produced thousands of educational videos with hundreds of millions of views in their attempt to make high quality teaching available to the masses. As a medium, videos are time-consuming to produce and cannot be easily modified after release. As a result, errors or problems with legibility are common. While text-based information platforms like Wikipedia have benefitted enormously from crowdsourced contributions for the creation and improvement of content, the various limitations of video hinder the collaborative editing and improvement of educational videos. To address this issue, we present VidWiki, an online platform that enables students to iteratively improve the presentation quality and content of educational videos. Through the platform, users can improve the legibility of handwriting, correct errors, or translate text in videos by overlaying typeset content such as text, shapes, equations, or images. We conducted a small user study in which 13 novice users annotated and revised Khan Academy videos. Our results suggest that with only a small investment of time on the part of viewers, it may be possible to make meaningful improvements in online educational videos."
2665783,22457,20561,Experiences in Emergency Response at the Great East Japan Earthquake and Tsunami,2016,"Disaster information processing has been researched in the United States of America and Europe in terms of information processing for emergency management to a great extent. While we have had many natural disasters in Japan, only a very few of the researchers in information processing have been working on this issue. From this perspective, we try to identify what sort of information processing was required at the Great East Japan Earthquake and Tsunami on March 11th, 2011. In particular, we explored the needs and seeds for disaster information processing in Iwate, Japan. We interviewed local government officials, doctors and university administrators. This paper reports our newly started project of interviewing people who worked on disaster relief during the emergency response in Iwate as well as some results from our interviews."
2696192,22457,20561,Understanding the Impact of Interruptions on Knowledge Work: An Exploratory Neuroimaging Study,2016,"This paper explores how technologies can interrupt concentration, focus and attention of knowledge workers. The mechanisms by which an interruption takes attention away and the task performance decreases are unknown. The paper explores this impact of interruptions through neuroimaging. Subjects were given a reading task and subjected to a series of randomly timed audio interruptions. Using an EEG measurement device, we recorded their brain waves. Consistent with the literature, we found interruptions significantly increased task completion time and decreased task performance. We found activities in the frontal and temporal lobes of the participants changed or increased due to interruptions. In addition, increased activities in the frontal regions after an interruption appear to lead to better performance. The results suggest application developers to consider underlying mechanisms of processing interruptions."
2707657,22457,20561,Empowering Business Users to Explore Visual Data Through Boundary Objects and Storytelling,2016,"This research is inspired by two important industry trends: (i) a growing demand for visual analytic (VA) across all industry sectors, and ii) serious shortage of VA skills on the market, especially among business professionals. This project focuses on the following practice-inspired research question: How to empower business users to develop visual data exploration skills? This paper describes a VA pilot project conducted at an industry, rather than organizational level. We focused on a challenge of gradual development of VA skills among industry professionals from the Australian Cooperative and Mutual Enterprises (CMEs) sector, which is considered to be of national importance for the Australian economy and society. The CME sector also plays significant economic and social roles in the lives of over one billion members worldwide. Following the principles of action design research, the paper describes a method of gradual development of VA skills using visual stories as boundary objects."
2862082,22457,8228,Dominoes with communications: On characterizing the progress of cascading failures in Smart Grid,2016,"Cascading failures are one of the most devastating forces in power systems, which may be initially triggered by minor physical faults, then spread with Domino-like chain-effect, resulting in large-scale blackout. How to prevent cascading failures becomes imperative, as our daily lives heavily depend on stable and reliable power supply. The next-generation power system, namely Smart Grid, is envisioned to facilitate real-time and distributed control of critical power infrastructures, thus effectively forestalling cascading failures. Although cascading failures have been well investigated in the literature, most studies were confined only in the power operation domain with the assumption that communication is always perfect, which is, however, not true for today's communication networks, where traffic congestion and random delay happen. Therefore, an open question is how to characterize cascading failures in the communication-assisted smart grid? To this end, we take an in-depth inspection of cascading failures in smart grid and reveal the interactions between the power system and the communication network. Our results provide insights into the interactions between physical failure propagation and communication message dissemination. In addition, we show that while ideal communications can undoubtedly help prevent cascading failures, under-achieved communications (i.e., communications with severe delay) can, counter-intuitively, exacerbate cascading failures."
2340234,22457,8494,Identification of chains of events leading to catastrophic failures of power systems,2005,"Catastrophic failures have been traditionally treated as rare events. However, in view of the manner in which power systems have been evolving over the past decade, and the frequency with which catastrophic failures have occurred in this period, it is imperative that systematic approaches be devised to identify the likely chains of events that lead to these failures, so that appropriate countermeasures - strategic and tactical - may be designed and implemented. The paper discusses the recent body of work on structural issues, such as hidden failures and failure sequences, and identifies the need to explore further how chains conspire to form, and how the transition rates of the dependent events might change as the chain evolves. The paper then proceeds to develop a genetic algorithm based method that searches through the state space to identify likely event trees that connect healthy system states to catastrophic failure states. The method is illustrated via a small test system. The simplicity of the system enables an intuitive understanding of the mechanics of the method."
2702433,22457,20561,Meeting Quality Standards for Mobile Application Development in Businesses: A Framework for Cross-Platform Testing,2016,"How do you test the same application developed for multiple mobile platforms in an effective way? Companies offering apps have to develop the same features across several platforms in order to reach the majority of potential users. However, verifying that these apps work, as intended across a set of heterogeneous devices and operating systems is not trivial. Manual testing can be performed, but this is time consuming, repetitive and error-prone. Automated tools exist through frameworks, such as Frank and Robotium, however they lack the possibility to run repeated tests across multiple heterogeneous devices. This article presents an extensible architecture and conceptual prototype that showcase and combines parallel cross-platform test execution with performance measurements. In so doing, this work contributes to a quality-assurance process by automating parts of a regression test for mobile cross-platform applications."
1854558,22457,20332,The Many Shades of Anonymity: Characterizing Anonymous Social Media Content,2015,"Recently, there has been a significant increase in the popularity of anonymous social media sites like Whisper and Secret. Unlike traditional social media sites like Facebook and Twitter, posts on anonymous social media sites are not associated with well-defined user identities or profiles. In this study, our goals are two-fold: (i) to understand the nature (sensitivity, types) of content posted on anonymous social media sites and (ii) to investigate the differences between content posted on anonymous and non-anonymous social media sites like Twitter. To this end, we gather and analyze extensive content traces from Whisper (anonymous) and Twitter (non-anonymous) social media sites. We introduce the notion of anonymity sensitivity of a social media post, which captures the extent to which users think the post should be anonymous. We also propose a human annotator based methodology to measure the same for Whisper and Twitter posts. Our analysis reveals that anonymity sensitivity of most whispers (unlike tweets) is not binary. Instead, most whispers exhibit many shades or different levels of anonymity. We also find that the linguistic differences between whispers and tweets are so significant that we could train automated classifiers to distinguish between them with reasonable accuracy. Our findings shed light on human behavior in anonymous media systems that lack the notion of an identity and they have important implications for the future designs of such systems."
1201751,22457,9896,Enterprise blogging in a global context: comparing Chinese and American practices,2011,"We present three studies that compare adoption and appropriation between China and the United States of BlogCentral, an internal blogging tool employed by a large global enterprise. We first analyzed 23 months of usage logs for users in both countries and found that compared to the U.S., Chinese users were much less active, with less activity and sparser user interaction. We then conducted 25 interviews and surveyed 213 bloggers in both countries to understand user motivations and behaviors of corporate blogging in more detail. The results show that Chinese employees use internal blogs for organizing personal work and short term team formation, unlike U.S. users who are driven more by the goal of sharing information to a broad community. The Chinese users were seeking (and not finding) greater social interaction and felt instead a sense of alienation from the global blogging community. We further identify a gap between Chinese users' requirement for local community and the existing global aspect of enterprise blogging tools. Lastly we discuss implications from the data analysis."
2475994,22457,8806,A lifecycle approach to SOA governance,2008,"Due to the distributed nature of Service-Oriented Architectures (SOA), maintaining control in a SOA environment becomes more difficult as services spread over different lines-of-business. The concept of SOA governance has emerged as a way to implement control mechanisms in a SOA. In this paper we identify a lifecycle based approach for executing SOA governance. This approach consists of defining a SOA strategy, aligning the organization, managing the service portfolio, controlling the service lifecycle, enforcing policies and managing service levels. By incorporating a maturity model in this approach, it is possible to minimize the required effort while still having sufficient governance. From a series of interviews that have been carried out we could conclude that most current SOA projects - although relatively limited in their scope - raise governance issues that need to be addressed to prevent future problems."
3019985,22457,20561,Pertinence and Feasibility of a Unifying Holistic Approach of IT Governance,2015,"In accordance with the Design Science percepts, we present in this paper an approach that aims to give a holistic unifying framework that ensures consistency and coherence between the existing IT governance approaches and mechanisms. It considers the advances and best practices suggested by COBIT ITIL, etc. Therefore, it proposes an operational implementation and instantiation of information system of IT governance based on SOA architecture. It meets the requirements posed by gaps in the research on IT governance, which have been proven by the literature study. As well as the managerial problems highlighted by a two-year in-depth case study conducted inside one of the largest telecommunication operators in Europe. The relevance and feasibility of this approach have been proven by the implementation of this approach in a another two-year in-depth action research case study inside another large European telecommunications operator."
2725418,22457,20561,Exploring Cloudy Collaboration in Healthcare: An Evaluation Framework of Cloud Computing Services for Hospitals,2016,"Cloud computing (CC) is regarded as having the potential to facilitate collaboration in the hospital sector. Yet, adoption of cloud computing services (CCS) in hospitals is low. While a well-designed evaluation of CCS can promote informed adoption decision-making, research on CCS evaluation in the hospital sector is insufficient. To address this research gap, we propose an evaluation framework (EF) of CCS for hospitals. Grounded in the human, organization and technology-fit model, our EF employs six dimensions to evaluate how a CCS facilitates collaboration in hospitals. By applying our EF to 38 identified CCS for hospitals, we demonstrate its efficacy. Our research contributes to both practice and research. For practice, our EF can be used to screen available CCS for hospitals and thus expedite cloud adoption processes. For research, our EF unfolds the complexity of CC in healthcare and is of particular relevance for IS research in healthcare."
2876183,22457,20561,Insider Threats in Emerging Mobility-as-a-Service Scenarios,2017,"Mobility as a Service (MaaS) applies the everything-as-a-service paradigm of Cloud Computing to transportation: a MaaS provider offers to its users the dynamic composition of solutions of different travel agencies into a single, consistent interface. Traditionally, transits and data on mobility belong to a scattered plethora of operators. Thus, we argue that the economic model of MaaS is that of federations of providers, each trading its resources to coordinate multi-modal solutions for mobility. Such flexibility comes with many security and privacy concerns, of which insider threat is one of the most prominent. In this paper, we follow a tiered structure --- from individual operators to markets of federated MaaS providers --- to classify the potential threats of each tier and propose the appropriate countermeasures, in an effort to mitigate the problems."
2658855,22457,20561,Modular Modeling and Optimization of Temporal Manufacturing Processes with Inventories,2016,"Smart manufacturing requires streamlining operations and optimizing processes at a global and local level. This paper considers temporal manufacturing processes that involve physical or virtual inventories of products, parts and materials that move through a network of subprocesses. The inventory levels vary with time and are a function of the configuration settings of the machines involved in the process. These environments require analysis, e.g., answering what-if questions, and optimization to determine optimal operating settings for the entire process. To address this problem, the paper proposes modular process components that can represent these manufacturing environments at various levels of granularity for performing what-if analysis and decision optimization queries. These components are extensible and reusable against which optimization and what-if questions can be posed. Additionally, the paper describes the steps to translate these complex components and optimization queries into a formal mathematical programming model, which is then solved by a commercial optimization solver."
911335,22457,422,Exploring iterative and parallel human computation processes,2010,"Services like Amazon's Mechanical Turk have opened the door for exploration of processes that outsource computation to humans. These  human computation processes  hold tremendous potential to solve a variety of problems in novel and interesting ways. However, we are only just beginning to understand how to design such processes. This paper explores two basic approaches: one where workers work alone in parallel and one where workers iteratively build on each other's work. We present a series of experiments exploring tradeoffs between each approach in several problem domains: writing, brainstorming, and transcription. In each of our experiments, iteration increases the average quality of responses. The increase is statistically significant in writing and brainstorming. However, in brainstorming and transcription, it is not clear that iteration is the best overall approach, in part because both of these tasks benefit from a high variability of responses, which is more prevalent in the parallel process. Also, poor guesses in the transcription task can lead subsequent workers astray."
665934,22457,9438,Foundations of a Reference Model for SOA Governance,2010,"Although the lack of elaborate governance mechanisms is often seen#R##N#as the main reason for failures of SOA projects, SOA governance is still very#R##N#low in maturity. In this paper, we follow a design science approach to address#R##N#this drawback by presenting a framework that can guide organisations in#R##N#implementing a governance approach for SOA more successfully. We have#R##N#reviewed the highly advanced IT governance frameworks Cobit and ITIL and#R##N#mapped them to the SOA domain. The resulting blueprint for a SOA#R##N#governance framework was refined based on a detailed literature review, expert#R##N#interviews and a practical application in a government organisation. The#R##N#proposed framework stresses the need for business representatives to get#R##N#involved in SOA decisions and to define benefits ownership for services."
987742,22457,9896,Lurking as personal trait or situational disposition: lurking and contributing in enterprise social media,2012,"We examine patterns of participation by employees who are members of multiple online communities in an enterprise communities service. Our analysis focuses on statistical patterns of contributing vs. lurking. The majority of contributors (in one or more communities) were also lurkers (in one or more other communities). These results argue against hypotheses derived from common theories of participation and lurking. We propose that contributing and lurking are partially dependent on a  trait  (a person's overall engagement), modified by the individual's  disposition  toward a particular topic, work task or social group. Contributions include critique of theory, an analytic framework, and implications for design of community services."
661251,22457,20358,Improving Productivity in Citizen Science through Controlled Intervention,2015,The majority of volunteers participating in citizen science projects perform only a few tasks each before leaving the system. We designed an intervention strategy to reduce disengagement in 16 different citizen science projects. Targeted users who had left the system received emails that directly addressed motivational factors that affect their engagement. Results show that participants receiving the emails were significantly more likely to return to productive activity when compared to a control group.
2717551,22457,20561,A Taxonomy of Industrial Service Systems Enabled by Digital Product Innovation,2016,"Against the backdrop of pervasive digitization, industrial equipment in the manufacturing industry is increasingly augmented with digital technology. Since the industrial service business plays a growing role for original equipment manufacturers (OEMs), the physical and digital materiality of industrial equipment particularly has gained importance for service innovation. Despite these new opportunities, OEMs, industrial equipment operators, and service organizations struggle to (1) identify and build up adequate technological capabilities and (2) fully harness the potential of digital product innovation for their service business. Within this paper, we propose an evaluated taxonomy to classify and better understand industrial service systems enabled by digital product innovation. As an anchor in theory, we draw on the service-dominant logic and the theory of affordances. The taxonomy helps practitioners to better understand the impact of digital product innovation on the service business in respective industry contexts."
2691878,22457,20561,Exploring Innovation Ecosystems as Networks: Four European Cases,2016,"More often than ever before, innovation takes place in the context of innovation ecosystems. New data, tools, and questions are available for insights on latent structures within innovation ecosystems. Used in concert, socially constructed data and network analysis afford new insights to compare and analyze the structure and dynamics of innovation ecosystems. In this article, we apply a novel approach for exploring innovation ecosystems through networks. Moreover, we investigate whether this new way of measuring innovation produces similar results compared to more traditional indicators, here Innovation Union Scoreboard. We conclude that network analysis of socially constructed data yields into results that are comparable to traditional innovation indicators and, importantly, allows completely new insights into the system-level structure of the innovation ecosystem. The new views allow and indeed call for new ways to conduct decision-making in the context of innovation ecosystems."
2641251,22457,20561,The Influence of Organizational Culture on IT Governance Performance: Case of the IT Department in a Large Swedish Company,2016,"IT governance is one of the top concerns of organizations today seeking to gain value from their IT investments and create competitive advantage. Organizational culture on the other hand is one of the various factors influencing IT governance performance. However there is not much research conducted to understand this topic deeply. This research thus, is exploring the influence of organizational culture on four IT governance performance outcomes through a case study in IT department of a large Swedish company. The results provide evidence that organizational culture is influencing IT governance performance. Specifically the current clan culture orientation of the IT department has led to a successful IT governance performance in cost-effective use of IT. Furthermore adhocracy as the preferred culture is identified to influence IT governance in effective use of IT for growth which is not so successful with the current clan culture."
2318530,22457,20332,Peer-to-Peer Human-Robot Teaming through Reconfigurable Schemas,2006,"This position paper presents our ongoing work of developing mechanisms to facilitate human-robot teaming with a focus on peer-to-peer interaction. We have developed an approach that autonomously configures solutions for multi-robot teams based on the team capabilities and the task objective. With the success of this approach in simulation and on physical robots, we plan to extend it to address several challenging issues in human-robot teaming."
1212698,22457,9896,Designing futures for peer-to-peer learning @ CSCW,2014,"Open, online learning environments, such as massive open online courses (MOOCs) and open learning communities have been promoted as a way to expand equitable access to quality education. Such learning experiences are potentially enriched via extensive networks of peer learners. Even though challenges exist to realize these aspirations, open, online learning environments can serve as a mechanism for how we provide transformative learning experiences. This workshop aims to bring researchers and practitioners from diverse disciplinary backgrounds to explore how the body of CSCW knowledge can better support the vision of sustaining peer-to-peer learning in online environments. Integrating contributions from designers, researchers, and practitioners at the intersection of CSCW & education, participants will co-create future visions and proposed implementations for open, online learning environments."
2717693,22457,20561,A Systematic Literature Review on the Relation of Information Technology and Information Overload,2016,"Until this day information overload is an important issue and the influence of information technology cannot be denied. Even though there is a lot of existing research on the relation of information technology and information overload it is still contradicting. Therefore, this systematic literature review investigates the contents and applied research designs of the body of knowledge of the relation between information overload and information technology, in order to uncover what kind of research is missing to tackle the information overload problem. Based on an interdisciplinary database search, this literature review unveils several research gaps and calls for further investigation on proposed research questions. Overall, this literature review promotes the investigation of humans exposed to specific information technologies and conducting inductive behavioral studies. The results help researchers to identify less researched areas and less researched methods and practitioners to gain first insights about the field."
2646702,22457,20561,A Processual View on Social Presence Emergence in Virtual Worlds,2016,"Distributed collaboration is increasingly conducted in virtual worlds. Successful distributed collaboration is can benefit from social presence, the feeling of being there with others in a virtual environment. Social presence includes the dimensions of copresence, psychological involvement and behavioral engagement. Despite the importance of social presence, we currently lack empirically grounded understanding of how social presence emerges through these dimensions. To begin remedying this shortcoming, we analyzed how the social presence dimensions were organized in social interaction. We found that the order of the dimensions depends on verbal and nonverbal communication. These findings clarify extant theory of social presence emergence in 3D virtual worlds."
2655229,22457,20561,Unfolding the Types of Organizational Inertia in Information Systems Adoption,2016,"Even though a company is willing to adopt an information system, there is often some organizational inertia associated with the adoption process. In this paper, we explore the types of inertia in IS adoption in the context of a specific business process. Drawing on seven case studies where inertia can be observed, we illustrate the inertia types found in earlier research and find indication for the existence of two new types of inertia: externality inertia and mimetic inertia."
2182073,22457,8494,Probabilistic load-dependent cascading failure with limited component interactions,2004,"We generalize an analytically solvable probabilistic model of cascading failure in which failing components interact with other components by increasing their load and hence their chance of failure. In the generalized model, instead of a failing component increasing the load of all components, it increases the load of a random sample of the components. The size of the sample describes the extent of component interactions within the system. The generalized model is approximated by a saturating branching process and this leads to a criticality condition for cascading failure propagation that depends on the size of the sample. The criticality condition shows how the extent of component interactions controls the proximity to catastrophic cascading failure. Implications for the complexity of power transmission system design to avoid cascading blackouts are briefly discussed."
2717450,22457,20561,What Makes a City Smart? Lessons from Barcelona,2016,"Innovation, and technological innovation in particular, can help city governments to meet the challenges of urban governance, to improve urban environments, to become more competitive and to address sustainability concerns. To prevent and manage these challenges, cities need to operate in an innovative way. In this context, the smart city approach is emerging as a way of solving tangled and wicked problems. However, there is no one route to becoming smart and different cities have adopted different approaches that reflect their particular circumstances. The objective of this paper is to assess the strategy adopted by the city of Barcelona, which has been repeatedly considered among the top smart cities in the world, using a comprehensive framework that includes eight variables for the analysis. The ultimate goal is to provide useful insights on the development of a smart city."
2685399,22457,20358,Smart City and Smart Government: Synonymous or Complementary?,2016,"Smart City is an emerging and multidisciplinary domain. It has been recently defined as innovation, not necessarily but mainly through information and communications technologies (ICT), which enhance urban life in terms of people, living, economy, mobility and governance. Smart government is also an emerging topic, which attracts increasing attention from scholars who work in public administration, political and information sciences. There is no widely accepted definition for smart government, but it appears to be the next step of e-government with the use of technology and innovation by governments for better performance. However, it is not clear whether these two terms co-exist or concern different domains. The aim of this paper is to investigate the term smart government and to clarify its meaning in relationship to the smart city. In this respect this paper performed a comprehensive literature review analysis and concluded that smart government is shown not to be synonymous with smart city. Our findings show that smart city has a dimension of smart government, and smart government uses smart city as an area of practice. The authors conclude that smart city is complimentary, part of larger smart government movement."
2691954,22457,20561,Toward an Ontology of Workarounds: A Literature Review on Existing Concepts,2016,"While workarounds are studied frequently in information systems research, a coherent and interrelated structure to organize the knowledge of the field is still missing. In this study, we provide a first step towards an ontology of workarounds in order to enable researchers to study the relationships among the core concepts. By identifying existing literature, we discover three gaps in workaround research: (1) lack of conceptual consensus, (2) fragmentation and (3) static perspective. To advance theory, we provide an overview of different types of workarounds that are frequently used in literature. Based on these findings we derive core concepts of workarounds that are used in literature and provide an ontology of workarounds."
2707891,22457,20561,Predicting Travel Volumes for Long-Distance Coach Services Through Big Data Analytics -- A Case Study on German Public Viewing Events During the UEFA EURO 2016,2016,"Capacity planning is a key challenge for long-distance coach vendors due to the competitive market pressure. Travel-intensive events have the potential to increase the capacities for existing routes or to offer new connections. Actually, planning activities of vendors are mainly based on past-data. To improve the quality of predictions about future capacities, information from different data sources e.g. social media, geo-based information or websites has to be considered. Technologies to collect structured and unstructured information from different data sources are available. This paper presents an approach to use these technologies for capacity predictions and pricing of coach vendors in terms of travel-intensive events. To verify the approach, a case study, focused on the UEFA EURO 2016, is described. The case study is necessary to demonstrate the value of the research and to give a deeper understanding about data sources and the discussion culture of travelers in social networks."
2646780,22457,20561,Open Strategic Planning in Universities: A Case Study,2016,"This paper introduces a case study in which the crowdsourcing model has been used to implement the open strategy concept in an Australian university. This model helps the organisation to include more stakeholders and provide the opportunity of a transparent planning process. The paper explains an IT artefact and accompanying conceptual design supporting an internally open strategic planning process of a university. It also explains the result of the case study in accordance to the suitability of the crowdsourcing model for implementation of an open strategy approach, challenges which were faced during the study, and root causes. It concludes with some recommendations for future research and practices."
2246637,22457,422,Using rough sets as tools for knowledge discovery,1995,"An attribute-oriented rough set method for knowledge discovery in databases is described. The method is based on information generalization, which examines the data at various levels of abstraction, followed by the discovery, analysis and simplification of significant data relationships. First, an attribute-oriented concept tree ascension technique is applied to generalize the information; this step substantially reduces the overall computational cost. Then rough set techniques are applied to the generalized information system to derive rules. The rules represent data dependencies occurring in the database. We focus on discovering hidden patterns in the database rather than statistical summaries."
1377968,22457,8806,A role-based enterprise architecture framework,2009,"Organizations deal with contrasting domains such as people, strategy, business processes, and information systems as well as with their representation, alignment and governance. In this setting, different approaches to enterprise architecture have been introduced to address these concerns. This paper focuses on describing an enterprise architecture framework centered in three core concepts (role, entity and activity) from which domain-specific concepts are derived from. The framework abstracts the organization's domains as five architectural views (organization, business, information, application and technology) and captures the concept dependencies and relationships across the different domains."
2670399,22457,20561,Addiction to Mobile Phone or Addiction through Mobile Phone,2016,"The current study aims to distinguish between two perspectives dominating the mobile phone addiction literature, addiction to a mobile phone and addiction through a mobile phone (i.e. addiction to mobile phone application). We extend state-of-the-art addiction literature by building on dual-systems theory and investigating both perspectives in the same theoretical model. We empirically test our model (n=333) and results provide support for all of the hypothesized relationships. Results indicate that addiction to mobile phones can't be fully explained by addiction to mobile phone applications. Theoretical and practical contributions of the study is discussed."
2725314,22457,20561,Introduction to the Emerging Technologies and Innovations for Development Minitrack,2016,"Emerging technologies, such as mobile payment systems, use the power of innovation to improve the lives of people. The concept of Development is used to understand how these improvements in people's lives take place. According to the World Economic Forum (WEF), technological breakthroughs promise innovative solutions to the most pressing global challenges of our time. Key characteristics of emerging technologies for development are: 1) they lead to improvements in people's lives, 2) offer new ways of conducting business, and 3) support indigenous practices that support the environment."
2650243,22457,20561,Using Social Media to Manage Customer Complaints: A Preliminary Study,2016,"As Social Media platforms have become increasingly popular among customers, Firms are still exploring ways to harness the potential of these platforms. The viralness of these platforms increases the reach of customer complaints and exacerbates the impact from follow-up comments by the dissatisfied customers. By analyzing complaint tweets and drawing from Justice theory, we explore how organizations should cope with customer complaints on social media platforms. Our preliminary analysis shows that several important mechanisms that can be used to cope with customer complaints. Practical and theoretical implications are discussed."
1681230,22457,9896,A content analysis of wikiproject discussions: toward a typology of coordination language used by virtual teams,2013,"Understanding the role of explicit coordination in virtual teams allows for a more meaningful understanding of how people work together online. We describe a new content analysis for classifying discussions within Wikipedia  WikiProject  - voluntary, self-directed teams of editors - present preliminary findings, and discuss potential applications and future research directions."
2715182,22457,20561,Dotting the I and Crossing (out) the T in IT Governance: New Challenges for Information Governance,2016,"The purpose of this paper is to explore the factors influencing information governance, and particularly the role of new challenges such as cloud-based services, boundary-crossing use of data and new system development practices. Governing information within - as well as outside - the organization, balancing access and security, and aligning investments with corporate goals, are all becoming crucial for today's digital business models. We propose a framework that shows how new challenges influence the mix of procedural, structural and relational mechanisms used by organizations. Using data from 202 large international organizations, the framework is subsequently tested. Preliminary results offer new insights and better explanations of how firms govern information to optimize business value. The implications of these findings are discussed."
2874813,22457,20561,Introduction to E-Government Infrastructure Security Minitrack,2013,This is a Minitrack introduction for the e-Government minitrack titled Infrastructure Security
1490720,22457,20561,Introduction to Advances in Design Research for Information Systems Minitrack,2013,Introduction to Introduction to Advances in Design Research for Information Systems Minitrack.
415680,22457,20561,"Introduction to Analytics, Information Systems, and Decision Technologies for Sustainability Minitrack",2015,"Introduction to Analytics, Information Systems, and Decision Technologies for Sustainability Minitrack"
362722,22457,20561,"Introduction to the Business and Enterprise Architecture Minitrack: Processes, Approaches and Challenges",2015,"Introduction to Business and Enterprise Architecture: Processes, Approaches and Challenges Minitrack I."
2557372,22457,20561,Introduction to Processes and Technologies for Small and Large Team Collaboration Minitrack,2013,Introduction to the Processes and Technologies for Small and Large Team Collaboration Minitrack
758843,22457,20561,Introduction to the Social and Psychological Perspectives and Theories in Collaboration Research Minitrack,2013,Introduction to the Social a Psychological Perspectives and Theories in Collaboration Research Minitrack
2680347,22457,20561,Introduction to the Minitrack on Intelligent Decision Support for Logistics and Supply Chain Management,2016,Introduction to the minitrack Intelligent Decision Support for Logistics and Supply Chain Management.
1001675,22457,20561,"Introduction to Knowledge Management for Innovation, Agility, and Complexity Management Minitrack",2014,"Introduction to HICCS-47 Minitrack: Knowledge Management for Innovation, Agility and Complexity Management."
1273201,22457,20561,"Introduction to Innovation, Design, and Analytics Supported Development of ICT Enabled Services Minitrack",2013,"Introduction to Innovation, Design, a Analytics Supported Development of ICT Enabled Services Minitrack."
1830813,22457,20561,Mobile agents and mobile workers,1996,The goal of the paper is to explore the emerging research issues in the nexus of mobile computing and organizational work.
2724967,22457,20561,Introduction to the Internet and Digital Economy Track,2016,"Introduction to the Internet and Digital Economy Track which focuses on the impacts of the Internet, as well as it's fundamental operation."
324014,22457,20561,"Introduction to Open, Participatory, and Anticipatory Government Minitrack",2015,"Open government is an approach that purposefully emphasizes and re-invigorates the basic principle of a government of the people, for the people, and by the people."
2725313,22457,20561,Introduction to Securing the Cloud and the Internet of Things Minitrack,2016,Introduction to the HICSS-4 Software Technology Track's Securing the Cloud and the Internet of Things mini-track.
2358818,22457,20561,"Introduction to Knowledge Flows: Knowledge Transfer, Sharing, and Exchange Minitrack",2014,This short paper serves to introduce the minitrack on knowledge flows and to summarize its constituent proceedings articles.
1478285,22457,20561,"Introduction to the Minitrack on Knowledge Flows: Knowledge Transfer, Sharing And Exchange In Organizations",2005,This short paper serves to introduce the minitrack on knowledge flows and to summarize its constituent proceedings articles.
694628,22457,20561,"Introduction to Knowledge Flows: Knowledge Transfer, Sharing and Exchange in Organizations Minitrack",2012,This short paper serves to introduce the minitrack on knowledge flows and to summarize its constituent proceedings articles.
353350,22457,20561,Introduction to Information and Communication Technologies for Development (ICTD) Minitrack: Contributing to Human Development and Social Justice,2015,This minitrack explores opportunities to use Information and communication technologies to promote human development and social justice.
2684934,22457,20561,"Introduction to the Organizational Issues of Business Intelligence, Business Analytics, and Big Data Minitrack",2016,"Introduction to HICSS-49 Organizational Issues of Business Intelligence, Business Analytics, and Big Data Minitrack."
1591088,22457,20561,Technological Aspects of Knowledge Systems,2007,The objective of this mini-track is to develop the architecture of knowledge management systems to support organizations facing changing environments.
1279689,22457,20561,"Introduction to Human-Computer Interaction: Informing Design Utilizing Behavioral, Neurophysiological, and Design Science Methods Minitrack",2014,"Introduction to the Minitrack Human-Computer Interaction: Informing Design Utilizing Behavioral, Neurophysiological, and Design Science Methods."
2689488,22457,20561,"Introduction to the Minitrack Human-Computer Interaction: Informing Design Utilizing Behavioral, Neurophysiological, and Design Science Methods",2016,"Introduction to the Minitrack Human-Computer Interaction: Informing Design Utilizing Behavioral, Neurophysiological, and Design Science Methods."
480447,22457,20561,Negotiation Support Systems for Intercultural Negotiation,1997,"As background for an open forum on negotiation supportsystems (NSS) for intercultural negotiation, the topic isoutlined from the viewpoint of Evolutionary SystemsDesign (ESD)."
345917,22457,20561,Introduction to E-justice and E-law Minitrack,2015,"This mini-track aims at discussing trends, challenges, case studies and best practices, theories, and methodologies in the field of e-justice and e-law."
2418564,22457,20561,Introduction to Collaboration Systems and Technologies Track,2012,"This track considers collaboration from a systems perspective, taking into account the people who collaborate, the processes and procedures by which they collaborate, and the tools and technologies that support their efforts."
2257851,22457,20561,Issues Related to Development of E/E Product Line Architectures in Heavy Vehicles,2009,"The amount of electronics in vehicles is growing quickly, thus systems are becoming increasingly complex which makes the engineering of these software intensive systems more and more difficult. In  ..."
1596898,22457,20561,Introduction to Transformational Government Minitrack,2013,"This mini-track is one of the key international platforms at which the transformational aspects of e-Government, as well as their implications for government and society, are being discussed from a multidisciplinary perspective."
2145939,22457,20561,Introduction to the Minitrack IT Governance and its Mechanisms,2005,"IT governance is the organizational capacity exercised by the board, executive management and IT management to control the formulation and implementation of IT strategy and in this way ensuring the fusion of business and IT."
998963,22457,20561,Introduction to decision technologies for management track,2001,The goal of DTM is to present topic areas involving the adoption of innovative technology for management decision making. A brief synopsis of the DTM Minitracks is presented.
1431195,22457,20561,"Introduction to Agile and Lean Organizations: Management, Metrics, and Products Minitrack",2014,"In this mini-track, research papers and experience reports examine how agile development and lean product management interact with organizations, their structures, cultures and products."
1936570,22457,20561,Towards a Typology for Designing Inter-Organisational Controls for Network Organisations,2005,In this paper a typology is introduced for inter-organisational control mechanisms for network organisations. We also show how the design and analysis of such inter-organisational controls can be supported with the design methodology e^3 -value⁺.
1451672,22457,20561,Introduction to Topics in Organizational Systems and Technology Minitrack,2012,This minitrack is special. It is set up to provide a forum for papers in the Organizational Systems and Technology track that do not fit exactly in a specific other minitrack. We often serve as an incubator for new ideas.
1542888,22457,20561,"Introduction to ICT-Enabled Crisis, Disaster and Catastrophe Management Minitrack",2014,"This HICSS-47 Minitrack Introduction introduces the four papers accepted by the ICT-enabled Crisis, Disaster a Catastrophe Management Minitrack within the HICSS E-Government Track."
1409444,22457,20561,Introduction to Software Security for Mobile Platforms Minitrack,2014,This minitrack focuses on the research and automation techniques that can be applied to mobile platforms to ensure that software developed for these devices is secure without compromising other system properties such as performance or reliability.
1695743,22457,20561,"Introduction to Diffusions, Impacts, Adoption, and Use of ICTs on Society Minitrack",2014,"The aim of this mini-track is to offer a global perspective of how ICTs are being diffused, used and adopted within society including households, organizations and social communities around the world."
1388197,22457,20561,"Introduction: Electric Power Systems Restructuring :Engineering, Economics and Policy Track",2007,"This track seeks to explore methods at the frontier of understanding the restructuring of electric power system worldwide. It will focus on engineering, economics and policy issues that are at the forefront of current thinking."
1469797,22457,20561,Minitrack Summary: Wireless Sensor Networks,2005,"The field of wireless sensor networks (WSNs) is maturing, and this year?s contributions to this minitrack reflect this growing maturity with considerable breadth in the first session and depth in the second session."
471575,22457,20561,"Introduction to the Monitoring, Control, and Protection Minitrack, Electric Energy Track",2015,"This minitrack focuses on topics related to the monitoring, control, and protection of electric power systems for real-time operations and short-term operations planning. The minitrack has two sessions."
1483711,22457,20561,Topics in Organizational Systems & Technology Minitrack,2007,The Topics in Organizational Systems and Technologies is a track for papers that often do not fit well in other tracks due to the leading edge nature of the topics. We look for paper that are innovative and thought provoking.
760952,22457,20561,Validating OPA with WECC Data,2013,We validate the OPA cascading blackout simulation on a 1553 bus WECC network model by establishing OPA parameters from WECC data and comparing the blackout statistics obtained with OPA to historical WECC data.
1301442,22457,20561,Internet Security: Intrusion Detection and Prevention in Mobile Systems,2007,"Summary form only given. This article focuses on the types of security problems that can occur in mobile wirelessly-connected systems, the solutions for known problems, and strategies for circumventing these problems in the future"
1596728,22457,20561,Introduction to Innovation and the Digital Economy Minitrack,2012,"In the Minitrack (MC) Innovation and the Digital Economy, which belongs to the track Innovation and the Digital Economy, we want to provide a platform for researchers with insights into how innovation management and processes are affected by the digital economy and how managers can take advantage of it."
485885,22457,20561,Introduction to the Smart Cities and Smart City Government Minitrack,2015,"This minitrack focuses on the interactions between citizens, government, and technology to promote, facilitate, and create smart cities. Smart City is a fuzzy concept, not well defined in theoretical researches nor in empirical projects."
911983,22457,20561,Introduction to E-Government Education Minitrack,2014,The aim of this paper is to introduce the mini-track on Electronic Government Education organized as part of the Electronic Government Track at the 47th Hawaii International Conference on System Sciences (HICSS-47).
1630839,22457,20561,Introduction to Cloud Infrastructures and Interoperability Minitrack,2012,The availability of ubiquitous networks and bandwidth enables us to access services online using all kind of devices from anywhere at any time. The cloud infrastructures and interoperability minitrack covers a variety of topics related to cloud infrastructures and interoperability.
1439613,22457,20561,Public Participation GIS: The Case of Redistricting,2014,"Recent technological advances have enabled greater public participation and transparency in the United States redistricting process. We review these advances, with particular attention to activities involving open-source redistricting software."
1951138,22457,20561,Does Distance Matter? - Bridging the Discontinuities in Distributed Organizations,2005,"This forum is a debate on the impact of distance on teamwork, and the roles IT has played. It provides insights from quantitative and qualitative studies about employees' virtual work in Intel Corporation, and experiences of executives in another company."
2676633,22457,20561,Introduction to the Crowdfunding and the Wisdom of the Crowds Minitrack,2016,"Crowdfunding research thus far has largely examined its link to entrepreneurship, despite the phenomenon's digital nature. This mini-track calls for papers that delve into the digital, or information systems, involved in crowdfunding."
1742579,22457,20561,Introduction to Wireless Networks Minitrack,2012,"Security is challenging for wireless networks, in part because signals radiate outwards and can be intercepted easily and unobtrusively. Because of this, security cannot be provided simply by protecting the hardware, and must be supported by the communication protocol and implementation."
1858398,22457,20561,Software Platforms--How to Win the Peace,2007,We look at three historical case studies to investigate how software platforms evolve after their initial establishment. The success of a platform often creates new dynamics among the complementers which question the original architecture
492772,22457,20561,Introduction to the Ethical Issues in Organizational Information Systems Minitrack,2015,"This is a short introduction to the mini-track Ethical Issues in Organizational Information Systems at HICSS 2015. It discusses the relevance and scope of the mini-track, the paper (s) to be presented, and thoughts on future academic research on ethical issues in IS."
2692216,22457,20561,Introduction to the Impacts of Information Technologies on Consumer Activities and on Business Operations Minitrack,2016,This year the Impacts of Information Technologies on Consumer Activities and on Business Operations minitrack at HICSS has accepted a total of seven papers that explore the increasing complex roles that advanced information technologies play in businesses.
2278346,22457,20561,The Role of the Election Commission in Electronic Voting,2005,"In this paper the control possibilities of an Election Commission in an Electronic Voting process are described and technical solutions are presented. Decisions in the committee need not be made unanimously, rather arbitrarily defined quora are supported."
2673906,22457,20561,Quantifying the Value of Local Showrooms in Consumer Search and Purchase,2016,"We investigate how the presence and absence of local showrooms impact customers' searching and purchasing behavior with competitors. Using an exogenous event of showroom exit, we found that showrooms not only impact sales of competitors, but more importantly, change the intensity of customer search."
488471,22457,20561,Introduction to the Impacts of Advanced Information Technologies on Business Operations Minitrack,2015,This year the Impacts of Advanced Information Technologies on Business Operations minitrack at HICSS has accepted a total of eight papers which explore the increasing complex roles that advanced information technologies play in businesses. The eight accepted papers are as follows.
769448,22457,20561,Introduction to E-Government Services and Information Minitrack,2012,This mini-track explores various types of electronic services and information in the public sector. The mini-track includes five papers that address diverse e-government services from across the globe using both quantitative and qualitative measures.
1912885,22457,20561,Lessons from a decade of group support systems research,1996,"A decade of research, development, and implementation of group support systems has occasioned the learning of many lessons. The paper uses a heuristic model to compare group support systems to other groupware, and then summarizes many lessons learned about GSS in the laboratory and in the field."
1658957,22457,20561,Minitrack: Clinical Process and Data Integration and Evolution,2007,"Demands from governments, insurers and clients for more effective and efficient healthcare services are increasing. To satisfy these demands, the healthcare industry must find innovative ways to transform and streamline preexisting processes and healtcare systems."
2192965,22457,20561,Hazard potentials and dependent network failures,2000,"This paper endeavors to explain the nature of dependence in network failure. The introduction of a new notion in the mathematical theory of reliability, which we term the 'hazard potential', provides us with a vehicle for generating parsimonious models for dependent failures."
1887038,22457,20561,Supporting the Screening of Corporate Acquisition Targets,2009,"This paper discusses the screening of potential corporate acquisition targets from the acquiring company perspective. A structured process to screen acquisition targets using both, financial and nonfinancial data and a developed prototype DSS to support the screening process are presented."
2266849,22457,20561,Introduction to Information Technology for Development Minitrack,2012,The papers in this minitrack take the discourse of how Information Technology (IT) applications enable development objectives to take place to a new level. The contributions from the papers in this minitrack illustrate the innovative ways in which IT applications can bring about improvements in the lives of people.
1412433,22457,20561,Techniques for secure system development,1998,Computer security has become an increasingly important topic as societal reliance on computer systems grows. This minitrack is intended to address techniques for secure system development. Such techniques encompass both protocol development issues and assurance.
1547076,22457,20561,Software Technology Track Introduction,2007,"The Software Technology Track consists of thirteen minitracks and one symposium, grouped into six clusters: Human-Computer Interaction, Security, Software Engineering Application Areas, Software Engineering Practices, and Software Engineering Tools and Techniques."
2652207,22457,20561,Introduction to the Minitrack on Humanitarian Operations Research -- Decision Analytics for Crisis and Disaster Management,2016,"The aim of this minitrack is to provide a forum for discussion on methodologies, solutions, and issues related to decision analytics in humanitarian operations research. Submissions were invited covering the general area of providing analytical capabilities for decision support."
1889258,22457,20561,An Outcome-Based Learning Model to Identify Emerging Threats: Experimental and Simulation Results,2007,"The authors present experimental and simulation results of an outcome-based learning model as it applies to the identification of emerging threats. This model integrates judgment, decision making, and learning theories to provide an integrated framework for the behavioral study of emerging threats"
2170991,22457,20561,Technology transfer in university-based research centers at the University of New Mexico,1997,The purpose of this paper is to report findings from an investigation of the role of research centers at the University of New Mexico in the process of technological innovation and technology transfer. We surveyed 56 research centers at the University of New Mexico. Survey data are used to explain the role of university-based research centers in technology transfer.
2442990,22457,20561,Toward a Generic Model of Security in an Organizational Context: Exploring Insider Threats to Information Infrastructure,2008,This paper presents a generic model for information security implementation in organizations. The model presented here is part of an ongoing research stream related to critical infrastructure protection and insider threat and attack analysis. This paper discusses the information security implementation case.
1962894,22457,20561,Information Sharing and Patterns of Social Interaction in an Enterprise Social Bookmarking Service,2008,"In this paper, we explore how a social bookmarking service is used to support knowledge sharing in a large enterprise. While there has been considerable interest in social bookmarking and collaborative tagging systems in recent years, very little is known about their actual usage. In this paper, we present the results of a"
2515272,22457,20561,Applications of Web-based workflow,1998,"A Web-based workflow system was developed at the Jet Propulsion Laboratory and several pilot applications were developed. The authors give an overview of the architecture and functionality of the workflow system, describe three pilot workflows that have been or are being deployed, and relate lessons learned."
842416,22457,20561,Panel: integrating DSS into EIS,1996,"In addition to displaying information, most executive information systems (EIS) provide decision support system (DSS) capabilities. The purpose of this panel is to bring together leading EIS researchers and practitioners to share their insights and experiences about integrating DSS into EIS."
1680542,22457,20561,Introduction to Internet and the Digital Economy Track,2012,"The Internet and Digital Economy track focuses on the ways in which the Internet affects people, groups, organizations, and societies (e.g., markets, social networks), as well as fundamental issues in the development and operation of the Internet and Internet applications (e.g., security, open source)."
1442511,22457,20561,Introduction to the enterprise content management and XML minitrack,2004,"Content management in contemporary enterprises concerns a variety of information resources: documents in different forms, databases, and metadata such as ontologies, annotations, and indexes. XML and the web are important technologies used to support both resource integration and distribution."
1864943,22457,20561,Biometric Authentication for Web-Based Couse Examinations,2005,The paper discusses design considerations and a prototype for a biometrics (fingerprint) based identification and authentication system to support web-based course examinations. The goal of the resulting system is to be acceptable to the university culture and minimally disruptive to university procedures and processes.
1912331,22457,20561,Evaluation of a human-robot interface: development of a situational awareness methodology,2004,This paper outlines a methodology to evaluate supervisory user interfaces for robotic vehicles based on an assessment of situational awareness. The results of an initial experiment are discussed. The evaluation method will be validated in a future experiment that will also result in a benchmarked user interface.
2496631,22457,20561,Knowledge representation tools for molecular scene analysis,1995,A hybrid knowledge representation scheme for molecular scene analysis is presented. The molecular knowledge base provides a framework in which existing sources of protein information can be integrated. Representations and strategies for visual and spatial reasoning are also included in the scheme. >
1487975,22457,20561,Digital documents and media,2003,The Digital Documents and Media Track has been part of HICSS for the last number of years. What I personally find fascinating about this Track is the amount of turnover and renaming of MiniTracks each year. I feel this represents the dynamic nature of the digital age in which we live.
1526949,22457,20561,An Experimental Study to Explore Attacker Response to Changes in Security and Reward,2013,"In previous simulation studies, attackers were assumed to respond to changes in reward with an S shaped curve and to changes in security with a declining S shaped curve. This paper reports experimental work that investigates the validity of those assumptions. In general, the results suggest that the assumptions are reasonable."
1487017,22457,20411,Personal vs non-personal blogs: initial classification experiments,2008,"We address the task of separating personal from non-personal blogs, and report on a set of baseline experiments where we compare the performance on a small set of features across a set of five classifiers. We show that with a limited set of features a performance of up to 90% can be obtained."
1846235,22457,20561,Information Fusion for Intelligence Analysis,2005,"Ensuring the accuracy of intelligence assessments is made difficult by the pervasiveness of uncertainty in intelligence information and the demand to fuse information from multiple sources. This paper describes Infusiun, a model-based software tool for information fusion and uncertainty assessment in intelligence analysis."
2063760,22457,20561,A Blueprint for Enhancing Future Reliability,2006,"This paper describes the efforts underway at NPCC to enhance system reliability since the August 2003 Blackout, and summarizes how the NERC and the U.S. - Canadian Power System Outage Task Force Recommendations are being addressed in Northeastern North America."
1640046,22457,20561,Designing a Pedagogy for an IT Security Course and Textbook,2006,"This paper describes how the author designed his IT security course and his IT security textbook, ⧼name withheld for anonymity⧽. The paper describes the issues and tradeoffs that all teachers will have to face when they design introductory IT security courses for information systems (IS) students (as opposed to computer science students)."
1721387,22457,9896,PopCore: a system for network-centric recommendation,2013,"Recommendations are not just informed by the social network, they may also influence it. Thinking about how recommendations impact underlying social processes provides a  network-centric  approach to recommendation. We describe the design of a recommender system, PopCore, as a testbed for understanding the interplay between recommendation and networks."
1934181,22457,23827,Data Warehouse-Based Personalized Information Service Scheme in E-Government,2009,"In this paper, we study the application of data warehouse in e-government from the point of view on the personalized information service, and analyze its structure and features combining with the requirement of the e-government information service. Finally, we explain the processes of data warehousing in the e-government with a real example in traveling."
930965,22457,20561,Introduction to Enterprise System Integration: Issues and Answers Minitrack,2013,"Over the years, this mini-track has been a forum to disseminate knowledge on enterprise systems. Naturally, as the area matured, we have witnessed a shift in the issues drawing the attention of the researchers. In this edition there is a strong focus on the integration of these complex software packages with their surrounding environment."
2089861,22457,20561,The Issue of System Use in Knowledge Management Systems,2005,"This paper discusses system use as a measure of system success. It is proposed that for knowledge management systems it is not the amount of use that is important, but rather, the quality of that use and the intention to use. Evidence is provided to support this proposition and a knowledge management system success model incorporating this proposition is discussed."
388041,22457,20561,Artificial computer-assisted international negotiation: a tool for research and practice,2002,We propose a Web-based computer-assisted tool for diagnosing progress in international negotiations. The system is based on a general linear model. Innovative features of the program include branching and flipper question to account for the need to address different types of negotiation processes.
2289293,22457,20561,Interoperability of Medical Applications and Devices,2008,This paper discusses several types of interoperability for medical applications and devices: the ability of applications to run on any platform; how modularity affects interoperability; and data exchange between heterogeneous applications. It draws from experience with Internet standardization to find lessons for creating standards for interoperability.
2562348,22457,20561,Multicriteria analysis in telecommunications,2004,The paper presents an overview of multicriteria analysis techniques applied to the design of telecommunication networks. A special module called ISAAP for interactive multicriteria analysis is adapted for this purpose. We will also present the use of multicriteria analysis for supporting strategic decisions related to negotiating interconnection agreements in telecommunications.
475109,22457,20561,"Equilibrium Channel Structure for B2C Electronic Distribution: The Interactions among Consumer Preferences, Product Characteristics, and Initial Channel Configuration",2002,"We create a taxonomy of channel structures, and analyze the strategic implications of these structures. We identify the drivers of market outcomes in each channel structure and analyze several business models that have failed because of channel conflict and the notable few that have survived and succeeded. Finally we recommend strategies that can be successfully pursued in each channel context."
1505370,22457,20561,Introduction to the Digital Media: Content and Communication Track,2012,"The Digital Media: Content and Communication Track has been running for several years. Its name has changed a few times over these years to better reflect the changing nature of the Track itself and thus reflect the dynamic nature of digital media. This year we have a mix of new and old minitracks, as described below."
1834552,22457,20561,Information technology in the health care industry: a primer,2000,The paper discusses current and future applications of information technology within the health care industry. It presents some broad strategies for approaching information technology investments and various tools available. It also discusses how information technology can support the medical providers' competitive strategy.
2025442,22457,20561,Issues in the use of hypermedia in organisations,1997,This paper investigates the potential of hypermedia as an information delivery tool for large organisations. Information is provided that may be of use to management and procurement personnel in the selection or development of new hypermedia management systems. Insights are provided to software developers investigating an organisation's information delivery requirements.
2382995,22457,20561,Branching Process Models for the Exponentially Increasing Portions of Cascading Failure Blackouts,2005,We introduce branching process models in discrete and continuous time for the exponentially increasing phase of cascading blackouts. Cumulative line trips from real blackout data have portions consistent with these branching process models. Some initial calculations identifying parameters and using a branching process model to estimate blackout probabilities during and after the blackout are illustrated.
1401268,22457,369,Personal Environment Service for Mobile Users,2006,"The personal environment service (PES) configures user's computing and communication environmental based on the user's personal organizer profile, which stores the user preference data. PES then coordinates the reconfiguration of the user's physical environment, such as appliances, through the use of short-range wireless communications."
2531260,22457,20561,Why Do People Play Games? A Review of Studies on Adoption and Use,2015,"This paper reviews empirical literature on adoption/acceptance, continued use as well loyalty in the context of games. The study reviews dependent variables, independent variables, coefficients between independent and dependent variables, used methodologies as well as types of games covered in the reviewed literature."
2016985,22457,20561,Customer assessment of CRADA program performance,1996,"The objective of the research project presented was to develop a focused analysis of Cooperative Research and Development Agreement (CRADA) program performance against the needs and expectations of industry partners. Archival survey, and interview data were collected on 237 CRADA partners of a major US federal laboratory."
2152880,22457,20561,The role of organizational culture in the management of clinical e-health systems,2003,"The research here presented focuses upon the informal, social, and cultural side of managerial coordination and control as manifested in clinical e-health systems. Specifically, the research seeks to analyze and determine the role specific dimensions of organizational culture may have upon effective managerial coordination and control in clinical e-health systems."
2298680,22457,20561,An Empirical Study of Software Process in Practice,2005,"In adopting a software process model, many small software companies are ignoring standard process models and models for process improvement. This study uses an empirical approach to investigate what processes software companies are using on a day-to-day basis and examines why these companies are rejecting best practice approaches."
653658,22457,20561,Investment decisions using genetic algorithms,1997,"We examine the performance of genetic algorithms as a method for deciding on a strategy to invest in different financial instruments. We discuss the literature, pointing out the different methods for making investment decisions. We then describe genetic algorithms, linking them to the procedure used in this study. We then report on the results obtained in our experiments."
430833,22457,20358,The social meanings of social networks: integrating SNA and ethnography of social networking,2013,"In this talk, I examine the manifest, emic meanings of social networking in the context of social network analysis and it uses this to discuss how the confluence of social science and computational sociology can contribute to a richer understanding of how emerging social technologies shape and are shaped by people's everyday practices."
1487161,22457,20561,Strategic Alliance via Co-Opetition: Supply Chain Partnership with a Competitor,2010,This paper conducts a formal analysis of the incentive and potential cost of the cooperation between competing firms with different goals by negotiating a contract agreement. We use a game-theoretical model to study the impact of co-opetition activities on market competitiveness and the economic incentives for starting.
569967,22457,20561,Edge disjoint graph spanners of complete graphs and complete digraphs,1997,"A spanning subgraph S=(V, E') of a connected simple graph (digraph)G=(V, E) is a f(x)-spanner if for any pair of nodes u and v, d/sub S/(u, v)/spl les/f(d/sub G/(u, v)) where d/sub G/ and d/sub S/ are the usual distance functions in graphs (digraphs) G and S, respectively. The delay of the f(x)-spanner is f(x)-x. The authors investigate the existence of multiple edge-disjoint spanners in complete graphs and complete digraphs."
2287678,22457,20561,Modeling Emergency Response Systems,2007,"This paper discusses a model for an emergency response system. The model is based on a review of the literature and the incorporation of lessons learned from Hurricane Katrina response. The paper takes a holistic view of a system in that an emergency response system is viewed as including emergency response members, procedures, and the organization as well as the ICT components of the system"
2447786,22457,20561,Factors Influencing Users' Intentions to Make the Web Accessible to People with Disabilities,2008,"The aim of this paper is twofold: to provide a theoretical model to analyze obstacles, challenges, and incentives which lead a nonprofessional user to design websites and produce information that are accessible to people with disabilities, and to develop a reliable and validated instrument designed to measure the construct that are part of this model."
2636959,22457,20561,Design Implications of User Experience Studies: The Case of a Diabetes Wellness App,2016,"We developed a health and wellness smartphone app to support diabetes self-management. The target users are older, less healthy adults with advanced type 2 diabetes. We illustrate the design implications of a health and wellness smartphone app for such users by presenting the process and results of our usability and user experience lab test with our app."
1747643,22457,9896,An input-process-output model of shared understanding in partially distributed conceptual design teams,2013,"In this study, we used qualitative data analysis to examine factors that are associated with shared understanding in the context of partially distributed conceptual design teams. The identified factors were then organized in an input-process-output model. The utility of the model as well as current and future works are discussed."
2070088,22457,20561,Benchmarking mobile network QoS,2003,"This paper addresses the benchmarking of mobile networks in terms of QoS, facilitating a service quality comparison of one mobile network with another. A framework for mobile network QoS benchmarking is proposed and suitable performance indicators are identified. Recommended QoS performance values are described that offer an industry benchmarking target."
1261366,22457,20561,Introduction to Designing and Deploying Advanced Knowledge Systems Minitrack,2014,"The objective of this minitrack is to contribute to the body of knowledge that helps academics and practitioners to design, deploy and evaluate advanced knowledge systems, explore and leverage appropriate project management methods and tools for designing and deploying knowledge systems, and study changing organizational knowledge processes and structures."
2334832,22457,20561,Uncovering Modes of Interorganizational Governance of IT,2011,"This research aims to better understand how IT governance supports organizations in their business exchanges with other organizations by investigating further the various modes of interorganizational governance of IT. After conducting case studies and interviews with committee members and IT executives, two modes of governance of IT during interorganizational relationships were uncovered: outsourced mode and networked mode."
1264442,22457,20561,"Introduction to IT Adoption, Diffusion, and Evaluation in Healthcare Minitrack",2014,"Adoption, implementation, and evaluation of information technology (IT) in healthcare continue to challenge organizations and society, as well as researchers. This mini-track addresses these Health IT topics within the framework of 1) EHR and PHR; 2) adoption resistance and attitudes; 3) health information exchanges; 4) HIT use; and 5) teleservices."
1247280,22457,20561,Corporate and Artificial Moral Agency,2013,"The paper considers the implications of the Corporate Moral Agency debate for the notion of artificial moral agency and the general intelligence project. A distinction is drawn between meta-arguments and object-level arguments, whilst the implications of the arguments within each category are indicated. The metaphor mutuality and political arguments are then discussed further."
2550308,22457,20561,Impact of IT Service Provider Process Capabilities on Service Provider Performance: An Empirical Study,2006,Using the resource based view of the firm this research identifies a set of provider capabilities most likely to impact the success of an IS outsourcing relationship. These capabilities are categories into key process areas. The results presented show the effect of the routinization of these processes on four client/provider related IS outsourcing success measures.
314985,22457,20561,Mobile agents and Java mobile agents toolkits,2000,"This paper gives an overview of what mobile agents are, what they should do, and how they can be implemented in Java. Why Java? The choice to concentrate on Java is evoked by many existing solutions in Java that handles architectural heterogeneity between communicating machines on the net. It seems to be the best available language for making mobile agents roam through the Internet for the time being."
1981719,22457,20561,Criterion based assessment using the support of a computer,2002,"It is often thought that it is not possible to use a computer for the assessment of work such as essays, paintings, diagrams, prototypes and sculptures, which the teacher must assess. The method of criterion-based assessment, described in this paper, shows how an adaptation of the multiple-choice test can be used to provide a useful tool for assessing."
2454338,22457,20561,Issues Associated with the Development of a Wide-Area Analysis and Visualization Environment,2006,"This paper provides a discussion of issues associated with the development of an environment for wide-area power system analysis and visualization. In particular, the paper considers issues associated with the exchange of information between regional transmission operators, the use of a unified state estimation and contingency analysis solution, and the visualization of the results."
1497194,22457,20561,Introduction to Open Data Services Minitrack,2013,"This is the first HICSS minitrack focusing on different aspects of open data services, including issues related to the publication of the open data sets followed by new service development and their implications. Of special interest are novel applications of available open data in various domains, such as, preventive healthcare and traffic."
1664731,22457,20561,Introduction to Analytics and Design-Led Innovations and Management Minitrack,2014,"There is a need to apply robust research findings in the appropriate management and organizational contexts related to analytics and intuitive thinking, and how to connect creativity and innovation with design. The purpose of this minitrack is to explore the challenges, issues and opportunities related to analytics and design-led innovations and management, from conceptualization to practical implementation."
2489081,22457,20561,"Discovering attribute relationships, dependencies and rules by using rough sets",1995,"The paper reviews the methodology of the application of the theory of rough sets to the problem of knowledge discovery in databases. The methodology is based on the idea of information generalization, to look at the data at various levels of abstraction, followed by the discovery, analysis and simplification of significant data relationships, dependencies, fundamental factors and rules. >"
2125645,22457,20561,Indexing into controlled vocabularies with XML,2001,"This paper presents an architecture to place index references from control vocabularies into XML documents. This provides three advantages currently not present in XML: the ability to simplify the writing of complex document type definitions that refer to control vocabularies, the ability to write XML documents with better indexing, and better retrieval of XML documents."
2429976,22457,20561,Technology imperatives of BPR and their effect on organizational decision support,1995,Business process redesign has brought to attention the need for inter and intra organization-wide nature of decision making. Technologies to support such an undertaking has immediate relevance to organizational decision support. We show that the technologies needed to enable the new business processes are indeed the same needed to implement ODSS. >
807478,22457,20561,Understanding User's Behaviors in Coping with Security Threat of Mobile Devices Loss and Theft,2012,"As mobile devices widely used for personal and business purpose, mobile devices loss and theft have become one big security threat. In this paper, we analyze the potential risks of mobile devices loss and theft and summarize the countermeasures that can be used to cope with such risks. Based on protection motivation theory, we propose a research framework to investigate the factors that affect users' behavior to cope with the risk of mobile devices loss and theft."
685816,22457,20561,Developing Internet security policy for organizations,1997,"The paper describes a general framework for developing an organization's Internet security policy. A model of Internet security risks for an Internet user organization is proposed; the framework utilizes this model, as well as considering important holistic issues, in order to develop the user organization's Internet security policy. A hierarchy of subpolicies for the Internet security policy is also suggested. The paper presents the results of one phase of a wider investigation into Internet security policy."
1059528,22457,20561,Finance Sourcing in a Supply Chain,2011,"We examine the relative merits of bank versus trade credit in a supply chain consisting of a manufacturer and a capital-constrained retailer. We show that trade credit is more effective than bank credit in mitigating double marginalization in the supply chain when marginal production cost is relatively low, and that bank credit becomes more effective otherwise."
2101064,22457,20561,SERVIAM Maintenance Framework,2006,"Web services systems impose additional complexity upon software maintenance and evolution processes. To handle it, we propose a framework for evolving and maintaining Web service systems. Our framework includes organisation, role, and process changes. The feedback on its credibility has been provided by ten software organisations in Poland and Sweden."
1529676,22457,20561,Institutional theory: a new perspective for research into IS/IT security in organisations,2004,"The aim of this position paper is to argue for the suitability of an institutional perspective in IS/IT (information systems/information technology) security research. Institutional theory, including some of its central concepts, is presented, along with examples of how it has been used in information systems research. A discussion of how the theory could benefit managerial IS/IT research concludes the paper."
1175302,22457,20561,Software Engineering Decision Support,2007,"Developing software involves making hundreds, even thousands, of decisions. Decisions in the context of software systems are hard to make, as the information available is incomplete, uncertain and dynamically changing. Even worse, these decisions are often impacted by conflicting objectives, restricting constraints and stakeholder preferences."
1824340,22457,20561,Automatic Identification of Home Pages on the Web,2005,"The research reported in this paper is the first phase of a larger project on the automatic classification of Web pages by their genres. The long term goal is the incorporation of web page genre into the search process to improve the quality of the search results. In this phase, a neural net classifier was trained to distinguish home pages from non-home pages and to classify those home pages as personal home page, corporate home page or organization home page. Results indicate that the classifier is able to distinguish home pages from non-home pages and within the home page genre it is able to distinguish personal from corporate home pages. Organization home pages, however, were more difficult to distinguish from personal and corporate home pages."
1263917,22457,20561,Algorithms for Detection of Static Voltage Instability in Power Systems Using Synchrophasors,2010,"When a power system is operating under unforeseen conditions or under unusually high stress, the system can face operational reliability problems from any of voltage instability, small-signal instability or transient instability phenomena. This paper will focus on recent tools that have been developed for fast detection and mitigation of static voltage instability mechanisms using synchrophasors."
2420237,22457,20561,Using Association Rule Mining for Behavioral Analysis of School Students: A Case from India,2009,Association rule mining has been typically used in transaction databases to understand correlation between various items and/or events. This paper describes a work done in the education sector in India to understand association of various dimensions of behavior of school children and represents a case which has actually been executed successfully.
1854102,22457,20561,An Approach for Intent Identification by Building on Deception Detection,2005,Past research in deception detection at the University of Arizona has guided the investigation of intent detection. A theoretical foundation and model for the analysis of intent detection is proposed. Available test beds for intent analysis are discussed and two proof-of-concept studies exploring nonverbal communication within the context of deception detection and intent analysis are shared.
2462453,22457,20561,"Technology transfer in Sandia's scientific areas. The engineering sciences Technology Information Environment. Systematic approach to security, privacy and appropriate access",1995,"This paper describes the need for faster and more efficient technology transfer mechanisms. It outlines the design of a computerized technology transfer mechanism for the engineering sciences area based on Sandia National Laboratories' Technology Information Environment for Industry (TIE-IN). It explains the security, privacy and appropriate access issues that arose in the design of the system. >"
1727428,22457,20561,Using Social Media to Capture and Convey Cultural Knowledge: A Case of Chamorro People,2013,"The purpose of the paper is to understand if information and communication technologies, specifically social media, are used to capture and convey Chamorro cultural knowledge. Two data collection methods were used to understand the type(s) of Chamorro cultural knowledge that is valued, and what social media is used by the Chamorro people today to capture and convey cultural knowledge. The results indicate that the Chamorro people today share the core Chamorro cultural values, and do use information and communication technologies, including social media to capture and convey Chamorro cultural knowledge."
1731024,22457,20561,Introduction to Decision Support and Operational Management Analytics Minitrack,2013,"Taken in isolation, algorithmic data sciences approaches and human-centred visual analytics methods hold great promise for operationalizing archival datasets and streaming real-time data in support of strategic and operational decision-making across a broad range of human activities."
1760045,22457,20561,Hyperknowledge in practice-users attitudes to active DSS,1997,There is some common wisdom that managers do not use computers and that nothing much could be gained with computer support. We have made an empirical study of the attitudes of a group of senior managers towards computer support. We found that senior managers do use computers and computer-based systems; they do believe in support systems and they have high expectations on the impacts of support systems on decision-making.
1694472,22457,20561,Introduction to Mining and Analyzing Social Media Minitrack,2013,"This minitrack encompasses papers of a quantitative, theoretical or applied nature that focus on:    Content Mining of Social Media -- discovery of patterns from the text, images, audio, video and other data generated by Social Media sites Structure Mining of Social Media -- social network analysis of the node and connection (graph) structures underlying Social Media sites"
618563,22457,20561,Directions in general-purpose computing architectures,1997,"General purpose computing devices and systems are commodity building blocks which can be adapted to solve any number of computational tasks. We adapt these general purpose devices by feeding them a series of control bits according to our computational needs. We have traditionally called these bits instructions, as they instruct the programmable silicon on how to function."
1169922,22457,20561,Minitrack: E-Government Organization and Management,2007,"The development and effectiveness of e-Government is strongly influenced by the degree to which government leaders and organizations adopt management and organizational strategies that emphasize change management, new organizational forms, different professional and organizational relationships while they take advantage of the power of information technology to transform government operations and public services."
2557887,22457,20561,Deal or No Deal? Vendor Issues in Two Multi-organization Pilot Test Projects,2008,"This paper compares issues in managing technology vendor relationships in two pilot tests of the FSTC eCheck and a pilot test of the US Treasury's Internet Payment Platform (IPP). We discuss issues related to participation of technology vendors in these projects, and conclude with suggestions for further research on planning and managing emerging technology pilot test projects."
1368376,22457,20561,The Adoption And Diffusion Of Collaborative Systems And Technology,1998,"Starting with hicss-31, this mini-track has been focussing on the processes and dynamics relating to the organizational adoption of collaborative systems and technology, and the subsequent diffusion of such systems and technology within adopting organizations. Adoption is the process through which an organization decides to acquire the systems or technology. Diffusion is the process through which the acquired systems and technology become assimilated into an organization."
1809206,22457,20561,Managing projects through a corporate repository,2000,"TRW's Project Review Online System (PROS) was created in late 1996 to automate the collection and analysis of project data. It provides a web-based repository of up-to-date information to support project management, senior manager oversight, and process improvement. This article captures our experiences with establishing and using this concept."
1686965,22457,20561,Propositional Research Framework for the Conceptual and Technological Adoption of Digital Coupons in the US,2010,"This paper provides a theoretical and methodological approach for assessing adoption of digital coupons in a US population. Using a field experiment approach, it is proposed that digital coupons will reduce the consumer costs of using coupons thereby increasing the economic incentives for use and potentially improving the current redemption rates of coupons. Wider acceptance of coupon redemption has the potential to revolutionize the couponing industry."
2360670,22457,20561,Towards Fast Incremental Hashing of Large Bit Vectors,2008,"Many application domains require algorithmic support for collections of large bit vectors that are frequently referenced. In a compiler that performs type inferencing, this problem occurred in representing sets of possible types at each program point. This paper presents an incremental hashing technique that performs well in this domain."
2109382,22457,20561,Seven levels of interorganizational connectivity an examination of the U.S. grocery distribution channel,1996,The paper examines interconnectivity within the grocery channel and suggests an interorganizational connectivity framework modeled in part on the ISO model of systems connectivity. This seven level model of interorganizational connectivity and channel interdependence is illustrated using examples of processes that span multiple levels of interconnectivity and interdependence within the grocery channel between different groups of customers and suppliers.
521122,22457,20561,Introduction to the Mobile and Sensing Solutions for Health Promotion and Maintenance Minitrack,2015,"This mint rack will include two sessions with high quality papers focusing on mobile applications as well as theoretical analysis and literature review in the field of patient centered care. Design, usage, and evaluation of various smartphone apps will be addressed. Specific research subjects and results will be presented."
2093447,22457,20561,Knowledge Management &#8212; The Ethics of the Agora or the Mechanisms of the Market?,2006,"Knowledge management [KM] first appeared as a distinct phrase in the context of IS in the mid-1990s, since when it has grown to become the latest item in the IS pantheon. The term itself ought to promote more uneasiness than it appears to do so within the IS academy, and this paper outlines the reasons why the term should be viewed with less enthusiasm and more suspicion."
2324550,22457,20561,Telecommunications demand analysis in transition,1998,"The paper focuses on the problems and challenges to applied demand analysis in the telecommunications industry that have been posed by technological change, deregulation and competition. Challenges discussed include the development of new sources of data, estimation of price elasticities which apply to firms and users, the modelling of choice of carrier, and the emergence of the Internet."
1877476,22457,20561,State change architecture: a protocol for executable process models,1989,"The key concepts and requirements for a process mechanism and the state change architecture (SCA) protocols are presented. The SCA is thought to solve many of the process modeling problems associated with conventional languages and methods. It integrates object-oriented programming, a common repository for the logical view of data, and logic programming. >"
2522615,22457,20561,The impact of rumors on the judgmental forecasting process,1995,"The study investigates the impact of rumors when forecasting changing time series. In this study, the subjects were presented with three types of rumors about the future direction of the time series-correct rumors, incorrect rumors and rumors which provide no information. Results indicate that correct rumors improved the quality of the forecasts; incorrect rumors and rumors with no information content evoked the same quality of the forecasts. The latter relationships persisted and affected forecasting quality in subsequent time series. >"
1618062,22457,20561,Introduction to the minitrack on data warehousing and business intelligence,2004,"Data warehousing and business intelligence continues to evolve as a field to address new trends in the marketplace, such as compliance and privacy, managing and leveraging unstructured data, and real-time, tactical decision making. One set of papers in this year?s Data Warehousing and Business Intelligence Minitrack investigates how the field is meeting changing business needs."
2296807,22457,20561,A metagraph-based DSS analysis workbench,1996,"A metagraph is a graph-theoretic construct that has been shown to be a useful basis for graphical visualization and algebraic analysis of DSS resources such as models, data and rules. We describe the structure and use of a metagraph-based DSS analysis workbench that can also be used as a front-end to an existing DSS for activities such as database design and model analysis."
911401,22457,20561,Price Discrimination in Organized/Centralized Electric Power Markets,2006,"Price discrimination is a concept that is well understood in economics where it applies to the ability of, generally, a seller to price the same product at different levels as a way of increasing revenue. This paper presents the concept of price discrimination from the position of both the buyer and the seller. It looks at the concept in unregulated industries and argues that price discrimination is now a significant issue in the electric power industry."
1884861,22457,20561,Technological penetration and cumulative benefits in SMEs,1995,The relative importance of the benefits derived from the adoption of computer-based administrative and production applications depends to a large extent on the level of technological penetration attained by a particular firm. This evolutionary perspective is investigated in an empirical study carried out in manufacturing firms operating in one specific sector of industrial activity. >
1508201,22457,20561,Introduction to Cross-Organizational and Cross-Border IS/IT Collaboration Minitrack,2012,"Research on cross-organizational and cross-border collaboration addresses the integration of systems, people, processes, and infrastructure across organizations, borders, and world regions to enable productive interactions, performance, and satisfaction. Electronic and virtual collaboration has been growing and is driven by competitive advantage, lowered costs, and increased knowledge."
2399384,22457,20561,Two experiences of knowledge management in knowledge intensive organizations of the French social sector,2002,"We presented at HICSS-34 a new methodology based on the semantics of contracts to model business and, beyond, to manage the knowledge assets of a firm. In this paper we present two cases in which we apply our methods. This brings some insights, in real situations, about some problems and issues on knowledge management which cannot be separated as we will show from human resources management."
2382611,22457,20561,Physicians' Usage Experiences of a Mobile Information System,2005,The health care professionals are increasingly using handheld devices in their practice. This paper presents some findings from an interview study conducted on users of a medical information system running on a Nokia 9210 Communicator. The users have in general a positive picture of the system but the actual usage patterns and the settings in which the system is used vary.
2449790,22457,20561,Individual differences and the use of collaborative technologies in education: an empirical investigation,2004,"This study investigated the extent to which students' participation in and satisfaction with a computer-mediated collaborative learning system was affected by their preference for autonomy and anxiety about the use of computers. The results indicated that although students varied significantly in terms of their preference for autonomy and anxiety about the use of computers, there was no significant difference in participation and satisfaction levels between low and high computer anxiety students or between those with a low preference for autonomy relative to those with a high preference for autonomy."
2173109,22457,20561,Modeling and implementing an adaptive human-computer interface using passive biosensors,2004,"Modeling of the human-computer interaction as a partnership between two systems provides a flexible method of modeling both the quantitative and qualitative requirements of a human-computer interface. A discussion of the components of a system, system structures and system issues are reviewed along with a description of the research model used at the adaptive multimodal interactive laboratory."
1683667,22457,20561,"Introduction to Data, Text, and Web Mining for Managerial Decision Support Minitrack",2014,"This mini-track has five papers that are about developing systems for decision support by means of data, text, or web mining. These five papers focus on a wide range of application areas from healthcare to social media, reinforcing the fact that data, text, and web mining are effective and recently popularized tools to develop decision support systems in various domains."
2114257,22457,20561,Managing technology within transitory organizational structures,2000,This paper examines nonlinear adaptation to change in the high-technology environment of the computer industry. These environments are defined and the efficacy of different organizational adaptations is assessed with respect to these environments. Results from our analyses show that there is a direct and causal relationship between the employment of nonlinear organizational archetypes and organizational effectiveness within high-technology industries.
1457521,22457,20561,DC Optimal Power Flow Proxy Limits,2010,"Proxy limits are used to represent voltage constraints from an AC power flow as line flow constraints in a DC power flow. When a DC power flow is used to settle markets, the use of proxy limits can introduce errors in LMPs, dispatch, or both. This paper describes a method to obtain the optimal set of proxy limits for known voltage constraints. We discuss the general properties of these proxy limits."
1989196,22457,20561,Spatial simulation model for infectious viral diseases with focus on SARS and the common flu,2004,"This paper focuses on simulating the infectious process on a computer. To simulate how an infectious viral disease spreads not only shows how people get sick, it can also be a powerful tool in disease prevention. You can test actions such as to isolate people that get sick and analyze if the disease spread can be circumscribed or stopped. Special focus is given to SARS and the Common Flu."
2336946,22457,20561,Influence of Cultural Differences on Multi-National and Multi-Organizational Collaboration in Collaboratories,2009,"This study examines the influence of cultural differences on multi-national and multi-organizational scientific collaboration in collaboratories. It is found that the impact of cultural differences interplays with other social and economic factors such as project funding, scientists own perception of their role within the project, and national policy. Practical implications of the study are also suggested."
2530734,22457,20561,Linearized Power Flow Equations Based Predictive Control of Transmission Voltages,2013,"In this paper, an approach based on the concept of Model Predictive Control (MPC) is used to control transmission voltages and prevent long-term voltage instability. The MPC model is based on a linearized steady-state system model derived from power flow equations. Simulation results are presented for the case of Nordic32 test system."
2684940,22457,9896,Beyond Official: Government Information Work through Personal Accounts,2016,"This research demonstrates how government information workers employed different communication strategies through social media after a mass-causality event. Effectively using social media for some government functions may blur the lines between official work and the personal boundaries of government workers, thus raising privacy concerns for government employees."
537263,22457,20561,Reviewing Event Studies in MIS: An Application of the Firm Value Framework,2003,"Our objective in this paper is to show how the firm value framework can be used to examine IT investments and research on IT investment decisions. The firm value approach adds to the process-oriented approach through simultaneous evaluation of all of the factors that affect firm value. We demonstrate how to use the firm value framework in evaluating two streams of research in MIS, event studies of IT investment announcements and e-commerce initiatives."
2394740,22457,20561,A Model for Temporal Interval Authorizations,2006,"A new model for representing temporal access control policies is introduced. In this model, temporal authorizations are represented by time attributes associated with subjects and objects, in a time interval access graph. The time interval access graph is used to define constraints on the temporal relations between subjects, objects, and the time of access. Interval algebra is used to precisely define and analyze the time interval access graph, and to specify the evaluation of access requests.¹"
2562815,22457,20561,Design and Implementation of Java Sniper: A Community-Based Software Code Review Web Solution,2011,"With the advent of the web, more and more information systems are being built web-centric, and more recently, these systems are leveraging the advantages of online community practice as well. This paper describes a lightweight community-based software code review web solution that allows a user to easily upload source code, review, and vote on peer reviews and reviewers."
1785916,22457,20561,A Mobile System and Application for Facilitating Emotional Awareness in Knowledge Work Teams,2008,"In this paper we present a prototype of a mobile system and application for enhancing emotional awareness in knowledge work teams. The prototype gathers emotional, social and informal information on a group of users explicitly and implicitly. The advantages of using the prototype are expected to be increased emotional awareness within group possibly leading to positive effects on group performance."
2003778,22457,20561,Generic description of a software document environment,2001,UQ* is an evolving generic language-based environment for manipulation of structured documents. The environment is intended to capture both syntactic and relational structure within and between documents and to support user interaction via both textual and diagrammatic views. This paper illustrates the innovative features of the environment description language used to instantiate a UQ* environment.
1041470,22457,23827,Towards a distributed software architecture evaluation process: a preliminary assessment,2006,Scenario-based methods for evaluating software architecture require a large number of stakeholders to be collocated for evaluation sessions. Collocating stakeholders is often an expensive exercise. We have proposed a framework for distributed evaluation process. We present the proposed framework and initial results of a controlled experiment that we ran to assess the effectiveness of the proposed idea.
2093858,22457,20561,A comparison of scales for assessing personal creativity in IS,1996,"Assessment of the individual creativity of IS personnel is a critical component in enhancing creativity and innovation in IS organizations. There are over two hundred scales designed to assess an individual's creativity but only three have seen substantial use in IS. A review of these three scales (KAI, ISP, CPSP) is provided and a list of the characteristics of an ideal individual creativity assessment scale to be used in IS is offered."
2271344,22457,20561,Groupware and the Internet: charting a new world,1997,"We contrast Web-based groupware with other forms of communication, such as e-mail, listservs, newsgroups, and proprietary conferencing systems. We report the results of a study of more than 100 organizations that have used Web groupware to better understand how they are using it, and what advantages and disadvantages they have experienced. We then use this data to develop a framework for analyzing, organizing, and fitting groupware systems to organizational needs."
1434622,22457,20561,Minitrack: Electronic Democracy,2007,"E-Democracy focuses on the use of information and communication technologies to support the democratic decision-making processes and to allow more effective and transparent engagement between government, business, NGOs and citizens. As such e-democracy examines the interrelation of technological innovation, institutions of government, decision making practices, elections, and the societal effect of technology on the democratic process."
344244,22457,20561,"Almost, More Than, or Truly Human?: Examining Sci-Fi TV through the Lenses of Digital and Theological Anthropologies",2015,Metaphors are powerful aspects of modern social imaginaries. In this paper I examine how old metaphors interact with new metaphors in contemporary sci-fi shows through the lens of digital and theological anthropologies. The human computer interactions imagined in these shows reveal Western social concerns with human security and human nature itself.
1892610,22457,20561,Scheduling interval orders in parallel,1995,Interval orders are partial orders defined by having interval representations. It is well known that a transitively oriented digraph G is an interval order iff its (undirected) complement G~ is chordal. We investigate parallel algorithms for the following scheduling problem: given a system consisting of a set /spl Tscr/ of n tasks (each requiring unit execution time) and an interval order  >
1112275,22457,20561,Team and Organizational Identification among Information Systems Personnel: An Exploratory Investigation of Post IT Outsourcing Personnel Impacts,2012,"This study examines the impact of social identification of IT employees in IT outsourcing firms. Specifically, we ask: What effect does social identification have on employee attitudes in the wake of major outsourcing initiatives? We examine social identification through the separate dimensions of team identification and organizational identification. The results suggest that when team identification and organizational identification are viewed as two distinct measures of social identity, the effect on the workplace attitudes of IT employees vary."
1361737,22457,20561,Minitrack: Genres of Digital Documents,2007,"The four papers included in the conference proceedings for this year?s minitrack on Genres of Digital Documents demonstrate wide range of research questions dealing with genre theories and models as well as the genres themselves?their nature and their function in communication, society, and work, as well as our ability to exploit genre information for enhancing the representation and retrieval of digital documents."
1236655,22457,20561,Foundations for Software Assurance,2012,"Our society's growing dependence on software makes the need for effective software assurance imperative. Motivation to address software assurance requires, at a minimum, an understanding of what to do, how to go about it, and why it is needed. Two key foundation elements are principles for software assurance and a curriculum to educate those who must address this need. This paper highlights efforts underway to address both of these elements."
2233744,22457,20561,An assessment of venues providing public access to ICT: a tale of 25 countries.,2009,"This paper is based on a comparative study of venues that provide public access to information and communication technologies in 25 countries. We study how diverse people can and do access and use ICT and what factors influence availability at these venues. Our aim, through such an analysis is first to map what is available through the public access venues in these countries and second to arrive at policy recommendations to increase public access in these countries."
2197276,22457,20561,Effective Versus Ineffective Communication Behaviors in Virtual Teams,2007,"The critical incident technique was used to interview 18 professional virtual team workers about their experiences with effective and ineffective communication behaviors of virtual team workers. We clustered the 317 behaviors that we found into 11 categories that are critical for the success or failure of a team and/or satisfaction of team members. These categories are discussed, and suggestions are made for future research"
890873,22457,20561,"Introduction to Knowledge Management Value, Success and Performance Measurements Minitrack",2012,"This mini-track explores research into strategies, methodologies, and stories that relate to measure this success. Papers explore the bodies of performance measurements that define the current state of research in measuring KM, organizational memory, and organizational learning success. Three papers will be presented in one session. Brief summaries of each is presented here."
1930782,22457,20561,Stability of limit cycles in hybrid systems,2001,Limit cycles are common in hybrid systems. However the nonsmooth dynamics of such systems makes stability analysis difficult. This paper uses recent extensions of trajectory sensitivity analysis to obtain the characteristic multipliers of nonsmooth limit cycles. The stability of a limit cycle is determined by its characteristic multipliers. The concepts are illustrated using a coupled tank system with on/off valve switching.
2534962,22457,20561,Join the standard forces Examining the combined impact of process and data standards on business process performance,2009,"What impact do process and data standards have on business process performance? This paper shows that process and data standards have a positive combined impact on business process performance  measured in business process time, cost and quality. This combined impact of process and data standards on business process performance is empirically confirmed using data from an annual study of the recruitment process among Germanys Fortune 1,000 companies 1 . Building on the confirmed positive combined impact of process and data standards, the paper provides actionable managerial recommendations on how to achieve this impact."
790310,22457,20561,Introduction to Emerging Issues in Distributed Group Decision-Making: Opportunities and Challenges Minitrack,2012,"This mini track addresses emerging issues, such as diversity, culture, adaptability and agility related to teams in distributed group decision-making, as well as the underlying theories of group dynamics, coordination, and communications. The papers submitted specifically examined the emerging issues related to team configuration, crowd sourcing and performance in a distributed environment."
919983,22457,20561,"Are We Becoming Socially Impaired? Computer-Mediated Communication, Human Evolution, and Social Capital",2012,"We review the literatures on human evolution, organizational communication, and CMC, focusing on research addressing CMC support for the transmission of socio-emotional signals, Theory of Mind (ToM), and social capital. We develop a social capital theory of communication in organizations, linking the use of CMC for the transmission of socio-emotional signals with one's ability to develop social capital, where ToM is proposed as a major mediator."
2408666,22457,20561,Identifying Employee Internet Abuse,2007,"This study attempts to illuminate employee Internet abuse through analysis of a company's firewall log file. The difficulty of determining whether a given instance of Web browsing constitutes abuse is addressed. Visits to Web sites subjectively labeled inappropriate were found at varying levels, ranging from incidental to excessive"
2119893,22457,20561,Participant-driven GSS: Quality of Brainstorming and Allocation of Participant Resources,2007,This paper examines the relationship between time duration and the quality of brainstorming output. Quality of brainstorming output is operationalized using creativity and feasibility measures. Results indicate that brainstorming quality does decrease over the duration of the brainstorming session. Results also indicate the number of off-topic and non-solution brainstorming output increases significantly over time. These findings are discussed in light of participant-driven group support systems
2520730,22457,20561,Bridging Boundaries in Offshore Outsourcing Organizations: A Case Study of Promoting KM System Initiatives in Wipro Technologies,2011,"Despite the increased attention on boundary spanning in organizations, we still know surprisingly little about how boundaries are formed and what spanning activities can be applied in the context of offshore outsourcing organizations. This paper examines the antecedents of boundary formation in this context and also has proposed spanning activities that can help offshore outsourcing organizations to realize return from their IT investment in an effective and efficient manner."
2094371,22457,20561,"Putting the parts together-concepts, description techniques, and development process for componentware",2000,"We outline and clarify the essential concepts of the componentware paradigm. After motivating the role of formal foundations and introducing a number of useful description techniques, we propose a flexible process model for component based development based on process patterns. The presented techniques and concepts serve as building blocks of an overall methodology for componentware which is the focus of our current work."
298883,22457,20561,Biases and Debiasing in Multi-criteria Decision Analysis,2015,"Developing models and estimating parameters for multi-criteria decision analysis requires judgments by experts and decision makers. These judgments are subject to biases, which can reduce the quality of the analysis. Some of these biases are due to faulty cognitive processes, some are due to motivations for preferred analysis outcomes. We describe these biases, how they affect multi-criteria decision analysis and discuss some debiasing techniques."
2991332,22457,20561,"Older Adults Adoption, Use and Diffusion of E-Government Services in Saudi Arabia, Hail City: : A Quantitative Study",2017,"Jyoti Choudrie, Adel Alfalah, and Neil H. Spencer, 'Older Adults Adoption, Use and Diffusion of E-Government Services in Saudi Arabia, Hail City: A Quantitative Study'. Paper presented at the Hawaii International Conference on System Sciences 50th Anniversary, 4-7 January 2017, Waikoloa, Hawaii, USA."
502051,22457,20561,Pentium MPP for OLTP applications,1995,"The paper describes a multi-Pentium architecture with a hierarchical memory and an I/O bus subsystem. On a board-level, this architecture achieves a very high-level of integration, by accommodating 8 Pentium processors with up to 2 Gigabytes of RAM. This hierarchical architecture has been extended to support multiple boards in a single cabinet as well as multiple cabinets connected via reflective memory. >"
1988249,22457,20561,Creating Strategic Value from Supply Chain Visibility- the Dynamic Capabilities View,2007,"To understand the role of supply chain visibility in creating strategic value, this study applies the dynamic capabilities view to investigate the nature of supply chain visibility. This research identifies four important measurable constructs of supply chain visibility that are proposed to drive supply chain reconfigurability and improve supply chain performance. They are sensing for visibility, learning for visibility, coordinating for visibility, and integrating for visibility. Implications for better understanding the nature and the role of supply chain visibility are provided based on the research model and survey results"
1782609,22457,21089,Implementing a Characterization of Genre for Automatic Genre Identification of Web Pages,2006,"In this paper, we propose an implementable characterization of genre suitable for automatic genre identification of web pages. This characterization is implemented as an inferential model based on a modified version of Bayes' theorem. Such a model can deal with genre hybridism and individualization, two important forces behind genre evolution. Results show that this approach is effective and is worth further research."
1834820,22457,20561,Assessing knowledge management success/effectiveness models,2004,"This paper proposes a framework for assessing knowledge management system, KMS, success models. The framework uses three criteria: how well the model fits actual KMS success factors, the degree to which the model has a theoretical foundation, and if the model can be used for two types of approaches to building a KMS. The framework is then applied to four KMS success models found in the literature and is determined to be a useful framework for assessing KMS success models."
2374263,22457,20561,Social profiles of virtual communities,2002,"The phenomenon virtual community reflects the social, political and economic impact of information and communications technology changing the architecture of interaction. We present an approach to describe and manage the social environments of transactions that are provided in virtual communities. We explore virtual communities, their novel social structures and the dynamics of the social momentum of communities. We present an empirical study of fifty virtual communities."
1813474,22457,20561,Understanding Locational Reserves and Reliability Needs in Electricity Markets,2006,"This paper describes a comprehensive set of examples being developed for the purpose of understanding the interaction between reserves and energy, the need to consider not only energy but also reserves by location, leading to the need to locational marginal pricing for both. The paper also illustrates how congestion in the transmission system that occurs for energy may or may not be correlated to congestion that occurs in the reserve markets."
2242826,22457,20561,Collaborative Modeling - A Design Science Approach,2009,We have used a design science approach to study the collaborative creation of conceptual models. We have designed a collaborative modeling architecture based on business needs and applicable knowledge from theory and empirical findings from a modeling study using conventional modeling. A tool for this architecture was then developed and used as an instrument to confirm the practical relevance of the approach and the validity of the employed theory.
1995589,22457,20561,Supporting concurrent engineering using an intranet approach,1997,Design and engineering processes are complex and inherently parallel. There is a need for a framework which allows document management for all phases of complex engineering tasks. The first part of the paper presents an introduction into the most challenging issues of this field. In the second part of the paper a case study from the area of car manufacturing is presented in which intranet technology is used to support design and engineering processes.
706029,22457,20561,Introduction to the Digital Innovation Minitrack,2015,"The goal of this minitrack is to offer a venue for research that focuses on digital innovation, broadly defined. This includes research into unique and specific effects of digital technologies on different forms of organizational innovation. In particular, new forms of service offerings, products, or ways of organizing processes that did not exist before the availability of large scale digitalization."
1965326,22457,20561,Factors Impacting Customers' Initial Trust in E-Businesses: An Empirical Study,2005,"Developing customers' initial trust in e-businesses is critical for many online vendors, especially for startup companies. As an effort to understand initial trust in the business-to-customer e-commerce context, this study uses previous studies and logical reasoning to define initial trust and examines its predictors. Empirical results explaining the factors impacting customers' initial trust in e-businesses are also presented. The results indicate that website quality, among others, has the most significant impact on customers' initial trust in e-businesses."
1655823,22457,8806,Extending the business engineering framework for application integration purposes,2005,"Current concepts of enterprise application integration often focus on technical issues only. Previous, more holistic approaches of deriving information system concepts from business requirements often addressed the development of a new information system replacing the existing, not integrated systems. In this paper, we describe an extension of the Business Engineering framework for application integration purposes."
2071091,22457,9896,Data-intensive collaboration in science and engineering,2012,"Science and engineering are facing huge increases in data volumes. This data deluge presents challenges for conducting collaborative data-intensive knowledge work and opportunities to provide better computational and organizational support for that work. This workshop will address three themes: infrastructures for big data, interoperability and standards, and data-intensive collaboration."
2291457,22457,20561,Late to the Game: Assessing IT Integration Risk after the Acquisition Target Has Been Identified,2015,"This article introduces a framework for assessing IT integration risk in acquisitions. We illustrate the framework's merits for the management of high-risk acquisitions and identification of low-risk acquisitions with the experience of Trelleborg AB, a global industrial company with acquisitions as integrated components of its corporate strategy. Based on the insights gained from Trelleborg, we provide lessons for CIOs in assessing and managing IT-related risk in acquisitions after the acquisition target has been identified."
842442,22457,20561,Introduction to Social Media and Social Networking Minitrack,2012,The Social Media and Social Networking Minitrack highlights the increasing importance of social media and networks in society. It is expected to provide an invaluable opportunity for researchers to share their findings in this new area. The Minitrack includes two sessions with four and three papers in each. The papers show the latest findings on the use of social networking in the context of government.
1891490,22457,20561,A meta ERM and its relational translation for a database design system,1997,"A meta model for an extended entity-relationship model is presented. This model was used as the data model for the implementation of a database design tool. Interesting aspects of the extended entity-relationship model, for which the meta model is described include generalization hierarchy and minimum and maximum cardinalities. Mapping of the meta model to the relational model of data is presented. In the context of its relational materialization, constraints on the meta model are also described."
827746,22457,20561,A comprehensive approach to database management of quantitative structure-activity relationships (QSAR) in chemistry and biology,1994,"Many quantitative structure-activity relationships (QSARs) have been published in pure organic chemistry as well as from biological sources since 1935 when Hammett introduced his equation. We have organized a database of about 6,000 QSARs about evenly divided from both sources. We discuss how the database can be searched for different types of QSAR and how this facilitates comparison of new QSARs with published results. >"
2165009,22457,20561,The Meaning of Open Standards,2005,"This paper develops the argument that many Information Technology standardization processes are in transition from being controlled by standards creators to being controlled by standards implementers. The users of standardized implementations also have rights that they wish addressed. Ten basic rights of standards creators, implementers and users are identified and quantified. Each of these ten rights represents an aspect of Open Standards. Only when all ten rights are supported will standards be open to all."
2367322,22457,20561,IT Governance and Sarbanes-Oxley: The Latest Sales Pitch or Real Challenges for the IT Function?,2005,"Building on an analysis of the Sarbanes-Oxley Act, literature, as well as private and public interviews, this paper hopes to shed light on the potential impact of Sarbanes-Oxley for IT governance, IT budgets, and relationships with vendors and outsourcers. Findings have implications for research as well as practical lessons-learned for American firms, and for IT vendors or other companies doing business with American companies."
1888112,22457,20561,Knowledge Reuse in Open Source Software: An Exploratory Study of 15 Open Source Projects,2005,"To date, there is no investigation of knowledge reuse in open source software projects. This paper focuses on the forms of knowledge reuse and the factors impacting on them. It develops a theory drawn from data of 15 open source software projects and finds that the effort to search, integrate and maintain external knowledge influences the form of knowledge to be reused. Implications for firms and innovation research are discussed."
2206785,22457,20561,Fault-diameter of the star-connected cycles interconnection network,1995,"Let G be a graph with vertex connectivity k(G). An important measure of the fault tolerance of G is its fault-diameter d/sub f/(G), which is defined as the maximum diameter resulting from the deletion of any set of nodes containing less than k(G) nodes. The robustness of G is often measured by comparing d/sub f/(G) with the diameter of the fault-free G, namely d(G). In particular, a family of graphs G/sub n/ is dubbed strongly resilient if d/sub f/(G/sub n/)/spl les/d(G/sub n/)+c, where c is a fixed constant independent of n. This paper derives the fault-diameter of the star-connected cycles (SCC) interconnection network. We show that the SCC/sub n/ graph is strongly resilient, exhibiting a fault-diameter of d/sub f/(SCC/sub 3/)=d(SCC/sub 3/)+4, d/sub f/(SCC/sub 4/)=d(SCC/sub 4/)+5, and d/sub f/(SCC/sub n/)=d(SCC/sub n/)+1, for n/spl ges/5. >"
2097176,22457,20561,Organizational strategy making support systems task driven development requirement,1995,"This paper discusses results of a pilot study into the use of computers to support organizational strategy making. Based on investigations into the strategy making task, the paper suggests main software characteristics that these support systems should have. The paper argues and demonstrates that the nature of these support systems can be identified that implementation is possible with the technology of today, and that such systems can be successful, provided that development is based on a sound understanding of the strategy making task. >"
2260855,22457,8228,On the superdistribution of digital goods,2008,"Business models involving buyers of digital goods in the distribution process are called superdistribution schemes. We review the state-of-the art of research and application of superdistribution and propose systematic approach to market mechanisms using super-distribution and technical system architectures supporting it. The limiting conditions on such markets are of economic, legal, technical, and psychological nature."
2322539,22457,20561,Re-Visiting the Knowledge Pyramid,2009,"The knowledge pyramid has been used for several years to illustrate the hierarchical relationships between data, information, knowledge, and wisdom. This paper posits that the knowledge pyramid is too basic and fails to represent reality and presents a revised knowledge pyramid. One key difference is that the revised knowledge pyramid includes knowledge management as an extraction of reality with a focus on organizational learning. The model also posits that newer initiatives such as business and/or customer intelligence are the result of confusion in understanding the traditional knowledge pyramid that is resolved in the revised knowledge pyramid."
276014,22457,20561,LL-ADR: Action Design Research in Living Labs,2015,"Design Science research is a mainstream Information systems discipline, yet Living Lab literature seems not to leverage its insights. The paper describes how Living Labs can be conducted as Design Science Research (DSR) by adapting the Action Design Research method. The resulting method is named LL-ADR. A case is presented to indicate how LL-ADR can be applied and findings for both Living Labs and DSR are discussed."
421952,22457,20561,Tell it Like it Seems: Challenges Identifying Potential Requirements of a Learning Health System,2015,"This paper provides a review of some previously identified requirements of a learning health system, a post hoc analysis of narrative artifacts describing a learning health system, and some new potential requirements of a learning health system. Engaging a transdisciplinary group of researchers and health care practitioners, we used a method of group conceptualization to elicit potential requirements of a learning health system. Several unresolved challenges of creating and using narrative stories, diagrams and storyboards to elicit and share the potential requirements of a learning health system amongst a diverse group of researchers are discussed."
1996764,22457,20561,On the Syntax and Semantics of Architectural Principles,2006,"This paper illustrates why architectural principles are important for IT management and how the principles can be used. By analyzing architectural principles at an enterprise, knowledge is gained on how to formulate principles so that they are an effective steering tool. This knowledge is transformed into a framework for formulating architectural principles. The analysis of the architectural principles has been performed from two different angles; have we got the principles right (syntax) and have we got the right principles (semantics). The industrial case is complemented with examples from literature."
1934179,22457,20561,"The Effect of Individual Needs, Trust and Identification in Explaining Participation Intentions in Virtual Communities",2007,"This paper studied individuals' intentions to participate in virtual communities. In order to assess what influences participation intentions, we studied individual-based factors (members' social needs and self expression needs), trust and identification. We found that although needs deficiency-based motivation theory is useful to explain participation intentions, trust and identification play an important moderating role"
2002824,22457,20561,Policy implications of organizational decision support systems,1996,"Many organizations are consolidating their data, models and information resources to create an organization wide system, called organizational decision Support system (ODSS). The paper discusses issues related to ODSSs and their policy implications. Issues are identified from ODSS definition. Specifically, we group the issues as data, model/tool and overall systems and consider policy related to each of these in the context of ODSS."
2532397,22457,20561,Geographic variation in Internet connectivity,1996,This paper presents a measure of Internet connectivity (number of connected companies per capita) normalized by the economic size of areas in the United States. We use cross sectional variation in connectivity to test some hypotheses about technology adoption. We find that areas in the South and Midwest have below average connectivity. Connectivity is also related to the living attractiveness of an area.
1540398,22457,20561,New Problems for Old? Defining e-Governance,2011,"This paper explores the question of whether there are any material differences between e-governance and traditional concepts of governance? It proposes a definition of governance that differentiates between structural and normative governance and examines the influence of ICT on two examples of each of these. It argues that while ICT has little effect in some aspects of governance, it has a considerable impact in others and is likely to pose new challenges in the near future."
2724583,22457,20561,Individual Support in Industrial Production -- Outline of a Theory of Support-Systems,2016,"Many different production systems for supporting, assisting or helping people at work are already available and even more will be developed in future. Such systems come in various forms and characteristics. This paper will introduce some first steps toward a theory of support-systems. It will focus on individual forms of employee support. The theory will be illustrated by exemplary solutions."
2229998,22457,20561,The impact of critical success factors across the stages of enterprise resource planning implementations,2001,The paper describes the impact of critical success factors (CSFs) across the stages of enterprise resource planning (ERP) implementations using the responses from 86 organizations that completed or are in the process of completing an ERP implementation. Our results provide advice to management on how best to utilize their limited resources to choose those CSFs that are most likely to have an impact upon the implementation of the ERP system.
2232324,22457,20561,Guidelines for designing evaluations of Web-based instructional materials,2002,"This paper is are overview of central issues for effective evaluation of Web-based instructional materials. It describes relevant issues from the perspectives of practitioners in the fields of computer science, educational psychology, and teacher education. In addition, it describes educator concerns, reviews relevant aspects of HCI, usability, and educational research, and provides an overview of usability evaluation."
1513885,22457,20561,"Introduction to Electronic Government Education, Training and Professionalization Minitrack",2013,"This paper introduces the objectives and content of the minitrack on Electronic Government Education, Training and Professionalization, organized as part of the Electronic Government Track at the 46th Hawaii International Conference on System Sciences, 7-10 January 2013, Hawaii, USA. After explaining the rationale, scope and topics of the minitrack, the paper presents the summaries of all accepted papers."
1067684,22457,20561,"Initial Case Study on the Good, the Bad and the Ugly Aspects of a New MSc Program in Computer Forensics and E-Discovery",2010,"There are a number of critical factors that will affect the success of new MSc programs in Digital / Computer Forensics and E-Discovery. This paper presents the idea that there are essential, basic criteria that need to be identified, defined and addressed from a student's perspective when examining an MSc program in Digital / Computer Forensics and E-Discovery. This paper makes two contributions. The criteria presented in this paper can be used to help assess an existing MSc program from a student's perspective and it can also be used as a guide to the development of new MSc programs."
2193883,22457,20561,Requirements for distributed virtual environments on the Internet,1997,"We examine the basic requirements for large scale virtual environments distributed on the Internet: a platform independent description of virtual worlds, support for multi user collaboration, the network infrastructure required to realize these features, and support for partitioned worlds. We show how we address these issues in our current prototype based on VRML (the Virtual Reality Modeling Language)."
2200394,22457,20561,The Effects of Competition and Time Constraints on Knowledge Transfer: Exploratory Findings from Two Experiments,2009,"This paper presents two experiments that examine the possible effects of competition (individual and team), and time constraints on knowledge hiding and knowledge sharing. Results suggest that competition plays a stronger role in knowledge sharing behaviors, but less of a role in knowledge hiding behaviors, while time, although a common excuse for not sharing, is not associated with knowledge hiding or sharing behaviors. Implications for research and practice are discussed."
2430860,22457,20561,"IT Governance Structures, Processes and Relational Mechanisms: Achieving IT/Business Alignment in a Major Belgian Financial Group",2005,"IT governance is one of these concepts that suddenly emerged and became an important issue in the information technology area. Some organisations have started with the implementation of IT governance in order to achieve the fusion between business and IT. This paper describes how an organisation can implement IT governance, using a mixture of processes, structures and relational mechanisms, and analyses the IT governance implementation at KBC, a major Belgian financial group."
423315,22457,20561,Practising what we preach: are knowledge management systems in practice really knowledge management systems?,2002,"Knowledge management systems (KMS) are predominant in both theory and practice. However, are the same systems discussed in theory actualised in practice? By comparing and contrasting KMS in theory and practice, this paper demonstrates that they are indeed dissimilar. In theory, KMS have both subjective and objective components. In practice, only the objective component of KMS appears to be actualized; hence, these KMS in practice are essentially organisational memory systems at best and not KMS at all."
709808,22457,20561,Antecedents to Stigma: Factors That Diminish IT Value,2013,"This research presents a technology stigma framework by using the lens of stigma and stereotypes to explore the possible relationships between negative labels, stereotypes, and stigma on IT professionals. The primary focus of this study was to conduct and analyze interviews with IT professionals to explore and identify the antecedents to stigma. The differences between IT professionals and users as well as IT professionals and peers are explicated and identified to illustrate the occurrence of stereotyping among and between the various groups."
2506153,22457,20561,Overcoming barriers to distributed interorganizational systems,1997,"We examine the challenges associated with implementing distributed interorganizational systems (DIOS), which can play an enabling role in information sharing required by many organizational forms. In particular, we discuss the role that middleware and information infrastructures play in facilitating DIOS. An example of how an infrastructure is used is discussed. Also, a research agenda is presented which, when completed, will enhance understanding of the role of middleware and information infrastructures in enabling DIOS."
2257429,22457,20561,Bounded Ideation Theory: A New Model of the Relationship Between Ideaquantity and Idea-quality during Ideation,2007,This paper presents bounded ideation theory (BIT) to explain the relationship between the number-of-ideas and the number-of-good-ideas contributed during ideation. BIT posits that certain cognitive and physical boundaries cause the ideation function to be an inflected curve that transitions from a positive-but-increasing slope to a positive-but-decreasing slope. We then present implications of the theory for process design
988157,22457,20561,Minitrack Virtual Communities,2007,"Virtual Communities have been studied from a variety of perspectives. Examples range from communities of interest to communities of practice, from gaming communities to communities of transaction. More specifically, community building and community management may be factors of key success in the digital economy. They may represent new business models in the digital economy, as well as being new venues of social interactions and social relationships."
1379828,22457,20561,"Electricity Restructuring, Consumer Prices and the Cost of Capital: Lessons for the Modeling of Future Policy",2014,"Electricity industry restructuring in both the United Kingdom and the United States failed to produce the expected lower prices to consumers, and the industry now is reverting to regulatory-like mechanisms to attract capital for the construction of new power plants. This analysis focuses on factors, unanticipated by system-analysts and policy-makers, which may be responsible for these outcomes."
1105962,22457,20561,Search and Graphical Visualization of Concepts in Document Collections Using Taxonomies,2013,The main idea of this paper is the search for semantic concepts in documents using taxonomies. The concepts to discover are represented by general taxonomy trees which can be combined to express more sophisticated concepts. The proposed algorithm allows the ranking of documents according to the relevance of the queried concepts as well as a graphical representation of the detected concepts inside a document based on a quantified version of the taxonomy trees.
1715538,22457,20561,"Introduction to The Humanized Web: Networks, Crowds, and Their Output Minitrack",2014,"Internet technologies now make it possible to produce new ideas, products, and services by catalyzing large scale social networks and crowds. The papers discussed here provide a cross-section of current research into human-centric computing on the web, covering user participation, political activism, user-generated recommendations, and user innovation."
2330170,22457,20561,Supporting Knowledge and Expertise Finding within Australia's Defence Science and Technology Organisation,2007,"This paper reports on work aimed at supporting knowledge and expertise finding within a large research and development (R&D) organisation. The paper first discusses the nature of knowledge important to R&D organisations and presents a prototype information system developed to support knowledge and expertise finding. The paper then discusses a trial of the system within an R&D organisation, the implications and limitations of the trial, and discusses future research questions"
1387041,22457,20561,Multi-Method Virtualization: An Architectural Strategy for Service Tuning,2010,A wide variety of virtualization methods have recently come into common use. Using these methods as a suite of tools to tune service offerings has becoming a viable strategy for enhancing an Academic Research Network (ARNe) as it services a globally dispersed user population. This report will present a model for organizing and applying these virtualization methods to maximize service efficiency.
2498369,22457,20561,Benefits Management and Strategic Alignment in an IT Outsourcing Context,2007,"It is important to understand the factors that influence the success of IT outsourcing, since IT outsourcing touches the core of organizations. The hypothesis in this article is that benefits management and strategic alignment influence the success of IT outsourcing. The research question is 'do strategic alignment and benefits management contribute to the success of IT outsourcing relationships?' To answer this question, a multiple case study strategy is used. The results support the research hypothesis; benefits management and strategic alignment have a positive effect on the success of IT outsourcing"
303773,22457,20561,MaXCept -- Decision Support in Exception Handling through Unstructured Data Integration in the Production Context: An Integral Part of the Smart Factory,2015,"Today, data from different sources and different phases of the product life cycle are usually analyzed in isolation and with considerable time delay. Real-time integrated analytics is especially beneficial in a production context. We present an architecture for data- and analytics-driven exception escalation in manufacturing and show the advantages of integrating unstructured data."
1073354,22457,20561,Introduction to Organizational and Social Dynamics in Information Technology Minitrack,2012,"This track addresses social issues related to information technology. Social issues are those research topics most aligned with the human factor in terms of information systems planning, development and utilization. The minitrack contains the following paper topic areas and addresses key topic areas related to (1) trust, (2) relationships, (3) human interaction, (4) diversity and culture in the IT workforce, among other social and IT issues."
1583634,22457,20561,Does SEO Matter? Increasing Classroom Blog Visibility through Search Engine Optimization,2013,"Educators today motivate learning and foster engagement through the use of Web 2.0 software such as classroom blogs. In this study, we discussed the reasons and benefits of moving classroom blogs to the public, and how Search Engine Optimization (SEO) strategies from industry can help increase classroom blog visibility. We proposed an SEO approach and demonstrated how it can be applied to the design, implementation, and analysis classroom blogs in higher education through an empirical study."
2353025,22457,20561,E-Evidence and International Jurisdictions: Creating Laws for the 21st Century,2011,This paper explores what laws and procedures a country entering the international cyber arena needs to have in place. Developing nations are creating their e-laws and e-commerce laws to do business in today's world. They can leap frog over the existing countries and laws to learn what works and what doesn't. This paper explores the existing international digital laws and some of the challenges that will be faced as technology advances at its current pace.
2352298,22457,20561,Classifying Knowledge Management Systems Based on Context Content,2006,"This paper discusses using users and the amount of context captured by a Knowledge Management System as the basis for classifying systems. The paper discusses previous classification schemes and concludes they arent helpful as Knowledge Management in an organization encompasses all the classification criteria in an ongoing basis. Ultimately, it is concluded that classifying the system based on the context for the captured knowledge being stored in the users heads or as part of the knowledge base is the appropriate method."
1785656,22457,20561,Information technology investment and firm performance: a meta-analysis,2004,"In the recent past, researchers have shown conflicting results regarding the returns to IT investment. Some researchers posit that the equivocal results of IT investment are due to inconsistent measurement of firm performance following IT investment. We propose to use meta-analysis to summarize and synthesize the patterns of relatively consistent relations from empirical studies of IT investment returns during the last decade."
1783230,22457,20561,Back to the wall: home video and digital decorating,1996,"The paper describes the experimental use of home video images as source materials for home decoration. It includes a brief description of the reasons for the experiment, as well as the equipment and software used. The remainder of the paper examines issues raised by the potentials offered by the availability of film titles in electronic form, and their use as sources in digital media."
308303,22457,20561,Intellectual property and open systems,2002,"Arguably, the most profound issue in designing and governing cyberspace focuses on intellectual property. Is cyberspace to be created as a common space - belonging to and used freely by the community as a whole - or is it to be partitioned into a multitude of proprietary closed boxes that are owned and sold, distributed, modified and used only according to the owner's whims? This paper discusses answers to this question."
1929043,22457,20561,IT and institutional constraints: effects of legal and administrative constraints to use it in production of health care services - focus on Finland,2003,This paper looks into the legal and administrative frameworks governing the different aspects of using IT as a medium and a tool in production of health care services. The administrative framework is described from the point of view of the status quo in Finland. The issues are elaborated by a discussion of a number of legal aspects and a short description of normative insights from actors in the health care production collected through a survey.
255148,22457,20561,Stochastic Modeling of Multi-area Wind Power Production,2015,In this paper we present a stochastic model for multi-area wind production that is used for planning reserves in transmission-constrained systems with large amounts of integrated renewable power supply. The stochastic model accounts for the inter-temporal and spatial dependencies of multi-area wind power production. Results are presented for two case studies of the California and the German power system.
343921,22457,20561,Convergence of telephony and cable: vital step in the creation of an information superhighway,1995,"This paper argues that an essential step in the evolution to the information superhighway, is the convergence of a host of discrete information industries into one. Most importantly among these is the integration of the telephony and CATV networks. This convergence is occurring primarily because of changing technological and competitive forces. The integration of these networks is not only inevitable but will provide significant benefits in the area of economics, education and the environment. >"
2267263,22457,20561,Just Right Outsourcing: Understanding and Managing Risk,2005,"The risks associated with outsourcing have been the principal limitation on the growth of business process outsourcing, especially cross border outsourcing. Technological improvements in risk management have lead to the dramatic increase in outsourcing in India. Further progress now comes from redesigning work flows and dividing work among multiple vendors, increasing the range of tasks that are now appropriate candidates for outsourcing."
1584162,22457,20561,Effect of Task Mental Models on Software Developer's Performance: An Experimental Investigation,2012,"This study provides some preliminary results on the efficacy of mental models in software development. Specifically, based on results from a controlled laboratory experiment, it shows that a software developer's mental model quality is a determinant of software quality performance, regardless of whether the task is performed individually or in pairs. Further, this effect is found to be consistent across software tasks of varying complexity."
2077328,22457,20561,Exploring the Impact of IS Theory on Health Informatics,2015,"We report the results of a citation analysis of the Health Informatics literature. The study takes the health informatics literature as its starting point, looking inward at the IS literature to seek evidence for the impact of IS theories in healthcare environments. A review of 286 references from the Health Informatics discipline confirms findings of earlier studies that the technology acceptance model is the dominant theory in use with some adaptations emerging."
1235634,22457,20561,Barriers to Project Performance,2013,"This paper contributes to our understanding of how the performance of IT projects might be improved. It identifies the need for including drivers of failure and underperformance in models of project performance and proposes such a model, focusing on organizational capabilities available to apply to projects. Barriers to learning and capability development are proposed that can offset capability accumulation, reducing the organization's ability to perform well."
2074406,22457,20561,Prioritising and Linking Business and IT Goals in the Financial Sector,2007,"IT governance and strategic alignment are issues that are high on the agenda in many organisations. To address those challenges, it is important that an organisation has a good view on its business goals and how IT goals and IT processes support the achievement of those goals. This research is aimed at providing guidance in building up such a cascade of business goals, IT goals and IT processes. This research builds on the list of business goals and IT goals, provided in COBIT4.0, and further validates and elaborates this material leveraging the Delphi research method"
2147522,22457,20561,Analysis of Overlay Network Impact on Dependability,2005,"Recently, peer-to-peer systems have become widely accepted and are probably the most recognizable examples of distributed applications. As they are maturing and their functionalities are becoming increasingly complex, the need for dependable solutions arises. In particular peer-to-peer systems' dependability is immensely influenced by their virtual overlay networks. The paper presents the results of analysis of diverse overlay networks with respect to their support for dependability."
2352317,22457,20561,The 'vanishing' IT productivity: a simple theory,2003,The perceived phenomenon that huge investments in information technology (IT) over the past four decades have yielded a very small gain in productivity has been dubbed the IT paradox. Researchers have tried various methods to prove or disprove the paradox. This article highlights the challenges researchers have faced and proposes a simple theory to explain what seems to be a vanishing contribution of IT to productivity growth.
2340904,22457,20561,Cross - Border Public Services: Analysis and Modeling,2007,"This paper describes our work in the field of semantic interoperability in Pan-European Public Services. After introducing a layered interoperability model, a typology of Pan-European Public Services is provided. This typology expresses our view on cross-border services and analyzes the heavily-used cross-border services term. Furthermore, we identify some recurring patterns of semantic interoperability conflicts in public service provision as they occur in a cross-border setting"
2273616,22457,20561,Introduction to IT Governance and Its Mechanisms Minitrack,2012,"IT governance or enterprise governance of IT is an integral part of corporate governance and addresses the definition and implementation of processes, structures and relational mechanisms in the organization that enable both business and IT people to execute their responsibilities in support of business/IT alignment and the creation of business value from IT-enabled business investments. The Minitrack is introduced in 2002. The goal is to enhance publications on the issue of IT governance and its mechanisms."
1791315,22457,20561,Individual Learning and Performance in Communities of Practice,2008,"This study examines the relationships among individuals' involvement in communities of practice (CoPs), learning, and job performance. Drawing on the CoP and learning literatures, we develop a theoretical model exploring how individuals' involvement in CoPs affects their learning and job performance. The model is tested using survey data collected from graduate students in a large Canadian university. Results support the hypothesis that CoP involvement is related to learning, and reveals a complex relationship between learning and job performance."
1972843,22457,20561,Philosophical Requirements of a Comprehensive D.I. System for Collaborative Modeling,2011,"This paper revisits the concept of dialectical inquiry (DI) from the perspective of collaborative modeling for collaboration engineering. It does so by integrating the recent literature with its theoretical and philosophical sources. The connection of DI and the problem framing paradigm is clarified. The paper also establishes the general requirements or desired features of an up-to-date DI system, and evaluates some current systems in light of these criteria."
651909,22457,20561,An approach to characterization of parallel applications for DSM systems,1998,"The paper concentrates on the problem of defining and measuring parameters that characterize behavior of parallel applications targeted to DSM (distributed shared memory) systems. Results are based on the SPLASH-2 application suite. The developed characterization tool Scopa, along with applied simulation environment Limes, are publicly available, and appropriate for performing measurements on other parallel applications, as well."
2489466,22457,20561,Unsocial Networks Restoring the social in social networks,2009,"This paper discusses multiple meanings of the idea of social networks. It discusses how the most common view of social networks in Information Systems, as the result of the interaction of autonomous agents, could be tested. It then introduces research that falsifies that premise. It introduces an alternative view of social networks that comes from sociology and discusses how Information Systems could make significant contributions to social science and be more of a natural science."
691519,22457,23827,Sketching software in the wild,2013,"This paper argues that understanding how professional software developers use diagrams and sketches in their work is an underexplored terrain. We illustrate this by summarizing a number of studies on sketching and diagramming across a variety of domains, and arguing for their limited generalizability. In order to develop further insight, we describe the design of a research project we are embarking upon and its grounding theoretical assumptions."
2210642,22457,20561,Making the requirements of process controlled systems explicit,1995,"Process controlled systems are used for dedicated applications. Every application is the subject of special requirements enforced by the customer. Requirements modelling is an user centred activity. These systems are time critical. The requirements modelling language used must facilitate the description of temporal requirements that are meaningful for these systems, while being understandable by user community. Here we discuss a language (TRL) and its features. >"
1573324,22457,20561,Contrasting the Dimensions of Information Quality in Their Effects on Healthcare Quality in Hospitals,2013,"This study examines the relationships between the dimensions of information quality and healthcare quality. Past studies have confirmed a positive relationship between these two constructs, however, the relationships among the underlying dimensions of the constructs have not been explored. One of the primary purposes of this study is to show that different dimensions of information quality have different relationships with dimensions of healthcare quality. As the paper indicates, this development has implications for researchers and practitioners interested in these two constructs."
2239567,22457,20561,"Exploring the Relationships among Corporate Entrepreneurship, IT Governance, and Risk Management",2011,"This study develops a more comprehensive picture of how a hospitals' entrepreneurial behavior influences its focus on IT governance and IT risk management. The key findings of this study contribute to the IT and corporate culture literatures in several ways. First, it presents corporate entrepreneurship as an antecedent to both IT governance and IT risk management. Second, it establishes a causal relationship between IT governance and IT risk management. Third, it introduces culture strength as moderator of the relationship between corporate entrepreneurship and IT risk management."
1944017,22457,20561,Knowledge-based systems support for information centers,1988,"The Information Center Expert (ICE) project, which attempts to provide knowledge-based support for information centres (ICs), is described. The project has three divisions, corresponding to the three areas of responsibility for information centers: Information Center Expert for Consultation, Distribution, and Help-Service (ICE/C, ICE/D, and ICE/H). The authors present the ICE/C architecture and discuss functional extensions to ICE/C, i.e., ICE/D and ICE/H for supporting the other responsibilities of the IC. An approach to knowledge elicitation using a group decision support environment is presented. The use of an object-oriented approach as a representation technique is discussed. >"
2204980,22457,20561,"Users' experiences in collaborative writing using Collaboratus, an Internet-based collaborative work",2002,"This paper reviews several user experiences that researchers at the University of Arizona have had in building Internet-based tools to support collaborative writing. First, the technological framework for an advanced collaborative writing tool called Collaboratus is presented. Next, we review the tools that make up Collaboratus, and then provide an overview of the various user experiences we have had. Finally, many suggestions are provided for developing the next generation of collaborative writing tools."
2145111,22457,20561,Design of an argumentation-based negotiation support system,1995,"This paper proposes a framework to model the negotiation process using a dialectic based argumentation language, which preserves and captures the qualitative aspects of the negotiation process. The argumentation language helps in representing the structure of the negotiation process and provides a normative argumentative evaluation methodology to represent and capture the roles played by the different participants in the negotiation process. The design of a prototype negotiation support system is described along with its intended use. >"
2714517,22457,20561,"Introduction to Big, Open and Linked Data (BOLD) in Government Minitrack",2016,"The minitrack Big, Open and Linked Data (BOLD) in Government aims at advancing our knowledge in this field. Open, big and linked data is a thrilling research field as more and more structured and unstructured sources are combined to create smart applications. Data governance will likely become more important in which redundant data and wrong data is reduced and data can be reused for various purposes."
326059,22457,20561,Introduction to Policies and Strategies for Digital Government Minitrack,2015,This year this minitrack explores the increasing importance of e-governance and the challenges for governance associated with the adoption and use of information technology in public administration. The importance of collaboration and new forms of governance to the success of e-governance projects are the core issues discussed in two of the papers. The question of value creation and ethics in e-government deployment is also addressed in the papers selected for the track.
874474,22457,23827,Co-Operative Method Development revisited,2005,"During the last five years, we applied a research approach we call 'Co-operative Method Development' formulated on first experience with empirical research focusing especially on the social side of software engineering. This position paper summarizes the experiences and discusses the improvement and further development of this research approach based on our experiences in different research projects in co-operation with industrial partners."
2272062,22457,20561,A distributed method for solving nonlinear equations applying the power load flow calculation,1997,"A new approach for distributed power load flow calculation using nonlinear equations is presented. This approach, which is similar to the Newton Raphson's simple method, uses an inverse Jacobian matrix of initial states for the iteration process. Moreover, nonlinear quadratic equations have been used as they are more appropriate for the distributed power load flow calculation. The paper describes and compares the new approach with the Newton Raphson method. It shows that such an approach is more suitable for distributed power load flow calculation as well as discussing some of its applications."
2147603,22457,23827,A Study on Issues in Context-Aware Systems Based on a Survey and Service Scenarios,2009,"To realize a practical context-aware system, we should be clearly aware of important issues in context-aware systems. In this paper, we review a wide range of existing researches and the history of context-aware systems. We derive technical issues on realizing context-aware services based on the history and explain them. In addition, we describe seven context-aware service scenarios and discuss related issues. We believe that the derived issues from our survey and the proposed service scenarios will be used as useful reference for future researches."
1587521,22457,20561,Measuring Boundary Objects in an Attempt to Explain Innovativeness,2013,"This study explores types of boundary objects, their relationships, and their effect on project innovativeness in the context of systems analysis. Four types of boundary objects are identified and their content discussed. Based on data collected from 258 student analysts, the results indicate that out of syntactic, semantic, pragmatic and metaphoric boundary objects, only pragmatic boundary objects had a strong positive effect on project innovativeness. Metaphoric boundary objects are shown to have positive effect on all other three types of boundary objects. Metaphoric boundary object affects project innovativeness indirectly through pragmatic boundary objects. Surprisingly, semantic boundary objects negatively affect project innovativeness, although not very strongly. A practical implication is the possibility of increasing project innovativeness by enhancing both pragmatic boundary objects and metaphoric boundary objects."
444891,22457,20561,Information systems development by US-Norwegian virtual teams: implications of time and space,2002,"We develop an understanding of how collaboration is possible among virtual team-members spread across the globe in time and space. We do so by interpretively examining communication patterns of virtual team-members located in the US and Norway, engaged in systems development projects for actual clients. A number of collaboration inhibitors are identified, along with strategies used by team-members to bridge the time-space divide."
2450489,22457,20561,Reengineering and adaptation in evolutionary interactive multi-objective linear programming,1996,"The paper shows how a formal modeling framework, evolutionary systems design (ESD), for evolutionary problem definition and solution, can be used for problem adaptation and restructuring (i.e., reengineering) in optimization problems, as developed for multiobjective linear programming (MOLP). Restructuring through a heuristic controls/goals/values referral process and adaptation are discussed for interactive MOLP, and illustrated by a numerical example."
673835,22457,20561,Innovation in business processes-a discussion of research methods to study the process of innovation,1995,"Our primary concern is innovation in business processes, especially with focus on how to analyze occurrences of radical innovation as a result of business process redesign (BPR) projects. BPR is a new field, and there has so far been little development of theories and methodology in the area. Important questions we address are: can BPR and innovation in business processes be studies according to the same principles as used in studies of information systems, what are the consequences of this alternative, and do we have other alternatives?. >"
2692867,22457,20561,"Introduction to Gamification: Motivations, Effects and Analytics Minitrack",2016,"During the last decade games have become an established vein of entertainment, and consumer culture, and essentially, a common part of people's daily lives. In the United States alone 59% of the population plays computer games while revenues of the computer games industry exceed US $15 billion (ESA, 2014). However, in addition to the increased penetration of games, also the ways in which people play and employ games have become more varied. The long-tail is getting longer: there are more different kinds of games available for a multitude of different platforms that cater for differing gaming needs for widening audiences, and which use a wide variety of business models. Perhaps the most prominent advancement stemming from these developments is gamification which generally refers to the increased convergence of games and everyday life. More particularly and practically, gamification commonly refers to the process of enhancing services and systems so that they increase enjoyable and intrinsically motivated use as well as support further behavioral change by employing elements characteristic of games - Transforming Homo Economicus into Homo Ludens. The Gamification: Motivations, Effects and Analytics -minitrack was established to address this growing junction of interests of both scholars and practitioners where games, services and information systems meet and merge. Even though this minitrack is featured at HICSS for the first time and there were two other minitracks competing for game-related submission, this minitrack managed to receive more submissions than the competing tracks as well as an amount of submission that is on par with other popular, more established minitracks. Ultimately, six high quality papers that cover gamification from diverse perspectives were accepted to be presented across two sessions. Gamification is still a rather novel development that suffers from growing pains, and therefore, it has still been under significant conceptual chaos and theoretical turbulence. In Reimagining gamification through the lens of Activity Theory, Hendranus Vermeulen, James Gain, Patrick Marais and Siobhan O'Donovan seek to contribute to the conceptual and theoretical understanding of gamification by identifying some of the pitfalls in how gamification has been currently conceptualized and perceived, and offering an alternative dialectical perspective for gamification that is based in activity theory. Even though gamification has been very transparently and pervasively acknowledged to be one of the big technology trends during the recent years both in academia and in industry, it has remained opaque as to what kind of technology is being developed around it as well as what kinds of patents companies are filing related to gamification. In Monitoring Gamification in International Patent Documents: Technology Classes, Firms and Preliminary Value Indicators, Patrick Julian H -- flinger and Eric Zimmerling investigate the international patent documents (from EPO, USTPO and Google Patents) in order to discover what kinds of patents are been filed related to gamification, in which classes of patents and who is filing them. The analysis provides interesting insights in the otherwise previously unexplored area of patents and company interests related to gamification. Increased competition is repeatedly touted as a detrimental side effect of leaderboards and other competition-inducing game mechanics. On the other hand, competition can also potentially increase task performance (at least on the short term). Therefore, competition is a complex issue, and currently, there has been a gap in our knowledge concerning the benefits and detriments of competition. In When Competition is the Loser, Robin Brouwer untangles how intra-team competition affects perceived task complexity, perceived psychological safety, level of team conflict as well as team performance. The use of information systems and services in healthcare is one of the largest and most impactful areas in HICSS-related sciences. Gamification especially can be seen as a crucial development in this area since one of the main strengths of gamification has been deemed to be its ability to motivate people to take on and maintain difficult habits. In Design Strategies for Gamified Physical Activity Applications for Older Adults, Dennis Kappen, Lennart Nacke, Kathrin Gerling and Lia Tsotsos explore and suggest design guidelines as to how playful and gameful systems could be harnessed to motivate older adults to maintain physical activity and wellbeing. The authors specifically investigate needs and preferences regarding technologies that support physical activity via semi-structured interviews with 19 older adults and a focus group. Similarly, another promising application areas of gamification has been regarded to exist in supporting sustainable and safe behaviors. In The Impact of Gamification-Induced Emotions on In-Car IS Adoption -- The Difference between Digital Natives and Digital Immigrants, Carolin Ebermann, Everlin Piccinini, Benjamin Brauer, Sebastian Busse and Lutz Kolbe investigate how users' experiences and interactions in an in-car gamification system vary based on their 'digital nativeness' and thus attempt to find optimal ways to design driving-related gamification systems for different kinds of users. Alongside with more traditional game design elements, virtual economies with their virtual currencies and virtual goods have also been shaping gamification designs. In Why do People Buy Virtual Goods? A Literature Review, Juho Hamari and Lauri Keronen seek to address the question of why do people purchase virtual goods by investigating and synthesizing past (quantitative) literature. Firstly, the study provides an overview to the literature, what, how and where the phenomenon has been studied before. Secondly, by combining results of past literature, the study aims to provide a more reliable, literature spanning look at which factors drive purchase behavior towards virtual goods."
1599992,22457,20561,Introduction to the asynchronous learning networks mini-track,2001,"As described in the call for papers, Asynchronous Learning Networks (ALNs) use computer-mediated communication to support online courses of study. ?Asynchronous? refers to anytime, anywhere access to interactions among the students and the teacher/facilitator via the Internet, as a key element. The ?Learning Network? refers to the community of learners who work together to build and share knowledge. The asynchronous nature of the interaction leads to new paradigms for teaching and learning, with both unique problems of coordination and unique opportunities to support active, collaborative (group or team-based) learning. Although ALN's have existed since the early 1980's, there are still many unresolved research questions and issues. The two groups of papers selected focus on two of these issues. One is, how do software, teaching and the role behavior of both students and teachers have to change in order to be most effective online? The paper by Coppola and colleagues is based on semi-structured interviews with faculty members, and describes the overall nature of role changes that are involved in ?becoming a Virtual Professor.? They found changes in the cognitive, affective, and emotional roles of faculty, part of an overall shift towards becoming a ?digital Socrates.? The work by Dufner, Kwon and Rogers describes a pilot study of the use of what they call a ?CyberCollaboratory.? Whereas most ALN environments have group discussion (computer-mediated conferencing) and Email, and many have synchronous chat, they have created an enriched environment for student collaborative work, which includes Group Decision Support Tools and Collaborative Document Production. If mastery of the material in a course can be validly measured by objective questions, then there is a variety of software that can provide online testing. However, what if performance in a course requires essay type questions and problems? What is the appropriate way to assess performance in such cases, other than requiring distance students to find in-person proctors? One possibility is to actually assess students based on the quality and Nulden and his colleagues examine quantity of their online participation- the pros and cons of such ?mandatory participation as examination?. Another possible approach, a totally collaborative examination process in which the students make up the questions and grade each other, as well as answering questions, is the online pedagogical innovation documented in the case study by Shen et. al. A second research question is, how effective are ALN courses, particularly as they compare to courses delivered by traditional face-to-face mode? Spencer and Hiltz survey 30 published empirical studies of ALN's. The majority are case studies of a single course, often by the instructor who taught it. Of the 15 studies that compare modes of delivery, five report that ALN is as effective as traditional delivery methods, and ten report that the results are better in some way. Levin, Levin and Waddoups report data on an entire online master's program at the university of Illinois. One measure of its extraordinary success is that all 26 of the students who started in the summer of 1998 graduated in May 2000.They conclude that ?building and maintaining a learning community? is extremely important in achieving success. They also emphasize that it is ?critical? to implement systematic program evaluation, to use it both formatively in improving the program, and to provide guidance to others for improving future online efforts. Finally, Benbunan et. al. use content analysis to look at how interaction differs between online and face-to-face teams engaged in a case study assignment. The face-to-face and online teams used different coordination strategies in their work. The findings are that ALN-mediated groups had broader discussions and submitted more complete reports than their manual counterparts.Among the issues not touched on in this group of papers is how specific characteristics of the technology used may improve or detract from ALN effectiveness and influence the roles played. For instance, what system features are especially helpful to support a rich online discussion and teamwork? For one-way delivery of materials such as lectures, is there any difference between videotapes, and Powerpoint plus Audio via the Web? Does including some synchronous (same time) sessions add to or detract from the building of the learning community? Hopefully future research will also look at these research questions."
2958825,22457,20561,Automated Anomaly Detection in Distribution Grids Using uPMU Measurements,2017,"Automated Anomaly Detection in Distribution Grids Using µ PMU Measurements Mahdi Jamei ∗ , Anna Scaglione ∗ , Ciaran Roberts † , Emma Stewart † , Sean Peisert † , Chuck McParland † , Alex McEachern ‡ , ∗ School of Electrical, Computer, and Energy Engineering, Arizona State University, Tempe, AZ, USA † Lawrence Berkeley National Laboratory, Berkeley, CA, USA ‡ Power Standards Laboratory, Alameda, CA, USA Abstract—The impact of Phasor Measurement Units (PMUs) for providing situational awareness to transmission system op- erators has been widely documented. Micro-PMUs (µPMUs) are an emerging sensing technology that can provide similar benefits to Distribution System Operators (DSOs), enabling a level of visibility into the distribution grid that was previously unattainable. In order to support the deployment of these high resolution sensors, the automation of data analysis and prioritizing communication to the DSO becomes crucial. In this paper, we explore the use of µPMUs to detect anomalies on the distribution grid. Our methodology is motivated by growing concern about failures and attacks to distribution automation equipment. The effectiveness of our approach is demonstrated through both real and simulated data. Index Terms—Intrusion Detection, Anomaly Detection, Micro- Phasor Measurement Unit, Distribution Grid I. I NTRODUCTION The state vectors of the transmission grid are closely monitored and their physical behavior is well-understood [1]. In contrast, Distribution System Operators (DSOs) have historically lacked detailed real-time actionable information about their system. This, however, is set to change. As the distribution grid shifts from a demand serving network towards an interactive grid, there is a growing interest in gaining situational awareness via advanced sensors such as Micro- Phasor Measurement Units (µPMUs) [2]. The deployment of the µPMUs in isolation without addi- tional data driven applications and analytics is insufficient. It is critical to equip DSOs with complimentary software tools that are capable of automatically mining these large data sets in search of useful, actionable information. There has been a lot of work focused on using PMU data at the transmission level to improve Wide-Area Monitoring, Protection and Control (WAMPC) [3], [4]. The distribution grid, however, is lagging in this respect. Due to inherent differences between operational behavior, such as imbalances and increased variability on the distribution and transmission grid, the algorithms derived for WAMPC at the transmission level are generally not directly applicable at the distribution level. Our work is aimed at addressing this issue. We focus on an important application of µPMU data in the distribution system: anomaly detection, i.e., behavior that differs significantly from normal operation of the grid during (quasi) steady-state. An anomaly can take a number of forms, including faults, misoperations of devices or switching transients, among others, and its root cause can be either a natural occurrence, error or attack. The risk of cyber-physical attacks via an IP network has recently gained significant interest due to the increase in automation of our power gird via two-way communication. This communication is typically carried out on breachable networks that can be manipulated by attackers [5]. Even if an anomaly naturally occurs, it is important to notify the DSO to ensure proper remedial action is taken. A. Related Work The majority of published work in anomaly detection using sensor data, primarily SCADA and PMU data, has focused on the transmission grid. The proposed methods are typically data-driven approaches, whereby the measurements are in- spected for abnormality irrespective of the underlying physical model. One such example, the common path data mining approach implemented on PMU data and audit logs at a central server, is proposed in [6] to classify between a disturbance, an attack via IP computer networks and normal operation. Chen et al., [7] derive a linear basis expansion for the PMU data to reduce the dimensionality of the measurements. Through this linear basis expansion, it is shown how an anomaly, which changes the grid operating point, can be spotted by comparing the error of the projected data onto the subspace spanned by the basis and the actual values. Valenzuela et al., [8] used Principal Component Analysis (PCA) to classify the power flow results into regular and irregular subspaces. Through analyzing the data residing in the irregular subspace, their method determines whether the irregularity is caused by a network attack or not. Jamei et al., [9] propose an intrusion detection architecture that leverages µPMU data and SCADA communication over IP networks to detect potentially damag- ing activities in the grid. These aforementioned algorithms are all part of the suite of machine learning techniques that the security monitoring architecture will rely on. B. Our Contribution µPMUs, due to their high sampling frequency, are a much richer data source in comparison to traditional Distribution Supervisory Control and Data Acquisition (DSCADA). In this"
639775,22457,20561,"Introduction to Analytics, Informatics and Decision Support for Sustainability Minitrack",2013,"The final report of the World Commission on the Environment and Development, also known as the Brundtland Report, defines sustainable development as development that meets the needs of the present with-out compromising the ability of future generations to meet their own needs. Subsequent international efforts such as the Rio de Janeiro Conference in 1992, the publication of Agenda 21, the Rio+5 special session of the United Nations (UN) in 1997, the formation of the World Business Council for Sustainable Development in 1997, and the Rio+20 UN Conference on Sustainable Development can be credited with raising environmental concerns to increase public awareness, serving as an initial focus and impetus for collaboration as well as conflict between government, industry, and academia. The Johannesburg Plan of Implementation, revealed at the Earth Summit 2002, affirmed commitment by the UN to fully implement Agenda 21. Environmental management systems standards (EMSS) such as ISO 14001 and the European Eco-management and Audit System (EMAS) provide a sound practical basis for environmental management within organizations. Information systems (IS) support both immediate action and sustainable long-term strategies, helping to address the urgency and scope of environmental problems. This mini-track emphasizes the significant research synergies that exist between IS and environmental management for sustainable development from an organizational as well as a technical perspective. Collaboration and cross-fertilization between these domains can be mutually beneficial and may in fact present unique, timely and socially relevant 'real-world' research opportunities as well as viable public sources of empirical ecological information for interdisciplinary research and application. The mini-track accommodates both research articles and practitioner reports exploring technical and organizational issues that pertain to the development, implementation, and deployment of IS in sustainable development. This year's conference has attracted contributions along two broad themes. The first theme centers around global scenarios and information management. In that regard, New lands et al. describe an integrated model for exploring potential impacts of global changes on the Canadian agricultural system. The methodology integrates stakeholder/expert knowledge, empirical and process-based model algorithms using remote-sensing and national agri-environmental datasets. With respect to energy and carbon emissions, Melville and Saldanha present the results of an exploratory empirical analysis into the extent to which regulations (Kyoto Protocol and UNFCCC) and management practices (carbon emission reduction targets and managerial incentives) are associated with their adoption. The results suggest that managerial incentives and carbon reduction targets are strongly associated with the adoption of information systems for managing environmental resources. With the proliferation of EMIS, Jamous et al. explores issues and requirements pertaining to the development of EMIS with a particular emphasis on the development of a Light-Weight Composite Environmental Performance Indicators (LWC-EPI) solution. The second theme centers on stakeholder knowledge. Rogers et al. use agent-based modeling to study the complexities associated with making decisions in an IT/S project context. The findings reveal variations in the types of project decisions, and show that the inclusion of environmental considerations improves the financial and environmental benefits of the resulting project portfolio. Scharl et al. also focus on environmental decision making by presenting a Web intelligence and visual analytics platform to aggregate, integrate and analyze climate change knowledge from multiple stakeholders. Gray et al. recognize the importance of stakeholder knowledge in environmental decision making by proposing a participatory modeling tool based on Fuzzy Logic Cognitive Mapping (FCM) called 'Mental Modeler' which makes the mental models of stakeholders explicit and provides an opportunity to incorporate different types of knowledge into environmental decision-making, define hypotheses to be tested, and run scenarios to determine perceived outcomes of proposed policies. While Jetter and Sperry describe an approach that is based on Fuzzy Cognitive Map Modeling that helps product planners to capture, understand, and assess stakeholder needs and their interdependencies to aid systematically in the design and selection of product concepts that avoid corporate irresponsibility."
864272,22457,20561,"Introduction to Materiality of Information, Documents, and Work Minitrack",2013,"The debates on materiality and sociomateriality, hailing from science studies and organization studies, allow information systems (IS) researchers to evade received distinctions between the social, natural and technical. The literatures that inform this Minitrack contest a purely information-based perspective that posit abstract meanings and immaterial data divorced from situated contexts. Instead the bodies of work that inspire this Minitrack draw on new materialist, pragmatist, and practice-oriented perspectives (amongst others) hailing primarily from the social sciences that analyze the social activities going into the manufacturing of documents through the manipulations of various material forms. The notion of the document serves as a lens into the practical and material nature of what organizational members do day in and day out. Documents are sociomaterial in that they are artifacts -- and, thus, embody the technical infrastructure -- and social -- as they embody both the work practices and shared orientations of those involved. For example, our production and distribution of this mini-track introduction involved the technology of word processors, several different computers, cloud services, hard copies, email messages and PDF files. Your reading of this document likely involves numerous other technologies, you may be reading a paper version of this introduction, part of the conference packet, or you might have stumbled over it among many other mini-track introductions on the HICSS-48 website, each case, again, depends on a set of web clients, computers, and cloud servers amid a web of social practices. Shared social practices are reflected in the degree to which you, the reader, and we, the authors, understand and share common knowledge about the form and contents of the genre of conference calls in general and HICSS calls in particular. Our shared activities are the basics of work practice. And, the heterogeneous material forms of this call for proposals are some of the infrastructures supporting HICSS and the broader information systems field. In short, the production of this call involves both the work of documenting and document work. As increasingly complex information systems are adopted and adapted within and across organizational environments, there is pressing need for more careful study of document work and the work of documenting within such contexts. Two innovative papers address this topic in this year's minitrack. First, Samantha R. Meyer, Casey S. Pierce, Yubo Kou, Paul M. Leonardi, Bonnie A. Nardi, Diane E. Bailey explore the topic of off shoring. However, they do not focus on the impact off shoring has on communication between people at different sites. Instead they investigate impeded person-to-object interactions at two offshore work sites representing two different occupations: automotive engineering and graphic design Second, Mohammad Hossein Jarrahi studies how digital and physical properties play a role in shaping people's perceptions and actions around the use of Fit bit devices. He argues that we cannot understand the role of information in those activities without examining how it is entwined with the technologies that record, process, share, and represent it. The papers represent an emerging literature converging old and new approaches to sociomateriality and documenting practices. Notably, last year's best paper award in the Digital and Social Media track went to a paper from the present minitrack authored by Megan Finn, Janaki Srinivasan and Rajesh Veeraraghavan. In that paper the authors explored how the circulation of everyday bureaucratic documents opens up the possibility for a population to gaze back and see the state. They did so by comparing the materiality of welfare documents in India and in the U.S. Building on work presented in prior HICSS tracks, this scholarship reignites a body of work on the genre of digital documents that has found a home in the Digital Media track since the mid-90s. Through its continued development, we find new practical and analytic relevance for study of information systems in the years ahead."
1730563,22457,20561,Introduction to the Creativity and Innovation in Teams and Organizations Minitrack,2012,"Innovation is a critical force in organizational performance and survival. Changes in technology, globalization, and increased competition have all created an environment in which creativity and innovation are needed in order to cope with situational and economic pressures and frequent changes. Designers and Developers of organizational systems must therefore innovate almost continuously to keep the organization aligned with such changes. Creativity is a critical pre-condition for innovation. Generating novel and creative ideas are the key to innovation and growth in every organization today. Providing employees with tools to think creatively has been proven to increase innovation in organizations. Research shows that organizations which have established skill-bases and tools for creativity outperform the competition in terms of revenue, rolling out new products, innovation and growth. Though organizations deploy groups for most creative processes, there has been little research in the area of group creativity. Most creative research is focused on individual factors affecting creativity. Many challenges that arise from pursuing creativity in teams remain unexplored. Consequently, it is important that creativity in teams be given a central place in organizational research. This year we received twelve papers, six of which were accepted. These submissions cover a variety of topics ranging from theoretical development to field experiences with group creativity to algorithms and tools to support idea selection. The first paper by Stan examines the effects of group structure and evaluation pressure on group creativity. The author's investigation of 32 teams working on an idea generation task offers support for the notion that teams working under an imposed, functional structure create higher quality results than teams that work under an emergent structure. The author's findings offer insights for design considerations of organizational creative teams. The next paper by Majchrzak, Birnbaum-More, and Johnson presents a qualitative longitudinal study of 31 creative teams. The authors investigated two practices that these teams used to manage their creative process: maintaining engagement and co-creating shared boundary objects. They found that these practices affected the assessment of the teams' innovativeness. Based on the findings, the authors recommend (1) that team members should engage in the co-creation of boundary objects early in the life of the team, and (2) that members need to maintain their engagement with a team, e.g. through the use of collaboration technology, even when they have to focus on other projects. The paper by Kempe, Horton, Buchholz, and Gors, An Optimal Algorithm for Raw Idea Selection under Uncertainty address the challenge of selecting the initial ideas for further development from a large set of raw ideas. The authors propose a ranking algorithm based on pair wise comparisons to be made by knowledgeable decision makers. Through a detailed exposition of the algorithm they show that its use will reduce uncertainty and effectively involve expert knowledge in the idea selection process. The next paper, A Collaborative Algorithm for Computer-Supported Idea Selection in the Front End of Innovation comes from the same research group. In this paper, another selection algorithm is proposed based on a method used in computer-based sorting. This algorithm combines individual and group-based selections to balance speed and simplicity with high quality selections. An experiment showed that the proposed algorithm compares favorably with individual and group methods. Cross-Level Influence of Team Characteristics on Individual Idea Generation in Technology-Supported Teams, by Srinivasan, Maruping, and Robert investigates the use of technology to support idea generation in groups. The authors draw on multilevel theory to understand the interplay between team characteristics and individual goal striving in influencing individual idea generation performance. Their results show that individual goal striving is a stronger predictor of individual idea generation performance in dispersed team contexts compared to co-located team contexts and in larger teams than in smaller teams. The final paper by de Vreede, Boughzala, de Vreede, and Reiter-Palmon, A Model and Exploratory Field Study on Team Creativity proposed a causal model of the antecedents of team creativity that combines individual creativity, knowledge sharing, and the formation of shared mental models. The authors provide anecdotal support for the constructs in their model through a study of an innovation team in a Telecom company."
3056046,22457,20561,Web Engineering,2001,"The Web, or the WWW architecture, has become, undisputedly, the premier delivery platform for the majority of applications today. Applications range from small, simple static sites to large applications, involving distributed, heterogeneous databases, scattered throughout a wide geographical area. In addition, more recent delivery platforms must also be integrated, such as the case of mobile networks.The constant technological evolution, coupled with the increasing complexity of applications, has stressed the already perceived need for adequate methods and techniques for the development, maintenance and evolution of such applications. The area of Web Engineering has focused on such methods and techniques, leveraging existing software engineering practices, enriched with new, web-specific approaches. The Minitrack consists of nine papers that cover a broad range of aspects concerning Web Engineering:In ?A Component-Based Architecture for the development and Deployment of WAP-Compliant transactional services?, Canataro and Pascuzzi present a general architectural framework to develop portable services and applications accessible by mobile terminals, extending end-to-end services between terminals and business applications. Goschka and Smeikal describe the Interaction Markup Language in ?Interaction Markup Language-An Open Interface for Device Independent Interaction with E-Commerce Applications?. They show how to make different interfaces work together with the same application by describing the interactions rather than the elements or components.Emilia Mendes and Nile Mosley argue in ?Using an Engineering Approach to Understanding and Predicting Web Authoring and Design? that prediction is a necessary part of an effective process, and that they can use some measurements obtained in a project to predict the effort in future Web applications. In their paper ?Supporting Reusable Web Design with HDM-Edit? Garzotto, Paolini and Baressi present HDM-Edit, a schema editor that supports general and detailed design of Web applications. They show that HDM-Edit promotes design reuse by supporting several navigation patterns as built-in modeling primitives.In ?Automatic HTML Generation from Formal Hypermedia Specifications? Shibuya, Leiva, Ferreira de Olivera and Masiero propose three strategies for automatically generating an HTML implementation from a hyperdocument model. They presume this model has been obtained using HySCharts, an environment for specifying state-chart-based hypermedia applications. Zafiris, Georgantis, Kalamaras, Christodoulou and Papatheodorou address, in ?Remodeling and Evolving Large-Scale WWW sites?, the issues of remodeling the heterogeneous information that is the foundation of many large-scale WWW sites. They present architecture for integrating diverse data repositories through a shared metadata layer.In ?Utilizing Abstract Web Engineering Concepts: An Architecture?, Heberle, Rehse, Onasch and Sieling present an open, platform independent and scalable architecture based on the object-oriented WebComposition approach. Liu, Lin, Chen and Huang argue that the explosive growth of information is creating difficulties for customers in searching for products they need. In ?A Framework for Personalized E-catalogs: an Integration of XML-based Metadata, User Models and Agents?, they propose an architecture that can facilitate resource-discovery and format translation. Finally, in ?Extending XML to Index from Control Vocabularies?, Arnold and Spenla present an architecture to integrate indexing from control vocabularies at a structural level into XML.In spite of the limited space, the collection of papers in this Minitrack is a faithful reflection of the variety of issues and approaches that are being taken within the Web Engineering field."
874405,22457,20561,Introduction to Social Media and E-Business Transformation Minitrack,2012,"Social media are online platforms that facilitate global collaboration and sharing amongst users. New social media applications in e-business and e-commerce appear on a daily basis and result in enormous shocks to the ecosystem of individuals and businesses. This minitrack provides a forum for the exchange of research ideas and best practices related to social media in e-business environments. It also aims to raise awareness in terms of the latest developments in social media, and address the challenges of using social media. This year, eight papers were selected for inclusion in the proceedings. The first paper, Social Media at Socio Systems Inc.: A Socio-technical Systems Analysis of Strategic Action by Don Heath, Rahul Singh and Jai Ganesh proposes an analytic framework to explain organizational strategies for directed action in social media. The next paper by Eric T.K. Lim, Dianne Cyr, and Chee-Wee Tan, Understanding Members' Attachment to Social Networking Sites: An Empirical Investigation of Three Theories, constructs a theoretical model of members' communal attachments within SNSs. The model is then empirically validated via an online survey of 787 active members of SNSs. Drawing from the push-pull-mooring model and uses and gratification theory, Fei Liu and Bo Xiao proposed and empirically tested a theoretical model explaining SNS users' switching behavior in their paper, Do I Switch? Understanding Users' Intention to Switch between Social Network Sites. The fourth paper by Alexander Richte, David Wagner and Andrea Back, Leadership 2.0: Engaging and Supporting Leaders in the Transition Towards a Networked Organization, illustrates the concept of Leadership 2.0 through a series of interviews with the persons who are responsible for the implementation of social software at publicly listed, multinational organizations in Germany. The next paper, Understanding Information Adoption in Online Review Communities: The Role of Herd Factors by Xiao-Liang Shen, Kem Z.K. Zhang, and Sesia J. Zhao, extends prior research on information adoption by incorporating the perspective of herd behavior to explain the influence of massive online reviews in online communities. The research model was empirically tested with 376 users of a Chinese online review community. Impact of Online Firm Generated Content (FGC) on Supply Chain Performance: An Exploratory Empirical Analysis, by Ajaya Swain and Qing Cao uses an advanced sentiment analysis approach to examine the impact of FGC effect on supply chain performance. Information sharing and collaboration are identified as two key FGC elements affecting supply chain performance. Based on an experimental investigation of the judgment ability of 478 subjects, Christian Wagner and Ayoung Suh found that collective size and expertise transfer effects are moderated by task difficulty and are strongest for tasks in a medium difficulty range in their paper, The Wisdom of Crowds: Impact of Collective Size and Expertise Transfer on Collective Performance. The final paper, Assessing the Effects of Navigation Support and Group Structure on Collaborative Online Consumers' Consensus and Mutual Understanding by Yanzhen Yue and Zhenhui (Jack) Jiang, explores an emerging phenomenon of collaborative online shopping by investigating the effects of navigation support and group structure on collaborative online consumers' consensus and mutual understanding. We thank the authors for submitting their work to make this another engaging minitrack. We hope you enjoy the papers and their presentation at the conference."
2195743,22457,20561,Linguistic Geometry: A New Paradigm for Intelligent Systems,1995,"In order to discover the inner properties of was successfully developed into syntactic methods of human expert heuristics, which were successful in a certain pattern recognition by (Fu, 1982; Pavlidis, 1977), and class of complex control systems, we develop a formal picme description languages by (Shaw, 1969; Feder, 1971; theory, the Linguistic Geometry. This paper reports 2 new Rosenfeld, 1979). The power of a linguistic approach might examples of applicution of Linguistic Geometry to be explained, in particular, by the recursive nature and autonomous robotic navigation that demohstrate dramatic expressiveness of language generating rules, i.e., formal search reductkm grammars. Searching for the adequate mathematical tools There are many real-world problem where h~~~an formalizing human heuristics of dynamic hierarchy, we expert skills in reasoning about complex systems are have transformed the idea of linguistic representation of incomparably higher than the level of modem computing complex real-world and artificial images into the idea of sYskms. *t the Same time there are even more areas where similar representation of complex hierarchical systems advm~s (Stilman, 1985). However, the appropriate languages not be directly applied. For example, there are Problems of should possess more sophisticated attributes than languages Planning and automatic Control of autonomous agenu such usually used for pattern description. They should describe as space vehicles, stations and robots with cooperative and mathematically dl of the essential syntactic and senantic opposing interests functioning in a Complex, hazardous feams of the system and search, and be easily generated by environment. Reasoning about such Complex Systems certain controlled grammars. The origin of such languages should be done autOmtltiCdly, in a hely mZUMler, and often can be traced back to the origin of SNOBOL-4 in a red time. Moreover, there are no hi@Y-Skilled human progrming language and the research on programmed experts in these fields ready to substitute for robots (on a attribute grammars and languages by (Knuth, 1968; virtual model) or transfer their knowledge to them. There is ~~~h~a, 1959). no grand-master in robot control, although, of course, the A mathematical environment (a glue) for the formal knowledge of existing experts in this field should not be implementation of this approach was developed following neglected - it is even more valuable. It is very important the theories of formal problem solving and planning by to Study human reasoning about complex (Fikes and Nilsson, 1971; Nilsson, 1980; Sacerdoti, 1975; systems in the areas where the ESUltS are SUCCeSSful, in MC-Y and Hayes, 1969), and othem, based on first order order to discover the keys to success, and then apply and adopt these keys to the new, as yet, unsolved problems. To show the power of the linguistic approach it is There have been many attempts to find the optimal important that the chosen model of the heuristic hierarchical operation for md-world complex One Of the basic system be sufficiently complex, poorly formalized, and ideas is to decrease the dimension of the real-world problem have successful applications in different areas. Such a model following the aPPmaCh0fahu-n eve* in a certainfield, was developed by Botvinnik, Stilman, and others, and by breaking the problem into smaller subproblems (Simon, successfully applied to scheduling, planning, and computer 1980; Albus, 1991; Mesarovich et al., 1970; Botvinnik, chess. The hierarchical constructions were introduced in 1984). (Botvinnik, 1984) in the form of ideas and plausible These ideas have been implemented for many problems discussions."
2383254,22457,20561,"E-Policy, Law and Governance: Minitrack Introduction",2005,"This minitrack is a direct successor to the previous e-policy, law and governance minitrack in the e-government cluster. Papers in this minitrack address how public policies, laws and governance are related to the use and development of information and communication technologies (ICT) both in government and in society at large. Government policies and legislation can create the technological environment and the necessary boundaries for egovernment and e-democracy applications and services. At the organizational level, this includes aspects of equal access rights, privacy protection, public safety, security, and information dissemination. In the context of government information systems and at the infrastructure level, it encompasses the introduction of national ID cards, central citizen registries, data centers, public key infrastructure and Internet-based infrastructure. Policy issues and their analysis pertain to the digital divide, infrastructure development, use of open source and standards and educational uses of ICT. This minitrack also addresses e-policies related to national development. Governance refers to the system of directing and controlling the actions, affairs, policies and functions of a political unit, organization, or nation. E-governance is getting more attention, as it has the potential to ensure that the spending of public money is not only done in an effective and efficient way but should also ensure the spending can be accounted for. This would create a dynamic, creative public sector capable of anticipating on and being open, responsive, adaptive, democratic and accountable for their action, facilitating customer preferences. The first paper in this minitrack Examining the socio-economic determinants of Broadband adopters and nonadopters in the United Kingdom by Jyoti Choudri and Yogesh K. Dwivedi presents the findings of a selfadministrated, postal questionnaire. The findings of the survey support the view that socio-economic attributes such as age, gender, education, incomes and occupation have an imperative role in explaining the adoption of broad band in households. In the second paper, Emerging Issues in United States Telecommunications Policy:An Analysis of Federal Communications Commission Activity, Satya Prakash Saraswat and William T. Schiano explores unforeseen issues that emerged since the passage of the Telecommunications Act of 1996 in the USA. The authors utilizes content analysis of Federal Communication Commission news releases to identify and categories the most import emerging regulatory issues and discuss implications of the focus of the Federal Communications Commission for the design, management and deployment of network based information technology. Three different approaches to a fundamental legal issues, the definition of the exact time of a communication is received by an agency, are examined in Time, Space, and Documents – Principles for e-government regulation by Gustaf Johnsson. The three approaches, spatial analogies, availability and retrieval fail to provide sufficient guidance to system designers. An alternative approach is offered based on the concept of functional equivalence, which results in recommendations for information systems design. Although the number of accepted papers in this minitrack is limited this year, we have all by all three very interesting papers covering important issues in the field of e-policy, law and governance. We hope that HICSS will again be an ideal spot for discussing, meeting with peers and exchanging ideas in the field of e-policy, lay and governance."
1109436,22457,20561,Introduction to HCI and Consumer Health Informatics Minitrack,2013,"There is increasing interest in reaching, engaging, and empowering healthcare consumers directly through various forms of information and telecommunication systems. The success of such initiatives largely depend on how healthcare IT is perceived as usable and useful for its intended audience - healthcare professionals and providers, health consumers and patients. Not surprisingly, it becomes increasingly important and relevant to pay attention to HCI issues in healthcare IT. The objective of this Minitrack is to provide an outlet for sharing research that focuses on improving healthcare IT through an HCI lens. This year, the HCI and Consumer Health Informatics Minitrack team selected five papers from a pool of highly competitive submissions. This year's first article, Text Simplification Tools: Using Machine Learning To Discover Features That Identify Difficult Text, by David Kauchak, Obay Mouradi, Chris Pentoney, and Gondy Leroy, focuses on tools for analyzing of text difficulty for health consumers. The paper uses six different machine learning algorithms to predict the difficulty of health texts. Our second article, Alignment of Concerns: A Design Rationale for Patient Participation in eHealth, by Tariq Andersen, Jorgen Bansler, Finn Kensing Jonas Moll, and Karen Nielsen, focuses on divergent concerns of physicians and patients when it comes to illness. The research explores the importance of understanding these differences and provides suggestions for incorporating them in the design of eHealth interfaces. Video Conferencing as a Tool to Enable Participation in Discharge Planning - Experiences from Implementers regarding the Implementation Process, by Malin Hoff Lander, Lina Nilsson, and Christel Borg, focuses on the challenging task of discharge planning. This research emphasizes the concept of time, including consideration of the time needed to prepare and reflect, and it highlights the importance of leadership in framing the meaning of time during this process. Video conferencing is explored as an IS-based approach to addressing related issues. Determinants of Vertical and Horizontal Online Health Information Behavior, by Hye-Jin Paek and Thomas Hove, examines two different types of online health information behavior. The article investigates the association between these online behaviors and demographic, psycho graphic, and lifestyle factors. Magic Mirror for Neurorehabilitation of People with Upper Limb Dysfunction Using Kinect, by Orlando Erazo, Jose Pino, Rosario Pino, and Carmen Fernandez, focuses on rehabilitation. It explains how patients requiring neurorehabilitation can receive training using systems developed for the Microsoft Kinect platform, with a focus on natural user interface systems as used by patients. We are honored by the consistent and strong interest in the HCI and Consumer Health Informatics Minitrack and would like to thank all twenty of this year's contributing authors for submitting their outstanding and interesting research."
1072628,22457,20561,Creativity in information systems,2002,"As the innovation rates in most markets increase, an organization's ability to sustain creativity in its products, processes and members becomes a significant competitive challenge. Often an organization is considered only to be as valuable as its last great idea. Recognizing that information technology (IT) has the capacity to enable innovative processes and products, many organizations are now looking for IT to directly support their creativity needs. Accordingly, the Creativity in Information Systems (CIS) Minitrack is interested in exploring a wide variety of topics involving when and how creativity can be sustained or enhanced by IT.Because creative people produce creative systems, one area of interest for the CIS Minitrack involves exploring ways to support creativity within the IT function. Not only must IT personnel find creative ways to enhance system acceptance, productivity and satisfaction, but they also are increasingly being expected to develop systems that can enhance the creativity of end users. Awareness and understanding of which tools and techniques best support creativity can help designers and developers create better applications.Another focus for the CIS Minitrack involves examining ways organizational processes have been re-conceptualized using information and communications technology. A consideration of the issues and challenges involved in recognizing the need for process change as well as determining exactly how communications and information technology applications might allow for new processes supports organizational efforts to perform effectively these dynamic times.Because of the variety of topics covered in this year's submissions, we are expecting very lively and interesting discussion. The session begins with a paper by Christopher Barlow from the Illinois Institute of Technology that explores how the approach taken to frame a problem often limits one's awareness of potential solutions. Dr. Barlow develops a model that re-frames the definition of a creative event from ?a newer and better idea? to ?a shift in perspective that makes new possibilities obvious?. He explores the research benefits that are likely to accrue from this shift and offers a preliminary assessment of its usefulness.The second paper, by Drs. Christopher Landauer and Kirstie Bellman from the Aerospace Corporation, discusses some of the challenges faced in developing systems to support human creativity. They describe a system infrastructure they have developed called ?wrapping? that can provide the richness and flexibility required for human support.The third paper, by Dr. Sherry M. B. Thatcher from the University of Arizona, explores the concept of ?identity fit? and its impact on creative performance. She uses the results of a field study to demonstrate how identity fit has a positive effect on creative performance.The fourth paper, by Drs. Keith S. Horton and Rick G. Dewar from Napier University, considers the use of patterns in relation to information systems strategy formulation and applies the concept Alexandrian patterns to an empirical case study to demonstrate the value of reflection and context."
1143827,22457,20561,Minitrack: quality of service in mobile and wireless networks,2004,"In recent years the areas of mobile computing and wireless networks have seen an explosive growth both in terms of the number of services provided and the types of technologies that have become available. Indeed, cellular telephony, radio paging, cellular data, and even cellular multimedia services have become commonplace and the demand for enhanced capabilities will continue to grow into the foreseeable future. It is anticipated that in the not-so-distant future, mobile users will be able to access their data and other services such as electronic mail, video telephony, stock market news, map services, electronic banking, while on the move. As mobile and wireless networks are being called upon to support real-time interactive multimedia traffic, such as video tele-conferencing, these networks must be able to provide their users with Qualityof-Service (QoS) guarantees. Although the QoS provisioning problem arises in wireline networks as well, mobility of hosts, scarcity of bandwidth, and channel fading make QoS provisioning a challenging task in mobile and wireless networks. Recently it was noticed that multimedia applications can tolerate and gracefully adapt to transient fluctuations in the QoS that they receive from the network. The management of such adaptive multimedia applications is becoming a new research area in wireless networks. As it turns out, the additional flexibility afforded by the ability of multimedia applications to tolerate and adapt to transient changes in the QoS parameters can be exploited by protocol designers to significantly improve the overall performance of wireless systems. The minitrack focuses on fundamental challenges and issues arising in the process of QoS provisioning in mobile and wireless networks, including cellular, ad-hoc, satellite, and IP-based networks. Our principle goal was to bring together leading researchers in this booming field of research in order to identify the fundamental challenges and future perspectives of this important area. Indeed, it has been noticed that wireless communications and mobile computing are redefining computing as a discipline. The impact is expected to be profound and lasting, ranging from educational, to medical, to military, to industrial, and to societal. We felt that it was very important to capture the state of the art and to identify the important trends in this new and exciting area or research. A minitrack on the same topic was run successfully within HICSS’37. The attendants and participants have urged us to continue the effort for HICSS’38. The result is a collection of eleven outstanding papers dealing with many aspects of QoS provisioning in mobile and wireless networks. Indeed, the minitrack brings together leading researchers in this booming field and identifies fundamental challenges and future perspectives of this important area. We want to take this opportunity to thank a number of folks that made this minitrack possible. First, we thank the authors of the papers for considering our minitrack as an outlet for their work. Next, we extend our thanks to the referees whose dedicated work and constructive comments allowed us to present a high-quality product. Last, but certainly not least, our thanks go to Professor Gul Agha for his encouragement and support and to the indefatigable Eileen Dennis for her patience in working with us."
604643,22457,20561,The Dynamics Of Business Engineering Introduction To The Minitrack,1998,"The field of Business Engineering can be best described as the development and use of methods and tools for quantitative and qualitative analysis of current business processes, and for design and implementation of new ways of working. The focus of Business Engineering is usually not on the production and assembly of goods, but more on administrative processes that occur in all public and private organizations. Part of the attention is aimed at the service industry, because high quality processing of information is usually the added value the industry provides for its customers. The administrative processes are their primary process. In that way, Business Engineering is closely linked to business process redesign [2, 3, 5], but it has a broader focus. In this minitrack we look especially at recent developments in the field, focusing on concepts for modeling the dynamic behavior of business processes. Several conferences [e.g. 10], tracks, and minitracks have been devoted to business engineering. This year, we selected a number of interesting papers for the minitrack, which give a good insight into the current state of the field. Two of the papers highlight simulation support for business s engineering. The paper of Van Eijck and De Vreede [4] gives new insight into the support for quantitative analysis of business processes. The modeling template for the ARENA simulation environment they describe is a first example of a one-to-one translation of task / actor / coordination diagrams into a simulation environment. They claim that templates like this can decrease the effort needed for creating an empirical model of a business process tremendously. Lee et al. [8] also look at how to construct simulation models of business processes, but their focus is on group support for model construction. They provide a candidate architecture for supporting collaborative modeling and simulation using the DEVS framework and IDEF-3 like diagrams. More information on collaborative approaches for business engineering can also be found in [11]. The two other papers focus on the relation between performance and workflow modeling. Modeling business processes is an important part of the workflow field [6, 7]. The paper of Brataas, Hughes, and Solvberg [1] pr oposes a method for determining system requirements and performance analysis from a workflow standpoint of view. They suggest that the interaction between computer system performance and organizational performance can best be carried out in the same framework. Seidmann, Walter, and Dewan [9] present a mathematical description of task consolidation and the effect of consolidation on cycle-times and task performance. Their major contribution is the mathematical description of the effects of changes in work processes and tasks. The papers in this minitrack provide new insight into interesting business engineering frameworks. Both the theoretical background and case evidence that the methods work in real life cases are presented. We can clearly see that over the recent years, the research focus has shifted from presenting new methods, to developing tools that can be and that are really applied in practice. All in all, these papers are an important contribution to the field of business engineering, by creating and testing methods for the analysis and design of business systems in service industries, public, and private organizations."
2278486,22457,20561,Applying a layered policy model to IP based voice services,2003,"Traditionally, specific telecommunications services were essentially confined to certain types of networks; e.g., television over broadcast networks or cable and voice service over wireline or wireless networks. Regulations were built around the underlying infrastructure. The regulations imposed on these providers were as stratified as the networks and the services they carried. Convergence of services onto nontraditional platforms creates a dilemma where the rules no longer conform to the infrastructure. This creates inconsistencies and gives rise to problems such as: market, investment, and interconnection distortions, as well as universal service, accessibility (for the disabled) and public safety concerns. One of the most relevant of these services is voice, specifically voice over the internet protocols. While several authors have suggested alternative regulatory models to deal with these changes, these models tend to ignore important aspects of market power, network design and technology evolution. One proposed solution to this problem is based on a layered model similar to that used in the development of technical communications protocols. The consistency and modularity of such an approach may be a workable alternative to the current title-based policy. However, a layered model in and of itself is insufficient. A layered model solution must reflect the reality of network design and business arrangements, and, to be viable, it requires a transition policy to get there from the existing policy regime. Emerging policy must address the diversity of existing access technologies (e.g., cable networks versus common carrier wireline networks), the disparity within industry segments (e.g., ILEC vs. CLEC use of last mile) and the strong influence of present policy on these various segments when implementing a transition to new policy. It is important to realize that interconnection will remain at the core of any competitive telecommunications policy. There is always some physical or logical interconnection that must be resolved and this involves pricing. Without the correct incentives or obligations in place, providers will not be motivated to interconnect. The theory behind our model is to separate policy issues along what we see as logical boundaries; ones that make sense in terms of such issues as cost, technology and network design. The method we apply is simply to consider the problems of the existing policy and show how a layered model might be used to resolve them. As we move toward more fully converged networks, we will need to understand how best to revise policy. A general direction should be to simplify the rules and to minimize regulation where necessary. We believe that a layered model could provide this simplification. In previous work, the author described the general notion of a layered model for telecommunications policy. In this paper, we examine the application of this model for voice over Internet protocols. We begin by describing the existing policy environment. Next, we rationalize why a layered model makes sense in a converged environment. We then consider the transition into such a model and a number of associated issues. Finally, we apply this layered model to a few vexing policy problems. Specifically, we look at how a layered model allows us to frame the issue of voice over IP and the closely related issue of universal service in a consistent and logical manner."
2121662,22457,20561,Strategic and Competitive Information Systems,1996,"This mini-track continues the long tradition of examining the linkage between organizational strategy and information technologies. This has gained new urgency with burgeoning electronic commerce and new communication technologies. For new technologies to be adopted not only do they have to be technically feasible, they have to provide some strategic advance to the firm. Conversely, some firms may adopt technology that is still evolving. Kauffman and Wang make this clear in the first paper. They use analytic modeling to show that some bill payers may adopt e-billing technology early, even in face of better solutions that might be available in near future, if there is a substantial installed base effect.Feurstein, Natter, Mild and Taudes look at knowledge sharing within the organization and they find that despite availability of advanced tools and techniques, of the kind discussed in detail in the Collaborative Technology Track, its success in organization depends crucially on incentives and other variables of the organizational architecture.Collaborative technology improvements and other advances in IT are expected to reduce costs, and increase output. This should result in an increase in productivity - the ratio of output to input. However, empirically, this has been hard to establish. ?We see computers everywhere but in the productivity statistics,? said Robert Solow, Nobel laureate economist. Debate has since then raged in the literature and this issue has been dubbed the ?productivity paradox.? The next paper by Thatcher and Oliver sheds new light on this matter. They use an analytical model to show that the paradox may be created by mis-measurement of productivity. Many researchers use revenue as a proxy for output in productivity measurement. The authors identify this mis-measurement as a source of the paradox.Continuing in the examination of decision making in the firm, Clemons and Aron look at the decision to allocate budget for product development and advertising. In this innovative work, the authors unite two hitherto disparate streams of literature. Investments in product design have been much studied in engineering management while marketing researchers have examined the value and cost of advertising. On the margin, a manager has to pick between these two competing activities and to-date there has been no comprehensive model to address these issues.Finally, Rudi, Gundepudi and Seidmann also unite two streams of literature, theory of options in finance and pricing from marketing, to offer fresh insights into inter-temporal purchases, such as subscriptions, of information goods."
898552,22457,20561,Next generation of learning platforms introduction to minitrack,2001,"Continuous education is one of the big challenges for all countries around the globe. Due to our leading role in the development of national learning backbones for Germany and South Africa, and of campus wide solutions for both cooperate and classical universities, we were approached by many people who asked us to provide contributions to the ongoing discussion on how learning architectures should be built to support the (adult) learning process. In its second year, the Next Generation of Learning Platforms minitrack focuses on general requirements of and current approaches to learning architectures that allow flexible delivery of learning content over traditional networks and upcoming wireless networks, in an attempt to reach potentially every person. The need for integrated systems exploiting a highly distributed web-based environment involves problem areas such as • collaborative computer aided authoring support, • work benches for international coverage of learning topics, • enabling the reuse of learning fragments, • specialized search engines, • personalization of the learning environment, • remote tutoring support, • retrieving learning material on-demand and • ensuring a proper certification of the learners’ achievements and quality control. The accepted papers for this year's minitrack provide a good coverage of the problem areas and sample insight into related projects. The topics include two aspects treated in the German lighthouse project L3, one on collaboration for learning environments designing specific instructional transactions for distance learning, and one on a design methodology, tool and run-time environment for massive support of personalized learning styles. An evaluation on learner-learner cooperation offers initial findings using a new simulation environment. A new approach regarding authoring for electronic books (slices) again emphasizes collaboration to demonstrate its potential. A digital lecture hall paper takes care of the massive need to integrate traditional lecturing situations with enriched multimedia capabilities to support the learner. Finally a method on criteria based marking as an instructional method is discussed. At least 3 reviewers from different organizations refereed each of the submitted papers. The accepted papers are summarized below. A contribution by FhG-IPSI sketches two current implementations of collaborative learning environments and embraces the evaluation of various collaboration modes for continuous learning environments. This paper describes the relevant set of directions regarding user and collaboration management as well as the transition between self-paced and multi-party learning situations."
362211,22457,20561,Creativity in information systems minitrack introduction,2000,"With the innovation rate in most markets increasing, an organization's ability to sustain creativity in its products, processes and members becomes a significant competitive challenge. Because information technology (IT) has often been considered an innovation enabler, many organizations are now looking for IT to support their creativity needs more directly. Accordingly, the Creativity in Information Systems Minitrack is interested in exploring when and how creativity can be sustained or enhanced by IT.Moreover, because creative systems are thought to come from creative people, this Minitrack is also in interested in exploring ways to support the creativity of IT personnel. Not only are they continually seeking new ways to enhance system acceptance, productivity and satisfaction, but IT personnel are becoming increasingly interested in developing systems to enhance users' creativity. Hence, understanding which tools and techniques best support creativity can be useful for application development.Because of the quality of this year's submissions, we are expecting very lively and interesting sessions. Session one examines a variety of idea generating techniques and offers insights into how they may best be used to support creativity within organizations. The first paper, by Thomas Chesney and Helen Fletcher, looks at the efficacy of keyword analysis to support idea generation for systems reengineering applications. The second paper, by Eric L. Santanen, Robert O. Briggs and Gert-Jan de Vreede, not only shows how the Cognitive Network Model can be a useful guide for explaining the effectiveness of creativity support tools, but also introduces a new and successful group support tool known as directed brainstorming. The third paper, by Ben Sheiderman, discusses design and graphical layout considerations for developing programs to support users' creativity as they compose documents, presentations, and other creations on their computers. Session two explores how individuals use information to perform more creatively. The first paper, by Paula J. Hinds, is an experiment designed to examine how asking individuals to suppress information, or protect proprietary information, inhibits their ability to think creatively. This paper was also submitted as the Creativity in Information Systems Minitrack's nomination for the HICSS-33 best paper competition. The second paper, by Jungwoo Lee and Duane P. Truex, develops a model of overall cognitive development as well as an instrument to explore the relationships between training methodology, cognitive complexity and creativity in system developers. The final paper, by L. Nguyen, J. Carroll, and P.A. Swatman, uses a field study approach to examine the creative process that emerged during the requirements engineering phase of an IT project for a Web-based Information Broker.We hope that you will attend, enjoy, and learn from this year's Creativity in Information Systems Minitrack."
423822,22457,20561,Intelligent Decision Support for E-Logistics and Supply Chain Management,2005,"Information technology (IT) is a prerequisite for successful supply chain management (SCM) today and will become even more so in near future. While IT systems are vital components in supply chains, their successful management rests on coordinated decision making throughout the logistics network. Data warehouses and data mining can be used to store and analyze product, inventory, and sales information. Simulation and optimization, which can be found in advanced planning and scheduling systems, can be employed for e.g. inventory, production, procurement, and distribution planning. Intelligent agents can e.g. communicate with different partners in the supply chain, assist in collecting information, share product information, negotiate prices, and distribute alerts throughout the logistics networks. This minitrack consists of three contributions which deal with intelligent decision support in the field of e-Logistics and SCM. The papers provide a heterogeneous yet complementary ensemble as they consider different approaches in coping with the uncertainty and complexity found in real-world decision situations. Roland Zimmermann, Stefan Winkler, and Freimut Bodendorf propose the application of agent technology to realize distributed supply chain event management (“Agent-based Supply Chain Event Management – Concept and Assessment”). After discussing the needs to propagate and process event-related information in operational fulfillment processes the authors describe the architecture of an agent-based implementation. The analysis of two use cases provides evidence for the effectiveness of the proposed concept. Rajanish Dass and Ambuj Mahani describe an enhanced heuristic search strategy within the domain of business intelligence (“An Efficient Heuristic Search for Real-Time Frequent Pattern Mining”). The proposed approach serves for mining frequent patterns in business data. Computational experiments show that the algorithm is faster than existing algorithms and effectively supports real-time decision making. From a practical point of view it is often important to determine robust plans that work under uncertain future conditions, even taking into account low frequency events with high impact. David L. Woodruff and Stefan Vos investigate heuristics based on the progressive hedging algorithm for coping with a small number of discrete scenarios (“Planning for a Big Bang in a Supply Chain: Fast Hedging for Production Indicators”). This approach is illustrated and analyzed for a specific cost minimizing production planning model."
1568202,22457,20561,Introduction to Multi-criteria Decision Support Minitrack,2013,"Almost all decisions people make are based on multiple factors or criteria. Decision makers generally pursue multiple, and often conflicting, objectives. A feasible solution that is optimum with respect to all such objectives or decision criteria almost never exists, and a satisfactory compromise solution is generally sought. Multi-criteria decision-making as a field of research deals with problem theory and solution approaches directly involving multiple decision criteria. Information technology and systems may help in dealing with such multi-criteria decision problems. This mini-track focuses on solution approaches, technology, and systems that support decision-making under consideration of multiple decision criteria. This is the third time that this minitrack is included in the HICSS program, and five contributed papers have been accepted. The papers deal with a wide range of decision problems, from software component selection, to recommendations for location-based services. Furthermore, the relevance of trust in multi-criteria decision support, support for research proposal grouping, and skyline operation for multi-criteria decision support are investigated and discussed. Becker, Kraxner, Plangg, and Rauber, in their paper on Improving Decision Support for Software Component Selection through Systematic Cross-referencing and Analysis of Multiple Decision Criteria discuss challenges and opportunities in using particular characteristics of scale in decision scenarios for software component selection. Building on an existing decision support framework, they formalize quality criteria so that they can be cross-referenced and analyzed across scenarios. The paper by Xu, Xu, and Ma, titled An Ontology based Frequent Item set Method to Support Research Proposal Grouping for Research Project Selection, introduces a novel approach to support grouping of research proposals to aid in research project selection. In this approach, first an ontology is constructed to standardize research keywords, and then a frequent item set with various degrees of support is extracted from the research proposals, based on the ontology. In their paper on Success of Multi Criteria Decision Support Systems: The Relevance of Trust, Maida, Maier, Obwegeser, and Stix present a consolidated view on different dimensions of trust and discuss the specific characteristics and dynamics of trust in multi-criteria decision support, based on a multidimensional model. They test the validity of their model with an empirical study, asking participants to complete a survey after using a specially developed decision aide. Emrich, Chapko, and Werth, in their paper on Adaptive, Multi-criteria Recommendations for Location-based Services, analyze influence factors of mobile users for choice of interest. They derive an adaptable ranking function capable of adjusting preference weights on the influence factors, so as to learn from user behavior and evolve the knowledge base. And finally, the paper by Chai, Liu, Yiu, Wang, and Li on A Novel Dynamic Skyline Operation for Multicriteria Decision Support investigates preference relations in skyline operations, a multi-criteria ranking procedure which generally relies on a predetermined preference system. The authors introduce the concept of preference intensity and propose a new decision model, the Tolerant Skyline operation, or T-skyline, which allows for dynamic decision preferences."
1220530,22457,20561,Introduction to IT Innovation for Change in Healthcare Minitrack,2013,"The innovative application of information technologies (IT) in the consumer, clinical, and public health spheres offers the potential for transformational improvements to the healthcare system. Addressing the significant challenge of developing, evaluating, and integrating such innovations requires a systems approach that encompasses the technical and social dimensions, as well as interrelationships across the personal, clinical and public health levels. Vital to the innovative process are electronic information platforms, or cyber infrastructure, that use grid and cloud-based systems for storage, harmonization, access, analysis, and utilization of data. IT innovation in healthcare includes infrastructures to support large data sets/sources as well as emerging data platforms such as the National Health Information Network (NwHIN), Public Health Information Network (PHIN), Cancer Research Network (CRN), and Health Data.gov. IT innovations are also important in health prevention and promotion. health surveillance data, such as the Health Information National Trends Survey (HINTS), are helpful for assessing population trends and informing health-related policy and practice. Such policy and practice applications can be accelerated through applied research, demonstrations, and open innovation developer challenges. Recent developer challenges have provided a key mechanism for applying disparate data sets to advance health promotion and disease prevention, improve health communication and coordination, and expand the use of applications targeting specific populations and health outcomes. This conference mini-track highlights some of the IT innovations in healthcare for population health and health services. It will feature the following papers: A Hybrid Case Based Recommender in mHealth for Smoking Cessation Lessons from an Online Stop-Smoking Intervention: Adaptations for Mobile Implementation Stage-Based mHealth Communication Interventions for HPV Education Towards Next Generation Health Data Exploration: A Data Cube-based Investigation into Population Statistics for Tobacco Towards Systematically-Enabled Next Generation Community Health Information Portals: The PopSciGrid Pilot These research papers address technical, behavioral, social and health issues, with topics ranging from high performance computing topics concerning the extraction of knowledge from various data collections, data acquisition and analysis in a data intensive health science world, and open technological advancements. A particular emphasis in several of the papers relates to the use of large data sets, mhealth, and cyber infrastructure to prevent, monitor, and manage cancer."
1566893,22457,20561,Experimental software engineering (STESE),2003,"Software engineering theory and practice is still to a large extent based more on faith than on science. Only by contributing to the scientific and empirically grounded body of knowledge within a specific area of application, theory and practice can develop. Experimentation is an important scientific approach to collect empirical data and to test theories as well as to bring light to new phenomena so that theories can be formulated and corrected. This is the background for the emerging field of experimental software engineering. The focus of this minitrack is on experiments and experimental studies performed in academic or industrial settings where the aim is to study the software professionals' work practices related to the development of software. This minitrack is divided in two three-paper sessions. The papers are briefly introduced in the following. The three papers in the first session are experiments performed in an academic setting. Syversen, Anda and Sjoberg report the results from an experiment with 26 subjects where they explore how a use case model can best be applied in an object-oriented development process. Serrano, Calero and Piattini describe how to apply the experimental method in metrics definition for multidimensional data models. Their paper gives an overview of the method including a description of how it was applied. The first session is concluded with a paper authored by Liu and Grandon where they empirically explore with 79 subjects how task performance and domain-specific self-efficacy influence the perceived ease of use of object-oriented analysis techniques. The first two papers in the second session include a set of experiments and an empirical study performed in an industrial setting. Jokela describes five different experiments where the attempt is to assess the quality of the usability engineering processes of four different companies. Jokela explains how the assessment process is iteratively changed and improved based on the results of the earlier experiments. Borjesson and Mathiassen compare two software process improvement initiatives carried out in industry. They focus on factors affecting the implementation success. Dugan, Glinert and Rogers conclude the minitrack by introducing a technology-focused methodology called CAMELOT, which is intended for testing computer supported co-operative work software. They report results from an experiment where the proposed methodology was tried out."
1882863,22457,20561,Market Structure and the Predictability of Electricity System Line Flows: An Experimental Analysis,2005,"Robert Thomas has shown, using simulations of experimental results, that the power flow on any line in an electric network is linearly proportional to the total system load when that system is optimally dispatched using accurate generator cost data. By comparison, when offers from generators obtained in a wholesale market that is not perfectly competitive are used to dispatch the system, that relationship between line flow and system load becomes nearly random. These simulations were conducted in a single-sided market environment, however, that is typical of most wholesale market regimes around the world. Here the central dispatcher (ISO, RTO, etc.) accumulates the demand from various buyers and satisfies that load with a least-cost purchase schedule, regardless of price, subject to all of the physical and reliability constraints imposed on the system. If buyers were also able to submit a schedule of bids that are related to price, does the same random relationship between line-flows and system load prevail? This experimental analysis demonstrates that letting the customers participate fully in the market re-establishes the predictability of line flows as a function of system load. In all of these experiments there are no restrictions on permissible offering behavior by suppliers (e.g. no price caps, prohibitions on withholding capacity or automated mitigation procedures). Two alternative forms of demand side participation are considered: 1) a demand response program (DRP) where customers are alerted to high prices in the subsequent period and are paid a pre-specified amount for each kWh less than their benchmark level of usage for that period, and 2) a real time pricing program (RTP) where customers are given forecasts of prices for each period over the subsequent day and they then pay the actual period-by-period market clearing price. As a benchmark, these experiments with six suppliers and seventeen buyers are also repeated where customers pay an average constant price in all periods (FP); although in all cases sellers receive the market-clearing price in each period. R-squares were greater, variances were smaller and the t-tests on regression coefficients were stronger on the relationship between line-flow and system load for RTP, as compared to the FP system that is commonly used in most electricity markets. DRP was usually somewhere in between. Not only does inducing active customer participation in the market through RTP lead to better system predictability, it also reduces price spikes and leads to greater overall economic efficiency in these markets. It is a winner on both economic and operational grounds."
513932,22457,20561,Introduction to the Practice-Based IS Research Minitrack,2015,"The debate over rigor and relevance has extended many decades with rigor leading the way in the overwhelming majority of our academic journals where theory contribution and methodological excellence transcend any practical implication the research may have. In its first decade, MIS Quarterly had a special section devoted to practice-based research called Application. Over the years, this section produced highly sighted and highly relevant work that often paved the way for a new research area based upon developments in practice, such as Watson, Rainer, and Koh's 1991 article on EIS that largely introduced a new research stream to our academic journals, or that introduced to the academic reader current state of the art practices in industry, such as Kettinger, Teng, and Guha's 1997 description of business process chance techniques, or that provided practical guidance to organizations on highly relevant IS issues, such as Watson, Pitt and Kavan's 1998 article on measuring and sustaining information systems quality in organizations. Unfortunately, the application section was discontinued after 1999. Today one can publish essays, opinions, idea, and method pieces in our top journals, but not exploratory or descriptive field studies on emerging topics. This mini-track seeks to encourage practice-based research on new and emerging IS issues in organizations. Practice-based research aspires to bridge the gap between academic theory and practice, it aspires both to introduce researchers to state of the art practices and issues from industry as well as introduce managers to research that makes sense of and brings coherence to the issues they face. The methods used in practice-based research are often exploratory, field-based studies involving interviews, observations, and/or descriptive surveys. The intense pressure to achieve methodological distinction and theoretical contribution often results in very current practice-based topics being eschewed by researchers, because the topics themselves are not mature enough in practice to achieve desirable samples or sample sizes, nor are they conducive to theorizing since so little is known. These are precisely the reasons that exploratory, practice-based research can play a tremendous role in helping establish and lay the foundations of a research domain while providing insights into an emerging topic."
64308,22457,20561,The Potential of Renewable Energy to Reduce the Dependence of the State of Hawaii on Oil,2009,"Deriving nearly 90% of its primary energy resources from oil, the State of Hawaii is more dependent on oil than any other U.S. state. The price of electricity in Hawaii is also more than twice the U.S. average. The Energy Policy Act of 2005 directed assessment of the economic implications of Hawaii's oil dependence and the feasibility of using renewable energy to help meet the state's electrical generation and transportation fuel use. This paper is based on the assessments and report prepared in response to that directive.Current total installed electrical capacity for the State of Hawaii is 2,414 MWe, 83% of which is fuel-oil generated, but already including about 170 MWe of renewable capacity. The assessments identified about 2,133 MWe (plus another estimated 2,000 MWe of rooftop PV systems) of potential new renewable energy capacity. Most notable, in addition to the rooftop solar potential, is 750 MWe and 140 MWe of geothermal potential on Hawaii and Maui, respectively, 840 MWe of potential wind capacity, primarily on Lanai and Molokai, and one potential 285 MWe capacity specific solar project (PV or solar thermal) identified on Kauai. Important social, political, and electrical-grid infrastructure challenges would need to be overcome to realize thismore » potential. Among multiple crop and acreage scenarios, biofuels assessment found 360,000 acres in Hawaii zoned for agriculture and appropriate for sugarcane, enough to produce 429 million gallons of ethanol-enough to meet about 64% of current 2005 Hawaiian gasoline use. Tropical oil seed crops-potentially grown on the same land-might meet a substantial portion of current diesel use, but there has been little experience growing such crops in Hawaii. The U.S. Department of Energy and the State of Hawaii initiated in January 2008 a program that seeks to reduce Hawaii's oil dependence and provide 70% of the state's primary energy from clean energy sources by 2030. The Hawaii Clean Energy Initiative (HCEI) activities will be concentrated in two areas: (1) HCEI Working Groups will be formed and made up of private, state, and U.S. government experts in the areas of Transportation and Fuels, Electricity Generation, Energy Delivery and Transmission, and End-Use Efficiency; and (2) Partnership Projects will be undertaken with local and mainland partners that demonstrate and commercialize new technologies and relieve technical barriers.« less"
2672923,22457,20561,Introduction to Health Behavior Change Support Systems (HBCSS) Minitrack,2016,"The Health Behavior Change Support Systems minitrack discusses how systems and services aimed at influencing health and/or wellbeing behavior can be designed, developed and implemented. Behavior Change Support Systems (BCSS), in general, are defined as socio-technical information systems with psychological and behavioral outcomes designed to form, alter or reinforce attitudes, behaviors or an act of complying without using coercion or deception. [1] Thus, all BCSSs are persuasive systems, i.e. they have been designed with the intent to influence user behaviors [2]. Health BCSSs provide a prominent area to apply persuasive systems design [2]. The minitrack highlights how persuasive theories and models can be used to develop efficient and effective HBCSSs as interventions for different contexts in healthcare, e.g. persuasive decision support systems for self-care or persuasive games to support chronic care, how end-users can be involved to design HBCSS in practice and what evaluation methods are needed to assess the impact of HBCSS on healthier living. Three research studies were selected for presentation at the conference. Taiminen and Taiminen [3] study one of the key persuasive software support categories for HBCSS, namely social support. They examine how frequency of use facilitates peer social support in weight loss, suggesting that frequent use of Facebook based solutions facilitates perceived emotional, informational, and instrumental social support, whereas even though online forum based solutions facilitate emotional and informational support they do it to a much lesser extent. Also Myneni and Iyengar [4] discuss social influence. They present a HBCSS study, regarding peer-to-peer communication in health-related online communities while seeking and providing health-related information. They seek to characterize social influence mechanisms embedded in these communication events through large-scale analysis of an online community for smoking cessation. In their HBCSS study, Al-Ramahi, El-Gayar and Liu [5] analyze persuasive system's actual use through grounded theory and text mining approaches. They seek to extract design concepts from online user reviews and feedback of mobile diabetes applications, suggesting the incorporation of social and structural features into designs."
1903582,22457,20561,E-commerce security issues,2002,"Without trust, most prudent business operators and clients may decide to forgo use of the Internet and revert back to traditional methods of doing business. To counter this trend, the issues of network security at the e-commerce and customer sites must be constantly reviewed and appropriate countermeasures devised. These security measures must be implemented so that they do not inhibit or dissuade the intended e-commerce operation. This paper will discuss pertinent network and computer security issues and will present some of the threats to e-commerce and customer privacy. These threats originate from both hackers as well as the e-commerce site itself. A straightforward comparison could be made of the security weaknesses in the postal system vs. security weaknesses on the Net. The vulnerable spots in both cases are at the endpoints - the customer's computer/network and the business' servers/network. Information flowing in the conduit (trucks/planes and wires) is relatively immune to everyday break-ins. Privacy issues are amongst the major drivers for improved network security along with the elimination of theft, fraud and vandalism. Two major threats to customer privacy and confidence come from sources both hostile to the environment as well as sources seemingly friendly. Coordinated attacks on Yahoo, eBay, ZDNet, Buy.com (on their IPO day) and amazon.com generated a huge amount of publicity and a federal government response. A brief description of these attacks will be given in this paper. Another threat may originate at ostensibly friendly companies such as DoubleClick, MemberWorks and similar firms that collect customer information and route it to other firms. Much of this transaction information is able to be associated with a specific person making these seemingly friendly actions potential threats to consumer privacy. Many of the issues and countermeasure discussed here come from experiences derived with consulting with clients on how to maintain secure e-commerce facilities. These methods and techniques can be useful in a variety of client and server environments, also serving to alert e-commerce users of potential threats."
1589441,22457,20561,Barriers to Increasing the Role of Demand Resources in Electricity Markets,2014,"The objective of this paper is to show that customers can benefit from a smart grid if they become more active participants in electricity markets by 1) relying more on deferrable demand (e.g. electric vehicles and augmenting space conditioning with thermal storage) to shift demand away from peak periods and buy more electricity when prices are low at night, and 2) selling ancillary services such as ramping capacity to mitigate the inherent uncertainty of wind generation. These two factors, coupled with the lower operating cost of wind generation compared to conventional generation from fossil fuels, have the potential for reducing the cost of electricity to customers. However, these benefits will not be realized unless the rates charged to customers reflect the true costs of supply. This paper compares how the bills charged to different types of customer are affected by different rate structures with and without the correct economic incentives. The main savings in operating cost come from the displacement of conventional generation by wind generation, and the main savings in capital cost come from reducing the amount of installed conventional generating capacity needed to maintain System Adequacy by 1) reducing the peak system load, and 2) by using deferrable demand to provide ramping services and reduce the amount of conventional generating capacity needed for operating reserves. A new stochastic form of multi-period Security Constrained Optimal Power Flow is applied in a simulation using a reduction of the North Eastern Power Coordinating Council (NPCC) network for a representative summer day. This model treats potential wind generation as a stochastic input and determines the amount of conventional generating capacity needed to maintain reliability endogenously. The analysis assumes implicitly that all deferrable demand at a node is managed by an aggregator. If the rates are structured with the correct economic incentives (i.e. real-time nodal prices for energy, a demand charge determined by the demand during system peak periods, and compensation for providing ramping services), the results show that 1) the economic benefits for customers with thermal storage are substantial, and 2) the main benefits for customers with electric vehicles (without V2G capabilities in this application) come from buying less gasoline. In contrast, if customers pay conventional rates with a fixed price for energy and no demand charge, the economic incentives are perverse and customers with deferrable demand pay more and customers with no deferrable demand pay less."
453426,22457,20561,"Introduction to the Smart Service Systems: Analytics, Cognition, and Innovation Minitrack",2015,"Economic and societal well-being depend on innovations that help people use big data more intelligently.  Human-centered, smart service systems for business and society can be characterized by: (1) the types of offerings to their customers and/or citizens, (2) the types of jobs or roles for people within them, and (3) the types of returns they offer investors interested in growth and development, through improved use of technology, talent, or organizational and governance forms, which create (dis) incentives that (re) shape behaviors. Innovators of smart service systems,  including entrepreneurs, managers, and policymakers seek to improve quality-of-service for customers,  quality-of-life for citizens, and/or quality-of-returns for investors. Smart service systems are ones that continuously improve (e.g., productivity, quality, compliance, sustainability, etc.) and co-evolve with all sectors (e.g., government, healthcare, education, finance, retail and hospitality, communication, energy, utilities, transportation, etc.). Regional service systems include nations, states, cities, universities, and hospitals.. Global service systems include multi-national businesses, professional associations, and NGOs. Natural or human-made disasters, technology failures, criminal activities, political collapse can disrupt or negatively impact quality-of-life for people living and working in service systems. Using big data analytics and cognitive systems to improve decision-making service providers try to compete for the hearts, minds, and wallets of collaborators by (1) improving existing offerings, (2) innovating new types of offerings, (3) evolving their portfolio of offerings, and, (4) changing their relationships to others in the ecosystem in ways stakeholders perceive as more positive, sustainable, fair, or responsible. The goal of this mini track is to explore the challenges, issues and opportunities related to innovation of smart service systems that enable value co-creation with analytics, cognitive and human systems.  NSF and other funders see this research area as essential to build interdisciplinary innovation capacity (http://www.nsf.gov/pubs/2015/nsf15610/nsf15610.htm)."
2019610,22457,20561,"Project-based, asynchronous collaborative learning",2004,"The value of collaboration as a tool to promote learning is becoming increasingly more evident. Students engaged in collaborative efforts typically retain the information being learned longer by becoming more actively engaged in the learning activity. There is evidence that collaborative activities foster higher-order thinking skills such as analytical reasoning, synthesis, and evaluation. Furthermore, students work in an environment that better prepares them to meet the challenges inherent in succeeding in the workforce. Constructivism in the form of project-based learning has likewise been shown to foster increased retention of material and greater depth of learning. When combined with collaborative assignments, students have demonstrated greater retention and enhanced capability of transferring concepts to practice. Promoting collaboration in a classroom setting is difficult and often resisted by both teachers and students. This difficulty is magnified for courses offered in an online learning environment. Although there are a number of applications available to enable real-time communication, the immediacy and intimacy of person-to-person interaction is difficult to replace. The non-verbal cues that comprise a large part of everyday communication are largely lost through even the richest online environment. As a result, educators are faced with a dilemma: both students and academic institutions are flocking towards courses offered via an asynchronous learning network, but there is no clear understanding of how to foster collaboration, one of the most promising pedagogical tools. Although asynchronous online environments certainly lack the intimacy and immediacy inherent in face-to-face settings and simulated to an extent by synchronous applications, meaningful collaborative assignments are still possible. The proposed paper details a five-step systems approach for fostering project-based, collaborative learning in an asynchronous learning environment. The steps are illustrated with examples from a graduate-level course in multimedia systems in which asynchronous collaboration was a featured assignment."
2555553,22457,20561,Governing health regions/informing board members,2004,"Governing boards of Canadian regional health authorities report deficiencies and dissatisfaction with the information available for decision making. Given the importance of health personally and politically the potential impact of deficits is great. The ultimate goal of this study is the improvement of decision support for the governing boards of regionalized and vertically integrated health care systems. Our immediate purpose is to understand how board members use information in decision making. This is required to both model the current communication and information use in decision processes, as well as, to design technology solutions congruent with these. Institutional ethnography was explored as a way of doing systematic inquiry as a preliminary step in the design process. This paper provides a methodological demonstration. Ethnographic fieldwork was conducted with one regional health board. Standard ethnographic data collection methods (observation, key informant interviews, meeting transcripts and documentation) generated data that were analysed using a framework and method developed by Canadian social theorist Dorothy Smith. Taking the standpoint of the decision maker and tracing information links to locations removed in time and space from the decision making environments permits a roadmap of knowledge construction to emerge. Preliminary findings confirm that a sequential linear decision making process is not in evidence. The Board relies on the knowledge and contacts of board members to become concisely informed from sources external to the organization. More extensive information infrastructure is in the planning stages to support the board but much analysis is currently ad hoc. A rich model of the dynamic interplay of work processes, professional discourses, institutional complexes and various knowledge practices, beliefs and ideologies is made visible. The insights gained in this investigation are used as a basis for developing strategies to improve the effective use of information and communication technologies for decision support."
2385401,22457,20561,Microarray gene expression profile data mining model for clinical cancer research,2004,"The DNA microarray is the latest breakthrough in molecular biology, which provides researchers with an approach to monitor genome-wide expression systematically. Its application in cancer study has proved to be successful in elucidating the pathological mechanism, with the potential of altering clinical practice through individualized cancer care and ultimately of contributing to the battle against cancer. However, the current hurdle and challenge is how to make use of the tremendous amount and ever-growing microarray experimental data to precisely explain the cancer mechanism and to better predict the cancer development in the early stage. This topic has been realized by traditional biologists and presented to a new group of scientists from Biology, Statistics and Computer Science. We propose a newly designed data mining model, fashioned from a computer science point-of-view, to store microarray experimental data in a systematical organization, and to provide an efficient way for researchers to mine the database and populate it in a reasonable manner as their research progresses. The model in our design addresses the interpretation of the meaning of the microarray gene expression profile data in cancer research in the context of the biological pathway, with focus on the elucidation of key pathways in cancer development, thus providing a bridge between clinical cancer research and microarray gene expression raw data. An object-relational database schema is proposed, which includes six subsystems: array, cancer, drug, gene, image and pathway. The relationship between the gene expression profiles under different experiment conditions and biological processes can be drawn from this database. This newly designed data mining model provides an efficient way to translate the large collection of existing profiles so as to be a handy reference for clinicians who face cancer early detection, clinical diagnosis and treatment decisions; it offers a new paradigm as a patient education tool for better patient care and health advisory against human disease; it also provides molecular biologists with an alternative and feasible route to interpret genetic experimental data, which may ultimately lead to a more complete understanding of a complex human disease-cancer."
2531707,22457,20561,Markets for reliability and financial options in electricity: theory to support the practice,2003,"The underlying structure of why and how consumers value reliability of electric service is explored, together with the technological options and cost characteristics for the provision of reliability and the conditions under which market mechanisms can be used to match these values and costs efficiently. This analysis shows that the level of reliability of electricity provided through a network is a public good within a neighborhood, and unless planned demand reductions by customers have the identical negative value as an unexpected service interruption, market mechanisms will not reveal the true value of reliability. A public agency must determine that value and enforce the reliability criteria. Furthermore, in order to get an efficient level of demand response by customers in periods of system stress, they must see real time energy prices plus they must be paid an amount equal to the suppliers' cost of adding reliability to the system, if that amount is not included in real time prices. An illustration is provided of how VARs might be scheduled and priced in contributing to system reliability, and a co-optimization procedure is required to determine energy and reserves simultaneously, similar to the method proposed by Chen, Thorp, Thomas, and Mount as stated in M. Friedman and L. J. Savage (1948) for locational reserves. The optimization can be decomposed into a two step process - first, both required capacity and energy are selected based upon suppliers' offers over both dimensions through the minimization of expected costs over the list of contingencies necessary to satisfy the reliability criteria. This first step commits the reserves, but energy supplies are allocated in real time based upon the previous offer prices but the actual realized state of the electric system. This procedure which satisfies physical realities has a natural parallel in financial markets that have a forward option market with a strike price, followed by real time market clearing."
2570731,22457,20561,Toolkits for open innovation - the case of mobile phone games,2004,"User toolkits enable consumers to develop customized product applications without having dedicated technical knowledge. Applied in the field of handheld computing, toolkits are a very powerful instrument to meet the growing demand for customized mobile applications. In this paper, the theoretical principles and functionalities of user interaction toolkits are translated into a technical software concept for mobile phone games. The presented toolkit is a new Internet based application allowing users to create a customized game on their desktop computer and to transfer it to handheld devices. In contrast to well known open source software development projects, no programming expertise is required. Thus, participation of innovative users is comparatively easy. In line with the open source concept, but as an extending feature to the toolkit approach, the presented solution is embedded in an online community. Thus, contributions by innovative users can be stored in a library leading to a continuously growing information pool of available components. Games and components can be passed on easily between customers, facilitating the adoption of other users' contributions as well as collaborative development between users. The community feature of the toolkit does not only provide the common toolset of online communities allowing for user-to-user communication, e.g. chats and bulletin boards, or text based contributions, e.g. recommendations, product evaluations and voting tools, but it also enables users to exchange and jointly develop actual product prototypes. In this regard, the presented 'toolkit for open innovation' is the foundation of a 'value web' in a unique manner: a value web in between consumers and users. The paper further derives economic benefits of the developed toolkit for mobile phone game creation theoretically and integrates them into a diversified business model. The toolkit as a distinct performance feature has the potential to establish a social environment for its most enthusiastic users and thereby to strengthen user relationships with the provider and increase overall business success."
2097527,22457,20561,Detection of deception: collaboration systems and technology,2004,"Deception is defined as messages and information knowingly transmitted to create a false impression or conclusion. Since 9/11 we are all aware of the threat of terrorism and need to be vigilant in our pursuit of the detection of deception. A major risk to the success of our society in the 21st century is the failure to detect and counter deception in the world. Success depends on our society achieving information superiority. This requires safeguarding information against manipulation, infiltration, and deception by adversaries. Yet achieving high information assurance is complicated not only by the very speed, complexity, volume, and globality of communication and information exchange that society now expects and demands, but also by the fallibility of human deception detection, vulnerability exacerbated by new information technologies. Although automating deception detection is an appealing prospect, the complexity of detecting and countering deceptions that involve humans as source, conduit, or target defies a completely automated solution. A more promising approach is to integrate improved human detection with automated tools. The objectives of this minitrack are to encourage research papers that offer approaches and theories to detecting deception through one of the following: (1) synthesize applicable theories to create a model of deception and detection processes; (2) identify through experimental and longitudinal research systematic uncertainty-reduction and information-processing biases that make humans susceptible to false positives and false negatives; (3) identify reliable indicators of deceit under varying task and communication conditions; (4) develop a multi-pronged, computer-assisted training program to improve detection abilities; (5) create prototypes for automated tools to augment human detection; and (6) test integrated training program and automated tools to improve accuracy in distinguishing truthful from deceptive information and communications. To accomplish these objectives, this minitrack will bring together scientists and practitioners from the relevant fields of information systems, communication, criminology, psychology, artificial intelligence and warfare."
2252680,22457,20561,Exploring the impacts of knowledge (re)use and organizational memory on the effectiveness of strategic decisions: a longitudinal case study,2003,"Two forces that dramatically affect the sustainability of firms' competitive advantage in the new competitive landscape have been identified as globalization and information and communication technologies (ICTs), such as the Internet and intranets (e.g., Castells, 2000; Porter, 2001). Organizations often rely on acquired knowledge from past experiences to make higher quality decisions on business strategies for better future performance. In this context, knowledge management (KM) and organizational memory (OM) become a central issue to the effectiveness of strategic decision-making and organizational performance. This paper examines the relationship between the (re)use of knowledge/organizational memory (OM) and the effectiveness of strategic decision-making in devising corporate strategies. As part of an exploratory case study approach, a number of interviews are being conducted among top executives at a multinational firm. As a framework, the components of the modified version of McLean's IS success model by Jennex & Olfman (2002) are being used to examine for the impact of knowledge strategy and technological resources, along with the impact of individuals and members from wider organizational context on strategic decision making processes. These components are then analyzed within Galliers' (2002) IS strategy framework of emergent and deliberate strategizing. The analysis accounts for the inter-subjectivity of the concept of KM. Results from a continuous longitudinal study have clearly shown the significance of culture and human-driven knowledge requirements along side the use of an ERP system as part of an OMS. On-going findings of this study aim to contribute to a richer understanding of the impact of knowledge and OM/OMS on organizational learning (OL) and the effectiveness of managerial decision processes. In the context of the IS success model, this paper highlights the intermingled approaches to organizational knowledge management practices due to the contextual nature of knowledge and the human need for social interaction."
2677325,22457,20561,Introduction to the Information Systems Procurement and Benefits Realization Minitrack,2016,"Organizational information systems are acquired through numerous means: as service (cloud computing), as configurations to large enterprise systems, as packaged software, or through dedicated development. Despite of existing tracks of research on these topics, yet, according to Gartner reports and popular press articles, numerous information systems acquisition projects fail in terms of costs, schedules, and objectives [2]. Moreover, despite two decades on research focusing on benefits realization of IT investments, challenges to adopt the recommended practices and to realize the benefits of information systems have largely remained. It is surprising that despite the problems the practitioners face in information systems acquisition, the topic is still little understood in the IS researcher community. For example, such questions as how to choose an appropriate acquisition strategy and method, how to execute the acquisition project successfully, and how to acquire IS related services have been left largely intact -- even though these are significant issues for practitioners. A recent Delphi study identified benefits realization as the most important issue to be considered by IS procurement professionals in the Norwegian public sector [1]. Public sector procurement is strictly regulated and instructed (e.g., in Europe), so that criteria for selecting the IS need to be known early on in the acquisition process. For instance in Norway, all public ICT acquisitions need to justify rather detailed benefits to the public or to the civil servants proactively, before the acquisition takes place. Although the literature documents several methods and techniques for benefits justification, management and realization, they have not reached wide utilization in practice. The situation is, up to large extent, identical in the private sector as, for instance, business cases are difficult to write and different IS initiations are difficult to compare. This minitrack consists of three different approaches complementary to each other in terms of information systems procurement and benefits realization."
1058666,22457,20561,"Grid Modernization: Seamless Integration of Protection, Optimization and Control",2014,"The objectives of smart grid and grid modernization are to increase automation and seamlessly integrate data, models, protection, optimization and control of the power grid. This effort is affected by technological advances. One such technology is the numerical relay which has increased its domination to the point that today has almost completely displaced electromechanical and solid state relays and the most recent technology of merging units that has separated the data acquisition function from protective relays and SCADA systems. The capabilities of the numerical relays are not fully utilized today, specifically, by and large, they simply mimic the logics that were developed for the electromechanical relays but with much more flexibility. Recent developments towards substation automation are utilizing the numerical relays for SCADA, communications and in general an integrated system for protection and control. These approaches indicate the recognition that numerical relays offer much more than simply mimicking protection functions of the past. They also offer the ability to form the basic infrastructure towards a fully automated power system, the subject of this paper. In previous work, we presented a new protection scheme that is a generalization of differential protection. The approach is based on dynamic state estimation. Specifically, the protection scheme is based on continuously monitoring terminal voltages and currents of the component and other possible quantities such as tap setting, temperature, etc. as appropriate for the component under protection. The monitored data are utilized in a dynamic state estimation that continuously provides the dynamic state of the component. The dynamic state is then used to determine the health of the component. Tripping or no tripping is decided on the basis of the health of the component. The present paper takes the above concept one step further. Using the dynamic state estimation of a protection zone as the basic technology, it builds an integrated automation system that performs the protection functions, validates models, transmits the models to the control center, integrates monitoring and control, enables optimization and provides automated disturbance playback capabilities. The system provides the infrastructure and real time models for any application along the spatial extend of the power system."
972923,22457,20561,The Hidden System Costs of Wind Generation in a Deregulated Electricity Market,2010,"Earlier research has shown that adding wind capacity to a network can lower the total annual operating cost of meeting a given pattern of loads by displacing conventional generation. At the same time, the variability of wind generation and the need for higher levels of reserve generating capacity to maintain reliability standards impose additional costs on the system that should not be ignored. The important implication for regulators is that the capacity cost of each MW of peak system load is now much higher. Hence, the economic benefits to a network of using storage and controllable load to reduce the peak system load will be higher with high penetrations of wind generation. These potential benefits will be illustrated in a case study using a test network and the SuperOPF. An important feature of the SuperOPF is that the amount of conventional generating capacity needed to maintain Operating Reliability is determined endogenously, and as a result, it is possible to determine the net social benefits of relying more on an intermittent source of generation, such as wind capacity, that lowers operating costs but increases the cost of maintaining System Adequacy. The capabilities of the SuperOPF provide a consistent economic framework for evaluating Operating Reliability in real-time markets and System Adequacy for planning purposes. Basically, a financially viable investment requires that the reductions in the total annual costs of the existing system should be larger than the annualized cost of financing the addition of, for example, wind generation to a network. The scenarios considered make it possible to determine 1) the amount of conventional generating capacity needed to meet the peak system load and maintain System Adequacy, 2) the amount of missing money paid to generators to maintain Financial Adequacy, 3) changes in the congestion rents for transmission that are collected by the system operator, and finally, 4) the total annual system costs paid by customers directly in the Wholesale Market and, indirectly, as missing money. The results show that the benefits (i.e. the reduction in the total annual system costs) from making an investment in wind capacity and/of upgrading a tie line are very sensitive to 1) how much of the inherent variability of wind generation has to be accommodated on the network, and 2) how the missing money paid to conventional generators is determined (e.g. comparing a regulated market and a deregulated market)."
2433613,22457,20561,Optimal decision making in a dynamic model of community health,2004,"This paper presents results from a preliminary system dynamics simulation model of a hypothetical community in poor health and suffering from a syndemic of intertwined afflictions. Prevention science has moved from an emphasis on single diseases and epidemics toward a more systemic, ecological perspective, including the concept of causal feedback. From this perspective, afflictions may be seen as being affected by - but also as affecting over time - adverse living conditions and the community's internal capability to address its health and social problems. System dynamics provides a methodology for translating this feedback view into testable form and analyzing its implications, including those involving policy decisions. Our simulation model is relatively compact, containing only three stocks and about 100 variables overall, including some thirty constants that specify fixed aspects of the community, the cluster of afflictions, the effectiveness of problem-fighting efforts, and the cost-effectiveness of potential outside assistance from government and philanthropies. The model is based on the literature and the observations of public health officials, researchers, and community health advocates, but has not yet been verified and refined through case study application. Nonetheless, optimization and sensitivity testing of the model have generated logically defensible hypotheses about the dynamic impacts on community health of various types of outside assistance and their relative benefits. One such hypothesis is that the first priority for outside assistance in communities that are weak and struggling against multiple afflictions should be to assist in building community strength, perhaps even before substantial assistance is provided for direct fighting of prevalent diseases. Another possibility suggested by the model is that outside assistance aimed directly at improving living conditions may have downsides (time lags, unintended side effects) that render such assistance less beneficial in the absence of widespread citizen participation than other types of assistance for health improvement."
2334694,22457,20561,The study of information system development (ISD) process from the perspectives of power development stage and organizational politics,2002,"This paper is to study the information system development (ISD) by looking into fifty-six cases from the perspectives of power development stage and organizational polities. We intend to find out why the ISD will be a success or a failure. In this research we sort out 192 examples of political games from 56 cases, which can be categorized into forty-one kinds of games. Some of them, because of their special features, appear only in one of the ISD stages of planning, development, or implementation. We have come to the following conclusions: The unclear performance evaluation system, role ambiguity, distrust placed in individuals, will induce more political games. And the political games will thus bring negative impacts on the organizational culture, too. Leading an easy life and providing lip service, game players usually exploit only the type of power I. The ten kinds of game players, including staying aloof exploit the type of power II, and then they can hold stronger power for they can act on their own, with no need to contact with others or to be bound by others' interests or actions, and express this kind of behavior, through a cynical retreat from polities. The eleven kinds of games, including finding a scapegoat may unconsciously exaggerate the danger of conflict and reprisal, and therefore cause workers more anxiety, because the players use the type of power III. The other five kinds of game players, including building a favorable image use the type of power IV, which can promote workers' interests and resolve conflicts while helping the workers develop some attachment to co-workers and the organization and lead to conventional organizational polities. This paper finds that the MIS manager and professionals play as many as half of the games, so it takes less effort to manage the MIS professionals in order to prevent many political behaviors. Finally, besides the four major adverse effects (deflection of goals, dilemmas of administration, dissipation of energies, and diversion of resources), the forty-one kinds of games mentioned above can also result in a good effect-the success of project."
1850992,22457,9804,A multilingual embodied conversational agent for tutoring speech and language learning.,2006,"Speech and language science and technology evolved under the assumption that speech was a solely auditory event. However, a burgeoning record of research findings reveals that our perception and understanding are influenced by a speaker's face and accompanying gestures, as well as the actual sound of the speech. Perceivers expertly use these multiple sources of information to identify and interpret the language input. Given the value of face-to-face interaction, our persistent goal has been to develop, evaluate, and apply animated agents to produce realistic and accurate speech. Baldi® is an accurate threedimensional animated talking head appropriately aligned with either synthesized or natural speech. Baldi has a realistic tongue and palate, which can be shown by making his skin transparent. Based on this research and technology, we have implemented computer-assisted speech and language tutors for children with language challenges and for all persons learning a second language. Our language-training program utilizes Baldi (or his likeness) as the conversational agent, who guides students through a variety of exercises designed to teach vocabulary and grammar, to improve speech articulation, and to develop linguistic and phonological awareness. We have also implemented multilingual agents, using a client/server architecture system. This system has been used to develop Bao, a Mandarin talker, which has been used in an initial training study for college students learning Mandarin as a new language. The results address the potential for using visible speech technology and pedagogy in language learning of both similar segments in the two languages and new speech segments in the new language. Although visible speech did not facilitate pronunciation learning relative to just auditory speech, we expect that a more prolonged training period would show an advantage of visible speech. Some of the advantages of the Baldi pedagogy and technology include the popularity and proven effectiveness of computers and embodied conversational agents, the perpetual availability of the program, and individualized instruction. The science and technology of Baldi holds great promise in language learning, dialog, human-machine interaction, education, and edutainment. Index Terms: Speech Animation, Language Learning"
2341234,22457,20561,Best practices in data warehousing to support business initiatives and needs,2004,"The paper presents the data warehousing architecture and practices used at a major U. S. retailing company. Many considerations were assessed when deciding which data warehousing architecture to adopt. The paper discusses the two pre-dominant styles in data warehousing, namely the Bill Inmon Style or the top-down approach and the Ralph Kimball Style or the bottom-up approach. The company chose the Inmon style due to a unique combination of circumstances in their business and technical environments, which are being discussed in detail. Much of the information presented in this paper is based upon the direct experiences of the lead data architect assigned to the projects under which this U. S. retailing company's customer data warehouse evolved. The architecture has evolved over time and currently has been accepted at the company as a best practice. It is interesting to mention that both the hardware platform (CPU and disk drives) and relational database management system (RDBMS) software employed today at this company for data warehousing is not the same as was selected for the first instantiation. The implication was that the best plan or practice was a flexible one. There were many challenges, like organizational, technical, data sourcing and data naming, needed to be solved during the pre-project, initial stages, and throughout the project and beyond. The initial data warehouse, implemented in 1996, was termed an overall success and approved for expansion. The current data warehouse data are being used by over six hundred registered users to fine-tune customer marketing and leverage and share data in an enterprise manner. The data warehouse has allowed the company to strengthen customer relationship management (CRM) core capabilities and business partnerships. Today, there are many departments benefiting from queries and requests for data warehouse data, many anticipated, some not. Although not planned, the data warehouse has been a valuable source of purchase and customer data in case of a manufacturer recall of merchandise. Above all, the company has been able to leverage and share enterprise customer data to the benefit of the entire company."
811080,22457,20561,Personalization through mask marketing,2003,"Customized marketing, so called 1-to-1 marketing, is often viewed as the panacea of e-commerce. User profiles, such as click streams logging every site the user accesses, are exploited to generate a profile of interests of the users. Marketing measures like advertisements in form of banners or product presentation are tailored according to these profiles. This kind of customizing suffers from insufficient information about the current interests of the users: the profiles are only a collection of past actions of the users. Additionally, sometimes personalization is seen an invasion of privacy and often unsolicited advertisements unrelated to the users' real interests are cited as an example of the nuisances of 1-to-1 marketing. This shows the dilemma that 1-to-1 marketing faces: The users feel they already offer too much information about themselves. Currently, users solve this dilemma by disabling all technical means that enable user profiling, e.g. by disabling cookies in their Web browsers, using anonymity services, and providing fake identities to Web sites. We propose an approach based on peer-to-peer networks to allow marketing to a specific target group while preserving the privacy of users, we call it mask-marketing. In this concept a user assumes the identity of a mask representing his or her intentions. E.g., a user buying a Christmas present will use the Christmas shopping identity, afterwards the same user may use an engineering mask for an information search relating to his work. The users are able to present their preferences and intentions without these being attributable to their true identity. The masks, which are technically realized by sharing cookies, are distributed and updated using a peer-to-peer networking approach. This permits use of a mask by several different users. All actions performed by different users under the identity of one mask contribute to the profile of this mask. Creation and distribution don't require a central service. This is an advantage since the sensitive profile data is not concentrated in a central entity in the network, which could be viewed by privacy sensitive users with suspicion."
2676618,22457,20561,On the Death and Possible Rebirth of Energy-Only Markets,2016,"Our previous research has shown that distributed storage capacity at load centers (e.g. deferrable demand) can lower total system costs by smoothing out and flattening the daily dispatch profile of conventional generating units. The main savings in cost come from the price arbitrage caused by shifting load and from the reduction in the amount of installed conventional generating capacity needed to maintain operating reliability and generation adequacy at the peak system load. However, the full capacity of deferrable demand will not be used to reduce the peak system load whenever the price arbitrage between the peak and off-peak periods is too small to cover the round-trip inefficiency of the storage. If this situation occurs on the peak load day, the outcome is inefficient. The reason is that the presence of deferrable demand makes the peak load endogenous. Since system operators determine the optimal dispatch by minimizing the expected operating costs, they implicitly ignore the potential savings in capital costs associated with reducing the peak system load. This paper presents a mechanism for augmenting the nodal prices during peak load periods to reflect the capital cost of a peaking unit that we call Peak-System-Load (PSL) pricing. The first objective is to show that PSL pricing can reduce the total system costs and increase efficiency. However, the relative unpredictability of wind generation makes it harder to identify the timing of the peak net-generation accurately. Since PSL pricing also implies that customers pay higher wholesale prices during peak-load periods, the second objective is to show that paying this extra revenue to generators reduces the amount of missing money caused by the lower wholesale prices associated with generating more from renewable sources. In this sense, PSL pricing may lead to a viable energy-only market. An empirical application illustrates our proposed mechanism using a stochastic form of multi-period Security Constrained Optimal Power Flow (the mops model) and a reduction of the Northeast Power Coordinating Council (NPCC) network to simulate operations on representative days."
2275600,22457,20561,Modular Integration Through Aspects: Making Cents of Legacy Systems,2007,"Recently, Continua Health Alliance has brought together a powerhouse team, including Cisco, IBM, Motorola and others, for personal telehealth products and services. This team can provide commodity interoperable healthcare devices and services by introducing new connectivity standards for health management tools. But the costs of integrating and configuring disparate system services have proven to be prohibitive in this domain- healthcare processes require extreme agility to assimilate information across traditional boundaries. As a result, these tools must work effectively with dynamic business processes that often elude cost-effective integration themselves. This creates a requirement for software to be fluidly configurable and interoperable in order to best support personalized care with truly integrated solutions. We believe that, without a new technology for the seamless integration of features within healthcare devices, costs associated with attempts to fuse IT with dynamic business processes can continue to be an obstacle in modern patient care. Aspect-oriented software development (AOSD) is focused on novel notions of modularity that crosscut traditional abstraction boundaries. AOSD techniques and tools, applied at all stages of the software lifecycle, are changing the way software is developed in a wide spectrum of application domains, ranging from embedded systems to enterprise IT. This paper outlines the ways in which aspects could aid the integration and evolution of software used to support modern healthcare practices across this spectrum, with examples at each stage. We believe the key principle of AOSD - the modularization of crosscutting concerns - to be an integral part of the solution to the challenges currently facing modern health service infrastructures"
2104706,22457,20561,Multi-perspective enterprise modeling (MEMO) conceptual framework and modeling languages,2002,"For many companies, the strategic as well as the organizational fit of their information systems is a pivotal factor for staying competitive. At the same time, there is an increasing demand for integrating business processes and informations systems with those of customers and suppliers. The resulting need for organizational changes and the introduction of corresponding information systems is a challenging task. The complexity of the task requires a separation of concerns. At the same time it causes language barriers between various stakeholders, especially between business people and information technology professionals. Enterprise models provide various abstractions that help with the design of corporate information systems which are in line with a company's organization and its long term strategy. They also promise to provide a common conceptual foundation to foster the communication between people with different professional backgrounds. In this paper we introduce a model for enterprise modelling that is based on an extendable set of special purpose modeling languages, e.g. for describing corporate strategies, business processes, resources or information. The visual languages provide intuitive abstractions for various observers. The languages are defined in metamodels which in turn are specified through a common meta-metamodel. Similar to a specialized technical language, they provide concepts that help with structuring and analyzing a domain according to specific objectives. Since the languages are specified in a semi formal way, the models allow for the generation of software prototypes. The languages share common concepts which allow for a tight integration of the various parts of an enterprise model. In addition to offering specialized modeling languages, the modeling method also includes examples, case studies and reference models - to promote the re-use of concepts and artefacts. The use of the method is illustrated by an example, where two different partial models are being integrated."
2174939,22457,20561,Multi-perspective enterprise models as a conceptual foundation for knowledge management,2000,"While successful knowledge management depends on numerous organizational and psychological aspects, the effective documentation, dissemination and utilization of knowledge recommends the introduction of computerized systems to manage knowledge. The design of such a system requires a notion of knowledge that allows to distinguish it from information as ii is handled by traditional information systems. In this paper, a pragmatic notion of knowledge is suggested. On the one hand, it is inspired by some characteristics of knowledge stressed in philosophy. On the other hand, it reflects ideas about knowledge as a corporate asset and as subject of organizational learning. Against this background, a number of requirements which should be fulfilled by a system that manages knowledge are developed. They result in suggestions for the content as well as for the architecture of a Knowledge Management System (KMS). Different from organizational memory systems, the proposed KMS features a high level of formal semantics. Different from expert systems or decision support systems, a KMS does not only help with individual problem solving. In addition to that, it provides a medium to foster discourses between people with different perspectives. Both, content and architecture, are inspired by languages that are part of a method for enterprise modelling. To give an idea of the the content a KMS provides, some of its various views are illustrated from a user's perspective. After that, the object-oriented software architecture is described in more detail by various excerpts from object models on different levels of abstraction. It emphasizes the reuse of existing, state of the art knowledge and allows for individual revisions and enhancements as well. The architecture also includes an interface level layer that helps with the semantic integration of KMS and traditional IS. Both, content and architecture of the suggested KMS are one out of many possible solutions. For this reason, we also briefly discuss the pivotal challenges that have to be faced by research in knowledge management if it includes the design of specialized software systems."
2208863,22457,20561,Adoption-related aspects of an information system in a health care setting,2004,"The goal of this paper is to highlight some health care related issues with regard to information systems implementations. This case study is connected to the adoption of a picture archiving and communication system (PACS) in Turku University Central Hospital. PACS is an information system, which handles radiological film images in digital form. Benefits, costs and drawbacks are discussed. The results are based on a four-year survey consisting of statistical data, cost analysis, modeling, customer satisfaction inquiries, and time and motion studies, observation and staff interviews. Less than I % of the hospital budget was dedicated to the implementation and adoption. PACS was expected to eliminate the use of film- and paper prints, and introduce a new working environment. After four years of adoption one clinical customer unit shifted to filmless activity, namely the intensive care unit (ICU). Availability of imaging requests, imaging studies and radiology reports was improved to 100 % from 87-88 %. A staff member was dedicated to the manual transfer of digital images to the wards. Film acquisition costs were not reduced as anticipated. Personnel tasks will reduce only to the degree to which paper and film prints will be renounced. Also, new tasks will emerge due to PACS. Hospital staff was unprepared for the change. Inexperience regarding informatics, system behavior, and lack of designated expert personnel slowed down the implementation process. In general there is inexperience regarding digital archiving of medical images, which hinders efficient adoption. Technology providers had not sufficient information or knowledge of clinical requirements. Budgets were not adequate for the build-up of a comprehensive cost-effective system. PACS did not overcome any of those concerns it was expected, but added new concerns."
309466,22457,20561,Can Energy Bids from Aggregators Manage Deferrable Demand Efficiently,2015,"Our previous research has shown that distributed storage capacity at load centers (e.g. Deferrable demand) controlled by a system operator can lower total system costs by smoothing out and flattening the daily dispatch profile of conventional generating units and providing ramping services. Since it is in reality impractical for system operators to control large numbers of customers with deferrable demand directly, aggregators will in all likelihood be responsible for managing the individual sources of deferrable demand using instructions provided by a system operator. The objective of this paper is to compare the performance of deferrable demand when 1) the aggregators act as clients to the system operator and receive physical charge/discharge instructions for managing deferrable demand (i.e. Centralized control), with 2) the aggregators follow their own interests and submit bids for purchasing energy into the wholesale auction using projected prices provided by the system operator (i.e. Hierarchical control). The analysis uses a stochastic form of multi-period Security Constrained Optimal Power Flow (SCOPF) in a simulation using a reduction of the Northeast Power Coordinating Council (NPCC) network for representative days. This model treats potential wind generation and load as stochastic inputs and determines the optimum daily profiles of dispatch and demand for different realizations of hourly wind generation and load. Ramping capacity is acquired to ensure that transitions from the realizations in one hour to the next hour, as well as contingencies, can be supported. The results show that if aggregators receive stochastic forecasts of energy prices for the next 24 hours, their optimum strategy for minimizing the expected cost of their purchases from the grid is to determine a high threshold price for discharging and a low threshold price for charging, and as a result, they provide ramping services as well as benefitting from day/night price arbitrage. However, the results are sensitive to the form of the price forecasts."
363248,22457,20561,A Multi-Agent Based NSS for Cost Allocation of Cross-Border Transmission,2001,"Regulation and protection have been the major issues to prevent the consumers from enjoying good quality of service (QoS) at reasonable prices, for example, electricity and long distance call service. Deregulation in such industries started in early 1970s and have achieved significant results in, for example, telecommunication industry. The deregulation in telecommunication was mainly focused on reducing the market power to add more competition to reduce the price and to improve QoS.Similarly, the power industry in several countries also underwent regulation. The power industry used to be protected and regulated. Consumers were forced to buy electricity from particular suppliers and suffered high prices and low QoS. After deregulation, the original boundary lines have been removed and consumers have more alternatives. How to support optimal planning of cross-border electricity trade has become an important issue since then. Decentralization, or participants have the rights to participate in decision-making, is one of the directions of deregulation.In this paper, a decentralized structure is suggested to solve the problem by using multi-agent technology to create autonomy for each participant. In such structure, the centralization of information transmission or decision-making is prevented. Each participant behaves rationally to search for best benefit or payoff through the information she or he owns or through information exchange with other participants. Although all the market participants make decisions to protect their own benefits, the optimal solution (total costs) of the whole system can be achieved finally. This structure is based on the method proposed in [5] and using Java programming language did implementation, which a multi-agent system called Multi-Agent System for Cross-Border Trade (MASCBT). A demonstration on a 5-area test system shows that the suggested new approach is effective and promising."
2147395,22457,20561,Coordination of purchasing and bidding activities across markets,2004,"In both consumer purchasing and industrial procurement, combinatorial interdependencies among the items to be purchased are commonplace. E-commerce compounds the problem by providing more opportunities for switching suppliers at low costs, but also potentially eases the problem by enabling automated market decision-making systems, commonly referred to as trading agents, to make purchasing decisions in an integrated manner across markets. Most of the existing research related to trading agents assumes that there exists a combinatorial market mechanism in which buyers (or sellers) can bid (or sell) service or merchandise bundles. Today's prevailing e-commerce practice, however, does not support this assumption in general and thus limits the practical applicability of these approaches. We are investigating a new approach to deal with the combinatorial interdependency challenges for online markets. This approach relies on existing commercial online market institutions such as posted-price markets and various online auctions that sell single items. It uses trading agents to coordinate a buyer's purchasing and bidding activities across multiple online markets simultaneously to achieve the best overall procurement effectiveness. This paper presents two sets of models related to this approach. The first set of models formalizes optimal purchasing decisions across posted-price markets with fixed transaction costs. Flat shipping costs, a common e-tailing practice, are captured in these models. We observe that making optimal purchasing decisions in this context is NP-hard in the strong sense and suggest several efficient computational methods based on discrete location theory. The second set of models is concerned with the coordination of bidding activities across multiple online auctions. We study the underlying coordination problem for a collection of first- or second-price sealed-bid auctions and derive the optimal coordination and bidding policies."
1000964,22457,20561,"Workflow by the back door? Using XML systems in health service processes, and changing the system",2003,"The UK's National Health Service (NHS) was founded 50 years ago and is now the largest employer in Europe. As with any enormous corporation, there will be procedural and administrative problems in enacting any type of organizational change, and the NHS, run partly by government, partly by managers and partly by clinicians, has been subject to most of them. In hospitals - traditionally a battleground between senior clinicians and the other two interest groups - there are signs of a new accommodation in at least one area; Electronic Patient Records (EPR). Partly through government sponsorship and partly through clinical need, new technology - particularly XML-based processes - is being used, and is beginning to have positive effects both on administrative and clinical processes. Unlike the UK finance industry, where large scale workflow systems have been implemented since the mid 1980s, the UK public health services have noticeably not automated the kind of prescriptive, repetitive workflow processes that have become popular in both cost- reduction and customer-focused programmes in the finance industry. However, evidence is now emerging that EPR processes are evolving, and crossing traditional departmental and informal 'turfdom' barriers. In this way, these XML systems are moving beyond the commonly accepted view of XML as a content management tool, and are now positioned to become a kind of 'proto-workflow' system. As such, they are beginning to display a number of characteristics of 'industrial strength' workflow systems, in creating changes in processes, user behaviour and possibly in organizational culture. This study is based on interviews and surveys with clinicians and administrators, and seeks to understand the development of EPR under a new government initiative. It also uses previous research into NHS systems, and into workflow management systems in the UK finance industry. It looks particularly at those hospitals that are implementing XML based solutions, and at the changes that are beginning to unfold."
1584980,22457,20561,Introduction to the Transformational Government Minitrack,2012,"Initially, e-Government was considered a solely technical phenomenon. However, in the last few years, research on this topic clearly showed its multidimensional nature and identified the importance of acknowledging strategic, political, managerial, organizational, and external relationship factors to understand and explain the transformation of government enabled by Information and Communication Technologies (ICTs). This mini-track examines the complexity of effectively managing e-Government and its transformational potential. Increasingly, this involves inter-organizational collaboration and the management of relationships with citizens, businesses, and other stakeholders. Transformational government is a rapidly evolving concept focused on ICT-enabled fundamental changes in the structure, functions, processes, and external relationships of government. Although the meaning of transformed government is still unclear, practical examples of transformational government involve innovative forms of public service provision through a variety of digital channels, new forms of back-office integration and joint-up government, digital engagement using social media, and new forms of open government and open public data. The aims for governments around the world to achieve transformational government are multiple and varied: they include increased efficiency, enhanced effectiveness, better coordination across government, good governance through increased transparency and accountability, increased citizen trust or even empowerment, improved public decision-making, and modernizing government. This mini-track is one of the key international platforms at which the transformational aspects of e-Government, as well as their implications for government, citizens and society, are being discussed from a multidisciplinary perspective. It welcomes papers with an empirical, theoretical, or conceptual contribution that show the importance of strategic, political, institutional, managerial, organizational, and democratic factors in managing transformational e-Government. This year's mini-track attracted seven paper submissions from which three were selected for presentation at the conference."
1484785,22457,8927,Preferential behavior in online groups,2008,"Online communities in the form of message boards, listservs, and newsgroups continue to represent a considerable amount of the social activity on the Internet. Every year thousands of groups ourish while others decline into relative obscurity; likewise, millions of members join a new community every year, some of whom will come to manage or moderate the conversation while others simply sit by the sidelines and observe. These processes of group formation, growth, and dissolution are central in social science, and in an online venue they have ramifications for the design and development of community software   In this paper we explore a large corpus of thriving online communities. These groups vary widely in size, moderation and privacy, and cover an equally diverse set of subject matter. We present a broad range of descriptive statistics of these groups. Using metadata from groups, members, and individual messages, we identify users who post and are replied-to frequently by multiple group members; we classify these high-engagement users based on the longevity of their engagements. We show that users who will go on to become long-lived, highly-engaged users experience significantly better treatment than other users from the moment they join the group, well before there is an opportunity for them to develop a long-standing relationship with members of the group   We present a simple model explaining long-term heavy engagement as a combination of user-dependent and group-dependent factors. Using this model as an analytical tool, we show that properties of the user alone are sufficient to explain 95% of all memberships, but introducing a small amount of per-group information dramatically improves our ability to model users belonging to multiple groups."
1835978,22457,20561,Successful Penetration into the e-Business Environment: An Empirical Study,2003,"The purpose of this research is to better understand reseller/integrator organizations in the IT distribution channel and some of the factors that may impact their ability to move into and successfully operate within the e-business marketspace. Reseller organizations have had astrong motivation for moving into the e-business space due to dramatically declining margins. In this study, a survey was conducted for 25 reseller/integrator organizations, yielding a response rate of 70%, assessing viability for moving into the e-business space. A surveyinstrument was created, tested, modified, and administered with 22 quantitative and 15 qualitative items. The mean annual revenue for the organizations surveyed was $346 million with an average of 437 employees with an average e-business sale of ¼ million dollars. Likert scales were employed to assess customer orientation, relationship management, and technical staff concerns. End-user organizations' e-business capabilities appeared to be considerably lower than expected contributing to the perceived opportunities to penetrate the e-business market. Reseller organizations are at the initial phases of being able to provide value-addedservices to their customer base. While developing relationships with firms that have needed expertise in order to successfully deliver e-business projects, reseller firms were hesitant to create acquisition strategies but rather focused on building partnerships and alliances fore-business projects. Respondent organizations had difficulty focusing on how to acquire and retain technical e-business resources to accomplish projects. Outsourcing and prime contract were considered to be critical in the overall success equation for reseller organizations. Managerial implications from this study included focusing on a unique set of differentiated e-business service offerings, selling e-business projects to the executive level of the organization, and creating a methodology to manage projects as the prime contractor."
966245,22457,20561,Sales-supporting e-services,2004,"In the ever-increasing number of services offered through the Internet channel, more sophisticated e-services can be found in the business-to-business market. In this paper, we describe the selection and pilot of a B2B e-service in the firm GE Plastics Europe (GEP). The practical aim of the research was to get new customers by turning Web site visitors into commercial leads and to deliver better services to them. The scientific objective of our research was to develop and test an e-services quality model. We reviewed literature and developed an integrated sales supporting e-services quality model (SSEQ model) consisting of the following components: technical reliability, functional reliability, responsiveness, user interface, assurance, customisation, and empathy. We used the SSEQ model at GE Plastics for generating 36 new e-services (by means of brainstorming sessions and interviews), for pre-selecting e-services, for implementing one new e-service (Web Radar) in detail through a pilot, and finally for evaluating the e-service pilot. The Web Radar service allows a GEP employee to monitor real-time who is visiting the Web site. The employee can then offer a chat window to the customer in order to provide sales assistance. The chat acceptance rate in the pilot was 40%. GEP and the customers were satisfied with the results from the pilot study and GEP intends to implement the Web Radar company-wide. Overall, we found that the SSEQ model was very helpful in identifying potentially successful e-services by supporting the company in reviewing 36 e-services thoroughly ex ante. This ex ante evaluation is valuable given numerous failed initiatives related to the use of Internet channels. Evidently, a high rating ex ante does not guarantee success, but it is expected to give better and more thorough insight into the e-services before implementing them full scale."
2043609,22457,20561,A collaborative on-line digital data tool for creating living narratives in organizational knowledge systems,1998,"Organizations, in addressing the need to keep knowledgeable of the many dispersed histories and cultures that emerge within their communities, have used various information technologies (IT) as tools to capture, preserve, sort and interpret organizational memory (OM). Unfortunately the paradigm for OM tools has followed a transfer model-how to transfer specific content or stories to others using the most efficient tools possible. The technology acts as a corridor through which the message travels. A constructionist paradigm strongly counters this approach. Technologies are used as memory makers, these knowledge building tools help cultures grow, lessening the geographical distance that separates organizational members by enabling them to contribute to what Goldman-Segall calls living narratives, digital documents of various media forms that change over time and in various spaces. Geographically dispersed organizations particularly need networked digital construction tools (1) to encourage users to understand each other's ever-changing contextual knowledge and (2) to foster collaboration while capturing, sorting, representing and, most important; interpreting the histories and the memories of their organizations. Web Constellations has been designed as an on-line analysis tool that encourages dispersed users to work on shared digital video datasets and build patterns or layers of interpretations leading to a greater level of understanding for those who were unable to participate in a given event or a series of events. In this article, we explain the need for these collaborative on-line tools that build multiple meanings, and then we discuss how Web Constellations can be used as a tool for organizational memory system (OMS) and organizational knowledge systems (OKS)."
2227050,22457,20561,Cognitive fit and an intelligent agent for a word processor: should users take all that advice?,2003,"While intelligent agents have been developed to provide objective and expert advice to users, most experienced users know that they should not be followed blindly. Cognitive fit theory was developed about ten years ago to support the notion that tools should fit the tasks for which they were designed in light of the user's capabilities. Recently, intelligent agents have been provided to nearly every computer user as part of the Microsoft Office Suite. In nearly all of the applications in the suite, suggestions pop up as the software encounters recognized patterns. Users' capabilities vary widely, however. Some users have noticed anomalies in the advice, and their expertise leads them to override that advice. The computer credibility literature would predict that some users will take that advice without questioning it; this paper asserts that this will occur when there is lack of cognitive fit. In this study, the advisor, one particular intelligent agent in Microsoft Word was examined. In this experimental study, 33 undergraduate students were exposed to a passage of text with five repetitions each of three types of error conditions: (1) errors flagged correctly, (2) errors found by the advisor that were not truly errors, and (3) errors missed by the Advisor. Hypotheses were that (1) the advisor would in general improve performance, (2) Expertise in English would in general improve performance, and (3) the advisor would help more those with higher English skills than those with lower English skills. Verbal SAT scores were obtained by permission of the subjects to serve as a measure of English skills. Analysis of the data showed that overall, all three hypotheses were supported in general. The paper also provides more detailed results for each of the error types. The results imply the need for careful use of intelligent agents; agents are not substitute for user expertise and could indeed degrade the performance of non-expert users."
2102017,22457,20561,Optimistic distributed execution of business process models,1998,"For the modeling of large and complex systems of business processes, a flow oriented, graphical modeling framework based on Petri nets has emerged taking the potentials of a qualitative and a quantitative analysis based on one and the same model. For the quantitative analysis of business process models (BPMs) representing realistically sized enterprise organizations, traditional evaluation techniques (like discrete event simulation) tend to become practically intractable. To be able to cope with very complex models, therefore, the author has developed a distributed execution mechanism based on the time warp distributed simulation protocol. A corresponding software tool was implemented based on the MPI communication library, thus portable to almost any distributed or parallel computing platform. In case studies performed on a 134 node Meiko CS-2 multiprocessor investigating real and hypothetical business or organizations, this work demonstrates that parallel/distributed simulation techniques make the execution of very large models feasible: in situations where the simulation model has reached a complexity prohibitive to an execution on a single processor computer (e.g. due to memory constraints), the decomposition into smaller submodels to be executed on a parallel processor or a network of workstations remains the only means to get the simulation done. As such, a whole new class of (complex) BPM simulations becomes practically tractable, and traditional simulations can be accelerated dramatically. As an example, a BPM of a document flow system comprising 64 offices with an average of 1000 documents per office gains a 250 to 300 fold acceleration of the overall execution speed using 32 processors of the CS-2."
2135554,22457,20561,Development of an effective remote interactive laboratory for online internetworking education,2004,"The Faculty of Engineering at Dalhousie University, Halifax, Canada has been offering a Master's degree program in Internetworking since 1997. The program also provides comprehensive hands-on laboratory experience in configuring, maintaining, troubleshooting and simulating networks. The university intends to increase its student base through online education retaining the same quality of interactions as the onsite program. In the online context, the design and the implementation of an effective remote interactive laboratory (RIL) environment is highly challenging on account of the special hardware, simulation and computing needs of the internetworking courses. This paper focuses on translating the onsite laboratory elements into the online RIL environment by allowing students at geographically remote sites to access and interact with internetworking devices located at Halifax. The RIL is devised using de-facto networking standards, free software and commercial Internet browser. Real-time interaction and information transfer with the Halifax site are achieved independent of the technology available to the remote student. The RIL design and delivery mechanism are tailored to: i) provide a constructivist pedagogical approach; ii) model a collaborative learning environment for group interaction; iii) match the characteristics of the delivery media to specific learning processes (media-synchronicity theory) including the provision of unambiguous feedback and guidance; iv) assign appropriate instructional roles; and v) determine desirable student competency outcomes; all in a remote learning context. A 4-tier role architecture consisting of faculty, facilitators at both local and remote sites and students, has been determined appropriate and adapted to maintain academic integrity and offer the same quality of interaction as the onsite program."
2195373,22457,20561,Development of a hand-held real-time decision support aid for critical care nursing,2003,"In the current health care environment, nurse clinicians must work faster and smarter making complex decisions on almost a continual basis. Evidence-based knowledge and standardized guides, such as clinical algorithms, can support clinical nursing decisions, however; effective real-time access is limited. This paper outlines research addressing this problem. In this research, current clinical knowledge is delivered to the clinician via an off-the-shelf handheld computer using wireless access to a central server and data repository. Innovative minimal-set database, data mining and knowledge discovery algorithms using a combination of case based and rule based learning with added confidence measures permitting bi-directional (forward and backwards) inferencing based on individual client data are developed and presented for the hand held device. The technology provides real-time decision support for the multiple cases and sequential decisions characterizing present critical care nursing practice. Nurses will be able to consider a full range of alternative explanations, determine additional data needs, find, isolate and examine patient case outliers for additional diagnostic data or verify the appropriateness of a selected strategy. Once fully developed the system will have the capacity to maintain a history of a series of decisions and outcomes thereby over time improving the case base and rule bases used for decision support. Outcomes of the real time decision support aid include more timely health care, less biased decisions, and improved patient outcomes."
272043,22457,20561,Cyber Security and Operational Reliability,2015,"This paper presents a new proposed infrastructure that enables simultaneous cyber security and operational security. The basis of the method is command interception and fast authentication from the cyber security point of view (reliable detection of cyber intrusions) and from the operational reliability point of view. To simplify the process, the command authentication is done at the relay level and relay controls. As such it does not depend on the communication architecture. The method is based on new developments on dynamic state estimation based protection and substation level distributed state estimation. This infrastructure provides the capability to monitor, intercept, and authenticate/block commands as they reach the relay and the control circuits of the relay. Since all controls are exercise through a relay, this approach provides 100% coverage. The authentication/blockage of commands is done quickly because of the distributed approach which enables quick assembly of a local real time model and fast analytics with this local model. Specifically, for each command the proper local real time model is constructed and quickly analyzed to determine the effects on the power system. The analytics determine the effect of the command, if executed, on the system and in particular on the operational reliability of the system. In case of a command that may have adverse effects on the operational reliability of the system, the command will be blocked and the operator will be alerted. In addition to the command authentication at the relay level, an open-source real-time network monitoring system for capturing and parsing network traffic is presented. Because the method is based on the substation level dynamic state estimator which uses only local substation level measurements and data, a byzantine type attack is not considered possible for the proposed approach. Finally, a discussion on the architecture required to integrate the network monitoring and state estimation systems is presented. The methodology is presently being tested in a laboratory setup that includes a digital simulator of the electric power system and hardware in the loop."
2158743,22457,20561,"Network control as a distributed, dynamic game",2001,"The operation of large, widely distributed networks can be modeled as distributed dynamic games. This paper assembles a space in which to seek good solutions for such games. Five dimensions of this space--automatic learning, resource shares, additional constraints, altruism and deference—are explained and illustrated. 1. Three Sub-Networks Large networks for the wide spread distribution of goods and services, such as the electric grid, and the internet, can each be thought to contain three subnetworks: • DN, a delivery-network to produce and distribute the goods and services. • AN, an agent-network to control DN. Nodes in AN are agents and arcs are communication links between agents. (By agent we mean any decision-maker, no matter how simple or complex, ranging from the most basic relays through optimization software to humans.) • PN, a problem-network whose nodes are problems, each specifying the goals of an agent, and whose arcs represent couplings between problems. (Two problems are coupled if they share variables.) The physical networks, DN and AN, are homogeneous (meaning that they are synthesized from only a far fewer types of primitives, such as generators, transformers, breakers and lines, than the number of nodes), and sparse (meaning that the average connectivity of a node is far smaller than the number of nodes). We believe that the problem network also has these properties, specifically: Conjecture-1: each problem in PN can be formulated as an optimization problem. That is, the goals of each agent, whether they are conventional control goals, such as trajectory following, or commercial goals, such as maximizing the profits from an auction, can conveniently be expressed in terms of objectives and constraints. Conjecture-2: PN is sparse and its problems are unaffected by growth. That is, each problem in PN is coupled to only a few other problems, and PN grows by adding problems, not by increasing the size of its existing problems. 2. Games and Regulations"
1925988,22457,20561,"Managing the tension in IS projects: balancing alignment, engagement, perspective and imagination",2004,"The differing experiences and practices of systems professionals and users cause major obstacles in the process of requirements definition. For system design projects to be successful, users and systems professionals must learn from each other. Wenger (1998) believes alignment, imagination and engagement to be the core elements for learning in a community of practice. Boland and Tenkasi (1995) believe that perspective taking and perspective making are core elements in learning across communities. We explore the value of these elements as a model for evaluating how users and IT professionals came together to work on an ERP project. The non-profit organization we observed undertook an accelerated and iterative approach to the configuration process in order to surface relevant issues and expedite the project's delivery. Participants were organized into teams dedicated to developing individual modules for the system. The model we propose offers theoretical insight and support for the major problems identified by management as the organization began to test the initial configurations of the system. The case provides insights into how a high degree of active involvement in the configuration process by users, with the assistance of knowledgeable and experienced consultants, can help bridge the boundaries of knowledge across these two communities of practice. Yet, the accelerated schedule limits their ability to leverage their future system. Furthermore, the current project structure created limitations in the team's ability to fully integrate the system modules. This research offers a new lens through which to examine systems design processes. For both practitioners and researchers, it provides insights into the importance of balancing the tensions in a design project."
2394016,22457,20561,Logicality of ASP in healthcare: the NHS case study,2004,"Obtaining value from information technology (IT) is important for organizations to survive and flourish in the highly competitive economy of the 21/sup st/ century. Especially when that organization is the UK's National Health Service (NHS), to whom an heavy investment - for IT improvement - of $7 bn is being injected to cope with pressures exerted within a more demanding population with constantly evolving healthcare needs. This paper explores the emergence of primary service provision (PSP) from perspectives that span the macrolevel of national health policies, the mezzo level of local strategies and the microlevel of IT procurement. These interrelations are studied at a greater depth within case study using the NHS. PSP is used in this paper as a subset of the application provision service (ASP) business model. In healthcare, the study of technology implications cannot be removed from an understanding of the processes of conceptualising, conceiving and using such technology. The authors argue the risk of falling into the trap of technological determinism or considering the impacts as a result of rationally planned actions guiding implementation of technologies. This research has shown there are thousands of hospitals, most doing different business processes in different ways thereby presenting an impossible task of successfully implementing a complex national project consisting of electronic patient records and booking systems. This study of PSP processes does not clearly show how and by whom the meanings of PSP are created, whose interests are voiced and taken into account, what are the overriding aims expressed by ASP vendors and what ethical concerns guide these developments being spearheaded by the NHS information authority."
1889893,22457,20561,Stochastic Model for Power Grid Dynamics,2007,"We introduce a stochastic model that describes the quasi-static dynamics of an electric transmission network under perturbations introduced by random load fluctuations, random removing of system components from service, random repair times for the failed components, and random response times to implement optimal system corrections for removing line overloads in a damaged or stressed transmission network. We use a linear approximation to the network flow equations and apply linear programming techniques that optimize the dispatching of generators and loads in order to eliminate the network overloads associated with a damaged system. We also provide a simple model for the operator's response to various contingency events that is not always optimal due to either failure of the state estimation system or due to the incorrect subjective assessment of the severity associated with these events. This further allows us to use a game theoretic framework for casting the optimization of the operator's response into the choice of the optimal strategy which minimizes the operating cost. We use a simple strategy space which is the degree of tolerance to line overloads and which is an automatic control (optimization) parameter that can be adjusted to trade off automatic load shed without propagating cascades versus reduced load shed and an increased risk of propagating cascades. The tolerance parameter is chosen to describes a smooth transition from a risk averse to a risk taken strategy. We present numerical results comparing the responses of two power grid systems to optimization approaches with different factors of risk and select the best blackout controlling parameter"
2228712,22457,20561,Making sense of the organisation's knowledge: does systematisation of the knowledge base have a positive or negative effect on organizational culture,2003,"This paper considers the impact on organisational culture of systematized knowledge management, as expressed through workflow management systems and through XML content management systems. Workflow management systems have been used, principally in the banking and finance industry, since the late 1980s. They are frequently associated with downsizing or with productivity initiatives, but a body of evidence also exists to show that they are (in the UK, at least) closely linked to customer service programmes, and to espoused corporate values that underpin those programmes. XML content management systems have frequently been associated with applications as varied as supply chain management and ad hoc enquiries, but are now increasingly being used in UK government, and particularly in electronic patient record systems in the health service. The focus of this study has been on the way in which these technologies have been used to gather the organization's knowledge from many disparate sources, and then to deliver, track and guide users. They act as 'expert assistants', providing information, creating new knowledge, and controlling processes. What effect will they have on the organisation's culture? Is such 'guidance' essentially empowering or constricting? Finally, if there is a cultural shift as a result of implementing these technologies, can it and should it be used consciously in the pursuit of further organizational benefit? The paper will show that both technologies represent ways of encapsulating both business processes and business knowledge, and mediating them to users. In so doing, the technology itself creates organizational and cultural change, irrespective of whether BPR or other initiatives are present. The research uses case study and interview material from the UK National Health Service and from the finance industry, together with examples drawn from the academic and practitioner literature."
1464705,22457,20561,"Introduction to Decision, Negotiation, Leadership, Social Communities, and Technology Minitrack",2014,"From a systems perspective, leadership can be viewed as a complex process leading to a negotiation agreement constituting a common ground for involved participants. This process implies the need of using technologies to support connectedness leading to negotiated outcomes, in addition to centralized and decentralized data and models. As Joseph Nye states in his 2010 book on The Power to Lead, leaders as those who help the group create and achieved shared goals,(p. XI) leadership is an integral part of effective group decision and negotiation (GDN) processes. Recognition of this bridge between the GDN and leadership areas allows us to bring to functioning leadership the technology available to support GDN processes. Also, the concept of connectedness has now become pervasive in social generations that are transforming the way organizations work and serve their customers and stakeholders.The newly redesigned HICSS-48 minitrack will continue to support research related to the role of NSS in a Web-centric platform and with applications in electronic markets, e-auctions and automated negotiation agents, and in social computing platforms. More particularly, we would like to expand this minitrack to explore research issues related to the concept, design, implementation, use and evaluation of technologies that involve decision-making, negotiation, leadership and social engagement in business. Since 1991, this minitrack has gathered a respectable collection of papers in this young but promising area of research. Collectively, the selected papers in this minitrack continue to offer innovative and thought-provoking research in computer-supported mediation, now embedded in a social context."
2137652,22457,20561,"Computers for communication, not calculation: media as a motivation and context for learning",2004,"As the skills that constitute literacy evolve to accommodate digital media, computer science education finds itself in a sorry state. While students are more in need of computational skills than ever, computer science suffers dramatically low retention rates and a declining percentage of women and minorities. Studies of the problem point to the overemphasis in computer science classes on abstraction over application, technical details instead of usability, and the stereotypical view of programmers as loners lacking creativity. In spring 2003, Georgia Institute of Technology trialed a new course, Introduction to Media Computation, which teaches programming and computation in the context of media creation and manipulation. Students implement PhotoShop-style filters and digital video special effects, splice sounds, and search Web pages. The course is open only to noncomputer science and nonengineering majors at Georgia Tech, such as liberal arts, management and architecture students. The course is supported through the use of a Web-based collaboration environment where students actively share and discuss their digital creations. The results have been dramatic. 120 students enrolled, 2/3 female, and only three students withdrew. By the end of the semester, the combined withdrawal, failure and D-grade rate had reached 11.5% - compared to 42.9% in the traditional introductory computer science course. 60% of the students who took media computation reported that they would be interested in taking an advanced version of the course; only 6% reported that they would otherwise be interested in taking more computer science. Results of the trial indicate that media computation motivates and engages an audience that is poorly served by traditional computer science courses."
1911681,22457,20561,Predicting Change: A Study of the Value Frequency Model for Change of Practice,2009,"Information systems (IS) researchers have made considerable progress on defining and formalizing structured methods to support collaborative development of information systems. Concepts and methods for transferring IS artifacts to practitioners in ways that give rise to sustained use nonetheless remain more an art than a science. A better understanding of the mechanisms that give rise to willingness or unwillingness to change could help IS developers predict whether intended users would be willing to embrace a new system if it were offered to them. Such understanding might also help IS researchers to develop more effective and reliable deployment concepts and methods for their solutions. This paper reports the findings of an action research study of change-of-work-practice among 17 groups at the headquarters of a 3,000-person organization. All of the groups considered changing to a new project-trackingand-status system which supported a new collaborative project management approach. Five of the groups adopted the new system while 12 either did not adopt, or adopted but then abandoned, the new IS. The goal of this study was to explore whether the change-of-practice behaviors and choices that manifested in the field were consistent or inconsistent with the Value Frequency Model (VFM), a new causal theory for willingness-tochange that emerged from the Collaboration Engineering literature. Observed outcomes were consistent with the theory, which suggests that the constructs and relationships proposed by the VFM may provide useful insights to help explain and predict willingness to change to new information technologies and the work practices in which they are embedded."
2015962,22457,20561,"Continuous audit: the motivations, benefits, problems, and challenges identified by partners of a Big 4 accounting firm",2003,"Early efforts regarding research on a new area of interest are, by nature, exploratory. Before theoretical models can be built and before meaningful empirical research can be performed, a careful process of identifying the appropriate research questions and problems must be undertaken. This is the current state of research regarding the relatively new area of the continuous audit (CA). Though the concepts of CA have been around for almost a decade, and recent advances have made the technologies both widely available and very affordable, firms have yet to make significant steps toward implementation. Thus, there is a need for exploratory surveys of key audit personnel in charge of providing assurance services for major clients to bring to light the issues regarding technology, people, and processes with which auditors and their audit clients are wrestling. This paper discusses the results of a survey of the U.S. assurance partners of a Big 4 accounting firm. The objective of the survey was to get the partners' perceptions and thoughts on the viability of the continuous auditing, the current state of the CA in the audit environment, the impact that CA implementation might have, and the various roadblocks to CA implementation. In addition, various demographic data was collected. So that the open-ended questions of the survey instrument could be systematically categorized and analyzed, and to minimize interpretation bias, QSR NUD-IST/spl copy/ (nonumerical unstructured data-indexing, searching, and theorizing) version 4 software was used to code responses and capture emergent themes. The purpose of this paper is to present the results of this survey, revealing the current state of the CA and the hurdles to overcome in its implementation."
2002107,22457,23735,Route generation for warehouse management using fast heuristics,2004,"In this paper, fast heuristics for a centralized multi-agent route planner are presented and computationally evaluated. We solve a sub-problem of warehouse scheduling involving the routing of intelligent agents as a preliminary step in optimizing the total schedule. The problem involves the generation of routes for automated agents tasked with the transfer of items within a warehouse from storage pallets to a common loading shed. The goal is to minimize the total distance of the routes and the number of routes generated. This constitutes a multiple-objective optimization problem which is NP-hard and hence can take a prohibitively long time to solve using existing search-based techniques. The approach adapted here is to model the system as a split delivery vehicle routing problem (SDVRP) with grid distances and to solve it using heuristics based on tested operations research concepts. Twenty-two such heuristics are tested including the well-known greedy nearest-neighbor (NN) heuristic, and the established savings heuristic of Clarke and Wright. The author introduces two SDVRP variations of the NN algorithm, namely the nearest-fill (NF) and nearest-fill farthest-start (NFFS) heuristics. Existing SDVRP improvement procedures are also considered and generalized to produce numerous heuristic variations. This novel approach of applying fast vehicle routing heuristics to multi-agent routing has the advantage of yielding good quality results within a very short period of time. The results of the study show that the greedy NFFS heuristic combined with the improvement procedures, consistently produces superior results with regard to minimization of distance and the number of routes in an the instances tested."
1991175,22457,20561,Developing E-Government Integrated Infrastructures: A Case Study,2005,"The Public Domain (PD) always serves as an agent to provide better and reliable services and information to citizens. Recent advancements in technology, citizen-demand and new public management initiatives, have all contributed to the advent of Electronic Government (eGov). Much emphasis has been given in achieving this objective through the development of Electronic Government Information Systems (eGov-IS). The authors support that an eGov platform should not been seen as a stand-alone system but as a solution that communicates with back office applications through an integrated infrastructure. An integrated eGov-IS can efficiently automate the business processes of the public domain and increase citizens' satisfaction. However, to achieve such a solution, PD and Local Governments (LG) need to bridge together their disparate systems to provide a common and shared view of their information and services. Many LGs have encountered difficulties in incorporating their systems, and have turned to the adoption of Customer Relationship Management (CRM) and Enterprise Resource Planning (ERP) software packages to improve their services. Nonetheless, many legacy systems have not been replaced and thus, the need for integrating their eGov applications with their front desk and back office systems still exists. Enterprise Application Integration (EAI) can be used to piece together eGov applications with packaged and legacy systems. Although, the application of EAI is flouring in the private sector, its adoption by the public domain is underutilised. The authors investigate EAI and demonstrate, through a case study, how EAI can be used to develop an integrated eGov infrastructure. In doing so, allowing others to relate their experiences to those reported herein as well as to aid public sector organisations on how they can integrate their disparate systems more efficiently and extend their lifecycles."
1766948,22457,20561,An exploratory study of alignment issues of IT acceptance with professionals in a project setting,2004,"The information technology (IT) literature has demonstrated a link with business performance and effectiveness when IT and business objectives are aligned. However, project settings and joint-venture projects in particular, challenge the way alignment has been conceptualized, exposing other sources of alignment. Projects require a quick diffusion of IT to many different stakeholders with different individual and group interests representing many professions with different professional affiliations. Coordinating the diverse groups of individual expertise that often have short stays and weak allegiance to the project is quite difficult. These factors lead to many types of incentive problems in learning and using new IT necessary for project success. This potentially leads to individuals rejecting or bypassing the use of mandated information technology when the individual's personal, group or professional interests do not coincide with project objectives. As a result, a joint venture project setting challenges the underlying assumptions of Diffusion of Innovation Theory and Technology Acceptance Model, thus providing an important contribution for theoretical development in the IT diffusion literature. Therefore, an important research question for IT diffusion, arising from project situations, is: How are individual professional and project incentives aligned in order to diffuse the necessary IT to achieve coordination and project success? The results of this exploratory study conclude that alignment issues affecting an individual's IT acceptance on joint venture projects originates from many unexplored sources. These five alignment issues include objectives, work output, work value, technology expectations, and peers and are required by the individual, their originating company, the project, and the owner company. Each of these alignment issues reveals different aspects of a complex negotiated order to IT diffusion."
2173764,22457,20561,COBIT and its utilization: a framework from the literature,2004,"The control objectives for information and related technology (COBIT) is a trusted open standard that is being used increasingly by a diverse range of organizations throughout the world. COBIT is arguably the most appropriate control framework to help an organization ensure alignment between use of information technology (IT) and its business goals, as it places emphasis on the business need that is satisfied by each control objective by J. Colbert, and P. Bowen (1996). This paper reports on the use of a simple classification of the published literature on COBIT, to highlight some of the features of that literature. The appropriate alignment between use of IT and the business goals of a organization is fundamental to efficient and effective IT governance. IT governance ...is the structure of relationships and processes to develop, direct and control IS/IT resources in order to achieve the enterprise's goals. IT governance has been recognized as a critical success factor in the achievement of corporate success by deploying information through the application of technology by N. Korac-Kakabadse and A. Kakabadse (2001). The importance of IT governance can be appreciated in light of the Gartner Group's finding that large organizations spend over 50% of their capital investment on IT by C. Koch (2002). However, research has suggested that the contribution of IT governance varies in its effectiveness. IT control frameworks are designed to promote effective IT governance. Recent pressures, including the failure of organizations such as Enron, have led to an increased focus on corporate accountability. For example, the Sarbanes-Oxley Act of 2002 introduced legislation that imposed new governance requirements by G. Coppin (2003). These and other changes have resulted in a new corporate governance model with an increased emphasis on IT governance, which goes beyond the traditional focus of corporate governance on financial aspects by R. Roussey (2003)."
1190592,22457,20561,Virtual decision maker for stock market trading as a network of cooperating autonomous intelligent agents,2004,"The idea of a machine that can learn from its own interactions with the world has been one of the driving forces behind artificial intelligence research since its inception (Turing, 1950). The motivation of this paper is to present and demonstrate the merits of a machine to assist a non-expert decision maker, in applying stock market hedging strategies that are typically used by experts. The machine, called a Virtual Decision Maker (VDM), provides the processing power to deal with the very high granularity of such strategies while offering higher flexibility in choosing the trading frequency. More specifically, the VDM is a network of cooperating intelligent agents' technologies that can exploit automated on-line trading services at any time and any place without the physical presence of the decision maker. At present, the VDM is developed in an Excel-VB environment with agents that cooperate to: (i) import the required stock market real time data; (ii) identify the opportunity of making a trade; (iii) formulate an appropriate strategy; and (iv) execute of the corresponding order on the fly. The design of the VDM takes as its main premise the technological advantage of reduced reaction time, as opposed to attempting to anticipate a given security's movement. Results indicate in a disturbing manner that, given expert-validated knowledge, decision-making by cooperating and negotiation intelligent agents could lead to higher returns than commonly used indexes. In the conclusion, the idea of full automation is discussed in relation to the decision maker's behavioural and the cognitive issues."
1871239,22457,20561,Introduction to modeling nonlinear natural and human systems minitrack,2002,"Numerous natural and human-made systems can be described as nonlinear or complex. Such systems often escape the straight cause-effect and linear modeling patterns which traditional science has successfully used over centuries. Linear approximations of dynamic phenomena rarely deliver satisfactory results. On the other hand, nonlinear modeling techniques became feasible and more popular only with the advent of the digital computer some fifty years ago and have been widely used for little more than a decade and a half. In other words, even though the theoretical foundations were laid out much earlier, practical research and application of nonlinear modeling are still in their infancy compared with linear modeling. Among the traditional approaches to modeling nonlinear and dynamic systems are techniques such as discrete event simulation or Markov chains. System dynamics (SD), which captures and analyzes the feedback structure of complex dynamic systems, and agent-based modeling (ABM), which focuses on the rulebased emergent behavior of interacting individual agents, are two other prominent modeling techniques. Multimethod approaches, dynamic triangulation, and complementary applications of these modeling techniques in terms of an integrated research design have been proposed before [1-3]. While such integrated designs have not emerged yet, this minitrack acts as a forum for bringing together nonlinear systems modelers of various backgrounds with the ultimate aim of exploring the prospects and benefits of integration through better understanding of each technique’s research design potential. The insights from integrated research will certainly be relevant and beneficial not only to academic research but also to managerial practice and decision making."
1823689,22457,20561,The influence of the meaning of pictures and words on Web page recognition performance,2003,"Firms spend high sums trying to make their home page as memorable as possible to attract repeat visits. For this purpose, fancy pictures and words are used to catch the attention of visitors. Interestingly, the effectiveness of all of this effort is nearly completely unknown. This study investigated how picture and word selections affected the recognition success rates of the sites visited by subjects. The clear finding in cognitive psychology is that meaningful pictures (Bower et al., 1975) and words (Wanner, 1968) are remembered with much higher performance than non-meaningful ones. In corporate Web sites, therefore, attention can be paid to the meaningfulness of both pictures and words in attempting to make them more memorable. Building on previous research by cognitive researchers that suggests higher memory retention for meaningful pictures and words versus meaningless ones, we hypothesized that Web pages where the salient picture and words are both business-meaning related (BMBM) will be much easier to remember than those with only dictionary meaning or no meaning at all, and that those with dictionary meaning (DMDM) will be easier to remember than those with no meaning. An experiment with 41 participants was performed to test these hypotheses. All possible combinations of pictures and text with no meaning, dictionary meaning, and business meaning form a 3 /spl times/ 3 matrix. Support was found for two of the three hypotheses; the recognition success rate of the combination BMBM was statistically much better than any of the other groups (with the exception of the group DMDM for which it was about the same). Rather than appealing to fancy pictures and words, this study suggests that companies should aim at having consistent business-related meaningful salient pictures and words in their main Web pages. Future research should manipulate the time delay between stimulus and measurement (e.g.; hours, days, etc.) perhaps to reduce the mean scores and increase variability, as well as to investigate interactions of the meaningfulness of the salient elements with other graphics and page elements."
2252148,22457,20561,Component monitoring and dynamic loading visualization from real time power flow model data,2004,"The technology of intelligent electronic devices in power systems has exploded and with it the available real time data. The data are typically used to extract a real time model of the system via traditional state estimation methods. The traditional approach estimates only the system voltages and uses a small part of the available information. This paper presents a new approach for better utilization of the available information. Specifically, we propose the use of existing data for estimating detailed operational models of major power equipment. For example, the detailed models can be in the form of electro-thermal models which then allow the monitoring of device temperatures, dynamic loading, etc. In general, the real time model can be as simple or as complex depending on the type and quality of available data. For example, from typical SCADA data, the real time operational model of a generator can be extracted. This model can provide the operating margins, etc. Addition of other data, such as ambient temperature, etc. can also provide an electro-thermal model in real time. The paper demonstrates the approach with the example of a power transformer. The methodology is applied to extract an electro-thermal model of the transformer. The real time electro-thermal model provides: (a) transformer temperatures including hot spot, (b) transformer loss of life and (c) transformer dynamic loading. The approach has been simulated in a multitasking environment using an electric power system model with a time-function electric load. The operation of the system is simulated by solving the power flow at user selected time intervals. As the time progresses the electric load changes and a power flow solution determines by computation the operation of the system. At each time step, the real time model of the selected power devices are extracted via statistical estimation methods. The real time model provides vital information for these devices. Their operation conditions can be visualized and animated as desired. The paper presents these applications."
2365523,22457,20561,On the first price spike in summer,2004,"The objective of this paper is to determine why price spikes occur in deregulated wholesale markets for electricity, and how effectively they can be mitigated by different modifications to the market. The analysis employs a multi-agent system (MAS) to replicate a spot market with six supply firms, represented by adaptive autonomous agents. These firms submit offers to maximize their own expected profits, and an independent system operator (ISO) clears the market for a predetermined load in a uniform price auction. The firms learn about the market and the behavior of their competitors by comparing actual market outcomes with predicted outcomes based on an estimate of their own residual demand curve. This estimated demand curve is updated each period using a Kalman filter. The main results for creating price spikes are: 1) uncertainty about the system load is an important determinant of observed behavior (i.e. offer curves shaped like a hockey stick) that is replicated in the MAS, and 2) all firms eventually become speculators, and it is unrealistic to expect firms to behave like price takers in a market with six suppliers. The main results for mitigating high prices are: 1) it is impractical to rely on more suppliers, vertically integrated firms, capacity payments or fixed contracts for power to eliminate speculative behavior, and 2) price responsive load is an effective way to mitigate high prices, particularly if some load responds at relatively low prices. Overall, the results show that a MAS can be used to evaluate a wide range of policy options and supplement the results of market tests using human subjects."
1896590,22457,20561,Joint Capacity and Contract Management for Operating Service Facilities,2009,"Capacity planning and incentive contract design have always been challenging strategic decisions, especially for companies operating in a stochastic service demand and delivery environment. Such service facilities often must make capacity decisions long before observing demand, so a practical approach is to make the decision based on the expected demand distribution. Due to stochastic demand and capacity constraints, service centers often incur delays and delay-related costs when the actual demand is high. When the actual demand is low, however, centers have to bear high idle capacity costs. Economics literature on principal-agent issue has mostly focused on designing salesforce compensation plans so as to motivate the agent and manage risk-sharing. However, in a typical principal-agent model setting, the principal faces no capacity limit and incurs no delay-related costs. Furthermore, the capacity decision and the compensation decision are usually treated as two separate decision processes both in practice and in research. This suboptimal decision process leads to suboptimal results: the principal either incurs high delay costs or high idle capacity costs. To tackle service facility capacity planning and incentive contract issue, we propose instead an integrated approach. That is, we integrate a firms decision regarding capacity investment with its decision regarding the design of a compensation contract. We outline this integrated decision approach and illustrate its benefits with numerical examples. We show that following our decision methodology the firm can achieve significantly higher profits. Several cases in the paper depict that the firm can achieve profit increments ranging from 10% to 42% by properly integrating contract design with its capacity decision process early on."
1946703,22457,20561,Learning through telemedicine networks,2003,"Telemedicine is advocated for its potential to improve the accessibility and quality of health care delivery while lowering costs. Although the potential benefits of telemedicine have long been a subject of research and intense discussion, the results of actual implementations have been far from conclusive. Most current research, which views telemedicine as a substitute for travel and a basis for economies of scale, is rather limited in exploring the full potential of telemedicine. In this paper, we develop a new framework in which organizational learning is the theoretical basis for explaining the development and potential benefits of telemedicine. We conceptualize telemedicine as an integrated IT-enabled health care network of collaborative relationships. A well-developed telemedicine network is high in density, maintains a balance of strong and weak network ties, and is comprised of a diverse set of relationships. This type of network facilitates learning through the exchange, transfer and distribution of medical information/knowledge, the generation and dissemination of new knowledge about how to collaborate effectively via telemedicine, and the application of this knowledge in telemedicine practice. Viewing telemedicine in this light directs our attention to outcomes not emphasized in most prior research, including the diffusion of medical knowledge and expertise, and the development of collaborative knowledge shared by the health care parties. This paper develops a research model to explain how learning occurs in telemedicine practice, identify factors influencing the learning process, and indicate how thriving telemedicine networks can be built. The model focuses on flexibility of information technology, network density, strength of network ties, and network diversity as key factors having impacts on learning. It also views the acquisition, transfer and sharing of medical knowledge and the development of telemedicine collaborative knowledge as two learning processes occurring simultaneously and recursively, and reinforcing each other. Ultimately, learning is the core process that helps realize the potential of telemedicine."
1640714,22457,23757,Prediction and analysis of Pakistan election 2013 based on sentiment analysis,2014,"The significance of social media has already been proven in provoking transformation of public opinion for developed countries in improving democratic process of elections. On the contrary, developing countries lacking basic necessities of life possess monopolistic electoral system in which candidates are elected based on tribes, family backgrounds, or landlord influences. They extort voters to cast votes against their promises for the provision of basic needs. Similarly voters also poll votes for personal interests being unaware of party manifesto or national interest. These issues can be addressed by social media, resulting as ongoing process of improvement for presently adopted electoral procedures. People of Pakistan utilized social media to garner support and campaign for political parties in General Elections 2013. Political leaders, parties, and people of Pakistan disseminated party's agenda and advocacy of party's ideology on Twitter without much campaigning cost. To study effectiveness of social media inferred from individual's political behavior, large scale analysis, sentiment detection & tweet classification was done in order to classify, predict and forecast election results. The experimental results depicts that social media content can be used as an effective indicator for capturing political behaviors of different parties Positive, negative and neutral behavior of the party followers as well as party's campaign impact can be predicted from the analysis. The analytical findings proved to be having considerable correspondence with actual results as published by Election Commission of Pakistan‥"
1238103,22457,20561,Can source code auditing software identify common vulnerabilities and be used to evaluate software security,2004,"Software vulnerabilities are a growing problem (c.f. MITRE's CVE, http://eve.mitre.org). Moreover, many of the mistakes leading to vulnerabilities are repeated often. Source code auditing tools could be a great help in identifying common mistakes, or in evaluating the security of software. We investigated the effectiveness of the auditing tools we could access, using the following criteria: number of false positives, false negatives by comparison to known vulnerabilities, and time required to validate the warnings related to vulnerabilities. Some of the known vulnerabilities could not be found by any code auditor, because they were fairly unusual or involved knowledge not contained or codified in the source code. The coding problems that could be identified consisted of string format vulnerabilities, buffer overflows, race conditions, memory leaks, and symlink attacks. However, we found it extremely time-consuming to validate warnings related to the latter four types, because the number of false positives was very high, and because it was not easily apparent if they were real vulnerabilities. These required that the code be audited locally, by people familiar with the code, and carefully inspected to see if the values could be manipulated in such a way as to produce malicious effects. However, the string format vulnerabilities were much easier to recognize. In small and medium scale projects, the open source program Pscan was useful in finding a mix of coding style issues that could potentially enable string format vulnerabilities, as well as actual vulnerabilities. The limitations of Pscan were more obvious in large scale projects like OpenBSD, as more false positives occurred. Clearly, auditing source code for all vulnerabilities remains a time-consuming process, even with the help of the current tools, and more research is needed in identifying and avoiding other common mistakes."
2509509,22457,20561,Strategies Supporting Heterogeneous Data and Interdisciplinary Collaboration: Towards an Ocean Informatics Environment,2005,"This paper considers the elements and challenges of heterogeneous data management and interdisciplinary collaboration, drawing from the literatures on participatory design, computer-supported cooperative work, and science studies to support information design efforts within the rapidly evolving world of large-scale science projects. Certain tensions are embedded in such collaborative projects, being rooted in distinctive disciplinary knowledge interests brought to the table and expressed in occasionally divergent understandings of project rationale, identity and success. A continuum of strategies exist for dealing with such tensions. In this paper, we discuss two of these: a strategy of 'mindful variety' built around an appreciation of disciplinary, organizational and biographical heterogeneneity of collaborative ventures; and attention to the proliferation of 'boundary objects' and shared languages between and within adjacent communities of practice. These strategies are considered specifically through the lens of an Ocean Informatics Environment (OIE), a concept that joins ocean, information, and social scientists working to construct locally responsive, adaptive and scalable information infrastructures for the practice of ocean science. Our team seeks to design an environment supporting reflexive and heterogeneous data practices responsive to the multiple work worlds of ocean science. We consider the development of an ethic of collaborative care, offered as a working principle for the identification, preservation and bridging of disciplinary difference in the cooperative design of scientific work settings as one of several strategies emerging from ongoing work."
2405210,22457,20561,MinISO: A Minimal Independent System Operator,1997,"The Independent System Operator or ISO is the leadactor in the various proposals for a deregulated, competitive electric power industry. The ISO has three possible objectives: security maintenance, service qualityassurance, and promotion of economic efficiency andequity. To achieve these objectives the ISO may be authorized to set the rules for transactions between suppliers and consumers, scheduling and dispatch of generators, loads and network services, and energy markets. Proposals differ in their specification of the ISO's objectives and authority. Two ISO structures are contrasted. MaxISO, based on the UK-Poolco model, hasambitious objectives and much regulatory authority. Itsscientific merit derives from an Optimal Power Flowdispatch model. MinISO's objective is restricted to security, and its regulatory authority is correspondinglymodest. MinISO seeks to provide direct consumer access. Its scientific merit is based on the CoordinatedMultilateral Trades model.By locating in the ISO both the transmission-securityfunction and the generation-economic efficiency function, MaxISO ends up being a hindrance to structuralreform. By separating those functions, MinISO maximizes consumer choice and technical and financial innovation. The California PUC decision of December 1995 is, understandably, a compromise between the twoproposals. The unexpectedly rapid response nationwideof utility and non-utility entities to the potential opportunities of a deregulated industry, however, threatens to make irrelevant the MaxISO model and to shorten the life of California's compromise decision. MinISO remains an option that is flexible enough to accommodatethe choices that consumers and producers may want."
2335376,22457,20561,Information in health care process - evaluation toolkit development,2003,"Increasing health care costs put a great strain on national economies. In recent years there have been several national and regional research and development projects in Finland and in the Netherlands with attempt to generate new modes and means of health care service processes. The aim is at better utilisation of the existing social and health care resources, improved quality of service and rationalisation of business processes without compromising high quality of care. Increased cooperation between the various actors and institutions of health care is essential in achieving this aim. Adaptability of processes , networking and seamless service chains are key words in this development. Information technology plays an important role in traditional business process designing. Both high hopes and large investments have been put in acquisition and implementation of health care information systems without exact evidence of their influence on the process itself. An information system has to appropriately support the flow, acquisition and handling of information needed within the process. The solutions should be both effective and cost-effective. However, implementing a new system or changing an existing one may have a profound, unexpected effect on work and service processes. From health care organisations' point of view, evaluation of information systems facilitates the utilisation of existing information and communication technology (ICT) solutions. Hence, a comprehensive set of evaluation tools is needed to facilitate the health service providers' work. This paper examines issues that have been studied in the ongoing research project that aims at compiling such toolkit."
1993724,22457,20561,"Research, development, and demonstration needs for large-scale, reliability-enhancing, integration of distributed energy resources",2000,"Distributed energy resources (DER) are in transition from the lab to the marketplace. The defining characteristic of DER is that they are active devices installed at the distribution system level, as opposed to the transmission level. While no specific size range has been defined, most distribution systems would have difficulty accommodating distributed generating resources larger than 10 MW/MVA at any single location and many systems may have even lower limits. Distributed energy resources include generation resources such as fuel cells, micro-turbines, photovoltaics, and hybrid power plants or storage technologies such as batteries, flywheels, ultra capacitors and superconducting magnetic energy storage. They may also consist of dynamic reactive power control devices and possibly customer end-use load controls. This paper summarizes technical requirements for large-scale integration of active devices into the existing distribution infrastructure to maintain or enhance reliability. The paper is intended to lay the groundwork for a multi-year program of research necessary to facilitate the transition to such a system. The scope of the research includes consideration of control systems including the sensors and instruments necessary to gather intelligence for real-time power management and dispatch or coordination among distributed generation resources and with utility distribution systems. It also includes improved modeling techniques to better characterize the technologies and their impacts on the distribution (and ultimately the transmission) system."
558901,22457,20561,"A database system for constructing, integrating, and displaying physical maps of chromosome 19",1995,"Efforts are underway at numerous sites around the world to construct physical maps of all human chromosomes. These maps will enable researchers to locate, characterize, and eventually understand the genes that control human structure and function. The volume and complexity of the data already generated requires a sophisticated array of computational support to collect, store, analyze, integrate and display data in biologically meaningful ways. The Human Genome Center at Livermore has spent the past 6 years constructing a database system to support its physical mapping efforts on human chromosome 19. Our computational support team is composed of experienced computer professionals who share a common pragmatic primary goal of rapidly supplying tools that meet the ever-changing needs of the biologists. In this paper, we concentrate on the design issues, tradeoffs, and consequences from the point of view of building a complex database system to support leading-edge genomic research. We introduce the topic of physical mapping, discuss the key design issues involved in our database, and discuss the use of this data by our major tools (DNA fingerprint analysis and overlap computation, contig assembly, map integration and database browsing). Given the advantage of hindsight, we discuss what worked, what didn't, and where to go from here. As early pioneers in this field, we hope that our experience may prove useful to others who are now beginning to design and construct similar systems. >"
2717643,22457,20561,Automatic Content Analysis of Media Framing by Text Mining Techniques,2016,"Political-related news is one of the most popular topics in various media platforms. When news is produced through a process of selection and rephrase by reporters and media firms, reporters' personal political leaning and personal opinions may influence the process, important messages may inevitably loss. In Taiwan, the Parliamentary Library of Legislative Yuan website provides detailed contents about activities happening in the Legislative Yuan, including such contents as transcripts and video recordings of interpellation, conference speech, interim and legislation proposals. Although there is a complete record of information provided online, but the quantity of the legislative documents are far too much for citizens to make sense of. It is imperative that better organized information released to the public would facilitate readers to reduce the cognitive loads in understanding what issues have been discussed by legislators and reported by the media. To minimize the gap between legislative documents and the general public, this study proposes a text mining mechanism to automatically cluster legislative and news documents to identify media frames, and then represents the proportion of each frame corresponding to information sources. The automatic clustering system can determine media frames with the minimum amount of human interference. The results of interviews show that the information system proposed in this study is able to provide political domain experts hard evidences of media framing, and assist the public to discover media framing phenomenon, which are the major contributions of this research."
2276483,22457,20561,Evaluating support for improvisation in simulated emergency scenarios,2003,"Technological systems involving hazards are typically managed by experienced personnel guided by well-formulated, pre-determined procedures. These procedures are designed to ensure that operations proceed in a safe and cost-effective manner. Yet normal operations in these systems are exposed to unexpected contingencies that can require personnel to develop and deploy new procedures in real-time. Creative thinking in such situations is therefore necessary in order to prevent degradation of operations, particularly when there is potential for personal injury, economic loss or environmental damage. One approach to addressing these situations is improvisation. The research described here discusses a series of studies conducted to evaluate the efficacy of a computer-based system for supporting improvisation in simulated crisis situations. The design and implementation of the system are first discussed, drawing upon prior work in blackboard-based systems. The experimental design is then reviewed, followed by a discussion of how the studies were run using groups of emergency response personnel from the Port of Rotterdam in The Netherlands. The group task was to address unexpected contingencies in a timely fashion. A number of measures of group decision effectiveness and uniqueness are presented. Results of the studies suggest that availability of decision support may have had an uneven influence on solution effectiveness and no influence on solution uniqueness. Possible implications for the design of group decision support systems for improvisation are then discussed, along with a number of observations on conducting experimentally-based research on group improvisation."
1133457,22457,20561,Value positions for financial institutions in electronic bill presentment and payment (EBPP),2003,"Business to consumer (B2C) electronic commerce has led to new relationships connecting various supply chain partners via the Internet, significantly increasing the quantity and quality of inter-organizational information flows. Banks are traditionally partners in the information and financial flow elements in the supply chain, but other nonbank parties are also getting involved in these activities. Electronic bill presentment and payment (EBPP) may be defined as technology solutions that allow billers to present their bills electronically to companies and enable companies to initiate electronic payments (Au and Kauffmann, 2001). EBPP may be seen, therefore, to have two main components: presentation of the bill and payment of the bill. The strength of the traditional role of banks will be seen in the second component, as billers and consolidators still do not have fiduciary powers of banks to actually pay the bill. Banks are providers of trust, play a role in insuring against credit risk and provide an infrastructure of network relations to businesses, governments, and individuals (Eriksson and Fjelstad, 2001). The paper advances a structural frame to explore the possible B2C value positions that banks may undertake in the area of EBPP. Banks will need to assess where the value proposition is for them in the various business models used in EBPP, and how best to leverage their position as a neutral trusted third party (TTP), so to modulate and reduce the risk for buyer, seller and the overall marketplace. Some case studies are described with the proposed frame."
2170873,22457,20561,A cooperative system to support inventory leveling negotiations,2004,"In many cases, deviations between actual product and service demands and their forecasts are inevitable, creating an excess of products and service. To deal with that excess, it is important that logistics professionals elaborate strategies for discovering potential and repressed demands. Traditional techniques to manage inventories do not suffice to reach all expected results. In this context, strategies for products and service excess destination are also promoted, in order to optimize application of organizational resources. Negotiation between the party holding excess and the potentially demanding party is a crucial issue in the excess destination activity. This is a process in which two distinct parties search for a consensus regarding their interests and objectives, trying to satisfy both expectations. Thus, it is fundamental to establish mechanisms that stimulate communication and motivation during the negotiation process, as well as the ability for decision-making, conflict management and reaching an agreement. Therefore, cooperation may be the best type of negotiation. Cooperation helps to establish points in common that favor the negotiation, and information sharing and consensus building plays a key role in this process. In this work, we present a system to support cooperative negotiations aiming at leveling inventory of products and services used by different processes, stimulating the integration among them. The system is used by several agencies within Brazilian Federal Government Defense Ministry, acting as a market for excess capacity of services and goods. The proposed environment facilitates system users to cooperate towards achieving common objectives in the negotiation."
2053874,22457,20561,"Supporting the design of an inland container terminal through visualization, simulation and gaming",2003,"The planning and design of an inland container terminal is a complex task due to many interrelated design parameters and interdependent stakeholders. Design tools may support the optimization of technical, economic and logistical values, but this optimization is strongly inhibited by conflicting interests, political and environmental boundaries and strategic stakeholder behavior. The main research question in this contribution is: how can visualization-simulation tools be used in an early stage of complex inter-organizational decision-making on infrastructures in such a way that it enhances the quality and progress of this decision-making? A collaborative design environment was developed for the early phase of inter-organizational decision-making. In the gaming-simulation 'containers a drift', a number of public and private stakeholders try to reach initial agreement on an inland container terminal. A team of process-managers facilitate a collaborative design process and set up a number of ground rules for negotiation. A visualization-simulation tool is used to explore the various technical, economic, political and spatial issues. While negotiating on issues such as location and size of the terminal, small groups of stakeholders interactively draw several terminal layouts. Logistical and economic data, e.g., on ships, containers and costs are entered in a database. The terminal's performance and its dynamic behavior is simulated and assessed. The game was played in three sessions with a total number of 77 students. The evaluation results indicate that the various tools are easy to work with, greatly contribute to the quality and process of negotiation and generate mutual understanding."
892520,22457,20561,"Value, Participation and Quality of Electronic Health Records in the Netherlands",2010,"Growing cost of health care, the gradual reorganization of health care on a free-market basis and patients evolving into health care consumers all prompt hospitals to gain competitive advantage by improving efficiency, quality of care, and customer friendliness. An electronic health record system (EHR) is one of the tools to achieve these goals. Hospitals are nevertheless lagging behind industry in implementing IT systems to support their core business processes. Eighteen case studies were conducted among Dutch hospitals to examine the EHR system implementation. Through seventy three interviews with key stakeholders, the relation between perceived value of the EHR, the degree of participation in the implementation process, and the resulting quality of EHR systems was investigated. The value that end users expect is not achieved within Dutch hospitals. It was found that no hospital had so far reached third generation EHR functionality, even though several hospitals are actively pursuing it. Innovation with respect to EHR systems in hospitals is limited because of a lack of capabilities, not because of a lack of participation. Extensive and ill-targeted end user involvement tends to delay decision making and exacerbates the mismatch between implementation goals and results. Quality issues focus on information quality in terms of completeness and system quality in terms of reliability. This study contributes in combining participation models with the technology acceptance model and the IS success models. Electronic Health Records can be evaluated with this combination and a prescriptive analysis has lead to practical advice to the Dutch Ministry of Health."
2091208,22457,20561,A Web-based game-oriented college selection system employing fuzzy rule trees,2004,"Our Web-based interactive game-playing-oriented college selection system acts as a smart advisor/mentor and helps students, parents, and teachers use an effective graphical user interface to efficiently search college information and to make good decisions at each stage of students' academic development. It is an expert agent with hierarchical fuzzy knowledge base using fuzzy logic. Users are expected to be able to use this agent as a trusted, involved and smart counselor, who remembers their profile and their past history and advises them through their high school years. It gives them increasingly better and specific nuggets of advice as they make progress through their schools, and guides them toward a selected set of colleges to apply that optimizes their potential. At the heart of this system is an assessment tree, which uses bottom-up fuzzy calculations to generate possibility of admission in various sets of colleges. The primary output is a short list of colleges to apply containing five kinds of colleges (highly-selective down to non-selective) with possibilities of acceptance in each college according to fuzzy rules provided. It is also a smart tool to play self-guided what if games to explore what specific action one should be taking to have maximum impact on the selection of colleges one can get in and on his/her chances of admission. It employs a natural interactive interview process for a user (i.e., a user can play a game with the agent to gradually find out rational solutions), and produces advisories at different stages."
1512116,22457,20561,A Neuro-fuzzy Approach to Bad Debt Recovery in Healthcare,2014,"In the U.S. the healthcare industry is often plagued by unpaid bills, collection agency fees, and outstanding medical testing costs. All these factors contribute significantly to the rising cost of healthcare. Health care providers often have to treat patients on credit, especially in emergency and trauma cases. Unlike financial institutions health care providers do not collect financial information about their patients. This lack of information makes it difficult to evaluate whether a particular patient-debtor is likely to pay his/her bill. In recent years researchers have started to recognize the potential of data mining methods in improving our understanding of medical bad-debt, but there is relatively little research that examines the effectiveness of data mining methods in classifying bad debt in healthcare. This paper evaluates the effectiveness of an adaptive neuro-fuzzy inference system (ANFIS) in classifying bad debt in the healthcare context. The data analysis and evaluation of the performance of the ANFIS model are based on a fairly large unbalanced data sample provided by a healthcare company, in which cases with recovered bad debts are grossly under represented. Computer simulation shows that ANFIS is a viable method which produced under some scenarios good classification accuracy. More in-depth interpretation of the results, including nonlinear interaction between various factors, is provided through the analysis of the control surfaces generated by ANFIS and receiver operating characteristic (ROC) charts. Finally the paper also shows the potential of data mining models to classify unknown cases, which are a potential source of revenue recovery."
2067672,22457,20561,No more shadow boxing with online music piracy: strategic business models to enhance revenues,2003,"Novel online file sharing technologies have created new market dynamics and posed a great challenge to the music industry to try and retain customers. Consumers have created anonymous online networks to exchange audio files at little cost, which has led to millions of shared, illegal copies of music files and related sales losses to the industry. Legal efforts to counter this trend have lagged the advances in technology. This research presents an analysis of selling strategies that can increase a music seller's revenues as online piracy continues to flourish. We study and compare scenarios of traditional music store selling with those of online-based strategies. We model and analyze pure per-unit, pure subscription and mixed strategies for online music services. Analytical modeling, empirical study and simulation analysis were used to investigate the issues in detail. Our results suggest that the quality of pirated music and search effort have a significant impact on viable strategies. For instance, as the quality of pirated music approaches that of a legal online seller, the per unit service becomes the least viable option. An interesting finding was that strategies that minimize piracy do not necessarily maximize revenues. In fact, both revenues and social welfare can be maximized in the subscription-based environment, even though they may lead to higher levels of piracy. Our research findings not only offer insights into an online experience market, but can also serve as a contemporary reflection on other similar information markets."
2043583,22457,20561,Thirteen assertions for globally dispersed software development research,1997,"Globally dispersed software development (GDSD) takes place when two (or more) development teams are separated by a national boundary while collaborating on common projects. Today, such instances occur with greater frequency as software development globalizes within the MIS unit of the multinational enterprise and within the packaged software firm. Deriving from the fields of globalized R&D management, globalized manufacturing management, as well as the MIS and software development literature, thirteen assertions are derived for further research. 1) The globalization decision stems from one or more of the following five reasons: mergers and acquisition, tapping into hubs of talents and skills, cost reduction, customer proximity, and the need to be a global company. 2) Task allocation is time-based for MIS projects and is module-based for packaged software. 3) In practice, key design activities take place in the home country. 4) With time some design activities move out of the home nation. 5) In practice, the advantages of follow-the-sun are small. 6) Rich communication is most important. 7) In practice, integrated development environments are no more important than with co-located teams. 8) Over time local managers take over in non-home country teams. 9) Customer proximity determines influence. 10) The globalized project manager is different from the domestic manager. 11) Outsourcing is more likely in MIS projects than in packaged software. 12) In practice, process maturity rarely determines dispersing development activities. 13) The more mature the development process the better GDSD management."
1875243,22457,20561,Measuring the utilization of collaboration technology for knowledge development and exchange in virtual communities,2004,"The success of a virtual community depends chiefly on the community members' utilization of the community system that supports it. It is therefore essential that the functions of the system meet the members' requirements. The objective of this paper is to identify usage patterns in virtual community systems focused on learning and knowledge exchange in order to derive recommendations for the design of virtual community systems. We therefore analyze two specific professionally-oriented virtual communities focusing on learning and knowledge exchange by in-depth case studies. The first one is a learning network consisting of participants of a post-graduate study program. The second one is an expert network consisting of academic researchers and employees of several major European financial services companies. For each of these two communities, we describe the community's initial situation, its special characteristics, its objectives, its members and different application areas regarding a supporting community system. Thereafter, we identify the requirements that the community system needs to fulfil to satisfy the members' needs. Based on these requirements, the different functions of the system that should meet these requirements, are presented. For each community, we measured the utilization of the functions implemented in the community systems using a Web log analysis tool. Reflecting the measurement results on the case descriptions and the members' requirements, we drew conclusions on how members use a virtual community system: Most importantly, functions that support structured user processes with clear user requirements are preferably used. Moreover, personal information on community members is frequently viewed. On the other hand, most synchronous and asynchronous communication functions are rarely used and community users make few own contributions to discussions. Finally, functions that implement potentially redundant functions, for example group calendars or link collections, are rarely used."
2455867,22457,20561,Application of ThinkLets to team cognitive task analysis,2004,"As was seen in the 2003 Gulf War, the U.S. Army is migrating to a lighter, more mobile and more lethal fighting force. In support of this desired paradigm, the major U.S. Army's battle laboratories are performing key experiments to determine how the projected mix of personnel, materiel, and doctrine can be interwoven into a desired structure for the year 2015. In February 2003, the U.S. Army's battle command battle laboratory (BCBL-L) at Fort Leavenworth, Kansas appraised, utilizing a more intuitive decision-making process, a simulated futuristic two thousand-man force structure with its anticipated equipment. There were several stated, and a few unstated, objectives to this experiment, necessitating the use of numerous observers and several data collection instruments. Of the data collection instruments, the principal instrument for team cognitive task analysis functions was the Wagon Wheel interview methodology. Of the tools, the principal tool employed to collaborate, consolidate and sustain the data collection events was a group support system. This paper first explores how the selected group support system tools were utilized to automate the Wagon Wheel process from a one-on-one manual process to an automated system that enabled simultaneous data collection from 20 individuals. This paper then examines how the concept of ThinkLets was used to define the Wagon Wheel process. Lastly, an exchange of ideas are provided, talking about the strong and weak points of using a group support system in the experiment, the problems that arose and the solutions employed, and some thoughts for using a group support system in the follow-on experiments."
2236285,22457,20561,"Managing Information Intensive Service Facilities: Executive Contracts, Market Information, and Capacity Planning",2010,"Effectively managing IT service centers such as call centers, computerized diagnostic imaging facilities, data centers, e-commerce sites, SaaS, and telecommunication networks has always been a challenging task, especially, when the managers running the centers possess private information about market condition and their marketing efforts. Prior studies often model IT service centers as queueing systems with exogenous demand and mostly focus on capacity allocation through an internal pricing scheme. Demand uncertainty and managers' private information (i.e., agency issues) are usually ignored. For service centers in general, customers often experience delays due to stochastic arrivals and random service times. Successfully soliciting market information from the managers becomes critical for the centers' profitability. If firms invest too much in capacity, while delay costs are under control capacity costs go up. If firms under-invest in capacity then delay costs explode. Because managers' information regarding market demand is valuable for the firms, how to solicit true market information and thereby induce desired levels of marketing effort from the managers becomes critical and is the focus of this paper. We present two incentive contracts that can effectively induce true market information from the managers. We show that one contract can even induce the first-best effort levels from the managers. Our study provides guidelines for firms that deal with congestion-prone systems with incomplete information, and it sheds light on how to effectively manage service facilities with combined moral hazard and adverse selection issues."
2535121,22457,20561,Business intelligence in healthcare organizations,2002,"The management of healthcare organizations is starting to recognize the relevance of the definition of care products in relation to management information. In the turmoil between costs, care results and patient satisfaction, the right balance is needed, and it can be found in upcoming information and communication technologies (ICT). The ICT developments are a challenge in two directions: internally towards massive data warehouses, and externally towards Internet dissemination. These new technologies deliver new solutions to old problems. This paper argues that, although the new technology has high potential, a great deal of the solution will be of an organizational nature. In four case studies, we show the spectrum from organizational solutions (changing structure and definitions, forms and procedures) to ICT solutions (changing systems and infrastructures). The main results of this study are, firstly, the notion that model bases, although theoretically existing for more than two decades, are still scarce in healthcare organizations; secondly, a big gap, both in content and in price, was noticed between decision-oriented and model-oriented systems; and, finally, the definition of terminology and the standardization were time-consuming tasks on the road to management information in the four cases studied. It is concluded that business intelligence can be the integration between the organizational and ICT components if one uses a management model and an integrated systems concept. The use of intranets and the Internet as communication channels for management information is seen as the challenge for the near future."
2403540,22457,20561,"Hyper-differentiation strategies: delivering value, retaining profits",2003,"In today's increasingly competitive business environment companies can, and indeed must, respond more rapidly to customers' changing demands, desires, and preferences. In today's information-rich environment customers can comparison shop, get product reviews from other customers, and, in general, become very well informed about what is available in the market. If your offerings are not differentiated, pure price competition will be more extreme than ever before. If your customer thinks your goods and services have direct competitors your prices (and theirs) will be squeezed down to your marginal costs of production! If your offerings are successfully differentiated, then your customers will not see other products as competing directly, or as competing at all effectively. Your prices will be determined by your value to your customers, and not by your costs or your competitors' costs of production. While differentiation has long been a basis of competitive strategy, newly available sources of information do change the nature and importance of differentiation. Information in the hands of customers has increased price pressure on all producers, increasing the need to differentiate your products and services. Information you provide to customers makes it possible for you to communicate your value proposition more effectively, increasing the value you receive from differentiation. Information makes it possible for you to determine what customers want, and makes it possible for you to tailor your design and your production to these needs, supporting accuracy and precision of differentiation. It is not necessary to be better in any absolute sense, or to be more costly to produce; it is merely necessary to be better for individual customers and more valuable to them. Information makes it possible for you to track the changes in behavior, preferences, demands, and desires of your best customers and serve them with precision, accuracy, and cost-effectiveness that competitors will never be able to match."
1463851,22457,20561,Identifying Weaknesses in VM/Hypervisor Interfaces,2013,"As cloud and virtualized environments become more widely used to solve challenges faced by companies of all sizes, it is increasingly likely that this infrastructure will be a common focus of attacks in the years to come. Successful attacks against this infrastructure could allow an attacker to break out of the virtual environment and gain control of the physical infrastructure effectively compromising the entire system. Given the recent surge in the development and deployment of these environments, it is reasonable to expect that these systems have not undergone the same amount of testing that comes with age and wide acceptance, and which we often require for critical services. Therefore, in-depth analysis of the attack surfaces exposed by these environments is necessary to ensure the security of these systems. This paper describes a Cyber Fast Track (CFT) project to create a testing framework to analyze the interfaces exposed by several hyper visors to potentially untrusted users (inside VMs) for vulnerabilities. The methods used consist of random input testing of emulated devices by intercepting and modifying valid device I/O with a state-aware system. These techniques are general enough that they may be extended to test many interfaces across a wide range of virtualization systems. This project then uses this tool against current versions of several virtualization systems with the ultimate goal to inform developers and system administrators alike about potential vulnerabilities in these systems."
2197304,22457,20561,System architecture for psychological customization of communication technology,2004,"Personalization is a process that changes the functionality, interface, information content, or appearance of a system to increase its personal relevance to an individual. Personalization systems accommodate individual's needs and interests explicitly through changes and selections initiated by the user, and implicitly through automatic adaptation techniques. Currently most of the emphasis in personalization systems is geared towards the utilitarian aspects of personalized information delivery. However, what is lacking is the customization of information based on its likely emotional and cognitive effects on different users of communication technology. Information presented to individual users or a group of users may be customized on the basis of the immediate emotional and cognitive types of psychological effects it is likely to enable or create in certain individuals or groups. Both content and its way of presentation (modality, visual layouts, ways of interaction, structure) may be varied. Despite obvious complexities empirical evidence suggests that the way of presenting information to certain psychological profiles has predictable psychological effects. For instance, one may facilitate positive emotion for users with certain personality type or more efficient learning for certain cognitive styles. This is the basic concept of mind-based technologies. Psychological customization may be considered an operationalization and technique of implementing the concept of mind-based technologies in system design. Psychological customization may be used for controlling social interaction-centric and individual-centric influence of the content and way of presentation of information on consequent and transient emotional and cognitive effects. This paper explores the design space and presents a basic system architecture to implement psychological customization."
1759927,22457,20561,Information dynamics and discourse in a distributed professional community,2004,"Professional associations could use virtual communities to reinvent their relationships with their members. One promising building block would be to revitalise special interest groups as loose knit Internet based communities. These would be what has been called networks of practice or communities of interest. Although recognised phenomena, these terms are little more than labels, however. Far more has been written about the rich, close knit relations of communities of practice. This paper argues that as a model the community of practice concept is useful in defining dimensions by which such looser knit groups can be studied. To this end, community of practice theory is reviewed. The paper then presents a case study of an informal community among Web developers. It uses genre analysis to identify a dominant discourse which constitutes the list's local culture or repertoire. The genres in use are very efficient means of exchanging information, offering broad learning opportunities. They also construct a member identity. They exclude social and political issues, constructing the problem of the Web as technical. The network has a sense of community, yet it does not have the level of engagement of a community of practice because of the lack of task interdependence, the limits of the technology in use and the size of membership. This has some advantages such as giving it a longer life, requiring less commitment from members and coordinators and making it scale to numbers in a professional association. Professional associations could build up from such networks of practice, just as corporations have sought to cultivate spontaneous informal groups, to manage knowledge."
2058261,22457,20561,Effectiveness and applicability of Internet-based training in the corporation - case of Egypt,2003,"Learning is the most indispensable activity in the current knowledge-based economy where firms, in order to compete and survive, must be constantly alert, capable of adapting to fast change, constantly learn, evolve, and transform themselves rapidly. In that respect, the use of innovative information and communication technology is perceived to play a key role in the development of new learning platforms and mechanisms. One of the emerging solutions is electronic training eTraining, which is a growing trend and is expected to become crucial in meeting newly introduced challenges and in catering for changing and diversified market needs. The global connectivity of the Internet and the availability of innovative information and communication technology are factors that have contributed in catalyzing the new Internet-based learning paradigm offering great opportunities for organizations to educate and train their management and staff. However, Internet-based training poses several considerable challenges for various organizations especially those operating in developing countries. Within the context of transferring and using information and communication technology into developing countries, this paper demonstrates the outcome of a research aiming at investigating the effectiveness and applicability of Internet-based training in providing training for organizations in Egypt. The focus of the research was mainly soliciting the opinions of three different groups of stake holders; human resources or training managers responsible for setting training policies; instructors responsible for facilitating courses and preparing material; and trainees undertaking the training."
2132459,22457,20561,The dynamics of market power with deregulated electricity generation supplies,1998,"Deregulated wholesale markets for bulk electricity supplies are likely to deviate from the perfectly competitive ideal in many areas where transmission losses, costs and capacity constraints isolate customers from the effective reach of many generators and limit the number of competitors. In those regions where a few suppliers or marketing agents dominate the market, prices may rise well above the competitive ideal of marginal cost. Furthermore, if all customers do not shift instantaneously to the lowest priced supplier, perhaps because of inadequate information about the reliability of alternative generators and/or additional investments required to switch suppliers; then depending upon the duration of those lags, the optimal pricing policy of the existing dominant generators may be to ignore the competition for an appreciable period of time. Using previously developed models of dynamic oligopoly pricing, estimates are provided of how rapidly and how far bulk power supply prices might deviate from competitive levels after the deregulation of those markets, depending upon the number of potential competitors serving a particular region and their individual market shares. These models have been calibrated and applied previously, ex-post, to the introduction of competition in long distance telephone service the United States, where they predict AT&T dynamic price behavior accurately, and they suggest that similar substantial lags may occur in the emergence of insensitive price competition in some electricity markets."
1706256,22457,20561,Adoption process of upgrading software: an empirical study of Windows XP,2003,"There are many studies in information systems on the adoption of new innovations. This paper, on the other hand, presents the findings of an empirical study, which explores factors affecting the adoption of upgrading software. End users' perception of former products significantly affects their adoption of the upgrading products and thus, their behavior changes accordingly. We use Windows operating systems as an example. Most people have been using Windows operating systems. They are familiar with the current software. Although Microsoft has enhanced the capabilities of new Windows operating systems, these new features are sometimes more than necessary. Thus, what factors drive the users to upgrade? A survey is carried out in a university and a government department. 300 data points from microcomputer users are collected. Five hypotheses are formulated to test research concepts from marketing and information systems. From the marketer's point of view, our findings indicate that adopters of upgrade software are stronger in opinion leadership and more independent when making purchase decisions. They also prefer seeking product information by their own effort. We have borrowed two innovation acceptance factors, perceived ease of use and perceived usefulness, from the technology acceptance model in information systems. We find that upgraders and non-upgraders have different perceptions of ease of use and usefulness in the older software versions. Furthermore, software usefulness is more significant and crucial to urge the users to buy new version products than software ease of use. Implications of our findings, from both a researcher's and a practitioner's perspectives are discussed."
422160,22457,20561,Introduction to Intellectual Property and Security Minitrack,2015,"We have heard and read many times in the last several decades that the most important asset of an organization is the knowledge of its employees. To allow an easy access to knowledge, organizations are implementing Knowledge Repositories. While this type of automation made it easy to store and distribute knowledge, it also made it easy to move knowledge outside the boundaries of a company. Organizations put in place many technology-based security measures (firewalls, filtering systems), yet they shouldn't overlook the human-side of security practices. An organization can have the best security technology in place, yet a careless employee talking or emailing or posting on Facebook about the 'new development' at the company bypasses all this security technology with ease. Furthermore, one can find lot of information about current projects done by a company by searching the web. How can an organization effectively protect its intellectual property remains an answered question. What type of security and intelligence techniques are out that that can protect the IP? What are the best ways to train employees so that they would spot potentially criminal activity among employees? Could crowd sourcing be used in this case, meaning asking employees to vote on a particular issue to determine whether it represents a potential threat? This mini-track seeks papers that investigate issues related to security and protection of intellectual assets and explore how organizations can use security measures to protect their KM practices."
2403896,22457,20561,Balancing Supply and Demand of an Electronic Health Record in the Netherlands; Not too open systems for not too open users.,2007,"About twenty suppliers of electronic health records (EHR) battle for the favor of about hundred hospitals in the Netherlands. The Minister of health has been promising for over a decade that every citizen in the Netherlands can have an EHR. Until now this promise has not been met. One of the main requirements for this national EHR is an agreed definition of an open EHR by both vendors and users. This paper first studies the demand side using the results of thirty eight interviews with end users asking them their core processes and their expected value of an EHR. Next we have a look at the supply side with an overview of the Dutch market and a focus on open EHR's as possible overall solution. This solution is further elaborated by using the experience with enterprise application integration (EAT) in industry. The contribution of this paper is twofold. First from a combined analysis of our data our main conclusion is the supply of EHR in the Netherlands is not open yet. Only suppliers with a small market share really offer external process integration. Only if the main suppliers are stimulated (by the government) to open up, a national EHR can arise. Secondly from a detailed analysis the following results stand out: majority of the end users (demand side) do not get support in their relevant working processes. Communication is badly supported and direct patient contact (what they think most important in their work) is even endangered by new systems. Availability, a benefit where all stakeholders agree upon, does not seem to be enough to open the market and create a good diffusion of EHR in the Netherlands. Much more focus should be laid on quality of care and communication with patients and colleagues"
2448050,22457,20561,"Trust, trait theory, and collaboration in telemedicine: a circumplex perspective",2003,"More than a process-automating tool, telemedicine is increasingly recognized for its ability to facilitate collaboration and knowledge creation between disparate healthcare providers. As trust is being demonstrated to affect positively the collaborative effort of practitioners and the concomitant, as well as subsequent impact on quality of health care delivery, the questions arise, What are the interpersonal traits of practitioners that contribute to a constructive and continuing telemedicine-centered collaboration? Furthermore, how do these interpersonal traits translate into specific types of interactions that maximize telecollaboration? These questions are especially germane as much telemedicine equipment remains underutilized, and administrators concern themselves with sustainability. Previous work has largely centered on relational variables affecting trust in collaboration, such as competence, reputation, and trustworthiness, but has neglected the personal characteristics that might impact participants' proclivity to collaborate and trust. This paper introduces the circumplex model as a framework for understanding the development of trust in collaborative telemedicine. The circumplex posits that interpersonal interaction can be explained along the two dimensions of power and affiliation. Sixteen personality traits may be arrayed in a circular or clockwise fashion around the psychological axis of Dominance and Nurturance. Recent causal modeling studies - of the relational relationships between the dimensions of the circumplex theory of interpersonal interaction and measures of interpersonal trust - have found that the circumplex dimensions of Dominance and Nurturance are sign positive predictors of interpersonal trust. Understanding these interpersonal characteristics of individuals may help address the constraints impeding telemedicine usage."
2515845,22457,20561,A framework for creating a facetted classification for genres: addressing issues of multidimensionality,2004,"People recognize and use document genres as a way of identifying useful information and of participating in mutually understood communicative acts. Crowston and Kwasnik discuss the possibility of improving information access in large digital collections through the identification and use of document genre metadata. They draw on the definition of genre proposed by Orlikowski and Yates (1994), who describe genre as a distinctive type of communicative action, characterized by a socially recognized communicative purpose and common aspects of form. Scholars infields such as rhetoric and library science have attempted to describe and systematize the notion of genre, and have offered many different definitions of genre. We like Orlikowski and Yates's definition because it takes into account all three aspects of genre that we recognize as fundamental: content, form, and purpose. A document's genre is a subtle and complex concept in which the content and form of a document are fused with its purpose or function. As such, a document's genre cannot be separated from the context in which it is used; the same document may be construed as being of a different genre depending on how it is invoked in a given situation. Starting from the document, a letter may be a personal communication, or a piece of evidence in a court of law, or an agreement, or even a work of art. Starting from the situation, we note that differences in an information situation are often reflected in the kind of document that is considered helpful (e.g., a problem set vs. a lesson plan vs. a tutorial about mathematics, for instance). Thus, we see genre as a multidimensional phenomenon, which takes into account not only the attributes of the document itself, but also of its role in human endeavor. In this paper, we discuss some considerations in developing a facetted classification for genres to address the problem of multi-dimensionality."
1374254,22457,20561,Pervasive real-time IT as a disruptive technology for the IS field,2003,"This paper builds on ideas in a recent paper which argued that the core subject matter of the IS field should not be the IT artifact (as suggested by Orlikowski and Lacono, 2001), but rather IT-intensive work systems. This paper extends the ideas in the previous paper by exploring whether pervasive real time IT might be a disruptive technology (Christensen, 1997) for the IS field, implying that the long term vibrancy and impact of the field depends on a change in focus and scope that emphasizes some version of work system concepts. This paper defines the term work system and explains that information systems, projects, value chains, and supply chains are all special cases that should inherit work system terminology, generalizations, and success factors. It summarizes six real world examples to demonstrate different types of overlap between work systems and information systems that support them. Comparison of these systems shows that many of today's more interesting information systems reflect a trend toward pervasive real time IT, i.e., increasingly commonplace application of IT to automate work practices or support and control them in real time. As this trend continues, the overlap between information systems and the work systems they support will increase, leading to a situation in which studying just the information system but not the work system it supports will have less and less significance. The paper concludes by arguing that the IS field needs to encompass work systems that do more than processing information. Expansion in this direction has implications for analyzing systems, conceptualizing system life cycles, communicating with business professionals, interpreting and performing research, and establishing different relationships with other academic fields such as organization behavior and operations management."
1507069,22457,20561,Are CIO's Any Different? Analyzing the Job Tenures of C-Suite Executives in the Public Sector,2010,"We often hear anecdotes that suggest the real meaning of the acronym CIO is career is over, rather than chief information officer. The premise of the quip is that CIOs' career paths and tenure (or survivability) in their positions may not the same as those of other C-suite executives: the chief executive officer (CEO), the chief financial officer (CFO) and the chief operating officer (COO). Is this truly the case? What evidence is available to assert that CIOs exhibit shorter job tenure than their C-suite executive colleagues? This research explores three alternate theoretical interpretations that compare and contrast reasons why team-building, the turbulence of the business and organizational environment, and the gender of the executive appear to have different impacts on the tenures of the different categories of executives. Our empirical research takes advantage of a new data set acquired during Spring 2009 from the State of California that provides information on C-suite executives from 223 state agencies. The data consist of 504 observations of executive tenure, including their start and finish dates, and the relevant variables for their organizational, market and technological environments that permit us to assess their survivability. To conduct this exploratory analysis of the empirical regularities of public sector executive tenure, we utilize statistical methods from epidemiology and public health. Our results cast doubt on many of the enduring beliefs about public sector CIOs by showing the relative infrequency of their job changes and by showing that job changes are, unlike for other C-suite executives, more closely tied to instances of environmental turbulence. In all, this exploratory paper suggests a reexamination of the way that public sector CIOs are viewed relative to other C-suite executives."
2162656,22457,20561,Proprietary vs. open standards in the network era: an examination of the Linux phenomenon,2001,"For networked IT industries, standards adoption is a key prerequisite for attracting complementary assets. Producer firms that hope to profit from their standards success must trade off control of the standard against the imperative for adoption. Moschella outlines three eras of modern computing: systems personal computers and network, each with its own form of standards competition. During the systems era of computing, mainframe producers maximized their control by offering vertically integrated standards architectures. In the PC era, IBM unintentionally surrendered control to two key suppliers in its haste to launch the IBM PC and maximize its adoption. Microsoft and Intel in turn sought pervasive adoption of their technologies by appropriating only a single layer of the standards architecture and publishing a subset of the interfaces to other layers. In reaction to these proprietary strategies, the open source movement developed software that relinquishes control in favor of adoption. Such free software has played an important role in Internet infrastructure, and its adherents argue that it will supplant such proprietary standards in the network era. This study examines the rise of the Linux operating system, with particular focus on its role as a PC server operating system in competition with the established Microsoft Windows OS. While Linux has its origins in the 1984 GNU Project, and was widely available beginning in 1993, we focus on the adoption motivations of organizational buyers and suppliers of complementary assets during the period 1995-1999."
2462065,22457,20561,Price comparison for music CDs in electronic and brick-and-mortar markets: implications for emergent electronic commerce,2000,"The Internet has great potential as a medium to reach consumers. We need to examine the efficiency of this medium in producing efficient allocations in market transactions and increasing buyer welfare. Using the case of Internet-based shops selling music CDs, we compared prices on the Internet and in brick-and-mortar shops, and investigated how the general market efficiency hypothesis is borne out in practice. We collected price information for 21 current-hits and 23 old-hits albums. Also, prices for the same albums were collected from top five nationally-known brick-and-mortar CD shops. Overall, 428 data points, 296 from the Internet and 132 from brick-and-mortar retail shops were collected. The results showed that a) the Internet market still shows price differences despite the apparently near zero searching cost, b) CD prices for the current-hit albums were lower in the brick-and-mortar market, but the old hits prices were nearly similar or slightly lower in the Internet shops, and c) the two largest Internet sellers seem to have a matching pricing strategy. Through this effort we derive a better understanding as to the shape of the fully-edged electronic commerce system that is taking shape now. We argue that a fundamental difference in the structure of the Internet market leads sellers to employ new strategies to extract the consumer surplus. We, especially, propose that differences in consumer base, sellers' inventory cost and buyers' purchasing cost can explain the higher-than-expected Internet prices and price dispersion for the two different types of products."
2419498,22457,20561,Worker incentives to learn in gatekeeper systems: lessons for the implementation of knowledge management systems,2000,"Behind most KM initiatives is the desire to make knowledge possessed by some employees of a firm more widely available to other employees of the film. Such a diffusion of knowledge can lead to the spread of useful skills and concepts for repeated application throughout the firm and can increases the likelihood of innovation. The assimilation of knowledge requires its application and if complex requires the employee's commitment to developing their experience with the new skills and engaging in a process of learning. To the degree that a worker cannot immediately successfully apply the knowledge drawn from the KMS successfully, they are making a 'long-term' investment in the development of their own human capital by using the KMS. This implies that the usefulness to the firm of a KMS will be dependent upon the incentives provided to employees to invest in their own human capital. In this paper we develop a model of the role a KMS can play within an organization and the decisions impacting learning made by employees that would draw upon the KMS to develop their own human capital. We build a conceptual model around the learning behavior of gatekeeper workers with general knowledge who control the flow of work to 'specialists' who have a more specialized body of knowledge. We then, as an example, formulate a mathematical model of the patient referral process in a managed care organization (MCO) in which primary care physicians (PCPs) serve as gatekeepers to specialists. Using this example from the healthcare industry we demonstrate how a firm must adjust incentives to take into account decisions about learning done by individual employees."
814156,22457,20561,Investigating User Acceptance of a Screenshot-Based Interaction System in the Context of Advanced Computer Software Learning,2014,"Most e-learning systems provide course materials in a variety of formats, such as text, image, and video, and allow students to interact with their classmates and teachers by means of discussion forums, chat rooms, or e-mail. However, most interactions between students seeking technical support are in textual format. To promote effective discussion and interaction between users, e-learning systems should make better use of media. Drawing on the media-richness theory, screenshot-based interaction can be regarded as the best medium for describing problems and troubleshooting in the context of computer software. As this form of interaction between users is based on screenshots, it is termed screenshot-based interaction. This study entailed the development of a screenshot-based interaction system, which is a system of discussion forums for advanced computer software learners, by integrating the richness of social-networking media with the traditional structure of present-day discussion forums. The system provided students with a convenient and clear means of explaining advanced computer software problems, by uploading screenshots, dragging rectangles, and leaving comments in text boxes. It also allowed students to give and receive individual responses to these problems, thereby enhancing their learning. In addition, the study investigated user acceptance of the screenshot-based interaction system. The results, based on data collected from 418 students, indicated that students' perceived enjoyment had a strong, positive, and direct effect on their behavioral intention, and that colleague opinion had a direct effect on their perceived enjoyment and their perception of the system's ease of use and usefulness, which in turn affected behavioral intention indirectly."
2074018,22457,20561,"Electricity Markets: How Many, Where and When?",2006,"Most markets compromise the economists ideal of matching the marginal benefits to consumers with the marginal cost of supply for incremental purchases because individual buyers and sellers are aggregated over space, time and/or other product attributes like quality or reliability. These aggregations into discrete market segments are designed to facilitate transactions by reducing search and distribution costs, and they may enhance the competitiveness of each market segment by encompassing a larger number of buyers and sellers, but at some loss of precise efficiency matches. Furthermore, as individual market segments grow in size, the price differences across their boundaries may also increase which can raise the transactions costs associated with increased arbitrage. These are important considerations for electricity markets since significant physical, operational and capacity barriers separate and define these markets over space and time. Thus principles for the optimal structure of these markets are developed, and in particular, it is shown that forward markets with lead times longer than the gestation period required to construct new generation capacity are essential to insure efficient subsequent spot markets. By comparison, if these forward markets occur only after new construction is begun, as with existing installed capacity markets, spot market prices may be higher. Similarly, the extent of separation and spacing of markets across regions and control areas, particularly in the face of transport congestion or operational boundaries, is important for enhanced efficiency."
1581641,22457,20561,Using Ontologies and Soft Systems Methodology to Provide Multi-user Support in Problem Structuring,2012,"Decision support systems (DSS) are aimed at helping decision makers in devising appropriate solutions to business problems while negotiation support systems (NSS) are aimed at assisting stakeholders in reaching mutually satisfactory decisions. The successful use of these systems involves a combination of human ability and computer support. An implicit assumption underlying their use is that the business problems for which they are deployed have been carefully defined by the stakeholders prior to their use. This includes, in particular, understanding of the problem variables and their possible impact on the decision outcomes and knowing which information is necessary for supporting it. However, this assumption might not hold in the modern business environment. This is due to the increasing complexity and rate of change of the environment, the geographical and temporal dispersion of modern organizations, and the diversity and quantity of information sources that is available. In this paper we propose the idea of extending the scope of these systems to include a step preceding the solution process: problem framing. We claim that new technologies such as Web 2.0 provide novel opportunities to add this facility to DSS and NSS. To achieve this, we propose a novel approach combining domain and task ontologies. The task ontology we propose employs concepts from soft systems methodology. Specifically, we suggest that a stakeholder can use the ontologies to understand the problem, frame the issue, and identify the information required for the task. The ontologies can support accessing the information sources when the system is being used by stakeholders."
2169634,22457,20561,Performance Analysis of a Middleware Demultiplexing Pattern,2007,"A key enabler of the recently adopted, assembly-centric development approach for distributed real-time software systems is QoS-enabled middleware, which provides reusable building blocks in the form of design patterns that codify solutions to commonly recurring problems. These patterns can be customized by choosing an appropriate set of configuration parameters. The configuration options of a pattern exert a strong influence on system performance, which especially for real-time systems is of paramount importance. Despite this significant influence, currently there are no techniques available to analyze performance at design time, prior to the use of a pattern in a system. Many software systems are based on an event-driven paradigm, primarily because it fosters evolvability and composability. The event demultiplexing and dispatching capabilities that are uniform across such systems are encapsulated in the reactor pattern, which can be used to facilitate their development. Design-time performance analysis of these event-driven systems thus requires a model of the reactor pattern. In this paper, we present a performance model of the reactor pattern based on the stochastic reward net (SRN) modeling paradigm. We discuss how the model can be used to obtain performance metrics such as throughput, loss probability and upper and lower bounds on the response time. We illustrate the use of the model to guide the selection of configuration options and for sensitivity analysis using a case study of a handheld mobile device. We also validate the performance estimates obtained from the model using simulation"
2466556,22457,20561,eCAD: a knowledge-based course engineering system,2004,"Colleges and universities have increasingly migrated towards utilizing the World Wide Web to convey at least a part and, in many cases, their entire curricular offering. Despite this trend, there is inadequate support for the professors responsible for restructuring the courses they have refined over a career in the classroom for delivery via the Web. Teachers who are expert in their subject area and masters of their craft when in a classroom find themselves in the uncomfortable position of having to relearn how to teach in a new environment with little or no support. The process of planning and developing a course for delivery in an online environment is, in many significant aspects, analogous to the processes required to develop a software system. Both situations require the developer to manage resources through a series of steps with the goal of designing a product that effectively utilizes the computer to solve a problem. The procedures and tools used in software engineering to manage software system development, therefore, offer promise for developing online courses. Computer aided software engineering (CASE) tools are of special interest by virtue of the support afforded the development process through computerization. This paper offers an architectural overview of a knowledge-based, course engineering system: eCAD (electronic Course Analysis & Design). The requirements for the system, the manner in which those criteria were developed and validated, and system design are detailed. A working prototype is also presented."
2188915,22457,20561,Power system state estimation: modeling error effects and impact on system operation,2001,"State estimation has been introduced to power systems and implemented in the 60s, using a single frequency, balanced and symmetric power system model under steady state conditions. This implementation is still prevalent today. The single frequency, balanced and symmetric system assumptions have simplified the implementation but have generated practical problems. This paper examines these simplified assumptions and their impact on the state estimation performance. It provides a theoretical basis for the well-known fact that the reliability of the state estimator algorithms has been below expectations. Specifically, sensitivity analysis methods are used to quantify the impact of modeling simplifications and measurement schemes on the performance of state estimation. The results clearly illustrate that the traditional state estimation algorithm is biased. These biases affect the accuracy of state estimation and its convergence characteristics.The paper also reviews the traditional state estimation approach against recent technological advances that have enabled synchronized measurements. The implications and possibilities of this new technology are discussed in this paper. Specifically, an example application of the new technology for a Three Phase State Estimator is described. A power system state estimation based on a) multiphase model, b) voltage and current waveform measurements, and c) synchronized measurements is formulated. The paper focuses on the following: a) modeling, b) implementation, c) observability and d) performance. The overall performance of the system is described in terms of confidence level versus error. These concepts are illustrated with simple systems. In addition, we demonstrate the performance of the proposed methods on an actual system (New York Power Authority system) using actual synchronized measurements. The paper concludes with a commentary on the implications of improved state estimation methods on the security/reliability monitoring and control of an electric power system."
2052986,22457,20561,Democracy functions of information technology,2003,"Information technology, IT, may play an important part in any community as a supporting tool in the democratic process. The conditions for that to happen are primarily a genuine wish of the community members to take democratic action, having access to the technology and the skills to use it. The purpose of this paper is to establish the democratic functions of IT in what we call the Swedish democratic model. The model describes democracy, in its perfect state, as a political governing based on citizen control, state governed by law and ability to carry out political decisions. In order to achieve this purpose we first identify the concepts of democracy referring to literature on democracy applying to the Swedish democracy model. With these concepts in mind, we then identify the concepts of democracy of information technology by referring to literature describing various aspects of IT. The inventory of concepts had to be extensive in order to avoid a bias of perspective. We have thus made a thorough survey of the concepts of democracy and information technology to find the necessary number of aspects. The democracy functions of IT have been defined as the various ways of how IT may support the individual and the various social communities in the Swedish democracy model. By the individual we mean the citizen as a private person acting on his own or in different social networks. We define social communities as organisations and public administrations at a local or central level. Seven functions have been identified: support for communication, support for human networks, support for efficiency, support for political decisions, support for authority decisions, support for community service, and support for public insight. Our conclusion is that an IT system containing these functions has a great potential to support the democratic process in any community, regardless the political course of its government."
1622307,22457,20561,XyberScout: a platform for the efficient construction of mobile location aware information systems,2003,"For many years mobile visitor information systems for museums or exhibitions are a topic of research. Research prototypes aim to provide the user with powerful means for organizing his visit and for navigation within the event's surroundings. But today, in real-world applications, we mostly find rather simple tools - mobile guides for fairs, conferences and similar events. In the area of these electronic catalogues, the Fraunhofer IGD Rostock has developed quite successfully a line of such systems. Our experiences with these events have shown that the true challenge of mobile information systems for real-world use is not to provide a large set of features, but to provide an effective and efficient production environment and a suitable and configurable browser application on the mobile platform. We need the integration of the diverse technology fields involved in such applications into a manageable and convenient production tool. With the XyberScout platform, we try to develop such an integrated environment for the efficient creation of such mobile information systems. It aims to provide a suite of technologies for the efficient delivery of mobile information applications that support intelligent and context-aware assistance for real use. In this paper, we outline motivation and concepts of the components of the XyberScout platform and describe some of the new possibilities and advantages for both types of customers of such a system - the organizer and the visitor of an event. Beside the construction platform itself the focus is directed to the user interface concept on the mobile client side."
2397537,22457,20561,Emergent supply networks: system dynamics simulation of adaptive supply agents,2001,"Supply chain networks of independent firms collaborating to serve a final market are becoming a normal business phenomenon. Yet at present it is not clear if and how such networks can achieve stability. Nor is it obvious what successful managerial guidelines might be for individual companies operating in such networks regarding collaboration with the other firms involved. This exploratory study investigates these questions using a generic simulation model of 100 actors distributed over three supply echelons. The model was developed in a system dynamics simulation environment using design principles from agent-based modeling. In this model, each actor holds mental models of the performance of the other actors he is interacting with. Preferences for doing business with these other agents are driven by this performance. Agents differ in the degree in which they value long-term relationships over short-term performance. Model analysis shows that stability in this complex network emerges spontaneously as relative preferences become fixed over time. This lock-in occurs fairly early in the simulation during a period of considerable stress in the various supply chain echelons. Overall, those agents that base their relative preferences primarily on the short-term performance of their counterparts fare somewhat better than agents focussing on the nature of their long-term relationships. A real-world example of a supply network exhibiting characteristics such as the ones observed in the model is presented. Methodological considerations, model limitations and tentative managerial guidelines are discussed."
1983281,22457,20561,"Strategic IS alignment: the necessity for a hybrid framework linking shared vision, leadership, change management and diffusion theory",2004,"The rapid pace of business process change, partially fueled by information technology, is placing increasingly difficult demands on the organization. In many industries, organizations are required to evaluate and assess new information technologies and their organization-specific strategic potential, in order to remain competitive. The scanning, adoption and diffusion of this information technology must be carefully guided by strong strategic and technological leadership in order to infuse the organization and its members with strategic and technological visions, and to coordinate their diverse and decentralized expertise. This view of technological diffusion requires us to look beyond individuals and individual adoption, toward other levels of analysis and social theoretical viewpoints to promote the appropriate and heedful diffusion of often organization-wide information technologies. Particularly important is an examination of the diffusion champions and how a feasible and shared vision of the business and information technology can be created and communicated across organizational communities in order to unify, motivate and mobilize technology change process. The feasibility of this shared vision depends on its strategic fit and whether the shared vision is properly aligned with organizational objectives in order to filter and shape technological choice and diffusion. Shared vision is viewed as an organizational barometer for assessing the appropriateness of future technologies amidst a sea of overwhelming possibilities. We present a theoretical model to address an extended program of research focusing on important phases during diffusion, shared vision, change management and social alignment. We also make a call for further research into these theoretical linkages and into the development of feasible shared visions."
2024492,22457,20561,Context-awareness on mobile devices - the hydrogen approach,2003,"Information about the user's environment offers new opportunities and exposes new challenges in terms of time-aware, location-aware, device-aware and personalized applications. Such applications constantly need to monitor the environment - called context - to allow the application to react accordingly to this context. Context-awareness is especially interesting in mobile scenarios where the context of the application is highly dynamic and allows the application to deal with the constraints of mobile devices in terms of presentation and interaction abilities and communication restrictions. Current context-aware applications often realize sensing of context information in an ad hoc manner. The application programmer needs to deal with the supply of the context information including the sensing of the environment, its interpretation and its disposal for further processing in addition to the primary purpose of the application. The close interweavement of device specific context handling with the application obstructs its reuse with other hardware configurations. Recently, architectures providing support for context-aware applications have been developed. Up to now such architectures are not trimmed to the special requirements of mobile devices regarding particularly the limitations of network connections, limited computing power and the characteristics of mobile users. This paper proposes an architecture and a software framework - the hydrogen context framework -which support context-awareness for considering these constraints. It is extensible to consider all kind of context information and comprises a layered architecture. To prove the feasibility the framework has been implemented to run on mobile devices. A context-aware postbox is realized to demonstrate the capabilities of the framework."
570243,22457,20561,The Role of User Resistance in the Adoption of Screenshot Annotation for Computer Software Learning,2015,"With the widespread coverage of the Internet, e-learning environments have greatly advanced. Students have increasing opportunities to access and interact both with course materials and with classmates. However, the functionalities of e-learning systems nowadays may not satisfy students across the full range of courses, especially computer software courses. The study makes use of the social networking site, namely Flickr, for students to upload screenshots to demonstrate computer problems and troubleshooting software, and to create annotations to diagnose and solve problems with greater certainty. The aim of the study is to investigate the acceptance of using screenshot annotation in the context of computer software learning. The subjects are undergraduates who are about to take the same computer software course, and the information technology measured is screenshot annotation. When students are asked to report their difficulties and interact with others using screenshot annotation, which is a new method for learning computer software, they need to adjust from their previous experiences with e-learning systems to using screenshot annotation. Some may accept this change, but others may resist it. Their resistance can be observed during this transformation. Thus, in addition to applying the technology acceptance model (TAM), three factors from the user resistance perspective, namely, user resistance, colleague opinion, and self-efficacy for change, were chosen as the basis for the research model. The results, based on data collected from 286 students, indicated that students' resistance had a strong, negative, and direct effect on their behavioral intention, and that both colleague opinion and their self-efficacy for change had direct effects on their resistance and their perception of ease of use and usefulness, which in turn affected behavioral intention indirectly."
2401418,22457,20561,The Annai environment for portable distributed parallel programming,1995,"We are developing a portable integrated tool environment, called Annai, for distributed memory parallel processors (DMPPs), as part of the joint CSCS-ETH/NEC collaboration in parallel processing. As we design and implement a sequence of tool prototypes, these are used and evaluated by a team of application developers. This close interaction allows rapid feedback, as requests from the application developers for functionality enhancements can be promptly considered for inclusion in future tool designs and prototypes. Our tool environment consists of an extended High Performance Fortran (HPF) compiler, a performance monitor and analyzer and a source-level debugger for distributed programs, all sharing a common user interface. The recently-defined Message Passing Interface (MPI) serves as our low-level machine interface and allows portability independent of the target hardware architecture. The key features of the tool environment comprise HPF language extensions to allow dynamic data distributions, and support for both high-level data-parallel and low-level message-passing programming paradigms by the interactive debugger and the interactive performance monitor and analyzer. The language extensions are particularly useful for the efficient parallelization of unstructured problems, and they are fully supported by both the debugger and the performance analyzer. We outline the structure of the tool environment, and summarize the functionality of its components. We also demonstrate an example user session and present performance results on two DMPPs. >"
1690017,22457,20561,"Design, Implementation, and Evaluation of a Virtual Meeting Tool-Based Innovation for UML Technology Training in Global Organizations",2012,"End-user training is complicated to implement in global corporations whose activities are typically scattered across multiple sites in different countries and leverage information systems in various ways. This is especially true in global software development where the sites may leverage a development tool for totally different purposes. Web-based Virtual Meeting Tools (VMT) enable synchronous communication globally through interactive audio, online chats, video, and the sharing of presentations. They provide potentially a cost effective way to train even complex topics to large numbers of people in global settings. Few industrial experiences from the design and use of VMT-based training innovations have been reported. This paper draws upon a case study in a global corporation to describe the design, implementation, and evaluation of a training innovation, consisting of a set of courses delivered by means of a VMT and conference calls, to support the global deployment of a Unified Modeling Language (UML) modeling tool and to develop UML modeling skills. Evaluation is based on interviews to verify 1) the impacts of the innovation on skills, knowledge and motivation, 2) perceived learner satisfaction with respect to the innovation. The innovation proved successful in improving skills, knowledge, and motivation in the case organization and learners were satisfied with it. Other organizations may benefit from using VMT to train people to use similar complex information systems for supporting global software development."
1973270,22457,20561,"Pure bundling better than mixed? or, why doesn't AOL offer standardized dial-up service?",2004,"Some dial-up Internet access providers, such as the market leader AOL, require customers to install proprietary connection software to use their service. This is puzzling, because while the software helps certain users, it creates disutility for others (especially expert users and early adopters of Internet service). Why, then, does AOL insist on this connection manager? Why not choose a mixed bundling approach where power users can choose a standardized service that offers access to the Internet and AOL-managed content, and novice users are given a service that integrates access with the connection manager. This paper proposes different possible explanations for why firms might willfully create barriers to entry for customers by pursuing a pure, rather than mixed, bundling strategy where the bundle contains one feature that is negatively valued by a customer segment. Developing economic models for this problem, we propose different hypotheses for explaining the puzzle. We postulate that power users impose exceptionally high cost on AOL's system, and show that the presence of bad customers (whose cost exceeds their valuation) can cripple the profits from the access-only option. Another hypothesis is that even if adding the access-only service improves profits in the short-term, the presence of this service may create a learning effect, where novice users learn to manage without AOL's proprietary software and switch to the cheaper access-only option in future periods."
2523344,22457,20561,Combining neural networks with other prediction techniques,1996,"The complexity and the inherent heterogeneity of real world problems are still one of the major challenges in computer science. Due to the necessity of using different data processing technologies general interest in hybrid systems is a fast growing research area. To support the integration of intercommunicating hybrids the paper suggests the use of distributed software architectures. The main advantages of the approach presented in the paper are the encapsulation of different paradigms, the separation of control and domain knowledge and the reduction of the complexity of individual problem solvers. The first section of the paper gives an overview of the state of the art in hybrid processing. A taxonomy of currently known hybrid system approaches is discussed. Because of the special importance of distributed artificial intelligence (DAI) the author examines issues and research directions in this field and concludes with the presentation of DAI as an integrative paradigm. The author then describes a case study. He gives an overview of the domain (economics) and discuss some prediction methods usually used in this area. After introducing some simple economic relationships and a description of how to use neural networks in multivariate prediction the paper shows how connectionist techniques are embedded in a distributed problem solving framework, called PREDICTOR. The last section shows an example in which a hybrid system out performs the homogenous approaches by combining them intelligently. PREDICTOR is a case study of how to design a so called intercommunicating hybrid system."
2056201,22457,20561,Supply chain coordination by means of automated negotiations,2004,"The coordination within supply chains depends on appropriate forms of distributed decision making. Considering joint decisions as formal contracts, the coordination problem may be regarded as a search process in a corresponding contract space. Automated negotiations, with firms or decision making units represented as software agents, can provide an effective mechanism to determine mutually beneficial contracts. The generic negotiation approach examined in this paper is based on a formal specification of contracts that represent bilateral collaborations between two firms (agents) which aim for the coordination of their production sequences. Taking into account asymmetric information and opportunistic behavior, a mediator supports the negotiation process. This mediator repeatedly generates new candidate contracts, which are accepted or rejected by the agents according to particular strategies. We define an explicit mechanism for implementing a cooperative acceptance criterion, whereby agents conditionally agree on utility deteriorations according to a probabilistic criterion similar to that of simulated annealing. The proposed design enables the definition of negotiation rules to be verified by the mediator, forcing both agents to behave in a cooperative manner. The negotiation approach is validated for different supply chain sequencing scenarios. In spite of the simplicity and generality of the negotiation mechanism, the experimental results are very promising. Thus automated negotiations may constitute an effective means for coordinating decisions within supply chains."
1948065,22457,20561,Design considerations for broadband community area networks,2004,"During the last few years, a number of community area networks (CAN) have been launched in North America and Europe. Contrary to other telecommunication infrastructures, these networks are sponsored and financed by local governments and operate according to business considerations and are based on business models that are different from a classical telecom operator, requiring therefore a tailored business and technological solution. Main CAN customer groups include (i) telcos and ISPs, (ii) business customers, (iii) public sector institutions and (iv) residential users. The two main product groups are fiber and wavelength products offered to wholesale customers and data, voice and video services offered to public sector institutions. Although the individual technologies to be deployed within these networks are no different from those used in the advanced telecommunications systems operated by public carriers, community networks can be more creative in using leading edge broadband core and access technologies and in providing advanced services. The main objective of the paper is to demonstrate that CANs, if properly designed, implemented and managed, represent a viable business model as well as the right technology basis for providing e-government services, in particular, and for contributing to the development of an e-society, in general. A preliminary design of a province network in Northern Italy has been carried out by the authors and serves as a case study for this article."
690465,22457,20561,Security First Network Bank: a case study of an Internet pioneer,1998,"In the US banking industry, the universal view appears to be that achieving larger scale is the only means for survival among the megabanks of the nation and the world. However, one of the smallest banks in the USA, Security First Network Bank, has shaken up traditional bankers by introducing branchless banking via the Internet. The implications of widespread Internet banking for the industry are still unclear for the future of the industry structure, but it is clear that the largest banks in the industry are watching closely to see how the Internet and other forms of electronic commerce will affect banking services, profitability and economies of scale in the industry. The advent of Internet banking could lead to radical shifts in economies of scale, as well leading to a new set of critical success factors for future banks that may be quite different from the requirements of succeeding in the current environment. This case study raises issues that are important for both academics and practitioners to examine in greater depth through additional research. Although this case study is unable to support or refute the research hypotheses suggested in this paper, it does provide important insights regarding the potential for electronic commerce to dramatically alter the structure of the banking industry. In addition to highlighting important issues for researchers to consider in examining the potential impact of the Internet on the banking and financial services industries, this case study may also be useful for academics in teaching students about the potential for this technology to transform industry structures."
1831569,22457,20561,Patients creating self-help on the internet -lessons for future design of internet based healthcare resources,2004,"This paper reports from an ongoing research work on patients? use of the Internet for medical information with special focus on how this can inform the design of future IT use in the healthcare ? patient relationship. The paper explores the process of initiating patient communities online as a way of coping and making sense of a difficult life situation when facing illness. The purpose of the paper is to analyze this process in order to increase our understanding of what triggers some individuals to put the technology to use in order to create online communities for patients. A better understanding of these processes is believed to be important both to increase our knowledge of the activities as an online phenomenon but also to inform the design of future information technology use. A descriptive qualitative design of the study was used and ten face-to-face, semi-structured interviews were conducted with purposefully selected patients who share the experience of initiating and managing online communities. In addition, online observations of 15 communities were performed mainly focusing their general structure and design. On a general level it is concluded that the initiation of patients? online community building is grounded in personal coping processes involving a complex mix of different coping strategies rather than as direct and purposeful action in order to fulfill group specific purposes. In addition it is suggested that the experiences and the knowledge developed by the patients during this process can be a valuable resource both in the design and in the maintenance of information technology support used in the healthcare ? patient relationship."
2314868,22457,20561,Reusing Relational Queries for Intuitive Decision Optimization,2011,"Decision optimization is used in many applications such as those for finding the best course of action in emergencies. However, optimization solutions require considerable mathematical expertise and effort to generate effective models. On the other hand, reporting applications over databases are more intuitive and have long been established using the mature database query technology. A decision optimization problem can be viewed as an inverse of the reporting problem. For example, a report may tell the total cost of a certain supply chain given the various sourcing and transportation options used; the corresponding optimization problem can be to select among all possible sourcing and transportation options to minimize the total cost. Reusing existing reporting queries for decision optimization will achieve the dual goals of taking advantage of past investments and of making decision optimization more intuitive. To realize these goals, this paper addresses two related technical issues with a decision guidance query language (DGQL) framework. The first is to annotate existing queries to precisely express the optimization semantics, and the second is to translate the annotated queries into equivalent mathematical programming (MP) formulation that can be solved efficiently. This paper presents the decision queries with examples, provides formal syntax and semantics to DGQL, describes an implementation method through a reduction to MP formulation. Finally, the paper illustrates via experiments on a prototype system that the optimization tasks done with DGQL compete squarely with expertly generated MP models."
2338457,22457,20561,"New technologies in emerging markets: understanding technology, market and policy constraints to the adoption of advanced automotive technologies",2001,"Analyses how technology, market and policy issues condition the adoption of aluminium in the manufacture of automobile engine blocks in Brazil. Due to important weight savings, there is a clear tendency in the automotive industry to change the engine material from iron and steel to aluminum. This tendency started in the triad market area, mostly because of scale issues, but the increasing global perspective of the industry is now leading to expansion of these practices into emerging areas such as South America. This paper uses a methodology developed at MIT called technical cost modeling to explore the key issues conditioning the adoption of this technology in Brazil and to assess potential supplier strategies for this market. The analysis identifies the scale of production and local policy conditions (in particular, the tax structure and the interest rate) to be the key drivers of differences in component sourcing costs. The study concludes that casting engine blocks in Brazil seems viable for production volumes above 65,000 engines per year for foreign investors and 100,000 for local manufacturers. To overcome diseconomies-of-scale arising from the small volume of engine production in the region, OEMs may need to subcontract the same local supplier, set up investments to the export market or find alternative applications to fill unused capacity in the casting line."
1863472,22457,20561,Balancing safety against performance: tradeoffs in Internet security,2003,"All Internet-accessible computing systems are currently faced with incessant threats ranging from simple script-kiddies to highly sophisticated criminal enterprises. In response to these threats, sites must perform extensive intrusion monitoring. This intrusion monitoring can have significant costs in terms of bandwidth, computing power, storage space, and licensing fees. Furthermore, when exploits are detected, the victims must take actions that can consume further resources and compromise their objectives (e.g., by reducing e-commerce server throughput). In this paper, we explore techniques for modeling the costs and benefits of various security monitoring and response actions. Given these models and stochastic expectations about the types of attacks that a site is likely to face, our CIRCADIA (cooperative intelligent real-time control architecture for dynamic information assurance) automatic security control system is able to make real-time tradeoffs between the level of safety and security that is enforced, and the level of system resources/performance that are applied to the main computational objectives (e.g., e-commerce transactions). We show how CIRCADIA is able to dynamically adjust its security activities to account for changing threat profiles and objectives. The result: a continually-optimized balance of security-maintaining activity that reduces risk while still allowing the system to meet its goals."
2406852,22457,20561,A model for the emergence and diffusion of software standards,2003,"The economic impact of the growth dynamic of standards is often described from a macroeconomic point of view, employing network effect theory and models dealing with externalities. Game-theoretic models try to depict and predict the situation on the microeconomic side. We follow a new approach, which simulates the system's behavior based on the modeling of a set of individual conduction rules, and their interaction in a closed environment. Implementing such an agent based computational economics approach, using a simulation environment called SWARM, we assume the existence of three firm sizes combined with three types of standards. Each standard has an optimal fit to a firm size, which results in reduced costs according to standardization benefits, whereas other combinations lead to lower savings respectively. In addition we postulate initial standardization cost for internal restructuring measures and different scopes of communication fitted to the three firm types. Each firm can repeatedly decide to standardize in various simulation passes depending on an expected standardization benefit. As an outcome of various simulations, we observe a dominance of the communication standard preferred by the large companies as a function of growing network density. For an increasing communication range the same behavior emerges for all firm types. The model underpins the well-known concentration tendency in real worlds' technology markets."
561120,22457,20561,Evaluating the Net Benefits of Investing in New Wind and Transmission Capacity on a Network.,2009,"The SuperOPF provides a framework linking the short-run criterion of operating reliability and the long-run criterion of system adequacy on an AC network. This is accomplished by allowing for load shedding as an expensive option to meet contingencies. The high cost of energynot-served implies that some equipment can be very valuable in contingencies if it reduces the amount of energy-not-served. Calculating the nodal prices correctly for different states of the system provides the basis for determining the economic value of improved reliability and investments in additional network capacity. The objective of this paper is to extend the cooptimization framework to determine the net economic benefit of adding an intermittent source of generation, such as wind capacity, and new transmission capacity to a network. Using the cooptimization framework, this situation can be represented by defining new contingencies that correspond to unpredicted changes in the level of generation from the wind capacity. Using the SuperOPF, the amount of additional reserve capacity that is required to maintain reliability with higher levels of wind penetration is determined endogenously. An empirical example illustrates how the SuperOPF can be used to determine the expected annual cost of meeting load after wind capacity is installed at a remote location. These annual costs are reduced when additional transmission capacity is installed to reduce congestion in transferring wind generation to a load center. Hence, the economic issue is to determine whether the savings in production costs are high enough to cover the annualized cost of investing in the new transmission capacity."
2120514,22457,20561,The Value to Consumers of IT-Supported a la Carte Pricing: An Empirical Test of the Strategic Decommoditization Hypothesis,2011,"We evaluate the theory of strategic decommoditization. The theory suggests that firms can strategically utilize Internet technologies to decommoditize the products that are being sold. This prompts the consumer to make a purchase decision that is less focused on price. This is an important new direction in the use of Internet technology to sell perishable products, which are subject to revenue yield management and for which numerous variations of a basic bundled offer are possible. We use data from a large international airline firm that offers tickets and tie-in services via its online portal. The latter includes frequent flyer mileage accrual, seat assignment, and itinerary change, among others. The airline offers a set of standard branded product bundles that can be modified by adding or removing services. This design is commonly referred to as an a la carte offering. We examine sales under this a la carte pricing mechanism and compare it to sales via channels that sell tickets in the more traditional manner, where bundled offers are less transparent and cannot be modified. We develop hypotheses about the value that consumers place on the a la carte channel and on the consequent differences in booking patterns across channels. We find that roughly one of six standard bundles is customized in the a la carte channel, and these customizations occur mainly for the low-feature standard bundles. We also find that the airline's frequent flyer members and business travelers purchase high-feature bundles more often in the a la carte channel than in the traditional channel. These findings support the theory of strategic decommoditization in the air travel context."
1990375,22457,20561,"NELS: a system for creating, archiving and serving digital courseware documents",1996,"The paper discusses an infrastructure needed to design, develop, and support a new National Educational Learning System (NELS). The NELS system, when established, would be a resource for those institutions with undergraduate curricula that want to evolve their educational program in new ways. It would capitalize on the development and use of newly emerging technologies in higher education. It would provide exemplars of digital documents, furnish tools, and help find national support for those faculty interested in the future of teaching. It would be a unique system that would provide an opportunity to combine pedagogy and technology. It is our belief that NELS would be a critical national resource available to educators focused on the following four specific areas: (1) A National Information Exchange (NIE), which includes authoring studios and delivery environments. (2) Quality assessment. (3) Educational theory and instructional pedagogy, and (4) Distance learning. These areas include elements that demand new roles for instruction, such as an ability to quickly access new information of high textual and visual quality, an ability for faculty and students to access and create information that fosters new teacher-student relationships, techniques that measure the impact of electronically mediated instruction, and studies that promote a sound educational and pedagogical foundation for the application of technology to learning both at local and remote sites."
2074968,22457,20561,Method for insuring IT risks,2004,"This paper explains in detail the method behind the insurance database estimated maximum information technology loss (EMitL). The database has been a crucial tool to make it possible to insure IT perils. It helps to insure IT-perils financially in the same professional way as consequences of traditional perils like fire, flood, and robbery are insured, and thereby secures shareholders' investments. EMitL estimates the security awareness in an existing IT-platform. Based on that information, existing security measures can be priced as they may reduce the estimated maximum loss figures - and thereby the costs for the insurance. In addition, a more cost-effective decision can be made on additional security measures. Furthermore, the costs for the loss exposure inherent in a business service/product can be estimated in a better way, and thereby be incorporated in the product's price. The IT insurances are based on the traditional industries' classes: liability, loss of property, and business interruption. The insurance class liability is divided into insurance policies for: business interruption, fraud and embezzlement, robbery and theft, defamation, infringement of privacy, and infringement of code, trademark etc. The insurance policies in the class loss of property are: fraud and embezzlement, and robbery and theft. The database EMitL layers insurance covers, which is a common method in the insurance industry. This means that the insurance policies are layered according to the amount of financial cover they provide. The insurance levels relate and are converted to security levels. These levels are built on the IT security properties integrity, availability and confidentiality, and are utilized differently, depending on the insurance level and the type of insurance policy. The properties and the levels constitute the base of the security polices produced by EMitL; they are used for the estimation of security awareness and as terms of insurance."
2494115,22457,20561,Implementing and testing ATM in a production LAN,1996,"Presents the results of a collaboration between Sandia National Laboratories' Advanced Networking Department and Engineering Sciences Center to study the implementation of asynchronous transfer mode (ATM) in one of Sandia's most heavily-loaded production networks. The network consists of over 120 Sun Sparc 10s and 20s, two SparcCenter 2000s, a 12-node parallel IBM SP-2, and several other miscellaneous high-end workstations. The existing network was first characterized through extensive traffic measurements to better understand the capabilities and limitations of the existing network technologies and to provide a baseline for comparison to an ATM network. This characterization was used to select a subset of the network elements which would benefit most front conversion to the ATM technology. This subset was then converted to equipment based on the latest ATM standards. With direct OC-3c (155 Mbps) host connections for the workstations and the file and computer servers, we demonstrated as much as 122 Mbps throughput (memory-to-memory TCP/IP transfers) between endpoints. Flow control in the classical many-to-one client-server environment was also investigated. Throughout all of our tests, the interaction of the user applications with the network technologies was documented and possible improvements were tested. The performance and reliability of the ATM network was compared to the original network to determine the benefits and liabilities of the ATM technology."
290103,22457,20561,"Dissortative from the Outside, Assortative from the Inside: Social Structure and Behavior in the Industrial Trade Network",2015,"It is generally accepted that neighboring nodes in financial networks are negatively assorted with respect to the correlation between their degrees. This feature would play an important damping role in the market during downturns (periods of distress) since this connectivity pattern between firms lowers the chances of auto-amplifying (the propagation of) distress. In this paper we explore a trade-network of industrial firms where the nodes are suppliers or buyers, and the links are those invoices that the suppliers send out to their buyers and then go on to present to their bank for discounting. The network was collected by a large Italian bank in 2007, from their intermediation of the sales on credit made by their clients. The network also shows dissortative behavior as seen in other studies on financial networks. However, when looking at the credit rating of the firms, an important attribute internal to each node, we find that firms that trade with one another share overwhelming similarity. We know that much data is missing from our data set. However, we can quantify the amount of missing data using information exposure, a variable that connects social structure and behavior. This variable is a ratio of the sales invoices that a supplier presents to their bank over their total sales. Results reveal a non-trivial and robust relationship between the information exposure and credit rating of a firm, indicating the influence of the neighbors on a firms rating. This methodology provides a new insight into how to reconstruct a network suffering from incomplete information."
1812137,22457,20561,A collaborative project management architecture,2003,"The project management (PM) paradigm is rapidly shifting due to business globalization and information technology (IT) advances that support distributed and virtual project teams. Traditional PM focuses on a single project at a single location according to R. Evaristo and P. C. van Fenema (1999) and is more concerned with project inputs and outputs than with project process by J. R. Turner (2000). Management in the past implied projects were conducted with a top down view by K. J. Cleetus et al. (1996). The PM paradigm has begun to change due to the increasing number of distributed projects involving project collaborators from different locations, organizations, and cultures according to N. D. Jonsson et al. (2001). Current and future PM are more concerned with tracking project work processes and efficient and effective sharing of information and knowledge, among project contributors. High-levels of collaboration become essential for distributed project success. Task interdependence and member distribution across time, space, and technology make high degrees of collaboration necessary to accomplish project work. Adequate and timely sharing of information, and knowledge in all directions, proactive change management, and process monitoring are some of the important factors required for successful project collaboration according to F. Maurer (1996). In this article, we review problems associated with traditional PM scenarios, explain how collaborative PM can provide solutions, present a comparison of current commercial collaborative PM tools, and propose a collaborative PM architecture to address the challenges facing distributed projects teams."
2140511,22457,20561,Socratenon-a Web-based training system with an intellect,2000,"The main goal of the project called Socratenon was to build a new Web-based training environment that would go beyond traditional ones. In the open literature, there are several solutions trying to accomplish the same to a certain degree. Some of them are nothing more but plain virtual textbooks that only flip pages on mouse-clicks. More sophisticated techniques include user modeling in order to personalize the content for the user, adaptive interfaces, intelligent agents for improved assistance and search, neural networks and case-based reasoning for building intelligent back-ends, etc. In general, many existing learning environments lack interaction, full utilization of Web resources is scarce, while solutions utilizing a combination of all above are practically non-existent or in development. This paper tries to merge the potential of the new Internet technologies and the latest developments in cognitive sciences, on the one hand, with the comfort of learning at the most suitable time and in the most suitable place, on the other hand. The project has been finalized, the package works, and its performance has been tested both objectively and subjectively; it demonstrates superiority over similar solutions from the open literature. Its complexity is such that it can fit even the widespread PC platforms, although it demonstrates the best performance on state-of-the-art corporate platforms."
1902112,22457,20561,Explaining the Global Digital Divide: The Impact of Public Policy Initiatives on Digital Opportunity and ICT Development,2010,"The development of affordable information and communication technologies (ICTs) over the past 25 years has created an environment for people across the globe to have greater access to telecommunication and Internet services. Much of the previous research suggests that these technological advances have mostly exacerbated existing inequalities between developed and developing nations and created new inequalities within societies between the information rich and poor. There seems to be very little research, however, that provides comprehensive explanations for the global digital divide and, in particular, the impact of national public policy initiatives that seek to expand access to ICTs. Most of these studies have tended to be either largely descriptive, qualitative case studies, or quantitative analyses that have had a very narrow concept of ICTs. Our research examines the digital divide by analyzing the impact of national policies in the form of strategic planning, regulation and investment on the International Telecommunications Union's Digital Opportunity Index and ICT access and use indicators in approximately 150 countries. Our multivariate regression analysis shows that when controlling for measures of economic, political, social and educational development, there is greater digital opportunity and greater overall technology adoption and use in countries that have competition to provide basic telecommunication services and make a higher financial investment in ICT development."
2367432,22457,20561,De-lurking in virtual communities: a social communication network approach to measuring the effects of social and cultural capital,2004,"The asymmetry of activity in virtual communities is of great interest. While participation in the activities of virtual communities is crucial for a community's survival and development, many people prefer lurking, that is passive attention over active participation. Often, lurkers are the vast majority. There could be many reasons for lurking. Lurking can be measured and perhaps affected by both dispositional and situational variables. This project investigates social and cultural capital, situational antecedents of lurking and de-lurking. We propose a novel way of measuring such capital, lurking, and de-lurking. We try to figure out what are the triggers to active participation. We try to answer this by mathematically defining a social communication network of activities in authenticated discussion forums. Authenticated discussion forums provide exact log information about every participant's activities and allow us to identify lurkers that become first time posters. The proposed social communication network approach (SCN) is an extension of the traditional social network methodology to include, beyond human actors, discussion topics (e.g. Usenet newsgroups threads) and subjects of discussions (e.g. Usenet groups) as well. In addition, the social communication network approach distinguishes between READ and POST link types. These indicate active participation on the part of the human actor. We attempt to validate this model by examining the SCN using data collected in a sample of 82 online forums. By analyzing a graph structure of the network at moments of initial postings we verify several hypotheses about causes of de-lurking and provide some directions towards measuring active participation in virtual communities."
1979760,22457,20561,The economic rationale of offering media files in peer-to-peer networks,2004,"File sharing is one of the most controversial applications in the Internet. Millions of users enjoy downloads of billions of media files such as songs or movies. But where do these files come from? While the economic rationale to download files is obvious, the motives of individuals to actually share and, therefore, internalize the costs (i.e. the risk of being sued for copyright infringement) are less obvious. Consequently, empirical studies have shown a large proportion of users demanding files but not offering any and, therefore, free riding on their peers. Nevertheless, sharing can be rational. This paper offers a theoretical base to explain sharing behavior and proves that the users' utility considerations depend on the network's life cycle. At the beginning of a network's life cycle the incentives to share files are high if an individual understands the economics of network externalities. Nonetheless, the user's utility to share files decreases over time, especially if the network grows and becomes anonymous. The strategies of individual users to share or free ride are explained using game theoretic approaches. Depending on the life cycle, the expectations and utilities of the users differ, leading to various games and optimal strategies. We empirically test our hypotheses using mixture regression models and explain the rationale of sharers in different stages of the life cycle. In order to prevent the (theoretically) inevitable break-down of the file sharing network, the authors finally present strategies for file sharing networks to enhance the user's willingness to share."
2066742,22457,20561,Experimental results for single period auctions,1998,"The objective of the paper is to present experimental results for testing the performance of different auction mechanisms related to the introduction of competitive markets for the generation of electricity. The research is based on the concept of smart markets introduced by Vernon Smith (K.A. McCabe et al., 1991) and a simulation model (PowerWeb) of a realistic bulk power system. There are unique physical aspects associated with the supply of electricity (e.g. required instantaneous matching of supply and demand, unintended congestion of parallel transmission routes and maintenance of system stability in response to disturbances). As a result, traditional theories of efficient markets and auction structures developed for other commodities may not be efficient if applied without alteration to markets for electricity. Conversely, current utility rules of operation developed for a centrally planned regime may not be appropriate in a competitive environment. The research does not address the issues of multiperiod operations (unit commitment) and multidimensional markets (ancillary services), and considers only real power in a single time period. The main objective is to test three alternative auction mechanisms when market power is a potential problem. This situation occurs when limits on transmission lines are binding to form a load pocket in which demand is met by a few (in this case two) generators."
1855224,22457,20561,Designing a market for quantitative knowledge,1996,"The awakening of government programs recognizing the information infrastructure of a country being a critical success factor for economic growth has not only stimulated the feasibility of electronic information sources but also has triggered the growth of electronic information pools. Unfortunately, the ever growing potential of electronic information such as the ubiquitous Internet is only poorly exploited. This is due to shortcomings in organizational aspects and in the semantical data modeling of existing information pools. To guarantee the current success of global and open information sources like Internet, we argue that economic issues as well as new approaches in data modeling must be considered in the near future. The paper presents architectural and implementation issues of a knowledge medium (KM) for quantitative information. Based on the vision of a KM introduced by M.J. Stefik (1988) we use market like coordination mechanisms (T.W. Malone and K. Crowston, 1991) to control generation, distribution and knowledge integration. First of all, the modeling of the quantitative information is discussed together with methods which allow to determine information semantics, origin, ownership and quality. Secondly, different organizational approaches within an information market are analyzed. These aspects concern different market coordination strategies, especially suitability thereof, the migration of local towards global information markets and the treatment of information as a negotiable good."
2095011,22457,20561,Market Engineering for Electronic Health Services,2012,"Various studies have proven the positive impact of e-health solutions on treatment success and health care spending. Utilization of e-health is therefore urgently recommended by German health authorities. However, the diffusion of such technologies is currently very low, despite the availability of the underlying technology. A market failure is a likely reason for the unsatisfying situation, as there are currently hardly regular business models for electronic health services. This paper conducts a case study on telemonitoring, which has significant positive impact on patients with chronic heart failure, to illustrate a market engineering approach for e-health applications. The introduced case study is located in a southern German region, where health insurances and a physician network want to establish a telemonitoring solution. We investigate the socioeconomic, technical and legal environment in order to derive a transaction object and build a transaction service. Patients will transfer vital parameters to physicians on a daily base. Caregivers observe patients' health status and compile quarterly reports for the e-health provider. The provider distributes the funds of the health insurances according to the compliance among the stakeholders and adjusts the model on an annual base according to the realized savings. The presented solution can be built upon the emerging German infrastructure for telemedicine and be extended to further regions later."
1785885,22457,20561,Document based process improvement in the public sector: settling for the second best is the best you can do,1997,"Documents play an important role in the public sector. Contemporary ICT (e.g. workflow management systems, image processing, electronic document management and electronic document interchange) offers possibilities to support organizational processes which handle large volumes of documents, enabling new organizational structures. In an inter-organizational setting this may result in a shift of boundaries between co-operating organizations. The paper describes a case study conducted at the Ministry of Housing, Spatial Planning and Environment of the Netherlands. We studied the Individual Rent Subsidy (IRS) program. A central governmental agency, 633 municipalities, and 2000 private organizations, such as non-profit housing corporations, are involved in the IRS program. Almost one million applications are yearly processed. Nearly all information is exchanged in hardcopy form. The possibilities of supporting the IRS program with ICT are examined. For this purpose a simulation model was constructed. Two kinds of alternatives were studied: optimizing current document exchange without changing the competence in the organizational chain and (re)structuring the inter-organizational structure. The paper demonstrates that the lack of consistency in the IRS operations at the local level is a barrier for implementing ICT on an inter-organizational level. Secondly, it illustrates that considerations at a political level block an efficient process structure."
421658,22457,20561,Creating a Data Science Platform for Developing Complication Risk Models for Personalized Treatment Planning in Radiation Oncology,2015,"The common approach to assessing risk in radiation oncology treatment uses Lyman-Kutcher-Burman (LKB) derived models to calculate normal tissue complication probability (NTCP). LKB is not sufficiently robust to capture the modern clinical reality of three-dimensional intensity modulated radiation therapy (IMRT) treatments, the approach accounts for only two factors -- Dmax and Veff. We present a data science platform designed to facilitate the rapid creation of data-derived NTCP models. The platform extracts native Philips Pinnacle data such as dose grids and contoured regions using the cross-vendor DICOM RT standard. Further, outcome data is encoded using Common Terminology Criteria for Adverse Events 4.0. Thus, the platform exploits the normal clinical workflow and information encoded with a standard ontology. Over the course of less than three weeks we used the platform to create NTCP models for two complications (xerostomia and voice dysfunction due to parotid and larynx irradiation, respectively). We assess the resulting platform with a focus on its context within a Learning Health System (LHS). We believe that the system reported can serve as a guide to the development of radiation oncology data science platforms in particular and local-level LHS components in general."
1938574,22457,20561,An approach to data visualization and interpretation for sensor networks,2004,"With the increase in applications for sensor networks, data manipulation and representation have become a crucial component of sensor networks. This paper explores an approach to process and interpret the data gathered by sensor networks. We have built sensor networks which consist of a series of sensor and communication units (pods) deployed to monitor rare plants or other endangered species. The environmental data, such as temperature, rainfall, and sunlight, around the plants are sent by the wireless sensor networks to a base station which is able to access the Internet. The approach presented in this paper combines database management technology, geographic information system and Web development technology to visualize the data gathered by the wireless sensor networks. The resulting maps created by a GIS system, GRASS, connect the environmental data with the pods' geographic positions obtained from GPS (the global positioning system). Voronoi diagrams are used to partition the map into areas holding different weather attributes based on the data collected by the pods. The Web development technology /sub y/namic Web programming - is also adopted in this system to make the data available via the Internet. Finally, we sketch the design of an asynchronous collaborative discussion environment which supports online communities among the end users of our information interpretation system. The integration of our data visualization tools and the online collaborative discussion environment makes the system useful to different communities of potential users."
971935,22457,20561,Ex ante and ex post designs for electric market mitigation: past and present experience and lessons from California,2003,"Restructuring in electric power sectors took a significant step backward in the summer of 2000 when wholesale and retail markets in California experienced staggering price increases that continued through June of 2001. During this period, California suppliers neared bankruptcy and one went into bankruptcy, as did the state's cornerstone market institution, the California Power Exchange. While the cause has been alternatively described as the perfect storm and a case of market manipulation the outcome has been a price mitigation process at the FERC, a series of federal and state lawsuits, and a California Market Design process led by the CA ISO that incorporates four separate proposals for statewide price mitigation. The objective of this paper is to present an analysis of the impact of actual and proposed market mitigation procedures for the California market. Based on detailed analyses (10 minute California electric system operating data for the refund period of October 2000 through June 2001) the paper: (1) reviews and critiques the FERC procedure for calculation of a Mitigation Market Clearing Price to be applied during the refund period, (2) evaluates market mitigation strategies that are being considered for future application in the State and the country as a whole, and (3) evaluates the possible success of any ex post price mitigation. The analysis is focused on the impact of such strategies on wholesale electric market development both in the US and internationally. Recommendations are offered for FERC's ongoing standard market design effort that affects the design of electricity markets throughout the country."
2364745,22457,20561,Impact of technology sustainability on healthcare governance,2003,"Healthcare technology investments must be borne by charity, government subsidy, or patient reimbursement. Such investments can be expensive and require partnerships of public and private institutions. This paper explores the relationship between technology sustainability and healthcare governance of multi-institutional technology partnerships. A technology is assumed to be sustainable if the initial investment is paid and the operating costs are covered from one or more of these sources. Entirely possible is need for new governance forms in order to manage the initial and ongoing partner expectations. Can partnerships that initially rely on charity and government subsidy transform into self-sustaining or profitable operations? This paper incorporates findings from a business study of the Brazos Valley Telehealth Partnership (BVTP) that provides telemedicine infrastructure for a group of healthcare institutions who serve a seven county rural area. This paper explores the impact of technology sustainability on partnership governance. The findings are based on experiences gained during the formation and operation of the BVTP. The paper considers the valuation of network externalities. The paper posits that impact of technology adoption on organizational continuity on governance forms. The paper suggests incremental and continuous changes are best addressed by individual organizations or partnerships. For disruptive changes, new organizational forms are needed to isolate the disruptive impacts on organizations and processes. The paper concludes by advocating practical suggestions and further research."
1791377,22457,20561,Customer relations management research: an assessment of sub field development and maturity,2001,"MIS research into electronic commerce customer relations management (ECCRM) has received a great deal of attention over the last five years. This study investigates the status and maturity of this emerging sub field through an exhaustive literature review from all available conference proceedings and journals from the first published article (1984) until the end of the first quarter 2000. Results of the study of 211 articles indicate a number of interesting trends, which should be of concern to IS researchers in this area and in MIS on the whole. First, exploratory surveys dominate the research literature, which in itself may be problematic. However, even more troubling is the fact that the majority of the survey instruments were either not validated, or the authors did not think it important to include validation procedures within their papers. Second, little theory has been developed and few empirical studies use hypothesis testing. Third, there is little cumulative tradition emerging, as each study develops a new conceptual model, new constructs and new instruments. Finally, the news is not all bad; on the whole ECCRM literature has employed a wide range of research methods, constructs and variables. Although the sub field of ECCRM is young, it is growing rapidly and professional activity within the IS research community illustrates its emerging importance."
1881882,22457,20561,MOBICHARTS: a notation to specify mobile computing applications,2003,"A standard notation, that unambiguously expresses different aspects of a system, is important to the process of software development. The expressiveness of a standard notation helps analysts and developers to describe a computing scenario or to formulate software architecture and then to communicate these decisions unambiguously to other team members. Much attention is already given to the software development methodologies and architectural descriptions. Specifically, statecharts and state transition diagrams have been used to show the state space of a system, the events that cause state transitions and the actions that result from a state change. The paradigm shift to object-oriented programming has changed the method of system analysis and design from traditional top-down approach to bottom-up object-oriented approach. This change in approach has motivated the development of objectcharts that depict the behaviour of objects used in a system. This paper extends the notational capabilities of objectcharts to specify the issues related to the mobile computing. We discuss the specialty and the limitations found in mobile computing to motivate the readers on the necessity of having methods for developing mobile computing applications. We have shown that while making use of all the niceties of Statecharts as well as objectcharts, the formalism can be extended for developing mobile computing applications. First, we discuss the need for an extension of objectchart notation by showing the limitations of objectcharts in specifying mobile computing applications. Second, we propose an extension to objectcharts, referred to as Mobicharts. The proposed Mobicharts can specify the important characteristics of mobile computing applications. We illustrate typical mobile computing characteristics such as migration, hoarding, cloning, synchronization, sharing and disconnected operations using Mobicharts."
2073143,22457,20561,Predicting groupware usage,1998,"As organizations are adopting new structures, groupware is increasingly being used as a way of implementing these new organizational forms. Although user acceptance of groupware technology by the intended users is a prerequisite for realizing its full potential in organizations, there is no clear understanding about why people accept or reject groupware technology. Davis's (1986, 1989) technology acceptance model (TAM) provides a useful basis in answering this question. With traditional end-user computing tools, behavioral intention measured shortly after brief training with the software can reasonably predict the usage behavior measured later in the system deployment process. Given the unique characteristics of groupware technology, however, it is not clear whether traditional TAM can be still used to predict groupware acceptance. In a longitudinal study with senior executives, intentions to use a specific groupware system, measured two weeks after the initial introduction of the technology, were found not to be correlated with system use eight weeks later. Perceived usefulness and ease of use were strongly correlated with contemporaneously measured behavioral intention and system use. These results suggest a possible existence of a social influence process in the groupware technology acceptance process. Managers need to be careful in trying to predict user acceptance using behavioral intention measured shortly after a short training or introduction of the technology to the intended users. Instead, managers may need to pay much closer attention to the social process of the groupware acceptance process in the workplace."
2117234,22457,20561,Verification of system models for steady-state and dynamic security assessment,2004,"The requirements for improvement in the stability of electric power systems and reduction in the effect of abnormal system conditions on sensitive customers can be met only by better understanding of the behavior of the system and optimized configuration of the different protection and control systems. The planning, design and implementation of such systems are based on the use of advanced analysis tools. They model the primary and secondary components of electric power systems and analyze its operation under normal or abnormal conditions. The accuracy of the different simulations and the assessment of steady-state and dynamic security is determined to a great extent by the accuracy of the models. The paper describes different types of system security related analysis tools: short circuit, protection coordination and dynamic stability. The models of power system equipment and the requirements for verification of these models in the different types of software are discussed later in the paper. Recording of system parameters during abnormal system conditions and comparison with the results from steady-state or dynamic stability simulations of the same event based on the model system allows the verification of the system models and building confidence in the assessment of possible system disturbances. The recording capabilities of multifunctional intelligent electronic devices (IEDs) are described and different recording modes are identified and proposed for the verification of system models. The architecture of a distributed system for recording of local or wide area system disturbances is presented. Requirements and methods for time synchronization of multifunctional IED located throughout the system are discussed."
1444855,22457,20561,"The Many Lives of an Agile Story: Design Processes, Design Products, and Understandings in a Large-Scale Agile Development Project",2012,"In Agile Software Development (ASD), stakeholders use stories to stimulate conversations that create and convey understanding of software requirements. Some authors have argued that ASD methods have limited applicability to large-scale projects because agile stories are not sufficient to capture the complexities of up-front design. This paper reports a 2.5-year field study of how an ASD team for a complex software system adapted the user story concept and the Scrum approach. The team sought to create a convention for representing agile stories which could capture the complexities of the system requirements without burdening the team with unneeded documentation. They developed eight different ways to represent a story. The core representation of the approach was called a HyperEpic, a structured collection of closely-related HyperStories. HyperEpics required 90-99% fewer words than conventional specifications. Because of their dense form, Hyper-epics were not useful for other phases in the design/build processes. The team evolved a design/build work practice that proceeded in stages. In each stage, stories underwent a one or more transformations. Each transformation represented stories differently to create varied kinds of understandings among different stakeholder sets. The team was able to gain the benefits of ASD -- faster development cycles, less documentation, rapid adaptation to insights and conditions."
1922388,22457,20561,Measuring and assessing online store image: a study of two online bookshops in the Benelux,2002,"The objectives of the research project described in this paper are (1) to develop reliable and valid measures for the components of online store image, and (2) to examine the influence of these components on the intention to purchase online. Conceptually, the project relies on the relatively established literature on traditional store image and the emerging electronic commerce literature seeking to discover the antecedents of online purchase intention. Empirically, we focus on two popular online bookstores in the Netherlands and Belgium. The process of instrument development put forward by Churchill (1979) was adopted. We conducted two rounds of data collection (pilot sample, n = 61, one online bookstore; main sample, n = 312, two online bookstores) and use a combination of exploratory and confirmatory statistical techniques to assess reliability and validity. The paper eventually presents multiple-item measurements for the following components of store image: online store usefulness (6 items), enjoyment (3 items), ease of use (6 items), store style (4 items), familiarity (3 items), trustworthiness (3 items) and settlement performance (8 items). All measures are unidimensional and contain acceptable alphas. The components are then regressed on online purchase intention, revealing significant, direct influences from usefulness, enjoyment, trustworthiness and settlement performance. Second order influences of the other components are investigated and reported. The paper compares these results with similar results in the literature and concludes with contributions and limitations of this particular project."
1267401,22457,20561,Could Decision Trees Improve the Classification Accuracy and Interpretability of Loan Granting Decisions,2010,"The paper compares the classification performance rate of eight models: logistic regression (LR), neural network (NN), radial basis function neural network (RBFNN), support vector machine (SVM), case-base reasoning (CBR), and three decision trees (DTs). We build models and test their classification accuracy rates on a historical data set provided by a German financial institution. The data set contains 21 financial attributes of 1000 customers. Though at the time of loan application all individuals deemed to the institution to be qualified to obtain a loan, 300 of them defaulted upon a loan and 700 paid it off. To obtain reliable and unbiased error estimates for each of the eight models we apply 10-fold cross-validation and repeat an experiment 10 times. We found that in the overall classification accuracy rates at 0.5 probability cut-off, two of the three DT models significantly outperformed (at alpha=0.05) the other remaining models. We then concentrate our attention on DT models and compare their performance at 0.3 and 0.7 cut-off levels which are more likely to be used by financial institutions. The DT models not only classify better than the other models, but the knowledge they learn in the form of if-then rules is easy to interpret, makes sense, and might be of value to financial institutions which may have to explain the reasons for a loan denial."
2477260,22457,20561,"A comparison of team developmental stages, trust and performance for virtual versus face-to-face teams",2004,"This study is an empirical analysis that compares virtual with face-to-face teams on team trust, performance issues and team developmental stages. The study uses data collected both before teams were formed and after teams completed their project deliverable. Pre-task measures include individual disposition to trust and initial team trust. Upon completion of their deliverable, team members responded to post-task measures on motivation, team trust and teamwork dynamics. In addition to these attitudinal comparisons, we investigate how teams spent their time during the completion of their team task. We examine potential differences in the percentage of time spent in each of the classic team formation stages (forming, storming, norming and performing). Team members also reported the total time spent completing the deliverable as well as time spent using various communication tools. In addition, we evaluate and compare team performance in terms of the deliverable quality. Our results indicate that both virtual and face-to-face teams bring relatively high initial trust to the team experience. More enduring trust, however, must be maintained by positive, task-oriented team dynamics. Team mates need to meet work expectations in order to maintain the trusting environment. We confirm that trust is important to team performance for both virtual and face-to-face teams. Higher trust teams do tend to perform better. We also found that both virtual and face-to-face teams spend similar proportions of time in each team formation stage. Finally, there is no significant difference in results produced by face-to-face and virtual teams, though in this study the direction of effectiveness leans towards the virtual teams. This is potentially good news since many believe that face-to-face groups produce better results than their virtual counterparts."
2333462,22457,20561,Pay-per-use concept in healthcare: a grounded theory perspective,2003,"Healthcare organizations worldwide are faced with the growing challenge of introducing structural and technological reforms and cost-effective IT solutions that will transform the traditional structure of healthcare provision. Current technological developments have shed optimistic light on the future of IT in healthcare. This paper introduces a 'Pay-per-use' concept in healthcare delivery services, which could prove appropriate for a small country like the State of Kuwait. The research question is directed towards the appropriateness and usefulness of such a concept. The need for effective and efficient healthcare delivery services in health organizations implies the need to establish a healthcare paradigm that is investment, communication, technology, platform, database, application-independent. The grounded theory (GT) forms the basis of the new concept, using a social context and referring to a typical clinical scenario. The social process fundamental to GT provides a specific and systematic approach to understand medical work and a network of relationships among healthcare entities. Interpretations and analysis of data in the social context facilitates clearer understanding of concepts and categories and enables the formulation of a theory and a model architecture. The State of Kuwait is a typical example of a small country with rapidly advancing IT, where the new concept can be put to the test within the required infrastructure for the development of a beneficial healthcare delivery system in the country."
2129436,22457,20561,A self-disclosure model for personal health information,2003,"The use of information technologies (IT) to collect personal health information is growing in popularity via computer-assisted interviewing and a wide variety of healthcare Web sites. However, a review of the literature on computer-assisted interviewing exhibits confounding and equivocal results regarding the effects of IT on individuals' willingness to disclose socially sensitive health information. Some studies revealed individuals' heightened concerns about entering their health information into a computer, while other studies exhibited greater willingness to enter sensitive information into a computer than to give it to a personal physician. The pervading lack of clarity in explaining these results may be largely due to limited attempts to model the underlying factors that motivate the self-disclosure of socially sensitive personal health information; most studies examine the relationship between the data collection environment and the willingness to self disclose without identify the underlying factors. In this paper, we propose a model of self-disclosure that contains three classes of motivating factors derived from a decomposition of the data collection environment of previous studies: perceived privacy, context sensitivity, and quality of feedback. Aspects of the data collection environment that reinforce the motivational factors are expected to increase disclosure and thus improve the quality of information. An analysis of the results of previous studies employing IT-enabled data-collection environments offers preliminary support of the proposed model. After presenting the model, we discuss research implications and suggest approaches for validating the self-disclosure model."
1856594,22457,20561,The effect of customer participation in electricity markets: an experimental analysis of alternative market structures,2004,"An experimental structure is demonstrated that represents end-use customers in electricity markets who can substitute part of their usage between day and night. Individuals' demand relationships are represented by a two-step value function for each period that are disaggregated from observed market demand relationships. Demand varies between day and night and during heat waves. Three alternative demand-side market structures are evaluated: 1) customers pay the same fixed price (FP) in all periods - the base case, 2) a demand response feature (DRP) is added in periods of supply shortages, wherein buyers receive a prespecified credit for reduced purchases, and 3) a real time pricing (RTP) case where prices are forecast for the upcoming day/night pair, then buyers select their quantity purchases sequentially and are charged the actual market-clearing prices. Initial experiments were conducted with active demand-participants, but with a predetermined typical hockey-stick supply structure that was varied randomly, over eleven day-night pairs that included heat wave and supply shortages. The RTP structure resulted in the greatest market efficiency, despite the more difficult cognitive problem it poses for buyers. Furthermore, a preference poll comparing DRP and RTP was conducted after each trial; and while 64% of the participants said they preferred DRP before RTP experiments, 76% selected the RTP structure afterwards, a statistically significant reversal of preferences."
2006410,22457,20561,Towards knowledge discovery through context explication,2004,"More and more knowledge does play a decisive role as a factor of production besides the classic factors work, raw materials, and capital. Companies get a competitive advantage from a lead of knowledge and the capability to transform superior knowledge into market driven business processes. The consistent orientation towards customers and their processes requires the customization of intracorporate processes and systems. Customer process oriented portals support the collaboration of customers, employees, and suppliers. They integrate companies' systems and provide transparent access to information objects stored in these systems. One key problem is to find relevant information objects in continuously growing and distributed systems. Necessary conditions for the core processes of knowledge identification and knowledge use are mechanisms of navigation and linking as well as functionalities for extensive searches and investigations. A decisive challenge is to make knowledge available at the right time and the right place. Therefore, the implicit context of information has to be explicated to fill 'knowledge gaps'. In this paper, we introduce a continuum of context explication, which comprises different relations between information objects and its contexts by means of their degree and ease of context explication. Furthermore, we evaluate different approaches for knowledge discovery in customer process oriented portals, provide patterns when to apply which approach, and present two small cases for knowledge discovery in such portals."
2316168,22457,20561,On Bus Type Assignments in Random Topology Power Grid Models,2015,"In order to demonstrate and test new concepts and methods for the future grids, power engineers and researchers need appropriate randomly generated grid network topologies for Monte Carlo experiments. If the random networks are truly representative and if the concepts or methods test well in this environment they would test well on any instance of such a network as the IEEE model systems or other existing grid models. Our previous work [1] proposed a random topology power grid model, called RT-nested-small world, based on the findings from a comprehensive study of the topology and electrical properties of a number of realistic grids. The proposed model can be utilized to generate a large number of power grid test cases with scalable network size featuring the same small-world topology and electrical characteristics found from realistic power grids. On the other hand, we know that dynamics of a grid not only depend on its electrical topology but also on the generation and load settings, and the latter closely relates with an accurate bus type assignment of the grid. Generally speaking, the buses in a power grid test case can be divided into three categories: the generation buses (G), the load buses (L), and the connection buses (C). In [1] our proposed model simply adopts random assignment of bus types in a resulting grid topology, according to the three bus types' ratios. In this paper we examined the correlation between the three bus types of G/L/C and some network topology metrics such as node degree distribution and clustering coefficient. We also investigated the impacts of different bus type assignments on the grid vulnerability to cascading failures using IEEE 300 bus system as an example. We found that (a) the node degree distribution and clustering characteristic are different for different type of buses (G/L/C) in a realistic grid, (b) the changes in bus type assignment in a grid may cause big differences in system dynamics, and (c) the random assignment of bus types in a random topology power grid model should be improved by using a more accurate assignment which is consistent with that of realistic grids."
528960,22457,20561,Whither configurable computing,1997,"Configurable computing has captured the imagination of many architects who want performance of application specific hardware combined with the flexibility of general purpose computers. Despite the efforts of many research groups over the past decade, successes have been rare: configurable computers so far exhibit poor cost performance for most common applications. To make things worse, configurable computers are notoriously hard to program. Commercial FPGAs are not well suited to most applications. These FPGAs are necessarily very fine grained so they can be used to implement arbitrary circuits, but the overhead of this generality exacts a very high price in density and performance. Compared to general purpose processors (including DSPs), which use very optimized function units that operate in bit parallel fashion on long data words, FPGAs are very inefficient for performing ordinary arithmetic and logical operations. FPGA based computing has the advantage only when it comes to complex bit oriented computations like count ones, find first one or complicated masking and filtering. In summary, future progress in configurable computers will result not from continued research along the same FPGA based path, but from a diversity of approaches including more coarse grained configurable architectures and constrained programming models that allow more powerful compilation techniques."
918117,22457,20561,"Minitrack: Consumer Health Informatics, Patient Safety and Quality of Practice",2007,"Health Information Consumers are increasingly seeking access to timely, accurate and accessible information, as made possible through Information Technology (IT). These technological developments have direct implications for access, awareness and use of health information by consumers, as well as patient decision making, safety, and quality of health care provision. Healthcare information systems are expected to reduce medical errors, improve quality of patient care and safety. These systems are increasingly supporting evidence-based medicine and patientcentric technologies, including monitoring of patient outcomes and adverse events, as well as better informing and empowering consumers themselves to work for better outcomes. This mini-track embraces all aspects of consumer health informatics and consumer-centric technologies or studies aimed at improving patient safety and quality of care, including: supporting consumers taking an active role in understanding, deciding about and/or managing their health; doctor-patient communication; clinical guideline and protocol support; monitoring and prevention of adverse events; and electronic health records (especially, security and privacy, access control rights, and consumer ability to make entries into the health record, including home monitoring). The Consumer Health Informatics, Patient Safety and Quality of Practice Minitrack uses the international and interdisciplinary forum provided by HICSS for the expression of practical, theoretical, academic and industrial insight in this area."
2394626,22457,20561,A comparison of high level synthesis and register transfer level design techniques for custom computing machines,1998,"The most expensive component in the process of building a custom computing machine is the time consuming and highly qualified work of hardware designers. This hinders the wide proliferation of CCMs and pushes this innovative technology into a niche market of research applications. A potential solution to the problem is behavioural or high level synthesis (HLS) which promises the compilation of algorithms into hardware. The experiment reported in this paper was aimed at the evaluation of general purpose HLS tools in building CCMs. We focused on identifying areas where the synthesis methods and tools should be improved in order to cope with CCM's specific design problems. The design case, a specialised computer for the simulation of the sintering process, has been carefully chosen to exhibit the problems that are likely to be encountered in advanced designs for CCMs. Our experiment shows that the HLS tools, when supplied with an appropriate input description, are capable of producing a design not too different from RTL level manual design. HLS needs to be improved, especially regarding loop unwinding, pipelining, and the synthesis of suitable memory configurations. However, many of the required techniques are already available from the field of parallel compilation. The conclusion is that improved HLS tools will bring the performance of compiled CCMs very close to that of manual designs. This can put the high performance of CCM technology at the fingertips of computer programmers without extensive hardware expertise."
2069616,22457,20561,Speculation agents for dynamic multi-period continuous double auctions in B2B exchanges,2004,"Business to business (B2B) exchanges provide opportunities for companies to streamline their supply chains in dynamic business situations, but they also create new management challenges. Managers are faced with more frequent buying and selling decisions, more available information, and even new problems such as speculation. Due to these new challenges, trading support systems play an important role in helping companies to achieve maximum profits in B2B exchanges. In this paper, we focus on providing support for two core capabilities, bidding and speculating, in the context of B2B exchanges with continuous double auctions (CDA). Our work extends previous research on bidding agents to more dynamic and realistic B2B exchange situations where both demands and supplies change from period to period. Changes in demand and supply cause price fluctuations and motivate companies to speculate on inventory. The action of speculation is one fundamental aspect of exchanges in general, and is the main way in which B2B exchanges can hedge against costly shortages. We develop a multiagent system in which a speculation agent makes speculation decisions for a given buyer or seller and interacts with a set of bidding agents. The related algorithms are discussed in detail. We also propose a theoretical model for the economic equilibrium in this dynamic situation. Under various market conditions, the experiments show that our system significantly increases the overall profit of the entire market."
1835605,22457,20561,Intelligent clearinghouse: electronic marketplace with computer-mediated negotiation supports,1996,"We propose an intelligent clearinghouse, an electronic marketplace with computer-mediated negotiation that is supported with both data and textual information about the dynamic markets. Most existing electronic market systems support relatively stable markets: traders are not allowed to revise their bids and offers once they are entered to the system. The intelligent clearinghouse addresses dynamic markets where buyers and sellers are willing to change their utilities as the market evolves or when more information becomes available to them. Traders in dynamic markets may suffer significant losses if they fail to execute transactions promptly or cannot utilize all the available information. We developed a prototype Virtual Property Agency to study the usefulness of such an approach. The system was developed with agent technologies, where information, particularly the text files, about the market will be automatically collected by a search engine from the selected Web sites for users to design their negotiation strategies. This system also supports multi-criteria negotiation and allows the users to enter the ranking of attributes to create a utility function. The system aims to improve the transparency and efficiency of the real estate market. It enables traders to compromise their original utilities to avoid transaction failures. The paper also describes the foundation of the intelligent clearinghouse system and its trading mechanism, which includes a short discussion about its order matching method and negotiation support capabilities."
1792205,22457,20561,A systolic ON-LINE non-restoring division scheme,1994,"A new improved version of the classic binary non-restoring division algorithm is presented. It is implemented on a systolic ON-LINE architecture, targeted at use in digital signal processing applications. The overall goal is to implement DSP algorithms using redundant data representations throughout the algorithm, and to obtain a balanced architecture according to the specifications of the application. The improved algorithm is based on calculating the absolute valve rather than obtaining the sign of the remainders. The use of absolute value is based on a paper introducing absolute value in the operations of a CORDIC unit by H. Dawid and H. Meyr (1992). Compared to the original work, the algorithmic contributions of this paper is a mathematical deduction of the algorithm applied to division. The new algorithm maintains the advantages of the non-restoring division compared to SRT: No normalization or scaling of the divisor is required, and the output quotient is produced in a non-redundant number representation. The algorithm is mapped onto a pure systolic ONLINE architecture, and an implementation presented. The architecture contains no global communication, and it can be pipelined all the way down to gate level, as opposed to traditional architectures. The architecture is both modular and regular, enabling further multiplexing for a better match to the specifications of an application. The presented implementation is shown to be area/spl times/time optimal for applications containing a mixture of both division and multiplication. >"
2519398,22457,20561,Increase of potential intellectual bandwidth in a scientific community through implementation of an end-user information system,2003,"Qureshi, et al. (2002) presented a case study where they used a framework, the intellectual bandwidth model to measure an organization's ability to create value. The model consists of two dimensions, information assimilation and collaboration. The IB model is a useful tool for managers because it enables them to plan solutions to complex business problems and to easily communicate these plans to key individuals. The model can also serve as a guide when making investment decisions. While it is important to increase an organization's intellectual bandwidth, it is equally important to assure that the resulting increase is employed to improve the organization's ability to innovate since, as it has been shown, innovation is the number one creator of organizational wealth (Baum et al., 2000). In this paper we discuss how intellectual bandwidth as proposed by Nunamaker et al. (2001) can be extended beyond the highest level of information assimilation identified in the model, automated sense-making, to ensure implementation of product innovations. To do this we propose adding two new information assimilation features, automated utilization and automated implementation. A real business example from the bioscience industry is presented in order to demonstrate how the IB model with extensions can be used. The study discusses an end-user information system, its current use and its potential to enhance an organization's value-creating capability."
836930,22457,20561,An event driven approach to customer relationship management in e-brokerage industry,2003,"Customer relationship management (CRM) is critical to the success of a business. Recent work in CRM has focused on the mining of customer-related data and the construction of customer behavior models. In this paper, we present a framework for an effective detection of business events that trigger the execution of customer-related activities based on a set of predefined business rules. An event is the occurrence of something interesting to the system itself or to user applications. Event driven execution of rules in event-condition-action (ECA) form can ensure efficiency and timeliness. This is an important aspect of CRM that few researchers have reported. In the e-brokerage industry, business events concern mainly with clients, brokerage firms and the stock market environment. Business events due to the clients include order placement, complaints filing, service exceptions, and change of personal profiles. Business events due to the brokerage firms include staff turnovers and amendment of e-brokerage services. Business events due to the environment include market news and fluctuation of stock prices. An event-driven CRM prototype implementing the proposed framework has been successfully applied to support an e-brokerage system. The prototype integrates a client portal, a call center, a managerial application, external event detectors and an analysis engine. There is little room in Hong Kong's stock brokerage industry for a brokerage firm to increase its revenue through cross- or up-sale trading. The key success factor of a brokerage is therefore its ability to retain existing clients and to increase their satisfaction through effective coordination and enactment of CRM activities."
2520621,22457,20561,Standardized Software for Wind Load Forecast Error Analyses and Predictions Based on Wavelet-ARIMA Models -- Applications at Multiple Geographically Distributed Wind Farms,2013,"This study introduces a standardized forecast error analysis and prediction tool that can be implemented into a software package that predicts the uncertainty range for generation resources involved in the power grid balancing service. The tool is reusable and transferrable to power generation systems of different variability. Given the multi-scale variability and uncertainty of wind generation and forecast errors, a natural choice is to use time-frequency representation (TFR) as a view of the corresponding time series represented over both time and frequency. Here we use wavelet transform (WT) to expand the signal in terms of wavelet functions that are localized in both time and frequency. Each WT component is more stationary and has a consistent auto-correlation pattern. We combined wavelet analyses with time-series forecast approaches such as the autoregressive integrated moving average (ARIMA) model and tested the approach at five different wind farms with similar or different field and weather conditions. The prediction capability is satisfactory -- the day-ahead prediction of errors matches the original error values very well, including the patterns. The observations are well located within the predictive intervals. Integrating our wavelet-ARIMA (stochastic) model with the weather forecast model (deterministic) will improve our ability significantly to predict wind power generation and reduce predictive uncertainty."
2493944,22457,20561,Workflow management for multiple sclerosis patients: IT and organization,2004,"Patients with multiple sclerosis (MS) visit various healthcare providers during the course of their disease. It was suggested that IT might help to orchestrate their care provision. We have applied the USE IT-tool to get insight in the relevant problems, solutions and constraints of the MS-care and the MS care providers both in the organizational and the information technological area. There is hardly a chain of healthcare, but rather, a network in which informal communication plays an important role. This informal network worked reasonably effective, but inefficient and slow. The patient himself plays a key-role in information exchange between care-providers. Many providers were unaware of the services that other healthcare providers could give in general or did provide to a specific patient. MS patients-count is only small for most care providers. None of the interviewed patients mentioned a lack of contacts between care-providers as a problem. They thought that lack of experience caused their major problems: insufficient and inadequate care. To improve care, we proposed a solution that combines a short MS-protocol, the introduction of a central coordinator of care and a patient relation management (PRM) system. This is a simple Web-based application that is based on agreement by the caregivers that supports routing, tracking and tracing of a MS patient and supplies the caregivers with professional guidelines, as written down in the protocol. It is likely that we would have suggested a far more complicated ICT solution if we had only analyzed the MS-care process as such, without specific consideration of the USE IT dimensions."
2517695,22457,20561,Different Paths to Broadband Access: The Impact of Governance and Policy on Broadband Diffusion in the Developed and Developing Worlds,2011,"A new digital divide is emerging both within and between nations that is due to inequalities in broadband Internet access. Our research examines the broadband digital divide by analyzing the impact of administrative culture and policy initiatives in the form of strategic planning, execution, regulation and investment on broadband diffusion in 139 countries. Our multiple regression analysis shows that factors that determine broadband diffusion in technologically developed countries do not necessarily have the same impact in less developed countries. For example, competition in the telecommunications sector has a positive impact in nations where access to information and communication technologies (ICTs) is expanding, but does not make a significant difference where ICT access is widely available. We also show that when controlling for measures of economic, political, social and educational development, there is greater broadband diffusion in countries that have an administrative culture of sound governance and make a higher shared financial investment in information and communication technologies. These results hold in nations where access to ICTs is expanding, even though the presence of a national telecommunications regulatory authority has a negative impact on broadband diffusion in the same group of countries. Our results suggest that the path to widespread availability and use of broadband requires different strategies depending on a nation's level of technological development. Furthermore, assessing overall government performance in terms of governance and policy initiatives on this journey is more important than factors such as the presence or absence of a national regulatory authority."
2398455,22457,10228,Range estimation and performance optimization for IEEE 802.11 based on filter,2004,"The dynamic character of complex and variable network environment, the key problem, puzzles the corresponding protocols design for wireless LANs. However, the distributed coordination function (DCF) of IEEE 802.11 MAC protocol, which is carrier sense multiple access with collision avoidance (CSMA/CA) using constant parameters, could not perform well when network environment changes. Thus many researchers try to optimize IEEE 802.11 DCF. However early dynamic optimization mechanisms for the protocol mostly depend on measuring the number of competing stations accurately. The problem of them is that the algorithms are too complex to apply in reality. In our research, we find that system performance approaches optimization with the same protocol parameters, when the number of competing stations changes within a certain range dynamically. Therefore, we propose a self-adaptive optimization mechanism, DOOR (dynamic optimization on range), for the IEEE 802.11 DCF. DOOR uses filter to estimate the range of competing station number and adjusts the protocol parameters to optimize system performance effectively. The detailed analytical model and performance evaluation for the new mechanism are given. Moreover, the measurement method and parameters of filter are introduced. At last, the elaborate numerical results show that our mechanism could not only achieve much higher throughput and lower delay than the standard IEEE 802.11 DCF along with the change of competing stations, but also improve the stability of system performance based on reasonably partitioned ranges."
1902853,22457,20561,Hot spot implosion: the decline and fall of flanders language valley,2004,"Resource-based theory of competitive advantage suggests that knowledge creates increased performance opportunities for those firms able to identify, access, utilize and disseminate relevant knowledge effectively [1]. The Flanders Language Valley (FLV) initiative, which met the Pouders and St. John [2] definition of a ?hot spot?, was established to create a global center of competence in speech and language technologies. However, this clustering of innovation occurred in an isolated location within a small European country and was reliant, not on inherent strength of knowledge within that country or region but on tradable technological interdependencies, with codifiable knowledge sold through licensing. Given these issues, FLV fell into bankruptcy and disarray early, due to fraud within Lernout and Hauspie (L&H), the fraud being brought out ? much before Enron, Andersen, WorldCom and others ? because of `spontaneous? investigative journalism subsequent to the decision to acquire Dictaphone. This decision overreached the underlying political and economical-financial capacity to protect and preserve a parochial-based pseudo hot spot against major national security interests of a superpower. This paper discusses the decline and fall of FLV, based on historical record, and provides some insights into what may curtail hot spot knowledge development."
1892833,22457,20561,A stochastic negotiation model for organizational choice,2004,"Traditional group negotiation has focused largely on human conduct with regard to large and generally isolated problems such as procurement and claim settlements. Once the negotiation is accomplished, the process usually attains closure and is quickly forgotten or the long-term impacts of the outcome are often ignored. In organizations, however, decisions involving gives and takes are also made on a continuous basis in that there is a ripple effect in the sequential nature of decision making. When lengthy periods are involved, the organizational contexts can change significantly. Hence, methods useful to a one-shot bargaining strategy may neither be applicable nor effective. Furthermore, when organizations face consequences of their own past decisions as well as that of external random events, it is hard to predict where the organization will be at a future time. In this research, we postulate that organizations evolve from one state to another following a probabilistic transition pattern than totally random. Considered this way, organizations can be modeled using sequential Markov chains having a tendency to achieve homeostasis. Understanding organizational behavior in this perspective can be greatly beneficial to negotiators by enabling them to accept short term losses in favor of the larger and better payoffs that are to come."
1064856,22457,20561,Intelligence Database Creation and Analysis: Network-Based Text Analysis versus Human Cognition,2008,"The 9/11 Commission Report and the National Intelligence Reform Act both state that the development of terrorist network database collection processes is an immediate and pressing requirement. This paper is a study and comparison of two complementary approaches to developing a terror network dataset: Automap, a network text analysis (NTA) tool; and Intelligence Analyst coding, a human process. NTA tools are an emerging branch of software that supports the analysis of quantitative characteristics of large-scale textual data as well as the extraction of meaning from texts. Intelligence Analyst coding is the traditional method that requires a human to read and cognitively process each raw field report. In this study, both approaches were applied to the same one hundred eighty-three open source texts on the Al Qaeda organization. Each approach's process, dataset product, and analytics are compared qualitatively and quantitatively. In terms of process, the Automap-assisted system required less manpower and time resources. In terms of dataset product, both approaches identified unique nodes and relationships that the other missed. Lastly, the differences in the datasets significantly impacted threat analytics and potential course of action selection. These results suggest an integrated human-centered automation support approach to intelligence dataset development."
2408348,22457,20561,Dynamic procurement subject to temporal and capacity constraints,2004,"Reverse auctions offer the prospect of more efficiently matching suppliers and producers in the face of changing market conditions. Prior research has ignored the temporal and finite capacity constraints under which reverse auctioneers typically operate. In this paper, we consider the problem faced by a manufacturer that can procure key components from a number of possible suppliers through multi-attribute reverse auctions. Bids submitted by prospective suppliers include a price and a delivery date. The manufacturer has to select a combination of supplier bids that maximize its overall profit, taking into account its own finite capacity and the prices and delivery dates offered by different suppliers for the same components. The manufacturer's profit is determined by the revenue generated by the products it sells, the costs of the components it purchases as well as late delivery penalties it incurs if it fails to deliver products in time to its own customers. We provide a formal model of this important class of problems, discuss its complexity and introduce rules that can be used to efficiently prune the resulting search space. We also introduce a branch and bound algorithm and an efficient heuristic search procedure. Computational results show that our heuristic procedure typically yields solutions that are within 10 percent of the optimum. They also indicate that taking into account finite capacity considerations can significantly improve the manufacturer's bottom line."
720236,22457,20561,Changing IT Providers in Public Sector Outsourcing: Managing the Loss of Experiential Knowledge,2010,"Although outsourcing of IT services has become a standard business practice in both the private and public sector, little is known how clients manage the change over from an incumbent, or prior vendor, to a new vendor. The current literature touts how the risks of knowledge loss and disruption in operations prevent many client firms from switching to a new vendor even in the case of less than satisfactory performance. We report on a longitudinal, descriptive case with a public organization in Finland that involves the process of switching a long-term IT vendor to a new IT vendor. The switching was motivated not by unsatisfactory performance but by the public procurement process that requires public tendering of outsourced services every four to six years. The case is significant as it allows us to advance insight how in fact the client and the new vendor manage the loss of learning by doing-knowledge (experiential knowledge) that the client no longer has. The case suggests that several elements were especially critical in facilitating the transfer or learning including the lost experiential knowledge: modularization of work, use of external sources, joint client-vendor collaboration, and personal identities at work. These elements allowed the inter-organizational project teams to minimize the disruptions in IT services to the client's user communities. The case findings provide insight to managing transfer of learning in inter-organizational groups in ad hoc dynamic relationships."
2177557,22457,20561,Using Foreign Forums,2007,"The paper considers the use of online technical discussions by software developers in Rio de Janeiro, Brazil, drawing on the results of a 5 month interview study. In the course of their daily work, Brazilian software developers routinely rely on online resources, which include as a key component foreign forum dedicated to technical questions. In rare cases, they actively participate in those forums; somewhat more often they lurk. Even more often, however, forum posts are simply found while searching for a specific topic. Forums are thus experienced not as intertwining threads of conversations, but rather as a searchable collection of questions and answers free from conversational context, which is appreciated in a detached, asocial way. The paper thus looks at the use of persistent conversations by people who are not party to them - not even as lurkers. It considers some of the reasons for such non-participatory use, including the reasons one would presume to be universal (e.g., the ease of searching), as well as those that may be specific to members of peripheral communities. The paper contrasts the forms of engagement with foreign and local (or national) technical forums, showing how foreign conversations are construed as asocial sources of knowledge while local forums are seen as spaces that bring together national or local communities of developers"
2013679,22457,20561,A Web services implementation framework for financial enterprise content management,2004,"There is an increasing demand to replace the current cost ineffective and bad time-to-market hardcopy publishing and delivery of content in the financial world. Four major goals, namely, management, cost, legal issues, and value, for a financial system should be reached. The new financial enterprise content management system (FECMS) could archive these goals by providing different content management, process establishment, and system integration functions. The main contribution of this paper is an enterprise content model and a system architecture for tackling two main technical challenges of FECMS, namely, global system integration and content flow management. It consists of three major types of engines: content editorial engines, content reception engines, and content publishing engines. A content editorial engine provides content and taxonomy maintenance and approval functions for different levels of administrators in the financial institute. A content reception engine collects content from external sources, and then delivers it to different parts of the system for approval and publication. A content publishing engine stores approved content and send them to different parties via different channels (such as email, fax, and conventional mail). It also serves as the Web storefront of the enterprise for user enquiries. In addition, we outline a unified scalable implementation framework with contemporary Web services technology to support both internal content flow and inter-enterprise interactions. Both interactive users and institutional programmatic users are thus supported."
568369,22457,20561,ERP critical success factors: an exploration of the contextual factors in public sector institutions,2002,"New information technologies have brought public-sector higher education institutions (HEIs) into increased competition, while their government funding in parallel has been continually eroded. In response to these growing pressures, there has been a call for HEIs to improve operational efficiency and to reduce duplication of resources by implementing advanced information systems that span the institution and improve processes. In response, HEIs have turned their efforts to implementing complex enterprise resource planning (ERP) systems. These systems are seen as the solution to address the growing governmental information requirements and to improve competitiveness, but do these systems represent a viable proposition for the diverse higher education sector with its traditionally strong and fragmented structure and culture? This paper investigates whether ERP systems offer a feasible information systems strategy for HEIs, using a 'critical success factor' model. Four in-depth case studies were conducted in HEIs that were in the process of implementing ERP systems. Numerous complexities, especially cultural and political ones, arose in light of the traditional structure of HEIs. The findings suggest that a careful use of communication and change management procedures to handle the business process reengineering (BPR) impact of ERP systems can alleviate some of the problems, but a more fundamental issue concerning the cost feasibility of system integration, training and user licenses may, in the end, impede ERP system utilization."
2399007,22457,20561,Evaluation of supervisory vs. peer-peer interaction with human-robot teams,2004,"We submit that the most interesting and fruitful human-robot interaction (HRI) may be possible when the robot is able to interact with the human as a true team member, rather than a tool. However, the benefits of shared control can all too easily be overshadowed by challenges inherent to blending human and robot initiative. The most important requirements for peer-peer interaction are system trust and ability to predict system behavior. The human must be able to understand the reason for and effects of robot initiative. These requirements can only be met through careful application of human factors principles and usability testing to determine how users interact with the system. This paper discusses the recent human participant usability testing, which took our current implementation to task using a search and rescue scenario within a complex, real-world environment. The purpose of testing was to examine how human operators work with the robotic system at each level of autonomy, and how interaction with the robot should be structured to enable situation awareness and task completion. Analyses revealed that our architecture equally supported situation awareness and target detection by novices and experts, although experienced users were more likely to have more performance expectations of the interface. Results also had implications regarding the ability of participants to effectively utilize the collaborative workspace and, most importantly, their ability to understand and willingness to accept robot initiative."
1887763,22457,20561,Using intelligent agents to repurpose administrative data in fostering disease prevention in an outpatient context: the case of pneumococcal vaccination,2004,"The use of intelligent agents is proposed as an economical way to repurpose administrative data in order to foster a program of disease prevention in an outpatient context. A retrospective computerized search was conducted using administrative hospital discharge data to identify patients admitted to a medical teaching unit who met the Canadian Immunization criteria for pneumococcal vaccination over a one-year period. For identification of persons eligible for pneumococcal vaccination, administrative discharge data was shown to have a sensitivity of 83%, (confidence interval [CI] 0.73-0.92) and a specificity of 78% CI (0.64-0.91), with a positive predictive value [PPV] of 87%, CI (0.83- 0.90) and a negative predictive value [NPV] of 72%, CI (0.58-0.86). This study demonstrates that administrative data appear promising as the basis for certain clinical applications. Specifically, the reasonably high specificity and sensitivity of diagnostic codes in administrative data could be utilized to trigger appropriate pneumococcal vaccination after hospital discharge among eligible patients who might otherwise never receive this efficacious intervention. Reminder systems in a hospital setting have received mixed results although positive results have been shown in several outpatient settings but using clinical data. Therefore, before a reminder system using administrative data in an outpatient context is implemented it seemed prudent to investigate this issue further."
2497104,22457,20561,A field study of use of synchronous chat in online courses,2003,"A field study of computer mediated communication (CMC) as used in higher education asks the questions, Will students take part in synchronous chat sessions if they are scheduled?  and What do students and faculty perceive to be the problems and the advantages of synchronous chat sessions? media mode is the independent variable, characterized by four nominal values derived from the mixture of asynchronous discussion forums, here called asynchronous learning networks (ALN), with various levels of synchronous media use. Data were collected from 29 course sections, for which instructors were interviewed, students were surveyed online to investigate their perceptions of the use of chat in online courses, and university records were used to determine grade distributions. The percentage of students participating in scheduled chat sessions varied from 5% to 50% and many of the instructors report problems with organizing the sessions as well as ideas about how to do it better next time. Instructors were nevertheless generally positive about the potential usefulness of synchronous sessions in terms of their ability to bring the students closer to the instructor. They report some small success in their first chat session and the experience leads to better facilitation in subsequent sessions. Students significantly find chat more 'rewarding' and less 'complex' in classes that scheduled sessions two or more times than students in asynchronous-only classes. The implication is that when students actually use chat they do find it 'rewarding' and not 'complex.' Given the problems with implementation of chat sessions, however, it is not surprising that its use is not significantly related to predicted improvements in outcomes for courses."
1581305,22457,20561,Instability of Relevance-Ranked Results Using Latent Semantic Indexing for Web Search,2010,"The latent semantic indexing (LSI) methodology for information retrieval applies the singular value decomposition to identify an eigensystem for a large matrix, in which cells represent the occurrence of terms (words) within documents. This methodology is used to rank text documents, such as Web pages or abstracts, based on their relevance to a topic. The LSI was introduced to address the issues of synonymy (different words with the same meaning) and polysemy (the same words with multiple meanings), thus addressing the ambiguity in human language by utilizing the statistical context of words. Rather than keeping all k possible eigenvectors and eigenvalues from the singular value decomposition which approximates the original term by document matrix, a smaller number is used - essentially allowing a fuzzy match of a topic to the original term by document matrix. In this paper, we show that the choice k impacts the resultant ranking and there is no value of k that results in stability of ranked results for similarity of the topic to documents. This is a surprising result, because prior literature indicates that eigensystems based on successively large values of k should approximate the complete (max k) eigensystems. The finding that document-query similarity rankings with larger values of k do not, in fact, maintain consistency, makes it difficult to assert that any particular value of k is optimal. This in turn renders LSI potentially untrustworthy for use in ranking text documents, even for values that differ by only 10% of the max k."
2231871,22457,20561,Understanding the Effect of Risk Aversion on Risk,2005,"As we progress, society must intelligently address the following question: How much risk is acceptable? How we answer this question could have important consequences for the future state of our nation and the dynamics of its social structure. In this work, we will elucidate and demonstrate, using a physically based model, that the attempt to eliminate all thinkable risks in our society may be setting us up for even larger risks. In order to illustrate this point the simplest example is something with which we are all familiar and have known from the time we were very young. When children burn their finger on a hot item they learn the consequences of touching fire. This small risk has taught the child to avoid larger risks. In trying to avoid these small risks as well as larger risks, one runs the dual danger of not learning from the small events and of having difficulty in differentiating between large and small risks. We will illustrate this problem with a series of social dynamics examples from the operation of NASA to network operation and then make an analogy to a complex system model for this type of dynamics. From these results, recommendations will be made for the types of risk responses that improve the situation versus those that worsen the situation. In order to progress, society has to recognize that accidents are unavoidable and therefore an intelligent risk management program must be implemented that is aimed toward avoiding or reducing major accidents. It is not possible to avoid all risk but it is more prudent to avoid the greater risk situations for society."
1844932,22457,20561,Procedural security in electronic voting,2004,"In this paper, we explore the security related procedures that are required for the successful development and deployment of electronic voting in legally-binding government elections. Initiating our research on the theoretical basis, which justifies the necessity for security in deploying electronic elections, we further explore the question of who and what should be safeguarded in the course of the e-electoral process. Based on our research study, we suggest that security in e-voting has two aspects, the technical and the procedural one. It is recognised that from the technical perspective further research is necessary to ensure full and complete voter authentication and voting security to enable an e-election. However, we argue that e-voting security can also be enhanced through providing procedural security measures at specific points in the e-electoral process. Our analysis of the Electoral Commission's evaluation reports on the 2002 UK local government e-voting pilots identified past cases of procedural security issues. Interviews and observations conducted during the 2003 UK e-voting pilots further confirmed these issues. We have established the need to further explore the re-design of the electoral process and consider procedural security as primarily applicable to agent-related processes. In view of the increased complexity of the e-voting processes, which can involve multi-channel e-voting options, and the increase in the number of agents involved in the administration of e-elections, we relate procedural security to the need for transparent allocation of responsibilities among the different agents. In concluding we argue that existing procedural security should be enhanced, that there is a clear need for better monitoring of compliance to such procedures and that further security procedures need to be put in place at specific points in the e-election process."
1672737,22457,20561,Group Support Systems,1998,"One of our objectives in coordinating this year's Group Support System (GSS) mini-track was to encourage a wide range of papers that touched on a variety of important issues. As in the past, we used a strong reviewing process ? all papers were sent to at least three, sometimes four, reviewers. Our reviewers included scholars, practitioners, and developers, social psychologists, computer scientists, and MIS'ers. Integrating reviews from such a diverse set of reviewers can prove challenging, yet produce a group of papers that can speak to many different interests and issues. This year, we have four papers that include both the development of new systems as well as the testing of theory. The authors of these papers can summarize their conclusions far more eloquently than we can, so we will not repeat their words.Over the years, the GSS mini-track has included research from a broad range of perspectives. This year is no exception. HICSS has emerged as an important venue for the discussion, development, and refinement of research on the use of information technology to support group work. Many of the ideas and papers first presented and discussed here have found their way into major research journals, not to mention those projects first conceived in animated conversations outside the formal sessions. We hope you enjoy the papers and the discussions they generate."
2141757,22457,20561,Knowledge management systems track introduction,2006,"It is with great pride that we are celebrating the inaugural year of the Knowledge Management Systems Track. The track includes Knowledge Management (KM) which addresses the process of acquiring, creating, distributing and using knowledge in organizations; Organizational Memory (OM) which is defined as the way an organization stores organizational knowledge and applies it to present activities; and Organizational Learning (OL) which is the development of shared meanings and interpretations of those meanings to enhance future activities. The Track has evolved from the first mini-track on OM initiated by Lorne Oflman and Joline Morrison thirteen years ago. The KMS Track seeks to maintain the integrity and continuity established in the past while continuing to grow the breadth of the discipline and acknowledge the growth in KM research by increasing the number of papers accepted. The KMS Track also seeks to preserve and grow the strong community developed over the last thirteen years. We appreciate the efforts of all our colleagues who submitted and/or reviewed papers. Through these collective efforts, we continue to see these interrelated research domains grow and flourish. Eighty-one submissions were received this year; Thirty-eight were accepted. The profile of accepted papers reflects the breadth and diversity of the research domain that the Track supports. Papers are organized in the following six mini-tracks covering thirteen sessions."
2448515,22457,20561,Use of online systems in clinical medical assessments: an analysis of physician acceptance of online disability evaluation systems,2004,"In today's world of ever increasing amounts of information, hospitals and medical groups must continually find ways to manage the myriad information that is gathered on patients. This reality makes the field of medicine well suited to benefit from integrative and online information systems. However, research reveals that at times physicians resist the use of information technology (IT) in the clinical setting. This paper seeks to develop a conceptual model for physician acceptance and test this socio-work structure model using a nationwide survey of physicians (n=141) conducted by the authors. The domain focus of this study is physician acceptance of an online disability evaluation system for generating and managing medical examination reports. The survey measured whether behavioral intention to use the new system varied as a function of IT infrastructure, organizational processes relating to IT, physician experience with computer use in clinical settings, and both specific and general attitudes toward IT use in clinical settings. Survey findings suggest that each of these factors affects behavioral intention to use online disability evaluation systems, and that these factors are more important than generalized attitudes toward online systems or socio-demographic predictors. These findings suggest that work-system variables are important when considering physicians use of online systems. This extends traditional use of TAM to consider organizational factors when analyzing the acceptance decision."
1867686,22457,20561,Runway operations planning: a two-stage solution methodology,2003,"The airport runway is a scarce resource that must be shared by different runway operations (arrivals, departures and runway crossings). Given the possible sequences of runway events, careful runway operations planning (ROP) is required if runway utilization is to be maximized. Thus, runway operations planning (ROP) is a critical component of airport operations planning in general and surface operations planning in particular. From the perspective of departures, ROP solutions are aircraft departure schedules developed by optimally allocating runway time for departures given the time required for arrivals and crossings. In addition to the obvious objective of maximizing throughput, other objectives, such as guaranteeing fairness and minimizing environmental impact, may be incorporated into the ROP solution subject to constraints introduced by air traffic control (ATC) procedures. Generating optimal runway operations plans was approached in the paper by Anagnostakis et al. (2001) with a one-stage optimization routine that considered all the desired objectives and constraints, and the characteristics of each aircraft (weight class, destination, air traffic control (ATC) constraints) at the same time. Since, however, at any given point in time, there is less uncertainty in the predicted demand for departure resources in terms of weight class than in terms of specific aircraft, the ROP problem can be parsed into two stages. In the context of the departure planner (DP) research project, this paper introduces runway operations planning (ROP) as part of the wider surface operations optimization (SOO) and describes a proposed two stage heuristic algorithm for solving the runway operations planning (ROP) problem. Focus is specifically given on including runway crossings in the planning process of runway operations. In the first stage, sequences of departure class slots and runway crossings slots are generated and ranked based on departure runway throughput under stochastic conditions. In the second stage, the departure class slots are populated with specific flights from the pool of available aircraft, by solving an integer program. Preliminary results from the algorithm implementation on real-world traffic data are included in (Anagnostakis and Clarke, 2002)."
2527961,22457,20561,Spreadsheets in Team X: Preserving Order in an Inherently Chaotic Environment,2009,"JPL is NASA’s prime center for deep space missions. In response to the need to reduce the cost and time to complete early concept studies and proposals JPL created the first concurrent engineering team in the aerospace industry: Team X. Started in 1995, Team X has carried out over 800 studies, dramatically reducing the time and cost involved, and has been the model for other concurrent engineering teams both within NASA and throughout the larger aerospace community. Since its inception, the software backbone of this highly successful design team – engaged in examining some of NASA’s cutting edge concepts – has been the unassuming spreadsheet. Over the years the Team X spreadsheet-based tools have evolved from simple standalone engineering models into a networked spreadsheet intensive system with real time parameter updating. Recent new capabilities include stochastic cost estimation and a graphical drag and drop block diagram that automatically populates the related spreadsheet parameters of cost, mass and power. This paper describes how the spreadsheet functions within Team X: its history, architecture, current capabilities, enabling strengths and persistent weaknesses. In addition, the verification methods and institutional oversight that have evolved as the Team X products became increasingly critical to Laboratory success are also discussed."
714215,22457,20561,A Work-Centered Visual Analytics Model to Support Engineering Design with Interactive Visualization and Data-Mining,2012,"To support the knowledge discovery and decision making from large-scale, multi-dimensional, continuous data sets, novel systems of visual analytics need the capability to identify hidden patterns in data that are critical for in-depth analysis. In this paper, we present a work-centered approach to support visual analytics of complex data sets by combining user-centered interactive visualization and data-oriented computational algorithms. We design and implement a specific system prototype, Learning-based Interactive Visualization for Engineering design (LIVE), for engineering designers to handle overwhelming information such as numerous design alternatives generated from automatic simulating software. During the exploration within a trade space consisting of possible designs and potential solutions, engineering designers want to analyze the data, discover hidden patterns, and identify preferable solutions. The proposed system allows designers to interactively examine large design data sets through visualization and interactively construct data models from automatic data mining algorithms. We expect that our approach can help designers efficiently and effectively make sense of large-scale design data sets and generate decisions. We also report a preliminary evaluation on our system by analyzing a real engineering design problem related to aircraft wing sizing."
2442190,22457,20561,Formalizing multi-agent POMDP's in the context of network routing,2003,"This paper uses partially observable Markov decision processes (POMDP's) as a basic framework for multi-agent planning. We distinguish three perspectives: first one is that of an omniscient agent that has access to the global state of the system, second one is the perspective of an individual agent that has access only to its local state, and the third one is the perspective of an agent that models the states of information of the other agents. We detail how the first perspective differs from the other two due to the partial observability. POMDP's allow us to formally define the notion of optimal actions in each perspective, and to quantify the loss of performance due to partial observability, and possible gain in performance due to intelligent information exchange between the agents. As an example we consider the domain of agents in a distributed information network. There, agents have to decide how to route packets and how to share information with other agents. Though almost all routing protocols have been formulated based on detailed-study of the functional parameters in the system, there has been no clear formal representation for optimality. We argue that the various routing protocols should fall out as different approximations to policies (optimal solutions) in such a framework. Our approach also proves critical and useful for the computation of error bounds due to approximations used in practical routing algorithms. Each routing protocol is a conditional plan that involves physical actions, which change the physical state of the system, and actions that explicitly exchange information."
2492020,22457,20561,Computer support and facilitated structure in meetings-an empirical comparison of their impact,1996,"Explores whether computer support provides benefits beyond facilitation, which is one of the keys to success in group support systems (GSS) environments and one of the possible explanations of inconsistent GSS results. Teams of different size worked on an experimental task under one of three working conditions. They either had full computer support, a structured and moderated meeting process including manual support tools, or no support at all. This experimental design allowed the isolation of the impact of computers, a structured intervention in the meeting process by a facilitator and an increasing number of meeting participants. Results showed that, overall, the introduction of GSS into meetings has a stronger effect than merely facilitation or moderation without GSS support, though the type of effect differs for the observed variables. As the most important effects which computer usage introduces to meetings, an increased perceived speed of the meeting process and stronger anonymization, as well as more directness of the participant contributions were identified. A facilitated structure improves task understanding, reduces the dominance of meeting participants and enables teams to stay focused on the issues at hand. In consequence, computer-supported meetings are especially worth their additional effort over moderated meetings, when speed and anonymity, as well as direct input are more important to meeting success than equal participation and a straightforward discussion among meeting participants. Moderators should thus consider adding computer-supported meeting tools to their toolset."
2316272,22457,20561,Developing information systems with creativity techniques: an exploratory study,1995,"Identifies creative measures for information systems development. Content analysis was used as a methodology for analyzing key attributes to distinguish between creative and less creative IS applications. 20 descriptions of information systems and the development process, published in 'Information & Management'-an international academic journal-served as the source for exploration. From a list of 43 possible keyword synonyms used to describe the novelty and value of creative products and services, 16 keywords and their derivations were chosen for study. The articles were scanned, cleaned and stored with a high rate of accuracy. A team of 3 raters were engaged for the project, rating the occurrence of each keyword in context. Inter-rater agreement scores all reflected acceptable reliabilities greater than 0.70. Summary statistics were used to evaluate average rater scores, average rating per article, total number of keywords per article, and other statistics useful to developing creativity measures. The average number of keywords per page was found to be an important variable, correlating highly with other key indicators. Expert judges' opinions were not found to add additional value to the raters' evaluations, lending evidence that the raters' evaluation of creativity were valid. Using the results from the correlation analysis, a metric for assessing the creativity in information systems development is suggested. >"
2138164,22457,20561,What do virtual Tells tell? Placing cybersociety research into a hierarchy of social explanation,2000,"Like archaeological Tells, large mounds resulting from the accumulation of human settlement debris, the remains of virtual communities can inform researchers about phenomena operating at many levels. However, for excavations to be effective, they need to be conducted within the framework of a scientific research program. The theory of interactive communication in cyber places developed here distinguishes between the social relationships that emerge from interactive group computer-mediated communication, and the cyber places where such communication occurs. It also links the density and form of cyber material to communication technology types. In so doing, it identifies four distinct levels of analysis: i) individual behavior or social theory; ii) spatial and temporal patterning of artifacts in cyberspace; iii) technology and the parameters of human interaction; and iv) cyber-ecology or online behavior and resource supply. The recognition of four distinct levels of analysis allows for the production of a hierarchy of social explanation for cybersociety. To date, the majority of research into online behavior has focused on the level of social theory. However, a balanced understanding of all levels of the hierarchy is preferable. The theory outlined is also linked to a research program into the material aspects of computer-mediated communication. Research into this under-represented level should inform e-commerce strategists as well as those interested in usability as a group level concept."
2454613,22457,20561,A reliability layer for ad-hoc wireless sensor network routing,2004,"We have been studying communication in wireless ad-hoc sensor networks. One of the authors has designed the multipath on-demand routing (MOR) protocol (Shu Hui Chen, 2003), which makes use of all possible paths to a given destination. Each node in MOR has, wherever possible, a choice of next hops for a given destination. We have designed and implemented a MOR reliability layer to take advantage of this. The basic strategy is to use a different node on each retransmission, and to keep track of which transmissions are successful. The main benefit is that a packet is likely to be delivered even if a given neighbor is temporarily unavailable, thus improving the delivery ratio or decreasing the number of end-to-end retransmissions. A further benefit is that nonresponsive nodes are removed from the routing table after a number of consecutive failures. In a sensor network transmission may be unreliable for a number of reasons, but particularly when congestion results in collisions. Without our reliability layer, collisions would cause packet loss and route loss. If the transport protocol is reliable, this results in end-to-end retransmission, which requires additional energy. We simulated transmission in congested conditions in different realistic sensor networks and compared MOR to available protocols. In our tests, the reliability layer helped MOR deliver data faster and less energy usage than the other protocols."
1896384,22457,20561,"Multivariate analysis of EEG: predicting cognition on the basis of frequency decomposition, inter-electrode correlation, coherence, cross phase and cross power",2003,"This paper describes analysis of EEG data collected while participants performed a gauge-monitoring task which simulated an industrial process. Participants performed the task on two separate occasions, and the mean interval between sessions was 13 weeks. Analysis of EEG involved derivation of 5166 separate dependent variables, and these included measures of inter-electrode correlation, spectral power, coherence, cross phase and cross power. A central aim was to identify those EEG measures which provided the most reliable prediction of task demand. In particular, a major question was whether each participant might have unique aspects of their EEG which predicted cognitive load. This stemmed from a concern that attention to individual differences might provide a means for improving prediction. Results indicated that there were idiosyncratic aspects of physiological response which were highly predictive of task load. Furthermore, the predictive power of these variables survived across sessions despite the mean 3 month interval between them. Analyses also indicated the presence of EEG predictors which were common to all participants. It is concluded that idiosyncratic aspects of EEG patterns reflect genuine and reproducible individual differences. Such differences may prove a valuable tool for improving prediction. Furthermore, exploration of these variables may result in a deeper understanding of different types of cognitive style."
2376523,22457,20561,Engineering a method for wide audience requirements elicitation and integrating it to software development,2004,"Consumer oriented information systems development has become increasingly important matter, as more and more complex information systems are targeted towards consumer markets. We argue that developing IS for non-organizational users creates new problems, which IS and requirement engineering (RE) community should attend to. First of all, the elicitation of requirements becomes more difficult as usually consumers do not explicitly know what they want, and it is difficult for them to express their ideas. To support different views of product development, such as project management and design, the method should present requirements in a 'rich enough' way to avoid overloading management, but in the same time giving designers the detailed information they need. Last but not the least, the results of requirements engineering should be easy to integrate to the software development process. To this end, we have constructed a new RE method and its support environment within Metaedit+ Meta CASE tool. We based our method on critical success chains (CSC) method, which supports top-down approach for planning, but also provides for wide participation of IS customers to get rich information. CSC aggregates the results of many individual interviews into meaningful graphical models of what is critically important about a potential system. In our work, CSC is extended with customer segmentation and lead user concepts from marketing."
1970836,22457,20561,The inherent inefficiency of the point-to-point congestion revenue right auction,2004,"Empirical evidence shows that the clearing prices for point-to-point congestion revenue rights, also known as financial transmission rights (FTRs), resulting from centralized auctions conducted by independent system operators differ significantly and systematically from the realized congestion revenues that determine the accrued payoffs of these rights. The question addressed by this paper is whether such deviations are due to price discovery errors which will eventually vanish or due to inherent inefficiencies in the auction structure. We address this question by studying a hypothetical DC-flow approximation model of a six-node system with known outage probabilities of each element and known statistical demand variability. We show that even with perfect foresight of average congestion rents the clearing prices for the FTRs depend on the bid quantity and therefore may not be priced correctly in the financial transmission right (FTR) auction. In particular, we demonstrate that if all FTR bid quantities are equal to the corresponding average transaction volumes and the bid values are set at the expected congestion rent level, then the resulting auction prices systematically deviate from the known FTR values. We conclude that price discovery alone would not remedy the discrepancy between the auction prices and the realized values of the FTRs. Secondary markets or frequent reconfiguration auctions are necessary in order to achieve such convergence."
2270215,22457,20561,Defining Complexity Factors for the Architecture Evaluation Framework,2006,"The design and implementation of telecommunication systems is an incremental and iterative process, and system architectures may need to be revised and refined several times during their lifetime. Formal evaluation facilitates the identification of the weak points, where improvements are due in these architectures. In the domain of telecommunications, such evaluation can be based on the Architecture Evaluation Framework (AEF). During the evaluation, a deep understanding of the processes within a system is needed. Meanwhile, the systems being designed are usually complex systems encompassing a large number of components with an intricate pattern of interaction between them. As a result, it is extremely difficult to understand, predict and control the behavior of such systems. Theoretical studies in the field of complex systems describe potential reasons of system complexity, and explain its possible outcomes, as reflected in system structure and behavior. This knowledge may be utilized in architecture evaluation, in order to deepen the understanding of the interactions imposed by the architecture, as well as to extend the understanding of the involved architectural tradeoffs. For this, the complexity factors should be taken into account during the evaluation. However, no such factors are involved in the current version of the AEF. In this paper, the attempt is made to identify how the knowledge about properties of complex systems could be utilized for the evaluation of information system architectures. Based on the theoretical advances in the field of complex systems, a list of the complexity factors to be included in the AEF is compiled. These factors are going to be further refined, as the AEF is employed for evaluating real-world architectures."
2449465,22457,20561,Experience using collaborative technology with the United Nations and multi-national militaries: rim of the Pacific 2000 Strong Angel exercise in humanitarian assistance,2001,"The Center for the Management of Information (CMI) at the University of Arizona engaged in a joint research project with the U.S. Navy's Commander Third Fleet (Third Fleet) and The MITRE Corporation (MITRE) to use and evaluate collaborative technology during Strong Angel, a humanitarian assistance/disaster relief (HA/DR) exercise. Strong Angel was a part of RIMPAC 2000, a five-week multinational exercise that involved seven nations with over 22,000 people, fifty ships, and 200 aircraft. RIMPAC 2000's Strong Angel set out to satisfy three goals: develop a mutual understanding of respective capabilities, limitations and expectations among multinational militaries and the main United Nations relief agencies; create a replicable system for the safe conduct of Strong Angel and subsequent exercises in civil-military interaction for humanitarian support; and deliver a coordinated response to a population in crisis. CMI, Third Fleet and MITRE teamed to achieve four objectives: provide a collaborative environment both at sea and ashore within an austere environment; use collaborative technology to establish a forum for the exchange of relevant information between civilian humanitarian organizations and the military; document the flux of combined activities each day; and evaluate the utility of collaborative technology during a civil-military exercise in humanitarian relief. The team met each objective and reports the results in this paper."
2097998,22457,20561,HyperSQL: web-based query interfaces for biological databases,1997,"HyperSQL is an interoperability layer that enables database administrators to rapidly construct browser-based query interfaces to remote Sybase databases. Current browsers (i.e., Netscape, Mosaic, Internet Explorer) do not easily interoperate with databases without extensive CGI (Common Gateway Interface) programming. HyperSQL can be used to create forms and hypertext-based database interfaces for non-computer experts (e.g., scientists, business users). Such interfaces permit the user to query databases by filling out query forms selected from menus. No knowledge of SQL is required because the interface automatically composes SQL from user input. Database results are automatically formatted as graphics and hypertext, including clickable links which can issue additional queries for browsing through related data, bring up other Web pages, or access remote search engines. Query interfaces are constructed by inserting a small set of HyperSQL descriptors and HTML formatting into text files. No compilation is necessary because commands are interpreted and carried out by the special gateway, positioned between the remote databases and the Web browser. Feedback from developers who have used the initial release of HyperSQL has been encouraging. At present, query interfaces have been successfully implemented for three major NSF-sponsored biological databases: Microbial Germplasm Database, Mycological Types Collection, and Vascular Plants Types Collection."
655632,22457,20561,A systematic approach to support the idea generation phase of the user interface design process,1998,"Human-computer interaction researchers have primarily focused on systematic techniques and tools for two phases of the user interface design process: design by prototyping and evaluation. Studies have shown that the advent of a number of rapid prototyping techniques and tools have not significantly reduced the amount of time and costs involved in the design and programming of user interfaces. This is due to the fact that designers do not spend enough time thinking about the design problem; instead, they resort to aimless prototyping with a complex set of tools. We introduce the need for a formal planning and idea generation phase in the user interface design process prior to prototyping, to minimize the effects of ad hoc design practices. This is the phase when preliminary requirements for an information system are available and the designer starts thinking and planning about the problem, making mental and written notes about it. This phase is similar to the problem formulation and idea generation phases discussed by researchers in the area of creative problem solving. We also propose a systematic design methodology containing fifteen non-sequential, highly connected, and iterative set of design tasks to structure the creative and opportunistic thought processes of the designer with appropriate guidance. A tool called HyperDesign has also been developed, incorporating hypertext functionality, to facilitate application of this methodology during this early phase of interface design."
958290,22457,20561,The Influence of Organizational Factors on Inter-team Knowledge Sharing Effectiveness in Agile Environments,2014,"Agile software development is known by focusing on interaction among team members to share knowledge. However, little guidance is provided to encourage interaction across agile teams. Based on a preliminary conceptual model, this paper examines influencing factors, such as organizational strategy, and communication flow and channels, regarding inter-team knowledge sharing (KS) effectiveness in agile environments. We analyze the characteristics and the influence of the mentioned factors through a survey research method. Data was gathered from seven Brazilian agile software organizations. We employed statistical analysis techniques, e.g., structural equation modeling and cross-table analysis, to analyze the results. Within the surveyed companies, organizational strategy reflects on moderate commitment towards knowledge. KS practices are carried out to an acceptable standard. Extensive communication flow and the use of several channels denote that agile companies are also fostering interaction across teams. We found strong relationship between these factors and the companies' experience on agile methods. As companies continue on an agile adoption program, they growingly focus on long-term goals and consider knowledge as strategic resource. However, they still need to improve strategy alignment to all organization levels. Thus, we recommend that agile companies consider these factors when striving on this endeavor."
2342881,22457,20561,Using virtual reality for distance teaching a graduate information systems course,1996,"The evaluation of distance learning models has become commonplace in many academic institutions. Two models tend to dominate current offerings-an expensive audio/video real time interaction place dependent model and an inexpensive Internet based delayed interaction place independent model. By combining the most favorable elements of these models with technology prevalent in the MOO/MUD culture, a new MDU model was developed and field tested. This was a text based inexpensive distance learning model that offered real time interaction and place independent accessibility. The key element of this MDU or virtual learning environment (VLE) model was Diversity University-an experimental object oriented virtual reality college that enables same time different place text based interaction over the Internet. During the Spring 1995 semester, it served as a platform for conducting an entire information systems (IS) seminar style graduate capping course field study. A comparative analysis was done between the VLE course and the PLE (physical learning environment) courses. The replicatable strategy and results of this successful field study are presented. It was found that the MDU model developed was able to satisfactorily replicate the real learning environment for the chosen course. Further it did so conveniently, inexpensively and without compromising the target course learning objectives. A summary of findings and recommendations is presented."
2067368,22457,20561,Reducing the technical complexity and business risk of major systems projects,2004,"Shared IT infrastructure achieves returns to scale and facilitates co-ordination. Determining the optimal investment is difficult because demand is derived from business projects that can free-ride once the infrastructure is established. Organisations control infrastructure investments by justifying them in business projects that are net present value (NPV) positive, such as business process re-engineering projects. This increases the technical complexity of the business project and misleadingly couples the project's business goals with shared infrastructure goals. Field research uncovered an alternative deviant model where a flexible, or agile, infrastructure is installed and justified ahead of the business needs. Those needs were then satisfied with multiple small business application projects, as each became NPV positive. The managers' intuition was that this gave them valuable options to capture benefits from uncertain future business scenarios. This paper draws on these insights to uncouple infrastructure projects from business projects while still aligning the two. Real options theory is applied both to control the costs and to specify the infrastructure flexibility. The assumption is that uncoupling would reduce technical complexity and lower business risk. The paper then shows how to improve business performance by using infrastructure flexibility either to suppress the cost variance of the IT projects or to amplify their business benefit variance, as called for by McGrath (1997) and Sambamurthy et al. (2003)."
2366206,22457,20561,e-Risk Management with Insurance: A Framework Using Copula Aided Bayesian Belief Networks,2006,"e-business organizations are heavily dependent on distributed 24X7 robust information computing systems, for their daily operations. To secure distributed online transactions, they spend millions of dollars on firewalls, anti-virus, intrusion detection systems, digital signature and encryption. Nonetheless, a new virus or a clever hacker can easily compromise these deterrents, resulting in losses to the tune of millions of dollars annually. To cope up with the problem, in this work we propose to further enhance their security management by investing in e-risk insurance products as a viable alternative to reduce these individual financial losses. We develop a framework, based on copula aided Bayesian Belief Network (BBN) model, to quantify the risk associated with online business transactions, arising out of a security breach, and thereby help in designing e-insurance products. We have simulated marginal data for each BBN nodes. The Copula model helps in arriving at the joint probability distributions from these marginal data. From the joint distribution data, we arrive at the conditional distribution tables for each node. This is input to the Bayesian Belief Network model. The output is frequency of occurrence of an e-risk event. Frequency of loss multiplied with the expected loss amount, provides the risk premium to be charged by insurance companies."
2423334,22457,20561,Text types in hypermedia,1997,"The discipline of narratology has long recognized the need to classify documents as instances of different text types. We have discovered that classification is as applicable to hypermedia as it is to any other document presentation. Following the work of S. Chatman (1978; 1990), we consider three such text types: description, argument and narrative. The goal of a description document is to describe some object or concept; this is usually achieved by describing component parts and then describing how those parts combine to constitute the entirety. An argument document, on the other hand, is concerned with establishing some assertion or point of view, and it is based on supporting evidence, as well as possible refutations and justifications for defeating those regulations. Finally, a narrative document recounts some sequence of events in time, addressing relationships such as causality and contingency among those events. We analyze these types through case studies that give an example of each as a hypermedia document. We then argue that this classification provides an organizational framework that facilitates the construction of outlines that serve the writer in preparing the actual content of a document. Such outlines can also benefit the reader's understanding of the content that the writer intended to convey; if the writer does not make those outlines available explicitly to the reader, the reader can use knowledge of the document type to construct his own version of those outlines. Finally, we review some early work in content based indexing and search of multimedia documents."
2370838,22457,20561,Estimating the actual cost of transmission system congestion,2003,"This paper describes a methodology that could be used by a utility to estimate the actual cost of congestion on its transmission system using limited, non-state estimator data. The assumed problem inputs are a power flow model of an entire interconnected grid (i.e., the eastern interconnect), costs for the utility's generators, and then hourly values of the utility's generation, load and tie-line flows over the study time period. Due to the common lack by most utilities of external measurements, the system is first equivalenced to retain only the utility's own internal buses and a small subset of the external buses. Then, for each hour, the utility's load and generation is set to match their historical values, while the external generation is adjusted to match the tie-line flows. Next, an economic dispatch is performed to determine the unconstrained cost. Finally, a security constrained OPF (SCOPF) is solved to take into account base case and contingent constraints. The methodology uses a complete ac power flow formulation to accurately estimate the impact of voltage constraints and the incremental impact of system losses. The inclusion of hydro generation is also considered. For illustrative purposes only, the methodology demonstrated on the TVA system using publicly available data transmission system data."
2210746,22457,20561,Translating the Adoption of B2B e-Business into Measurable Value for Organizations,2006,"In todays competitive business environment, companies are seeking ways to perform transactions efficiently and effectively. The Internet has created a flexible platform for the buying and selling of products and services. As businesses recognize the need for employing efficient methods for the vertical exchange of goods and services, they are considering the adoption of functional business-to-business (B2B) applications and technologies that allow transactions in real time. The purpose of B2B is to improve profitability through establishing relationships with other organizations that will allow supply-chain planning, collaboration, product pricing, logistics and distribution management, and procurement efficiencies (Ranganthan, 2003). Proven continuing growth in B2B provides that incorporating such technologies into business operations is a significant issue for consideration. However, how easily do businesses ascertain the value added to their organizations by the adoption of B2B e-commerce? It depends greatly upon the organization and the self-analysis performed before project commencement. Our study emphasizes how critical each identified factor is to the translation of employment of B2B e-commerce to value for the organization. In this paper, we address the ease with which organizations can translate the benefits of B2B e-business initiatives into direct measurable value. Significant results and correlations were found, as discussed in the statistical analysis portion of this paper."
2127539,22457,20561,Designing guideline-based workflow-enabled electronic health records,2004,"With the rising prevalence of chronic illness, there is a growing pressure to develop systems that engender evidence-based care. The potential for workflow support to coordinate services and improve communication in the context of chronic disease management is intuitively appealing, but is still a challenging (and hence rarely seen) accomplishment in practice. We examine the problem of achieving a close relationship of electronic health record (EHR) content to other components of a clinical information system (guidelines, decision support and workflow), with particular emphasis on integrating the EHR with workflow. We use the openEHR architecture, which allows extension of a core reference model via archetypes, to refine the detailed information recording options for specific points in the workflow and to represent the chain of instructions that is the workflow itself. We illustrate the use of openEHR for tracking the relationship of a series of clinical services or events to a guideline-based workflow via a case study of an early supported discharge (ESD) program for post-stroke rehabilitation. This case study shows the contribution guideline content and its derived workflow can have on problem specific EHR structure and demonstrates the potential for a constructive interaction of workflow support and the EHR. We conclude with a discussion of the practical boundary of applicability of workflow approaches versus decision support system approaches in supporting guideline-based care."
1632540,22457,20561,Market entry strategies of application service providers: identifying strategic differentiation,2003,"In the last few years there has been much interest in the delivery of software-as-a-service. The concept of the remote delivery of software by application service providers (ASPs) has captured the imagination of many academics, practitioners and technology analysts. Yet analyst predictions and expectations with respect to the growth of this new e-business model have not been realised. Although many independent software vendors (ISVs) and other firms such as Telcos' have embraced the ASP business model, few have managed to deploy this business model profitably. Many firms that entered the market in the dot.com wave have struggled to stay in business due to the highly dynamic and turbulent nature of the ASP market. This paper analyses how ASPs are developing their market entry strategies with a view to creating strategic differentiation. It first gives an overview of the outsourcing and ASP literature and then examines the strategies developed by two ASP market entrants: a global telecommunications firm and a European ASP startup. Whilst these firms occupy different segments of the technology sector, the research findings show that they both fail to differentiate their products and services resulting in a failure to successfully develop an ASP business. The paper concludes by suggesting that ASP market entrants need to become more adept at developing strategic partnerships with firms in the technology sector if they are to offer the end-user an outsourced business solution, which can compete on price, quality and service."
2098550,22457,20561,How Do People Resolve Dilemmas? Eliciting Subjective Decision Factors,2011,"The organization and operation of human societies involve many kinds of social rules which we all more or less obey. Such rules for proper behaviors in a society or a group are called normative or deontic. The deepest, most internalized forms of these rules govern our moral and ethical behaviors. A key concern in this type of situations is deontic conflicts: decisions where all the alternatives lead to the violation of some norms. People think critically about these kinds of decisions. But, what they think about may not be always clear. Our broad focus is on difficult kinds of forced decisions where people need to choose between alternative undesirable outcomes. Most specifically we focus on so-called deontic dilemmas, where each alternative results in some kinds of violation of a normative/ethical rule. An elicitation approach is proposed that helps to identify the subjective factors that people use to resolve these kinds of difficult choices. Our technique is a hybrid of two established research methodologies: repertory grid and conjoint analysis. We illustrate our technique using a well-known challenge problem from psychology, known as the Trolley Problem. The technique is implemented as a prototype web-based application. We refer to our technique as the Open Factor Conjoint Methodology. We identify areas that need further research in order to refine and fully validate the methodology."
1965905,22457,20561,Problems of management and decision making in multinational banking,1997,"Many organisations are tempted to introduce a centralised computer-based information system to serve all the information business needs of the organisation. A popular belief is that such information systems will solve many business problems. There are some organisations in which an integrated information system is a success story. However, this is not always possible or indeed desirable. An example of an organisation in which the implementation of a centralised computer-based system, whilst potentially desirable, does not satisfy the short-term information needs of the company is given. The paper examines multinational retail banking and the problems related to gathering and maintaining the information that is needed for making business decisions. The banking industry is undergoing a period of rapid intensification of competition and fundamental change where new products and services are both agents and consequences of change. The competitive position of banking is under increasingly serious challenge from non-banks offering financial services. Banks are confronted with numerous challenges in order to survive and indeed make a profit in such a competitive market where efficient and effective information management is of foremost importance. The complexity of the problem is illustrated using the example of Barclays Bank, which has a long history of operating internationally. The paper focuses on the problems and challenges of information gathering for the purpose of carrying out the business strategy of such organisations."
1550611,22457,20561,Ubiquitous Interpersonal Communication over Ad-hoc Networks and the Internet,2014,"The hardware and low-level software in many mobile devices are capable of mobile-to-mobile communication, including ad-hoc 802.11, Bluetooth, and cognitive radios. We have started to leverage this capability to provide interpersonal communication both over infrastructure networks (the Internet), and over ad-hoc and delay-tolerant networks composed of the mobile devices themselves. This network is decentralized in the sense that it can function without any infrastructure, but does take advantage of infrastructure connections when available. All interpersonal communication is encrypted and authenticated so packets may be carried by devices belonging to untrusted others. The decentralized model of security builds a flexible trust network on top of the social network of communicating individuals. This social network can be used to prioritize packets to or from individuals closely related by the social network. Other packets are prioritized to favor packets likely to consume fewer network resources. Each device also has a policy that determines how many packets may be forwarded, with the goal of providing useful interpersonal communications using at most 1% of any given resource on mobile devices. One challenge in a fully decentralized network is routing. Our design uses Rendezvous Points (RPs) and Distributed Hash Tables (DHTs) for delivery over infrastructure networks, and hop-limited broadcast and Delay Tolerant Networking (DTN) within the wireless ad-hoc network."
1894179,22457,20561,Current and emerging requirements for digital rights management systems through examination of business networks,2004,"Digital rights management (DRM) is an issue of controlling and managing digital rights over intellectual property. Research on the DRM domain focuses on specifying requirements for management systems from variety of perspectives, however, mainly concentrating on protecting rights in business to consumer trade with certain mechanisms. This article takes a novel viewpoint in evaluating DRM issues from the perspective of networked business operations. In contrast to studies on DRM, the article evaluates the creation and delivery of content in along an asset creation-delivery continuum in terms of role specifications, content processes and management of digital rights over content, i.e. assets, in formations of firms. Our interest in this conceptual study is on the issues of networked business models and, consequently, we contribute in defining and analyzing the complexities of such scenarios and from case scenario deriving emerging requirements for digital rights management in the introduced context. While simultaneously providing certain advantages to enterprises, the inter-organizational interdependencies in networked business model are prone to cause conflicts, thus, creating an increased need for control, contracting and coordination activities. We conclude that in order to build trust between various actors, multiple agreements describing rights and obligations of operation and over assets needs to be negotiated and signed, thus, establishing a requirement for utilization of standardized digital rights expressions and efficient agreement creation and management."
315787,22457,20561,"Creativity, Knowledge and IS: A Critical View",2005,"The growing importance of creativity in organizations, the reliance of creativity on knowledge, the increasing use of information systems (IS) as means to support organizational knowledge - all point to the importance of research on the relationship between IS, knowledge and creativity in organizations. In this paper, evidence from case studies of realworld industrial creative processes is presented. Drawing on the evidence, the creativity, knowledge and IS literatures are critically examined. In particular, attention is given to the Creativity Templates approach - according to which, fundamental templates representing creativity regularities underlie seemingly original product instantiations, and therefore algorithms for the development of creative products can be used to enhance creative processes. An alternative view of bounded creativity is explored that is reliant on flexible knowledge sharing, rather than on prescriptive creativity algorithms. This view involves primarily two complementary organizational practices: communication of exemplars and references, and knowledge restriction. Ideation, in this view, takes place with no direct use of techniques or creativity enhancement methods. Such approach may be more suitable to highly creative organizations given the strong sense of identity and high regard of originality. Unlike many of the creativity support approaches presented in the literature, it is not an isolated technique but rather a set of fairly specific organizational practices, which, brought together, seem to give rise to creativity, and mitigate against potential identity conflicts."
1772633,22457,20561,Structured study groups empower student learning. I cannot write my final until my class finishes creating its multimedia text,2000,"Structure and Reactivity is the first-year chemistry course at The University of Michigan. Each Fall, 160 students in the 1200-student course earn Honors credit by participating in weekly 2-hour supplemental instruction sessions we call Structured Study Groups (SSGs). Students bring written assignments to the sessions and engage in structured peer group critiques facilitated by upper-level undergraduate leaders. Projects broaden and deepen the students' learning of associated course topics. In the second term, there is a separate section of the course where all of students are in SSGs. In these sessions, students represent their ideas in writing, orally, and through computational tools. Since 1996-97, one of the term-long projects requires all of the students contribute to the construction of a written and HTML literature-driven resource. Creating animations of reaction mechanisms and interactive correlation of spectroscopic assignments causes students to consider the subject matter in ways more aligned with an instructor's work. Ultimately, the multimedia text (print, CD, and web site) is fully owned by the students, and they must seek out each other's expertise in order to examine their understanding. The final examination in the course is based completely an the student-generated text."
1189604,22457,20561,Teaching Digital Forensics Techniques within Linux Environments,2014,"Appropriately motivating digital forensics topics in an educational environment is a challenging task for a lecturer. Not only will the skill levels of the students vary widely, but designing a lab exercise that introduces a single concept runs the risk of requiring too much additional knowledge to appropriately describe the task or may easily devolve into a contrived example that does not allow the student to fully grasp the extent of the topic at hand. In some cases, this difficulty is compounded by the sheer amount of misinformation that results from years of common knowledge and research becoming invalid after changes to kernels and operating systems. Last year, the Honeynet Project Challenge 12 - Hiding in Plan Sight - and a computer security workshop sought to introduce some concepts regarding information and process hiding and disguising through a series of digital forensics labs. This paper will describe the components of these labs that were successful at motivating a core concept, as well as those that were not as successful and have been subsequently modified based upon feedback. These findings will be presented through a suggested lecture-lab format, and a series of scoped topics that can be used in other educational environments to motivate digital forensics and anti-forensics concepts. Scripts used to build each lab have also been provided to serve as a point of reference."
450574,22457,20561,Investigating the Correlation between Intention and Action in the Context of Social Engineering in Two Different National Cultures,2015,"In this paper, we shed a light on the intention-action relationship in the context of external behavioral information security threats. Specifically, external threats caused by employees' social engineering security actions were examined. This was done by examining the correlation between employees' reported intention to resist social engineering and their self-reported actions of hypothetical scenarios as well as observed action in a phishing experiment. Empirical studies including 1787 employees pertaining to six different organizations located in Sweden and USA laid the foundation for the statistical analysis. The results suggest that employees' intention to resist social engineering has a significant positive correlation of low to medium strength with both self-reported action and observed action. Furthermore, a significant positive correlation between social engineering actions captured through written scenarios and a phishing experiment was identified. Due to data being collected from employees from two different national cultures, an exploration of potential moderating effect based on national culture was also performed. Based on this analysis we identified that the examined correlations differ between Swedish, and US employees. The findings have methodological contribution to survey studies in the information security field, showing that intention and self-reported behavior using written scenarios can be used as proxies of observed behavior under certain cultural contexts rather than others. Hence, the results support managers operating in a global environment when assessing external behavioral information security threats in their organization."
479858,22457,20561,The Response of Investors in Publicly-Traded Utilities to Blackouts,2015,"Large blackouts are economically costly and socially disruptive, but in some cases can also be beneficial to investors in publicly-traded utilities. Large blackouts, particularly those that damage capital equipment, can increase future cash flows of utilities if replacement capital expenditures are permitted to be included in the rate base. The semi-strong version of stock-market efficiency suggests that these future cash flow increases will be reflected in utility stock prices following blackouts (but before the conclusion of any rate case proceedings). We use an event-study framework to examine abnormal returns for U.S. Electric utilities in the 60-day period following large blackouts. In many cases utility stock returns decline immediately following the blackout as cash reserves are depleted. In the case of blackouts that are unlikely to involve large-scale capital replacement, the blackout has little impact on abnormal returns over a longer time horizon. In the case of blackouts caused by natural disasters or extreme weather, we observe that fast recovery times (one week or shorter) are associated with a slight increase in abnormal stock returns, suggesting that investors have confidence that future rate cases will turn in the utility's favor. Finally, blackouts affecting more than one million customers and those that take more than 10 days to achieve full restoration are associated with a decline in abnormal stock returns for affected utilities, this decline persists for several weeks following restoration."
2350839,22457,20561,Evaluating the application service provider (ASP) business model: the challenge of integration,2002,"The paper evaluates the application service provider (ASP) business model. It draws from a large scale research program funded by the European Union and Engineering and Physical Sciences Research Council (EPSRC), into the emerging ASP industry where software is delivered as a service, priced on a per-seat, per month basis. Tracking a taxonomy of ASPs (pure-play, vertical, horizontal, enterprise and enabler) through longitudinal case study research, the paper suggests that two major inhibitors have contributed to the slow growth of this market. The first is economic conditions evidenced by the dot.com downturn, and the second is lack of education in the potential customer marketplace. The paper tracks the strategies of two major players within the ASP industry: Cable & Wireless, a traditional UK telecoms company moving into the IP market, and Jamcracker, a recently established US enterprise web services company. Through careful evaluation of key performance indicators (KPIs) for evaluating ASPs and customer perceptions of the software-as-a-service proposition (and e-business broadly conceived), the paper argues what integration of applications will be the major challenge if the ASP business model is to survive in the overcrowded and intensely competitive e-business sector."
2028534,22457,20561,The master clinical lexicon. Integrated product team approach,1998,"The Office of the Assistant Secretary of Defense for Health Affairs established a vendor consortium to develop a clinical lexicon for use by all Department of Defense (DoD) health care services and systems. Commercial vendors of lexicon software and government team members participated in an Integrated Product Team (IPT) from September 1996 through March 1997 to develop a proof of concept demonstration of how this lexicon will perform in the DoD clinical environment. After the first meeting of 40 members of the government and competing vendors, the Government IPT chairperson determined the use of Electronic Meeting Software (EMS) was essential to enhance communication and to promote consensus among the diverse members of the group. During the course of the five-month long project, use of the EMS focused the team on their accomplishments and the tasks yet to be completed, insured the ability of all team members to express their concerns, questions, and issues, and maintained documentation of all decisions and actions. After the demonstration of the lexicon and presentation to the Assistant Secretary of Defense, the IPT chairperson congratulated the team members on the exceptional results of this first-of-its-kind government and commercial vendor collaborative effort The use of EMS was cited as a critical success factor in managing the work of this team. This paper outlines the processes and rationale behind the sessions and provides a framework for future IPT efforts to follow."
2133750,22457,20561,The effect of external safeguards on human-information system trust in an information warfare environment,2003,"The modern military command and control (C2) center collects a massive amount of information that is both complex and contradictory. The amount of collected information is often more than can be effectively and efficiently understood by humans. Therefore, today's decision-makers have become reliant upon information systems to filter through the information and fuse that information into a computer representation of the battle space. The degree of reliance placed in these systems by the decision-makers suggests a significant level of trust. Trust theories and models are rich in the literature, but few have been developed for the human-computer trust relationship. A recent model of trust was found that was both broad in scope and supportive of human-computer trust theories. This model was used to explore the decision-maker's trust in information systems in a C2 environment. Given the vulnerability of information systems to information security incidents such as hacking and data manipulation, this study set out to examine if the presence of such incidents would effect the decision-makers trusting behavior. This study also examined if the use of such external safeguards, such as the computer emergency response teams (CERT) and the network risk assessment certifications, would affect the decision-maker. Two laboratory experiments were conducted with military personnel using a high-fidelity C2. The findings from both experiments suggest that the presence of information security incidents in a fast-paced C2 environment have no effect on the decision-makers trusting behavior. Decision-makers continued to trust information systems even though information security incidents occurred."
2865017,22457,20561,How Questions and Answers Shape Online Marketplaces: The Case of Amazon Answer,2017,"This paper uses data from two online shopping platforms to investigate the economic implications of the question & answer system. This research problem becomes increasingly important as many small and medium players in online marketplaces start to adopt this system rather than the typical online review system. Yet, the economic implications of such a Q&A system have not been studied in the previous literature. We employ the difference-in-differences approach to empirically examine the effect of question & answer elements, which exist only on one platform, on product sales. Interestingly, we find that controlling for everything else, question elements have a negative impact on sales while answer elements, particularly the depth of the answers, have a positive impact on sales. However, as we focus on the initial sales, it turns out that the number of questions and the fraction of questions that have at least one answer positively influence the sales. We also find that there is an interaction between Q&A elements and review elements in that an increase in the number of questions seems to be positively correlated with an increase in the number of reviews in the following period. Meanwhile, an increase in the number of answers appears to reduce the average length of reviews in the subsequent period. Our findings suggest that incorporating the question & answer system could be a potential approach to drive sales. However, it is crucially important for managers to develop appropriate policies to gather necessary answers to questions asked on the platform in order to capitalize on such a system."
2377248,22457,20561,Specifying and Analyzing Workflows for Automated Identification and Data Capture,2009,"Humans use computers to carry out tasks that neither is able to do easily alone: humans provide eyes, hands, and judgment while computers provide computation, networking, and storage. This symbiosis is especially evident in workflows where humans identify objects using bar codes or RFID tags and capture data about them for the computer. This Automated Identification and Data Capture (AIDC) is increasingly important in areas such as inventory systems and health care. Humans involved in AIDC follow simple rules and rely on the computer to catch mistakes; in complex situations this reliance can lead to mismatches between human workflows and system programming. In this paper we explore the design, implementation and formal modeling of AIDC for vital signs measurements in hospitals. To this end we describe the design of a wireless mobile medical mediator device that mediates between identifications, measurements, and updates of Electronic Health Records (EHRs). We implement this as a system Med2 that uses PDAs equipped with Bluetooth, WiFi, and RFID wireless capabilities. Using Communicating Sequential Processes (CSP) we jointly specify workflow and computer system operations and provide a formal analysis of the protections the system provides for user errors."
2473425,22457,20561,Using enterprise reference models for automated ISO 9000 compliance evaluation,2002,"A computational enterprise model representing key facets of are organization care be are effective tool to consider where planning are enterprise information architecture. For example, a specific organization's quality management business processes and organizational structures can be represented using such a model, and then compared to a reference model of good processes and structures, such as the ISO 9000 standards. The specific and reference models can be represented using common entities, attributes, and relationships-comprising general schema or data model-which are then formally defined and constrained. These definitions and constraints can be used as inference rules applied to the models. Hence identification of differences between the models as quality problems can be automatically inferred, as can the analysis and correction of problems. In this paper; the TOTE ISO 9000 Micro-Theory is presented as a formal reference model of quality goodness. ISO 9000 requirements represented as inference rules in the micro-theory are applied to facts about an organization's quality management processes and structures, and conformance or nonconformance to requirements is automatically inferred. TOTE Ontologies for Quality Modeling are the common data and logical (formal definitions and constraints) models of the reference and specific organization's models. The example use of the micro-theory demonstrates enterprise model use for a pre-audit, which lowers the cost and time for improving quality through achieving ISO 9000 compliance. Since these enterprise models are constructed using ontologies, benefits of using ontologies such as model re-usability and sharability can be reaped."
1926190,22457,20561,"Developing analytic, cognitive and linguistic skills with an electronic negotiation system",2003,"An increasing number of Web-based systems, including brainstorming, decision-making, and negotiation support systems, are being developed to aid users in solving particular types of problems in various contexts. These systems can be effectively used in language teaching providing learning experience in an authentic setting. The purpose of this paper is to discuss the value of integrating Inspire, a Web-based negotiation support system, to augment conventional teaching of communication and academic skills in second language courses. Inspire provides a platform and tools for negotiators to work together to resolve their differences. The preparation for the negotiation and the conduct of the negotiation in an asynchronous mode are designed to give the users control over the process and the outcome of their negotiations. Exchange of offers, counteroffers and messages creates a framework for a meaningful interaction, where results depend on the users' decisions and their ability to communicate effectively. Going through different phases of the negotiation, the students develop analytic, cognitive and linguistic skills, albeit some better than others. The paper argues that systems oriented on solving problems in a group setting lend themselves to the communicative approach to language teaching embedded in the theory of second language acquisition. It also discusses issues related to its adoption, and suggests strategies for its diffusion."
1925161,22457,20561,Perceived Benefits and Concerns of Prospective Users of the SmartCampus Location-Aware Community System Test-bed,2007,"The SmartCampus initiative aims to turn an urban university campus into a living laboratory for location aware community system services. To lay a foundation for this effort, the SmartCampus test-bed is being created through provisioning to 500+ students with personal computing devices (smart phones and tablet PCs), which runs a suite of applications that link people-to-people-to-place, or P3-systems. To explore anticipated usage and concerns, and to use this information to help to refine the design of various applications, semi-structured interviews were conducted with a cross section of 65 members of the NJIT campus community. The interviews employed hypothetical use scenarios to enable prospective users to give their opinions about applications that did not yet exist at the time of the study. Most students were quick to see the possible benefits of applications that can allow one, for instance, to see the campus location of their 'buddies' at a glance. The major concerns were with privacy control, the validity of the data entered (e.g., can applications be used to make verbal attacks on others?), and interruptions/overload with information, which may be disruptive. The concerns raised are being used to help inform the design of test-bed applications"
2244657,22457,20561,Data protection in the university setting: employee perceptions of student privacy,2001,"The right to privacy is not absolute and is often established by context and the need to know. The nature of the university environment sometimes distorts the sanctity of privacy because the need to know is so profuse. Although students are guaranteed the right to keep essential but confidential information private under the Family Educational Rights and Privacy Act of 1974, student data are vulnerable because of the need for academic departments to share and manage these data. Recent articles in the popular press suggest consumers as a whole are questioning organizational practices that are designed to protect their personal information. Similar practices occur in the university setting, but fewer concerns are being publicized. Because of the vast amount of data sharing that occurs in an academic setting, it is imperative that we ensure the employees adhere to privacy policies that are structured to impose conscientious behaviors. University privacy policies are in practice, but there is no method of determining their effectiveness. This research seeks to ascertain the attitudes of employees regarding student privacy. Using a 15-item instrument, this study explores employees' privacy perceptions of a large university located in the Southeastern USA. Our study examines the level of concerns employees have concerning errors in, unauthorized secondary use of, improper access to and collection of data."
2273972,22457,20561,Project Establishment in the Context of Participatory Design: Experience from a Hospital Information System Development Project in a Developing Country,2006,"This paper reports on a project establishment undertaking as proposed by the STEPS methodology (Software Technology for Evolutionary Participatory System Design). Project establishment in STEPS is aimed at getting an inner understanding of a projects environment. This understanding spans getting insights about the user environment, establishing a project team and ends with an initial proposal of the next steps as proposed by STEPS. We describe the methodology we applied: sustained individual and group interactions with the staff at the hospital informed by concepts of participation, collaboration and Joint Applications Design. By reflecting on selected instances of our engagement with the hospital staff, we report as findings the observations that before our project ideas can get ground, there are preliminary reviews and concerns (auxiliary to the central theme of participation) that need to be addressed. They touch on tools, processes and the prevailing organizational culture. The task at hand evolved to be that of cultivating a participatory culture on the hospital staff. At the end of the paper we present an outlook from our project establishment experience. We argue that our experiences as described in the paper inform our next steps. We frame our experiences into literature on: a) Power distance dimension in describing national cultures, b) empowerment and democracy in the practice of participatory design and c) incremental system development that proceeds from first defining a core system."
451066,22457,20561,Evaluating the Performance of Collaboration Engineers,2015,"Collaboration Engineering (CE) is an approach to designing collaborative work systems for high-value tasks, and transferring them to practitioners to execute for themselves without support from a collaboration expert. The stakes are high on a CE project, so it would be useful to have a way to evaluate the performance of the collaboration engineers (CEs) who design the work systems. One can evaluate an engineer in terms of the efficiency of resource use, the timeliness of completion, stakeholder satisfaction, and the quality of work with respect to objectives. Measures for resource efficiency, timeliness, and satisfaction are common across disciplines. Measures of work quality, however, are specific to each discipline because each has different objectives. This paper focuses on evaluating the performance of CEs with respect to work quality. Toward that end, we contribute a seven-stage CE methodology based on the Six Layer model of collaboration, and define for each stage its objectives, key activities and work products. From those we derive indicators of work quality for each stage based on a) the justifiability of key decisions, and b) quality of work products. The performance indicators are framed as checklist questions with either yes/no, no/yes, or five-point scales. These indicators are heuristics, they are not designed to be validated metrics for rigorously-defined theoretical constructs, and are not intended to support theoretical and experimental research. They are useful for evaluating of CEs' performance during and after a project, and also would support further exploratory and engineering research on the performance of CEs."
2357071,22457,20561,Constancy and Change in Scientific Collaboration: Coherence and Integrity in Long-Term Ecological Data Production,2012,"The world of science has long been a source of new models, ideas, and technologies in the practice of distributed group collaboration. Recent national-scale investments in 'e-science' or 'cyberinfrastructure, ' continue this trend, promising to extend scientific collaboration through space (geographic and disciplinary) but also time: building new monitoring systems while opening up existing long-term records to new forms of sharing and analysis. Drawing on ethnographic fieldwork and ethno methodological analysis, this study explores the tensions between continuity and change in long-term ecological monitoring and collaborative research. We observe the work of producing shareable data amidst the ever-present contingencies of day-to-day practice, which must respond to two separate temporal accountabilities: coherence in the short-term and integrity in the long-term. Changing environments, broken instruments, organizational shifts, and turnover in personnel threaten the integrity of the data record, but they also serve as crucial resources for accommodating contingency and change. We argue that the success of current cyber infrastructure investments -- and many other forms of collaborative system development -- will depend on just such delicate and local accommodations between continuity and change."
1870559,22457,20561,Network Structure or Tie Content? The Impact of Managerial Networks on Career Outcomes and Influence,2012,"Social networks are crucial for gaining information, enhancing one's own influence and promoting the career advancement. This paper addresses the question which network properties explain intra-organizational outcomes at work. Following the idea of Burt concerning the benefits of structural holes, I explore on the one hand the impact of structural holes on influence and career outcomes in a knowledge intensive firm. Considering the specific characteristics of knowledge intensive firms, I incorporate the importance of tie strength and professional closeness in my analysis of organizational outcomes. On the other hand, I explore the resources gained through different tie contents. The relational resources are clustered and analyzed with regard to their structural properties. Data was collected using online questionnaires in a Swiss service firm. The ego-networks of 288 managers were analyzed, using eight name-generating questions. Two effects stand out: Firstly, structural holes, strong ties and professional closeness do enhance influence and career success. Secondly, the networks can be clustered in three different groups: i) work related information, ii) strategic information or cultural norms and iii) personal support. The results show the relevance of tie content for network analysis. The consideration of the resource flow allows a better understanding of the contribution of structural properties to organizational outcomes."
2478671,22457,20561,"Innovator or owner? Information sharing, incomplete contracts and governance in financial risk management systems",2004,"Financial risk management has become increasingly important in the financial industry during the last decade, especially due to the financial disasters in the mid-1990s. Value-at-risk (VAR), developed by J P. Morgan in the late 1980s, has been the most widely accepted risk measurement methodology because it provides a single number summary of an institution's portfolio risk. To promote VAR, Morgan provided RiskMetrics, a VAR-based risk management service, for its clients (borrowers). Later, RiskMetrics was spun off as an independent company providing fee-based services. Building upon the theory of incomplete contracts and other related theories, we develop a game theoretic model to explain why adoption of the free RiskMetrics service stalled and how the change in ownership structure of the service led to wider adoption. In particular, we examine a situation where the borrowers have heterogeneous portfolio riskiness and this differential riskiness affects the value they can gain from the service and the impact of the service provider exploiting their private risk information. Our results suggest that the most important roadblock to borrowers' adoption of the free service might have been the potential damage from the service provider's information exploitation. When the service was spun off borrowers' concern was reduced due to the multi-party independent ownership structure, which led to wider adoption. The spin-off was Morgan 's strategic move to maximize long-term profits from RiskMetrics."
2637005,22457,20561,OpenLabs -- Open Source Microfactories Enhancing the FabLab Idea,2016,"Increasing social and economic imbalances as well as restricted access to production means and participation in value creation processes ask for new approaches to overcome the asymmetric distribution of knowledge and information between producers and consumers as well as between industrialized and developing countries. Technical progress in production technology, the advancement and spread of information and communication technologies (ICT) as well as the spill-over of the highly efficient and innovative open source principles to the world of physical products represent a new set of tools and concepts to address this challenge. Correspondingly, we can observe (new) modes of value creation that put into question traditional economic strategies and assumptions by stressing collaboration instead of competition and knowledge sharing instead of black box engineering. The FabLab movement (fabrication laboratory) is one emerging and promising approach for decentralized, participative, locally grounded and globally interconnected value creation. This paper presents findings from a study on the latest development, effects and success of FabLabs focusing especially on its potential for development cooperation. Based on findings from the survey and the premises of the FabLab idea, we finally present the multidisciplinary OpenLabs concept."
1877295,22457,20561,Comparing Decision Rules for Siting Interconnected Wind Farms,2011,"The variability and non-dispatchability of wind power creates many challenges for the operators of electric transmission systems. Current U.S. wind energy policies are focused on encouraging quantities of wind power without much attention paid to quality of the power produced. Using detailed meteorological data from 113 different weather stations in Oklahoma, we simulate power production from a large number of interconnected wind farms and devise a variance-minimizing rule for successively adding farms over a wide geographic area. Our variance-minimizing rule reduces the standard deviation of five-minute averaged wind power output decreases by 27% after grouping of 8 stations. We compare our variance-minimizing decision rule with two other decision rules for incremental wind investment: a nearest-neighbor rule that has been suggested in previous literature and a profit-maximization rule that reflects decentralized decision-makers. All interconnection decision rules reduce the aggregate variance of wind power output, particularly after several stations are interconnected. We find that the nearest-neighbor rule reduces variance by less than half that of the variance-minimization rule. The profit-maximization rule achieves 75% of the variance reduction attained through the variance-minimization rule. We also evaluate and compare wind power variability over hourly and daily time scales and analyze the sensitivity of variance-minimizing wind energy investment patterns to wind-speed measurement frequency. This work is a first step in a larger project, in which we plan to compare the intermittency costs of wind power that arise from different siting policies or decision rules."
2352557,22457,20561,A Comparison of Optimized Link State Routing with Traditional Routing Protocols in Marine Wireless Ad-hoc and Sensor Networks,2007,"The performance of mobile ad-hoc networks (MANET) is related to the efficiency of the routing protocols in adapting to frequently changing network topology and link status. This paper addresses the issue by comparing the relative performance of three key ad-hoc routing protocols: destination-sequenced distance vector (DSDV), ad-hoc on-demand distance vector (AODV) and optimized link state routing (OLSR). The protocols are tested based on two scenarios, namely, tactical networks for ships and sensor-based network nodes. Four performance metrics were measured by varying the maximum speed of mobile hosts, network size and traffic load, to assess the routing capability and protocol efficiency. The simulation results indicate that AODV performs better than OSLR and DSDV in the first scenario. Although OLSR also performed relatively well, the associated high routing overhead is the dominant reason for not choosing it. On the other hand, OLSR emerged as the protocol of choice for sensor networks, where the high routing overhead is counteracted by consistently better performance in all other metrics. Due to the slow evolution of the sensor network topology, OLSR performed satisfactorily for best effort traffic but needed subtle adjustments to balance between latency and bandwidth to meet the requirements of delay-sensitive applications"
2154156,22457,20561,System architecture for cross border payment: a case study for the financial services industry,2003,"The financial services industry is changing rapidly as a result of advances in information technology (IT), telecommunications and the Internet. Technological innovations and increasing customer demand have led to the emergence of new services and new organizational forms for financial services firms. Willingly or unwillingly, banks are being forced to move toward worldwide operation. This enables them to offer services and credit facilities on a global scale, tailored to customers regardless of where they are based. However, variations among national markets present obstacles as well as opportunities to companies attempting to go global. This paper describes specific problems and solutions for the globalization of banking services, and a case study carried out on payment services for an international bank to develop system architecture for cross border payment. The proposed architecture aims to keep apart of the processes local, but transfers the core of the transaction operations to a centralized system with clear services and clear interfaces. The bi-directional translation of formats makes standardized processing possible, while output for the specific contexts can be provided in the original formats. An important property of the architecture is that the rich context has been integrated into the handling of transactions."
2702399,22457,20561,RFPCog: Linguistic-Based Identification and Mapping of Service Requirements in Request for Proposals (RFPs) to IT Service Solutions,2016,"Request for proposal (RFP) documents describes a client's business and service requirements in natural language. RFP packages typically consists of tens to hundreds of documents each ranging from tens to hundreds of pages and come at variety of formats and structures. Processing RFPs manually is a tedious, error prone and slow process. It is a competitive advantage to a service provider to be able to process RFP documents to automatically extract client requirements, and understand how these requirements map to the internal offerings, products or solutions of the business to improve the efficiency of preparing RFP responses, and conduct sizing and pricing of the solutions. However, this is a challenging task due to the complexity and variety of forms that requirements are expressed, their level of detail, style and language expression. In this paper, we present a novel cognitive solution that employs linguistic-based and machine learning methods for automated processing of RFP documents for extracting requirement statements, and mapping them to offering taxonomies. We also present RFPCog as an interactive and explorative tool for analysis, refinement and browsing of requirements-offering mapping. The presented methods have been applied on RFPs submitted to a large IT service provider company, and the result of evaluation of the methods and tool by practitioners shows the effectiveness of the tool for intelligent requirement extraction and analysis."
1767201,22457,20561,Investigating the Use and Effectiveness of Virtual Collaboration Desks for Collaborative Military Planning,2009,"This paper focuses on the use of a Virtual Collaborative Working and Visualisation Environment (VCWVE), i.e. using virtual collaborative desks (VCDs), for the development of shared situational awareness using a common operational picture to support collaborative military planning in joint command and control situations. Joint usability, critical task and situational awareness assessment methods are employed to determine the effectiveness of this VCWVE in supporting commanders’ joint decision making. With reference to the British Army’s seven questions (7Qs) estimate process and intelligence preparation of the battlefield along with a small military judgement panel (MJP) used for the simulation experiment, the research focused on how effectively networked VCDs highlighted commander’s critical information requirements and their evolving requests for information during the planning process. The research also highlighted how collaborative technologies can not only help to improve joint decision making in a distributed HQ environment but also how an effective plan and its products can be delivered such as: the decision support overlay, the decision support matrix and the synchronisation matrix. As a result of this research a joint usability framework has been developed. This research has military significance in terms of enabling synchronised joint decision making in resilient agile distributed HQ groups and thereby reducing security risk of commander and staff."
1028675,22457,20561,E-Government Challenge in Disaster Evacuation Response: The Role of RFID Technology in Building Safe and Secure Local Communities,2010,"While geographic information systems (GIS) can provide information on the static locations of critical infrastructure and evacuation routes, they do not provide the dynamically changing locations of things and people on the move. In contrast, radio frequency identification (RFID) wireless network technology can automatically identify and track the movement of assets (i.e., fire engines, ambulances, and rescue workers) and vulnerable citizens on the move (i.e., the elderly and the disabled), and hence providing local governments and communities with real-time information and enhanced decision-making capabilities, during chaotic disaster response operations (i.e., evacuation). Although the potential high impact and strategic value of integrating RFID into e-government development and government's comprehensive natural disaster management policy for improved preparedness, response, recovery, and mitigation, very little has been written in the e-government literature regarding the adoption, use, and impact of RFID in building safe and secure local communities for citizens and businesses. This position paper, which is based on a review of the literature and a field case study, intends to contribute to the definition of the e-government research priorities needed to build regional disaster preparedness, as an integral part of e-government development policy."
232414,22457,20561,INFOFLOW: A Flexible Process-Oriented Workflow and Information System Based on Standard Office Products,2002,"This paper presents a modular, groupware- and workflow based System called INFOFLOW. The system was designed to meet the requirements of a DIN EN ISO 9000 certified development and pre production plant. As a compromise between usage of standard software and a complete custom solution it is partly based on Microsoft Standard Office Software to increase end-users acceptance, supplemented by plugins and a self developed workflow engine. The workflow engine controls the production flow, esp. exception handling and distributes relevant information between the several clients. It especially supports exception handling like activity related, predefined rework sequences, or handling the scrapping of damaged parts. INFOFLOW integrates workflow and information technology providing the users with relevant activity and order related information elements The user interfaces are realized as electronic forms, embedded in Microsoft's Outlook Web Access folders, representing the activities or People involved in the production process. These Web applications, called iaelectronic worklistsli are created and distributed by the workflow engine. A mechanism to easily create and integrate user defined input forms allows the customization of the user front ends."
1139412,22457,8235,SmartCart: A consolidated shopping cart for pareto-optimal sourcing and fair discount distribution,2013,"This paper explores two interrelated questions: First, when buyers form a coalition to obtain volume discounts on the purchase of multiple items from multiple sellers, how many of each item should be purchased from each seller to maximize the overall discount? Secondly, when this discount is obtained successfully, how should it be allocated to the buyers who pooled their resources to make one successful group purchase? An auction is the context under which these questions are tested, using a scenario in which multiple buyers form a coalition to consolidate their individual shopping carts into one aggregated shopping cart. A relational database is used to simulate an interactive auction and tracks buyers, sellers, items, prices before discount, prices after discount, purchase decisions, and other key data. When a critical mass of items to be ordered is reached, the shopping carts are locked and the coalition's overall demand for each item is copied to an aggregated shopping cart. To clear the auction, a decision guidance query language (DGQL) is executed to determine, using a MILP optimization, the quantity of each item to be ordered from each supplier to maximize discounts. A formula that allocates discounts to members of the buying coalition is then proposed. DGQL provides a great degree of flexibility and extensibility in the specification of constraints using a high-level language that can be embedded directly in SQL. This analysis provides a foundation from which a working tool could be built to allow buyers to form ad hoc purchasing coalitions to achieve discounts that otherwise would be unavailable to the individual buyers acting in isolation."
1794218,22457,20561,Internet/Web systems development: what can be learned from hi-tech new product strategic planning,2003,"A DELPHI questionnaire study of the management problems of Internet/Web systems development was completed in 2001 and its results have been reported in the literature. The most important problems collectively consist of a cluster of problems involving Internet strategic planning and other strategy-related problems. This cluster includes 4 of the first 5 problems and a total of 7 of the top 16. Other recent research studies have reached similar conclusions about the high importance of strategy considerations in the field of high-tech product development, where strategic planning for new product development was found to be the top problem. High-tech product development occurs in a different operating (and usually mutually exclusive) environment from that of Internet/Web systems (Web systems) development in that the former involves R&D, engineering, and production activities and produces a (usually) physical product suited for the marketplace, whereas Web systems development creates systems for internal use by the developing company, using analysis and development tools and methodologies that differ significantly from those of traditional IT systems development. However, the new-product development activities and Web systems development activities also have a great deal in common: each takes place in a highly uncertain, rapidly changing, complex, advanced-technology environment that is difficult for other managers to understand and properly consider during the strategy planning processes. A large body of knowledge has emerged about strategic planning and management of new-product development, but no such body of knowledge has yet emerged with respect to Web systems development strategic planning activities. This article is directed to strategic planning management knowledge transfer from the high-tech product development arena to the field of Web systems development. The article first describes, and then compares the processes of both activities. Then considered is how high-tech product development planning and management practices can be used for Web systems development."
1321607,22457,20561,The Impact of Variable Market Price on Optimal Control of Wind-Hydro Storage System in Kenya,2014,"The Lake Turkana Wind Power Project (LTWP) in Northern Kenya is currently under development, scheduled to bring 300MW of wind generation online by the end of 2016. The economic issues raised by the structure of the Kenyan electricity market include a fixed feed-in tariff for the wind generators on the system, and a strict Power Purchase Agreement (PPA). This agreement appears to significantly constrain the ability of the Kenya Power Company to operate the power system in a reliable and efficient manner. This paper analyzes the impact of different price policies on the operation of the LTWP coupled with pumped hydro storage. In particular the modeling results compare the system behavior when operating under the fixed price regime versus dynamic pricing defined by use of locational marginal prices. In addition, benefits from allowing the Kenya Power Company to spill wind as needed, rather than a strict requirement to take all wind power generated are investigated. The results demonstrate that the inclusion of system-driven prices produce a significantly different operational strategy than the fixed price model. Results also show that the exclusion of dispatch flexibility in the form of wind curtailment results in increased price volatility, particularly during periods of high winds."
2140067,22457,20561,Omnisphere: a personal communication environment,2003,"Small ubiquitous devices connected by wireless networks will become future Internet appliances. To support them, communication networks must evolve to seamlessly assist appliances and provide advanced functionalities. We present a personal communication environment called Omnisphere that provides a communication and information universe surrounding wireless appliances. It is based on a high level concept called ambient services that allows to construct complex services out of primitive ones by connecting them with typed data flows. A typed data flow is an abstract view of communication between ambient services. It encapsulates three elements: channels, control, and metadata. Omnisphere provides a predefined service for discovery of component services and binding them together with data flows. Our strategy for service discovery is to delegate most of the operations to the network infrastructure and to automate them as much as possible. Based on the user ID and appliance ID, Omnisphere retrieves the information that restricts the set of possible services: User preferences, device capabilities, and context. It then makes use of existing discovery protocols such as SLP, Jini, or UPnP to discover relevant services and matches them with the required characteristics. Such a discovery process relieves appliances, which may have limited resources, from the operation that may consume scarce resources and may require the availability of different discovery protocols on the appliance."
2273217,22457,20561,Web community of agents for the integrated logistics of industrial districts,2003,"Industrial districts are characterized by the agglomeration of medium and small-sized industries, localized within a certain geographic area with precise social and cultural connotations. A crucial element of industrial districts is the existence of a wide immaterial flow of knowledge and information. In this sense, industrial districts seem to have a network shape, rather than a hierarchical one. The paper aims to rationalize transportation flow within industrial districts. In particular, it focuses on districts in the first stage of the evolution process; that is, when a lot of companies exist, with low specialized level and absent inter-firm cooperation. Therefore, the considered industrial districts are characterized by nonlinear mechanisms of interaction among a variety of entrepreneurs, each of them trying to reach their target by conflicting with others, increasing the complexity of the system under examination and making more difficult the strategies for material flow rationalization. In this situation, a system able to facilitate both the contacts among agents and the negotiation processes, that creates a community of agents in a district with rare or absent relationships among different companies represents the most adequate solution. The paper deals with the definition of a community of agents in a real situation, using communityware tools - Web electronic media that facilitate contact with collaborators who have similar interests and preferences, but do not know each other. To define the similarity concept, a fuzzy algorithm is proposed."
2429996,22457,20561,Broadband penetration and participatory politics: South Korea case,2004,"This paper examines the potential impact of the Internet on the political process in a young democracy. Roh Moo-hyun's dramatic victory on December 19, 2002 represents a major watershed in modern day South Korean politics. The Internet enabled this upset victory. The Internet made available alternative sources of political information unfiltered by the conservative and often biased mass media. Citizens distributed worldwide could express their support for Roh Moo-hyun in the public forums on his official site and many other news and discussion sites. Rohsamo, a group of people who support Roh Moo-hyun, became the focal organizing structure around which the efforts of individual supporters were coordinated. In this paper, we draw on primary and secondary data sources and relate broadband penetration to political participation. We suggest that Roh's election would not have been possible had it not been for the nationwide broadband infrastructure and low costs for household high-speed Internet access. South Korea's broadband penetration rate is four times higher than the United States, 60 times higher than the United Kingdom and twice that of Canada. As the world's leader in broadband penetration and Internet usage, the South Korean case illustrates the potential impact of widespread Internet access on the democratization process in developing countries."
872495,22457,9896,Blogs as a collective war diary,2012,"Disaster-related research in human-centered computing has typically focused on the shorter-term, emergency period of a disaster event, whereas effects of some crises are long-term, lasting years. Social media archived on the Internet provides researchers the opportunity to examine societal reactions to a disaster over time. In this paper we examine how blogs written during a protracted conflict might reflect a collective view of the event. The sheer amount of data originating from the Internet about a significant event poses a challenge to researchers; we employ topic modeling and pronoun analysis as methods to analyze such large-scale data. First, we discovered that blog war topics temporally tracked the actual, measurable violence in the society suggesting that blog content can be an indicator of the health or state of the affected population. We also found that people exhibited a collective identity when they blogged about war, as evidenced by a higher use of first-person plural pronouns compared to blogging on other topics. Blogging about daily life decreased as violence in the society increased; when violence waned, there was a resurgence of daily life topics, potentially illustrating how a society returns to normalcy."
2223359,22457,20561,Leveraging the Wisdom of Crowds: Designing an IT-Supported Ideas Competition for an ERP Software Company,2008,"Crowdsourcing is currently one of the most discussed key words within the open innovation community. The major question for both research and business is how to find and lever the enormous potential of the collective brain. This research in progress paper provides an approach for finding and leveraging innovations for an ERP software company among its user base. This is done by designing an IT-supported ideas competition within the SAP UCC (University Competence Center) User Group to use the potentials of the collective intelligence of this crowd. The German SAP UCC User Group consists of about 60,000 people (lecturers and students) using SAP software for educational purposes. The practical problem is twofold: On the one hand, there is not much activity yet in this community. On the other hand, SAP has not tried to systematically address this highly educated group for idea generation or innovation development so far. Therefore, the objective of this research is to generate innovations, process and product ideas for SAP Research and Development through an IT-supported ideas competition among the SAP UCC Community. Furthermore, the concept aims at providing an interface to SAP Human Resources processes in order to identify the most promising students in this VC This paper follows an action research approach. It is focusing on the diagnosing and action planning phase to develop an integrated concept of the ideas competition within the VC."
2012114,22457,20561,Hitting the wall: errors in developing and debugging a simple spreadsheet model,1996,"Undergraduate MIS business students developed and debugged a spreadsheet model from a word problem. This model consisted of a bid to build a wall. The problem was designed to be relatively simple and domain-free to address the concern that past spreadsheet experiments may have used problems that were too difficult or that required domain knowledge that subjects did not have. During the development phase, 72 subjects created the spreadsheet model. Even with this rather simple problem, 38% of the models contained an error. This high number of incorrect spreadsheets was not due to subjects making many errors. They only made 0.4 errors per spreadsheet. In addition, their cell error rate (CER) was only 1.7%, meaning that only 1.7% of their cells contained errors. Unfortunately, spreadsheets tend to have long cascades of cells leading to the bottom line. This means that even tiny cell error rates will multiply into high rates of bottom-line errors. In a debugging phase, subjects tried to debug their own models. Of 19 subjects with incorrect models who did the debugging part of the experiment, only three (16%) found and corrected their errors. So even with a relatively simple model, development and debugging were problematic. This is a fewer rate of finding errors than (Galletta et al., 1993; 1996) found when subjects debugged models created by the experimenter. This may mean that people are not as good at debugging their own models as they are at debugging models created by others."
1894452,22457,20561,E-mail Bounce Management using Text Mining,2009,"Direct marketers assign the communication channel e-mail an increasing importance, evolving a marketer’s collection of customer e-mail addresses to an asset of important business value in order to provide customers the right offer at the right point in time. Besides the design and content of an e-mail campaign the e-mail-transportation process is of critical importance to really reach your potential customer. Possible errors in the transportation can be of either permanent – hardbounces – or temporary nature – softbounces. With the transportation error communication by internet-service-providers lacking of compliance to existing standards, companies face the problem of having inaccurate information regarding deliverability. And quite often this results in the blocking of actually intact potential customer addresses. Therefore a model processing bounce messages and predicting the possibility of deliverability using semantic information obtained through text mining and the embedded Singular Value Decomposition is presented. We discuss the application of text mining tools regarding error messages and apply a multistaged decision model that minimizes the falsenegative-rate to discard addresses with permanent non-deliverability from the database while identifying addresses that maintain business value although being bounced."
701377,22457,20561,Power system bidding tournaments for a deregulated environment,1997,"We describe certain tools for understanding and operating power systems in a deregulated environment. Many of the current models for this competitive market that employ an independent system operator (ISO) for controlling transmission, ensuring fair access and security, and providing a spot market for power are studied. This centrally dispatched power pool also ensures that generation meets demand based on bids submitted daily from independent generators (and from customers offering interruptible loads). Currently, most ISO bidding models allow only a single bid per day. We present an asynchronous bidding scheme as a possible alternative. In particular, we examine the effects of including a feedback mechanism such that upon receiving generation levels from the ISO, independent generators (IGs) be allowed to modify their bid if they so desire. This competitive or 'sequential' bidding process should be allowed to take place each day for a predetermined period of time; in this way, IGs will have a chance to compete and hopefully optimize their profit margins. The paper also discusses the development tools necessary for examining the effects of different bidding processes on the ISO model and evaluating their capability of driving the market to an efficient state of operation."
1967805,22457,20561,Global comparisons of key issues in IS management: extending key issues selection procedure and survey approach,2000,"Information systems (IS) departments face many challenges in today's rapidly changing environment. One approach to understanding these challenges is to survey IS managers to elicit what they consider are key issues. Studies of key IS management issues have been conducted for some years in many nations and regions. However, most of these surveys lack a theoretical basis for the selection of key issues. Furthermore, most studies have used a single-round or a multi-round Delphi method. This paper provides an overview of research approaches to key issues studies combined with key issues results from previous research. The paper presents methodological issues and choices for a survey on key issues in IS management which was conducted in Norway in 1998. A three step procedure for key issues selection is introduced, and a Q-method analysis is adopted. The paper presents results from the Q-sort survey and analysis. The highest ranked key issue in Norway, according to the survey, is concerned with improving links between information systems strategy and business strategy. Global comparisons of key issues in information systems management confirm this top ranked issue. Also, the issue of planning information technology projects for competitive advantage is a high ranking issue in Norway and most other countries. Improving interorganizational information systems planning was the third highest ranked issue in Norway, but it is non-existent in other survey lists. This can be partly explained by the lack of theoretical framework when issues were selected in other studies and by the small organizational sizes in Norway."
2270682,22457,20561,Multi-enterprise collaborative enterprise resource planning and decision support systems,2004,"Enterprise resource planning (ERP) and decision support systems (DSS) have independently evolved and prospered in the marketplace as well as in academia. More recently, ERP and related systems such as customer relationship management (CRM) and supply chain management (SCM) are incorporating decision support tools and technologies. These include business intelligence, customer intelligence, supply chain intelligence, and business analytics. At the same time, DSS are taking advantage of the data resident in ERP systems. This emerging convergence has motivated us to look at the integration of ERP and DSS. The integration of ERP and DSS provides firms with a number of advantages. First, they are able to maximise their Intelligence Density. Second, they are able to improve the quality and visibility of their information. Finally, they can form a solid foundation from which they can achieve multi-enterprise collaboration. Over the years, researchers and practitioners have proposed frameworks and architectures for ERP and DSS exclusively. However, there is little in the way of academic literature, frameworks, architectures, and implementations that integrate ERP and DSS in a coherent fashion. We address this area of research by first conducting a review of the independent and combined literature in the fields of ERP and DSS. This literature review paves the way for the proposal of a multi-enterprise collaborative conceptual ERP-DSS framework that considers SCM, enterprise management, and CRM as components. This framework brings together the ERP and DSS integrated solutions offered by a host of well-known vendors in the marketplace. We then combine our own insight with respect to multiple-enterprise collaboration via the integration of ERP and DSS to propose a set of high-level and medium-level system frameworks. These system frameworks depict the mechanisms behind the integration of ERP and DSS both within the firm, and in a multi-enterprise collaborative context."
2291994,22457,20561,The generative dance in pursuit of generative knowledge,2003,"This paper describes how a group working around the emotionally-charged topic of cultural and linguistic appropriateness created new knowledge about practice, and in particular practice about keeping a knowledge problem constantly open for inquiry. The group's work focused on the creation of a database of materials to support and educate practitioners in their field. Interviews with 23 participants revealed that key to their success was learning and growth in understanding the importance of opening up discussion on what appropriateness meant to group members, assumptions about appropriateness, and how to approach appropriateness on the way to deciding what to include in the database. Moreover, the group learned how to discuss and move forward a project based in the discussion of hotly contested areas in the face of passionately held beliefs. Cook and Brown's (1999) view that new knowledge arises from a generative dance between what knowledge is possessed by the individual and what is inextricably linked to practice, resonated with the kind of interaction and problem solving we found in this group. We adopt their perspective to interpret our data and further appropriate their terminology when we refer to and identify generative knowledge: an epistemically productive kind of knowledge predicated on constant openness, and characterized by repeated evaluation and interpretation of a problem."
2487026,22457,20561,Affective computing in tele-home health,2004,"This study exemplifies the integration of IS behavioral science in the area of technology adoption and diffusion into the design science process. We first identify the computer-mediated paradox, as it exists in the tele-home health care setting. Specifically, we address the challenges of providing quality patient inclusive of affective assessment. From the design science perspective, we then introduce an intelligent interface (MOUE) aimed at discerning emotional state from processing sensory modalities (or modes) input via various media and building (or encoding) a model of the user's emotions. We contextualize MOUE within the tele-home health care setting to provide the health care provider with an easy-to-use and useful assessment of the patient's emotional state in order to facilitate patient care. We then use an IS adoption model developed and tested in the general telemedicine context in a qualitative exploratory manner as a means to inform design science regarding adapting affective state output in consideration of tele-home health adoption and diffusion issues. Based upon this integrative exploration, we propose to expand the application of Wizard of Oz type studies by Dahlback, N., et al., (1998) to computer-mediated communication (CMC) environments to investigate how emotional state assessments influence responses from health care professionals and how MOUE can be accepted into the health care environment."
2023468,22457,20561,Framework for Establishing Enterprise Modeling in the Context of Collaborative Enterprises,2007,"Increased market dynamics, shorter product lifecycles and a higher customer involvement in product design have caused great changes to competitive conditions and many companies are confronted with the challenge of becoming interoperable. Becoming interoperable tackles a lot of areas within an enterprise (e.g. organizational structures, processes etc.) and the problem for most enterprises consist in identifying their weaknesses and strengths concerning their interoperability capabilities. Enterprise models have the goal to reduce complexity and give a representation of structures, activities, processes, information, resources, people and behavior of an enterprise and the dependencies between them. Especially for enterprise collaborations, models help to understand each other, to plan, implement and to support interactions. But most companies are not ready yet to harvest the benefits of enterprise modeling and fail in establishing model based collaborations. In the frame of enterprise integration and user oriented enterprise modeling this paper introduces an approach that supports enterprise stakeholders to implement enterprise modeling within collaborative companies. One objective is to present an approach that enables companies to get the most effect out of enterprise modeling in a collaborative environment based on the maturity of their organization relative to modeling. Further on, an enterprise modeling based establishment methodology can be presented which enables companies to understand and manage their current enterprise interoperability maturity. The methodology can describe discrete levels of interoperability improvement based on the successive adoption of good enterprise modeling practices in the different enterprise dimensions"
2409915,22457,20561,Visualization and Characterization of Stability Swings via GPS-Synchronized Data,2007,"This paper provides a methodology to characterize the accuracy of PMU data (GPS-synchronized) and the applicability of this data for monitoring system stability via visualization methods. GPS-synchronized equipment (PMUs) is in general higher precision equipment as compared to typical SCADA systems. Conceptually, PMU data are time tagged with precision better than 1 microsecond and magnitude accuracy that is better than 0.1%. This potential performance is not achieved in an actual field installation due to errors from instrumentation channels and system imbalances. Presently, PMU data precision from substation installed devices is practically unknown. On the other hand, specific applications of PMU data require specific accuracy of data. Applications vary from simple system monitoring to wide area protection and control to voltage instability prediction and transient stability monitoring. The paper focuses on the last application, i.e. transient stability monitoring. We propose an approach that is based on accurate evaluation of the system energy function (Lyapunov indirect method) and extraction of stability properties from the energy function. Specifically, we provide a methodology for determining the required data accuracy for the reliable real time estimation of the energy function. When the data meet these requirements, the estimated energy function can be visualized and animated providing a powerful visual tool for observing the transient stability or instability of the system"
2186739,22457,20561,Simulation Games for Collaborative Development in E-Government,2010,"Governments aim to improve service delivery to citizens and businesses and need to transform to accomplish efficiency savings and better customer orientation. This requires the coordination of dependencies among the various departments located in the frontend and backend of organizations, and might include interdependencies with external parties. Transforming this fragmented landscape requires an understanding of issues at play, and the collaborative development of possible solutions. Every stakeholder has its own perspective, background, knowledge, and interests, and with their own situation and issues in mind, they often fail to grasp the bigger picture. Simulation games refer to a situation in which human participants play a role and follow certain rules to simulate a complex real-world phenomenon. Such a game can enhance participant's understanding of the complexities involved in the big picture, which might facilitate improvement. In this paper we present and evaluate a simulation game for public service delivery. The game facilitates problem-oriented learning and collaborative improvement of public service delivery. We measured participant views on the success of the collaboration in multiple sessions, using observations and a survey. The analyses show that participants find the process of the game successful and are willing to commit resources to it."
1850317,22457,20561,The educated person in the next millennium,1997,"There are many questions about how new communication technologies are going to impact all organizations and what changes such mediated communication tools will have on all of society. One question that should be addressed in this kind of conference can be succinctly stated as follows: Given the rapid changes in information and communication technology, does anything that is offered in existing management curricula really pertain to the kinds of organizations that will exist in the very near future? That is a legitimate question for there is no question that the kinds of technological innovations that have occurred and will continue to occur at an increasing rate are going to change the nature of the workplace as well as all other aspects of life as: we know it. Technology, especially the kind of high-speed communication/information technology being developed, does not change anything in an additive manner. Rather, it changes everything, always. That we are going to be electronically interconnected within our own work environments and with the world via relatively unexplored channels like the Internet, CD-ROMs, cellular communication equipment, personal digital assistants and other electronic innovations is a fact. That the nature of work and communication patterns will be forced to change as we become even more technologically sophisticated is simply not debatable. We intuitively accept the fact that this explosive change has occurred already and will continue to occur."
1958843,22457,20561,CUMULVS: extending a generic steering and visualization middleware for application fault-tolerance,1998,"CUMULVS is a middleware library that provides application programmers with a simple API for describing viewable and steerable fields in large-scale distributed simulations. These descriptions provide the data type, a logical name of the field/parameter, and the mapping of global indices to local indices (processor and physical storage) for distributed data fields. The CUMULVS infrastructure uses these descriptions to allow an arbitrary number of front-end viewer programs to dynamically attach to a running simulation, select one or more fields for visualization, and up-date steerable variables. (Viewer programs can be built using commercial visualization software such as AVS or custom software based on GUI interface builders like Tcl/Tk.) Although these data field descriptions require a small effort on the part of the application programmer, the payoff is a high degree of flexibility for the infrastructure and end-user. This flexibility has allowed us to extend the infrastructure to include application-directed checkpointing, where the application determines the essential state that must be saved for a restart. This has the advantage that checkpoints can be smaller and made portable across heterogeneous architectures using the semantic description information that can be included in the checkpoint file."
448509,22457,20561,A Risk-Averse Optimization Model for Unit Commitment Problems,2015,"In this paper, we consider the unit commitment problem of a power system with high penetration of renewable energy. The optimal day-ahead scheduling of the system is formulated as a risk-averse stochastic optimization model in which the load balance of the system is satisfied with a high prescribed probability level. In order to handle the ambiguous joint probability distribution of the renewable generation, the feasible set of the optimization problem is approximated by an quantile-based uncertainty set. Results highlight the importance of large sample size in providing reliable solutions to the SCUC problems. The method is flexible in allowing a range of risk into the problem from higher-risk to robust solutions. The results of these comparisons show that the higher cost of robust methods may not be necessary or efficient. Numerical results on a test network show that the approach provides significant scalability for the stochastic problem, allowing the use of very large sample sets to represent uncertainty in a comprehensive way. This provides significant promise for scaling to larger networks because the separation between the stochastic and the mixed-integer problem avoids multiplicative scaling of the dimension that is prevalent in traditional two-stage stochastic programming methods."
1903657,22457,20561,SMAT: Synchronous Multimedia and Annotation Tool,2001,"We describe the design and use of SMAT (Synchronous Multimedia and Annotation Tool), a tool designed to be part of a scientific collaboratory for use in a robotic, arc-welding research project at the National Institute of Standards and Technology (NIST). The primary functional requirements of SMAT are to provide the capability to capture, synchronize, play back, and annotate multimedia data in a multi-platform, distributed environment. To meet these requirements, SMAT was designed as a control and integration framework that exploits existing tools to render specific media types and control annotation sessions. SMAT defines a component architecture framework where existing tools can be plugged in and controlled using a distributed, event-driven, tool-bus architecture. SMAT's modular architecture enables control inputs to come from anywhere in the distributed collaborative environment, thus allowing for simultaneous remote and local control of the tool, as well as painless interfacing with the existing collaborative environment. SMAT is built on an agent middleware called AGNI (Agents at NIST), also developed at NIST. We give an overview of AGNI that can be used to build failure-resilient, distributed, event-driven applications. In addition to describing SMAT's design, interface and underlying middleware, we present performance information, an initial analysis of welding users' experiences and feedback, related work, and directions for further SMAT development."
1947123,22457,20561,Increase in computing capability and its influence on service provision,2004,"Applications of information technology (IT) have in no doubt had significant impact in every stage of service provision, production, delivery, receipt and quality. Today, the greatly increased use of IT by service providers has in many ways changed the nature of service delivery. The dynamism and rapid changes in IT which progress from traditional business computing to mobile and pervasive computing and which is now tending towards ubiquitous computing have posed serious challenges to service globally. Service in the industrial era was well understood. It was considered distinct to product and limited by geographical locations and technological constraints. However, as we are entering the knowledge era, where knowledge has become the main competitive advantage, the distinction between services and products are blurring with increase application of information technology, and there seems to be no limit to what could be achieved with technology. Dynamism in the production of information technology also requires corresponding dynamism in its applications to the service provision. However, there is lack of adequate attention to these issues in information systems research and practice. There is little understanding of how the rapid changes and developments in IT could affect service provision. Using the four characteristics of service - intangibility, inseparability (of production and consumption), perishability and heterogeneity, this paper examines service provision, the current trends in ubiquitous computing and the possible changes it could have on service provision."
2577455,22457,20561,"The use patterns of large, interactive display surfaces: Case studies of media design and use for blueboard and MERboard",2004,"During the past several years we have been developing large, interactive display surfaces for collaboration uses in a variety of work settings. People in small work groups can easily create, annotate and share media with their partners. The Blueboard, developed at IBM Research, is a large display system for groups to use in exchanging information in a lightweight, informal collaborative way. It began as a large, ubiquitously placed display surface for walk-by use in a corporate setting and has evolved in response to task demands and user needs. At NASA, the MERboard is being designed to support surface operations for the upcoming Mars exploration rover missions. The MERboard extends the design to support the collaboration requirements for viewing, annotating, linking and distributing information for the science and engineering teams that will operate two rovers on the surface of Mars. Here we examine differing implementations of the same idea: a collaborative information tool that began from the same design goals, but which grew into somewhat different systems under the evolutionary pressures of the NASA and IBM task environments. Lessons about how media are designed, task requirements for collaborative use, information flow requirements and work practice drive the evolution of a system are illustrated."
2236022,22457,20561,Modeling the Economic Cost of Transmission Bottlenecks,2007,"The purpose of this paper is to model the stochastic behavior of nodal prices and use the predicted price differences between zones as the basis for measuring the magnitude and riskiness of congestion costs using the New York State electricity market as an example. The first step uses a principal components analysis to simplify the structure of nodal electricity prices in New York State, reducing 405 hourly prices in 2005 to less than 10 factors that explain 99% of the total price variability and correspond closely to established zones in the State. The analysis focuses on the Hudson Valley and New York City because these two zones are linked by one of the most important transmission bottlenecks in the State. A multivariate time series model for hourly temperature in different zones is estimated using data from January 1st 2000 to December 31st 2005 to represent the primary source of variability due to the weather. Multivariate models for the hourly electricity load in different zones conditionally on the temperature, and the hourly spot price of electricity in different zones conditionally on temperature, the load and the price of natural gas. By focusing on the zonal prices in the Hudson Valley and New York City, it is possible to simulate different realizations of temperature and to determine the financial riskiness of revenues from the price differences due to transmission congestion between these two zones. This in turn is an essential piece of information for evaluating the incentives for investing in merchant transmission upgrades between these two zones."
1985763,22457,20561,Locational pricing and scheduling for an integrated energy-reserve market,2003,"It is well known that given a network that can become constrained on voltage or real power flows, reserves must also be spatially located in order to handle all credible contingencies. However, to date, there is no credible science-based method for assigning and pricing reserves in this way. Presented in this paper is a new scheduling algorithm incorporating constraints imposed by grid security considerations, which include one base case (intact system) and a list of possible contingencies (line-out, unit-lost, and load-growth) of the system. By following a cost-minimizing co-optimization procedure, both power and reserve are allocated spatially for the combined energy and reserve markets. With the Lagrange multipliers (dual variables) obtained, the scheduling algorithm also reveals the locational shadow prices for the reserve and energy requirements. Unlike other pricing and scheduling methods in use, which are usually ad-hoc and are based on engineering judgment and experience, this proposed formulation is likely to perform better in restructured markets when market power is a potential problem. An illustrative example of a modified IEEE 30-bus system is used to introduce concepts and present results."
1941240,22457,20561,A Multi-Agent Infrastructure for Mobile Workforce Management in a Service Oriented Enterprise,2005,"With recent advances in mobile technologies and infrastructures, there are increasing demands for the support of mobile workforce management (MWM) across multiple platforms. Mobile users can interact with the MWM system through SMS messages or Web browsers from personal computers, PDA devices, or WAP phones. MWM typically involves tight collaboration, negotiation, and sophisticated business domain knowledge. Therefore, the main challenge of MWM for a service oriented enterprise is the integration of disparate business function for its mobile professional workforce and the management with a unified infrastructure, together with the provision of personalized assistance and automation. These requirements can be facilitated with the use of intelligent software agents, but has not been adequately studied before. As mobile devices become more powerful, intelligent software agents can now be deployed on these devices and hence also subject to mobility. Thus, MWM systems have to accommodate these requirements as well as the support of heterogeneous platforms. In this paper, we formulate a scalable, flexible, and intelligent multi-agent information system (MAIS) infrastructure for MWM with agent clusters in the context of a large service oriented enterprise. Each agent cluster comprise several types of agents to achieve the goal of each phase of the workforce management process, namely, task formulation, matchmaking, brokering, commuting, and service. We evaluate our approach against different stakeholders' perspective."
1995260,22457,20561,"Looking Ahead: A Contributor's Perspective on the Next-Stage Advances in Competitive Strategy, Economics and Information Systems Research",2007,"The author discusses several directions for research in the area of competitive strategy, economics and information systems. He remarks center on the potential for advances in the following areas: (1) the macroeconomic impacts of technology, and opportunities to explore the issues, theories and methods of aggregate analysis relative to IT industry agglomeration, technology diffusion and firm strategies; (2) theoretical and methodological knowledge for the exploration of technology adoption and business value, by leveraging the tensions from game-theoretic equilibrium analysis outcomes and technological change-led transformations; (3) further developing our valuation, risk management and services science approaches for business processes involving organizational systems, interorganization relationships, and market connections. The latter applies in such contexts as e-commerce services pricing, utility computing and Web services, and managerial approaches to IT project portfolio management. His expectation is that there is much to be learned in the next twenty years about that managerial decision-making in a world of business operations that involve mobility, and ubiquitous data and support, and technologies that will transform production, consumption, market value, social welfare and the way our business economy works"
1097410,22457,20561,The impact of experience on individual performance and workload differences using object-oriented and process-oriented systems analysis techniques,1996,"Interest in object oriented analysis (OOA) and object oriented design (OOD) has increased over the last several years. Proponents of OOA and OOD have called the shift to these methods revolutionary and have cited a number of impressive claims with respect to their use. However, empirical research investigating these claims remains in its infancy. This research study was conducted to test theoretical hypotheses designed to better understand the findings of previous research. The paper presents the results of an empirical study which examined both experienced and novice systems analysts using both procedural and object oriented techniques. This research examined whether experience in using procedural methods helped or hindered performance using OOA and compared procedural and OOA methods on the subjective mental workload induced. A cognitive processing model adapted from DeSanctis (1984) and Huchins, Hollan, and Norman (1985) provided the theoretical framework for this study. Dependent variables include subjective mental workload time to perform task, and attitudinal measures. While some of these dependent variables have been used in past research, we believe this is the first time that subjective mental workload (SMW) has been examined in an IS context. Our results indicate that both novice and experienced subjects demonstrate higher SMW when using OOA. However as a group, novices prefer object oriented techniques and find these techniques easier as compared to experienced subjects."
2492006,22457,20561,Interoperability by 'Edgeware': Wireless Grids for Emergency Response,2011,"'Edgeware' for wireless grid connectivity, utilizes open specifications developed by the National Science Foundation (NSF) Partnerships for Innovation (PFI) 'Wireless Grid Innovation Testbed' (WiGiT) to enable greater interoperability across devices, networks, applications, content and services. A wide range of new 'edgeware' applications is emerging for businesses, education, government agencies and individuals. Challenges in emergency response include interoperability, social and human factors. 'Edgeware,' a new class of software designed to share resources across people, devices, services and content has the potential capacity to solve problems of interoperability and control over resources, by the creation of wireless grids. This will allow people to access programs and data on disparate devices, across available wired and wireless networks and provide greater access to resources. Emergency services applications of wireless grids will empower citizens through their devices to contribute to their own community response. The authors describe 'Neighborhood Notification System' gridlets, now in development, which are just the first examples of use of wireless grids for emergency response. The authors conclude that police, fire, EMS, hospitals, municipal services, utilities, gas companies, media, and community residents will benefit from enhanced information sharing in emergencies based on this interoperability by 'edgeware' solution."
1950385,22457,20561,Reliability Assessment at Day-Ahead Operating Stage in Power Systems with Wind Generation,2013,"This paper proposes to evaluate reliability performances at operating stage for power systems with variable wind generation. This is a first step towards recognizing the stronger coupling of power system decision making across different timescales. In the day-ahead energy-reserve co-optimization unit commitment model, the validity of using operating reserve as an approximation of long-term reliability requirement is tested with realistic wind generation profile. Reliability indices such as Loss of Load Probability (LOLP) and Loss of Expected Energy (LOEE) are computed at each hour of the day at the conclusion of the day-ahead unit commitment decision. Numerical experiments conducted in the IEEE Reliability Test System suggest that while operating reserve requirement does not change within a day, the actual reliability performance of the system varies significantly depending on (i) system loading conditions , (ii) wind power variation, and (iii) operating rules. Also, the operating reserve requirement is shown to either over-approximate or under-approximate the reliability requirement of power system. It indicates that operating reserve could be a very coarse deterministic approximation of system reliability requirement especially with high wind penetration. A much more integrated approach for modeling, analysis, and decision making is envisaged for provision of reliable and cost-effective electricity services."
1820696,22457,20561,A Detailed Power System Planning Model: Estimating the Long-Run Impact of Carbon-Reducing Policies,2015,"In this paper, a much more detailed representation of the nation's electricity system than has been traditionally used in policy models is employed. This detailed representation greatly increases the computational difficulty of obtaining optimal solutions, but is necessary to accurately model the location of new investment in generation. Given the proposed regulation of CO2 emissions from US power plants, an examination of economically efficient policies for reducing these emissions is warranted. The model incorporates realistic physical constraints, investment and retirement of generation, and price-responsive load to simulate the effects of policies for limiting CO2 emissions over a twenty-year forecast horizon. Using network reductions for each of the three electric system regions in the U.S. And Canada, an optimal economic dispatch, that satisfies reliability criteria, is assigned for 12 typical hour-types in each year. Three scenarios are modeled that consider subsidies for renewables and either CO2 emissions regulation on new investment or cap-and-trade. High and low gas price trends are also simulated and have large effects on prices of electricity but small impacts on CO2 emissions. Low gas prices with cap-and-trade reduce CO2 emissions the most, large subsidies for renewables alone do not reduce carbon emissions much below existing levels. Extensive retirement of coal-fired power plants occurs in all cases."
2556634,22457,20561,Strategic management of IS/IT functions: the role of the CIO,2000,"Chief information officers (CIOs) have the difficult job of running a function that rues a lot of resources but offers little measurable evidence of its value. Line managers are increasingly assuming responsibility for planning, building, and running information systems that affect their operations. To respond to business and technological changes, CIOs now must build relationships with line managers and assume new and more strategic roles. The strategic role of the CIO is becoming ever more complex, requiring an expansion of the organizational and structural possibilities for filling that role. This paper presents an extensive literature review on the role of the CIO. The research examines CIO role in Norwegian organizations. In this paper, results from a survey of Norwegian CIOs are presented. Norwegian CIOs have on average worked in the current organization for eight years, have worked in information technology (IT) for twelve years, report mostly to the CEO or CFO, and have eleven people reporting to them. A large percentage have a masters degree. Also, formal IS planning tended to be adopted by organizations with higher annual revenue, larger number of total employees, and broader span of control (i.e., the number of people reporting to the CIO). Higher CIO reporting level was also associated with greater extent of information systems plan implementation."
2313063,22457,20561,Enterprise Information Architecture (EIA): Assessment of Current Practices in Malaysian Organizations,2007,"In this paper we described the findings based on a research study on current enterprise information architecture (EIA) practices in Malaysian organizations. Ten organizations from public and private sectors were chosen for case study analysis. The Zachman framework was chosen as a guideline to assess the current practice of EIA in these organizations. This study had successfully investigated the current practice and conditions of EIA in selected public and private organizations in Malaysia. The study found that majority of the organizations do practice some kind of enterprise information architecture either in-house or outsource to third parties. The study also found that certain aspects of the framework were not addressed at all, whilst other aspects that were addressed vary in terms of the different perspectives. This gives a general outlook of EIA implementation in the selected organizations, which could be incomplete or not adequately addressed. The study revealed a poor knowledge and understanding of EIA among the organizations though there had been efforts at implementing EIA focusing on the data, function and network architectures. The study discovered gaps in the current practice and provides suggestions for organizations to consciously embark on the EIA paradigm in order to better align the whole organization to its goals. Results of this study can be used by the government and private sectors to formulate new policies and guidelines on enterprise architecture so that the enterprise's IT adoption and information requirements fit nicely into its business strategy"
1844043,22457,20561,The nature of knowledge and its influence on knowledge sharing practice: experiences from building the MACROS system,2004,"This study investigates how the interactive influences of the nature of knowledge and multiple organizational and technological factors - trust, leadership, incentives and issues, group size and variety, implementation strategy, and technology - facilitated and/or impeded the knowledge sharing processes. Using a case study approach, the research focuses on the modifying effects of four characteristics of knowledge- codifiability, context-embeddedness, practice-embeddedness, and dynamics- on the processes and outcomes of knowledge sharing in a case of building the multi-purpose access for customer relations & operational support (MACROS) system involving multiple organizations, divisions, and geographically separated offices. The case results suggest that modifying effects occurred along at least three dimensions- codifiability, context-embeddedness, and practice-embeddedness. The levels of codifiability appeared to dictate the implementation strategy; reduced context-embeddedness allowed for more effective group coordination; reduced context-embeddedness also enhanced trust; codified knowledge is more effective than uncodified knowledge in demonstrating concrete incentives; and technology interacts with context-embeddedness and practice-embeddedness. The results of this study have theoretical and practical implications for a larger set of problems encountered in sizable organizations. More specifically, even though the relevance of the nature of knowledge has been widely acknowledged by I. Nonaka, et. al. (2001), it is not always clear how it comes into play. This study conceptualized the nature of knowledge as a modifying variable, and the results provide a new and more comprehensive framework for investigating the relevance of the nature of knowledge in knowledge management research."
2180443,22457,20561,Combining Structured and Unstructured Information Sources for a Study of Data Quality: A Case Study of Zillow.Com,2011,"Zillow is a web-based, leading real-estate information service in the US. We studied user-contributed facts in a sample of Zillow records. User-contributed information seems to improve the completeness and the level of detail of the information on Zillow.com. However, the accuracy of user-contributed facts may not be high. An investigation of the sources of error revealed several weaknesses, including conceptual challenges, information integration failures, and design deficiencies. A lack of shared, user-friendly, conceptual foundation has been found to be a significant drawback. In part, errors are a product of Zillow's wide geographic coverage and highly networked operation. In addition, important peculiarities of a property are often unknown to the public. Information about such peculiarities is typically shared by a small group of people, whose levels of expertise and stakes in that property, and in real estate in general, may differ. This environment poses a challenge for harnessing the collective intelligence. The results demonstrate the success of our unique evaluation strategy, which utilizes a systematic review of a rich set of online sources. A similar strategy may also be useful for large-scale error detection and correction, if an efficient automated equivalent is developed to implement it."
1867698,22457,20561,Strategic and Institutional Perspectives in the Adoption and Early Integration of Radio Frequency Identification (RFID),2007,"Using multiple lenses of strategic choice theories (diffusion of innovation, organizational innovativeness) and institutional theory as the basis and reflecting data from semi-structured interviews and news reports, the study develops an integrative conceptual RFID adoption model and presents testable hypotheses at the construct and rationale levels. The model incorporates different rationales for adoption and integration of interorganizational systems (IOS) namely the strategic choice perspective where adoption is voluntary with a view to improve organizational efficiency and performance and the institutional perspective where adoption is more a result of conforming to pressures from organizations within an organization's field of operation. Two technological factors (perceived benefit and perceived costs), three organizational readiness factors (top management support, financial readiness, IS infrastructure and capabilities) and three external environmental factors (perceived standards convergence, perceived consumer privacy and perceived stakeholder privacy) have been suggested as adoption and integration drivers from a strategic choice perspective while the three inter-organizational pressure factors (coercive, mimetic and normative pressures) have been proposed as predictors of adoption intent and expected integration from the institutional perspective . The study allows for a comparison of the relative influence of each rationale on the adoption and post adoption integration decisions by a firm"
933308,22457,20561,Introduction to Social Networking and Communities Minitrack,2012,"This minitrack has been ongoing under various titles since 2003. Over those years, our emphasis has continued to be on exploring how social media - internet, email, twitter, blogs, social networking, and more - affect the development and support of community-based endeavors. We consider community quite broadly to include work and learning groups, as well as more general social collectives. The empirical and theoretical papers that make up this minitrack address online communities of practice, inquiry, and interest relating to political, educational, business, social, and/or gaming pursuits, with attention to how online community building and management contribute to success in the digital economy and society. While the focus is primarily directed to online communities, papers also address the important interplay between online and offline worlds. The minitrack continues to attract a lot of interest and this year nine papers were selected following peer review of 21 submissions (43% acceptance rate). Papers this year examine issues of psychology and behavior, e.g., in papers on addiction, flaming, and unfriending, Crossover effects between the online and offline worlds, e.g., for those out of work, and those in academia, Learning and information exchange online, And effects and results of in-world, in-community online behavior."
1928574,22457,20561,Legal Issues in Agents for Electronic Contracting,2005,"Intelligent agents are a new emerging technology that allows for machine-to-machine contract formation. Agents equipped with a set of rules instructed by humans, surf the web, discover other agents and/or humans, and take decisions forming agreements in an autonomous way. Despite recent legislations on electronic contracting, there are no legislations governing automatic agent transactions except one preliminary attempt in the USA. In this paper, we are looking into the new legal issues that arise due to intelligent agents in automatic contracting. There are few scattered opinions in the literature and are inadequate to address these issues. So, we present a legal framework to analyze these novel issues and show why even recent legislations cannot adequately address this problem. We identify many of these issues which are rooted at the authorization management in agent delegation. Therefore, we advocate solutions that consider both legal and technical aspects. Based on current legal and business practices, we develop a conceptual model for agent authorization. We propose the use of a Contract Agent Authorization Platform (CAAP) that also supports alerts and acknowledgments, and illustrate the platform with typical use cases. We attempt to investigate the ambiguities of the existing legal framework on contracting agents that emerged due to new technical developments in the field."
744559,22457,20561,The Topological and Electrical Structure of Power Grids,2010,"Numerous recent papers have found important relationships between network structure and risks within networks. These results indicate that network structure can dramatically affect the relative effectiveness of risk identification and mitigation methods. With this in mind this paper provides a comparative analysis of the topological and electrical structure of the IEEE 300 bus and the Eastern United States power grids. Specifically we compare the topology of these grids with that of random [1], preferential-attachment [2] and small-world [3] networks of equivalent sizes and find that power grids differ substantially from these abstract models in degree distribution, clustering, diameter and assortativity, and thus conclude that these abstract models do not provide substantial utility for modeling power grids. To better represent the topological properties of power grids we introduce a new graph generating algorithm, the minimum distance graph, that produces networks with properties that more nearly match those of known power grids. While these topological comparisons are useful, they do not account for the physical laws that govern flows in electricity networks. To elucidate the electrical structure of power grids, we propose a new method for representing electrical structure as a weighted graph. This analogous representation is based on electrical distance rather than topological connections. A comparison of these two representations of the test power grids reveals dramatic differences between the electrical and topological structure of electrical power systems."
654194,22457,20561,Explorer at Los Alamos: a library for the future,1998,"Since 1993, Los Alamos National Laboratory has been developing World Wide Web (WWW) applications to facilitate access to vast quantities of information critical to the successful operation of a nuclear weapons facility. Explorer is a Web based tool that integrates full text search and retrieval technology, custom user interfaces, user friendly navigation tools, extremely large document collections, and data collection and workflow applications. Explorer's first major thrust was to enable quick access to regulatory and policy information used by Department of Energy facilities throughout the country. Today, Explorer users can easily search document collections containing millions of pages of information, scattered across Web sites around the country. Over fifteen large applications containing multiple collections are searchable through Explorer, and the subject areas range from DOE regulations to quality management related resources to technology transfer opportunities. Explorer has succeeded because it provides quick and easy access to stored data across the Web; it saves time and reduces costs in comparison with traditional information distribution, access, and retrieval methods."
2072401,22457,20561,Modeling intergovernmental collaboration: a system dynamics approach,2002,"Describes the development and testing of a system-dynamics model of collaboration, trust-building and knowledge sharing in a complex, inter-governmental information system project. The model-building and testing activity was an exploration of the feasibility of applying these modeling methods to a complex inter-organizational process about which only qualitative data were available. The process to be modeled was the subject of qualitative field research studying knowledge and information sharing in inter-organizational networks. This research had produced a large volume of observational and interview data and analyses about the technology project. In the course of collecting and analyzing data from this project, the researchers noted evidence of what appeared to be important feedback effects. The feedback loops appeared to influence the collaboration and knowledge sharing, critical parts of how the information system design and construction progressed. These observations led to conversations with colleagues who had extensive experience in dynamic modeling. All agreed that applying dynamic modeling methods to this process had considerable potential to yield valuable insights into collaboration. As a novel application of the methods, it could yield new modeling insights as well. The modeling experience supported both propositions and was judged a success that will lead to continued exploration of these questions."
2060488,22457,20561,'Letting go of Control' to Embrace Open Source: Implications for Company and Community,2010,"It is increasingly understood across the information technology and services sector that engagement with the open source software model can serve as a means for firms to capture intellectual energy, learn about productive software processes, access relevant technical skills, identify and recruit staff, as well as obtain valuable resources including code. This paper reports a study undertaken within two large global IT companies that have been actively involved with open source for more than ten years. The study involved over 30 semi-structured interviews with employees of the companies drawn from top, middle, and lower level management, and included active and experienced developer as well as open source community members. Our findings indicate how these companies have adapted their day-to-day management practices to take into account the need for flexibility and freedom expected by open source communities. This paper focuses on how they 'let go of control' and what the implications of this are for both companies and the communities involved. Our data reveals a number of themes and in this paper we focus on three principal ones; issues of requirements, total cost of adoption, and alignment of open source engagement with long term company strategy."
2347782,22457,20561,Productivity Breakdown of the Information Technology Industries across Countries,2003,"In this paper, we measure productivity growth of the information technology (IT) industries in fourteen OECD countries over the thirteen-year period of 1978 through 1990. The IT industries are the providers of IT capital goods, and this macro-level analysis seeks to find out how efficiently IT capital goods are produced. The basic unit of analysis employed is the Malmquist Total Factor Productivity (TFP) index. The Malmquist TFP index is next decomposed into three constituent elements accounting for different sources of productivity growth: technological progress, efficiency change, and the effects of economies of scale. The approach of measurement is based the concept of distance functions and employs thenon-parametric frontier method of data envelopment analysis (DEA). Our results indicate that each country's IT industry manifests its own particular patterns in various performance measures. Among the fourteen countries examined, ten had witnessed productivity growth in their IT industries. Overall, these IT industries are found more productive than other industries when compared with previous research. Further analyses reveal that most of productivity growth measured is due to technological progress. Efficiency change is found to exert a relatively small positive effect on the productivity growth. Moreover, the change of scale economies unfavorably affects productivity for most countries. Finally, practical implications for formulating IT policy are drawn from our results for further discussions."
2374488,22457,20561,Formal behavioural synthesis of Handel-C parallel hardware implementations from functional specifications,2003,"Enormous improvements in efficiency can be achieved through exploiting parallelism and realizing implementation in hardware. On the other hand, conventional methods for achieving these improvements are traditionally costly, complex and error prone. Two significant advances in the past decade have radically changed these perceptions. Firstly, the FPGA, which gives us the ability to reconfigure hardware through software, dramatically reducing the costs of developing hardware implementations. Secondly, the language Handel-C with primitive explicit parallelism which can compile programs down to an FPGA. In this paper, we build on these recent technological advances and present a systematic approach of behavioural synthesis. Starting with an intuitive high level functional specification of a problem, given without annotation of parallelism, the approach aims at deriving an efficient parallel implementation in Handel-C, which is subsequently compiled into a circuit implemented on reconfigurable hardware. Algebraic laws are systematically used for exposing implicit parallelism and transforming the specification into a collection of interacting components. Formal methods based on data refinement and a small library of higher order functions are then used to derive behavioural description in Handel-C of each component. A small case study illustrates the use of this approach."
1389325,22457,20561,Do Competitive Environments Have an Effect on Managerial Decision Making? An Empirical Investigation of the Newsvendor Problem,2014,"Our research aims to extend the literature by empirically investigating a few critical aspects of the Newsvendor decision making problem that have not been studied before. First, we look at the impact of playing the game in a competitive (tournament) environment, where all subjects in the room are ranked by their profits after each round. We also study the impact of incrementally adding decision support information on the outcome biases of the tournament participants. Finally, we investigate gender differences in decision making in the tournament newsvendor decision-making game. Our results show that displaying the best performance results per round (beyond telling each subject his own performance ranking) can increase the subjects' performance in terms of order quantities. We find that when we display the best performance results after each round in the competitive environment, subjects reduce their pull to the center bias, and gravitate toward the optimal order quantities in both high and low profit conditions as indirect decision support information is provided. We also observe that showing additional direct cues (such as the realized fill rate per round, or even plots of the expected profit as a function of the order size) has a negative effect on order quantity in the high profit condition, but helps participants in the low profit case after controlling for the learning-by-doing effect. Significant gender differences are only observed in the high competitive environment."
2156195,22457,20561,Online price competition within and between heterogeneous retailer groups,2004,"This study presents a model of price competition in a market for a homogenous good with many asymmetrically positioned retailers, a typical example of which could be the online markets for books, music, movies or software. These markets are highly competitive oligopolies served by hundreds of active retailers and that have been affected by information technologies such as price comparison engines and shopping bots. In these markets, firms can only identify broad group memberships to clusters of firms, and compete within and across clusters based on this information, due to the incompleteness of information on the characteristics of firms. The characteristics of the firms that shape their competitive behavior are their established loyal segment sizes and potential comparison shopper segment sizes. To analyze such markets, we develop and solve a static game of price competition in an asymmetric oligopoly with numerous clusters of firms. In our analysis we see that the firms with the smallest loyal segment sizes and the largest switcher segment sizes engage in a fierce price competition while the members of all other groups prefer to price at their reservation price points. We also test and provide empirical support for our model predictions using pricing data on three categories. Our data set contains prices on 112 printers from 20 retailers, 95 cameras from 53 retailers and 1388 books from 15 retailers."
1845641,22457,20561,Pattern matching in search problem solving,1996,"Search problems generally fall into the class of NP hard problems. Many real problems including planning, diagnosing, allocation tasks, classification tasks and scenario making, require examination of large search spaces. These problems cannot be solved directly (i.e., without searching) by simply applying the appropriate algorithms. Expert systems are usually applied to solve different search problems. However, only a few expert systems with the truth maintenance capability are able to solve them efficiently. A truth maintenance system is used to organize data into data abstractions that represent points in search spaces, and also to maintain data consistency, while the inference engine is used to examine problem states and to guide the search process. Knowing that expert systems spend about 90% of their time in each recognize-act cycle performing pattern matching, it is obvious that the pattern matching algorithm represents one of the most critical components of the inference engine. Two of the most popular pattern matching algorithms TREAT and RETE, are applied in almost all expert systems. Although these algorithms are very efficient in applications which do not require the examination of search spaces, they perform some futile work in search problem solving. We propose a pattern matching algorithm, specially tuned for the solution of search problems, which override the drawbacks of TREAT and RETE algorithms and increases the efficiency of the overall system."
708670,22457,20561,Introduction to Network Analysis of Social and Digital Media Minitrack,2014,"Social networks are representation of complex systems defined by the patterns of relationships among a system's components. Networks are created by information flows or other relations among entities through time and space. The goal of network analysis is to describe the structure of a higher-level system based on the pattern of linkages among a set of lower level nodes, and how this structure changes over time. It differs from traditional research by focusing on relationships rather than the attributes of individuals. The complex social networks that people create and manage are dynamic, multi-modal, and increasingly mediated by social and digital media.Network science has progressed in parallel with the development of social and digital media, computers and other information systems. This has provided social and communication network scientists with precise representations of information flows and advanced the state of the science. Additionally, the increased theoretical understanding and analytic representation of computer and information systems provides developers with a greater sense of how people and organizations utilize technology to manage resources embedded in their social and digital networks. The papers in this minitrack represent theoretical and analytic developments in social and digital media research. They focus on new media and information technology, or use new media data in the analysis. They cross disciplines and levels of analysis, using novel approaches to discover aspects of digital networks."
2272097,22457,20561,Consistent enterprise software system architecture for the CIO - a utility-cost based approach $,2004,"Previously, business operations of most large companies were supported by a number of isolated software systems performing diverse specific tasks, from real-time process control to administrative functions. In order to better achieve business goals, these systems have in recent years been extended, and more importantly, integrated into a company-wide system in its own right, the enterprise software system. Due to its history, this system is composed of a considerable number of heterogeneous and poorly understood components interacting by means of equally diverse and confusing connectors. To enable informed decision-making, the Chief Information Officer (CIO), responsible for the overall evolution of the company's enterprise software system, requires management tools. This paper proposes enterprise software system architecture (ESSA) as a foundation for an approach for managing the company's software system portfolio. In order to manage the overwhelming information amounts associated with the enterprise software system, this approach is based on two concepts. Firstly, the approach explicitly relates the utility of knowledge to the cost of its acquisition. The utility of knowledge is derived from the increased value of better-informed decision-making. The cost of knowledge acquisition is primarily related to the resources spent on information searching. Secondly, the approach focuses on ensuring the consistency of the architectural model."
1782051,22457,20561,Feedback mechanisms as intermediaries for Web information market: an exploratory study,2001,"The Internet is sometimes said to be drowning in contents. Users of information therefore experience great difficulty in identifying the accuracy, relevancy and interpretability of information. Total data quality management and centralized information intermediaries are either too expensive for the vast amount of Internet contents or they force information consumers to face the problem of determining the trustworthiness of the intermediaries. We explore the possibility of using various feedback mechanisms to serve as intermediaries. The service quality of four types of feedback is compared in this study: click-through count, open-ended feedback, close-ended feedback and no feedback. The potential benefits of feedback are twofold. For information consumers, it serves to provide quality proofs and helps the user to become aware of the public's preferences toward specific content sites. For information producers, feedback could provide peer support and recognition. This exploratory study concludes that open-ended feedback and click-through counts result in users with a higher perceived service quality. For the information providers, feedback information awards them with peer support and a more satisfied attitude toward the system. These results, while not conclusive, suggest that it is possible to make feedback mechanisms play the role of infomediaries in order to manage the information market - a much more important role than for accounting purposes."
856177,22457,20561,Disentangling the Value of Information and Analytics through Componentized Business Architecture,2012,"Data has been a key resource in the operation of enterprises for quite some time. Information technology practices have been created to manage data from a variety of perspectives. The growth of data sources and the need to obtain more value from huge volumes have paved the advent of business analytics. Expectations from business managers and executives have risen accordingly. Today, the need to align the value of information and analytics to the resource-base of an organization has become the 'new normal'. Realizing this potential calls for new practices, i.e., IT-centric data management activities need to be complemented with business-centric practices that help understand raw and analytical information entities and their value to operations and strategy. This paper presents models and techniques to help assess the value of information and analytics at the realm of the asset base of organizations. The approach is based on models of business operations and the way information (raw and analytical) is connected to the organization and its business priorities. This linkage builds upon the notions of componentized business architecture, simplified information metamodel and basic relationship between the two concepts. A real-world case study in the insurance industry with the corresponding business architecture frameworks and information models illustrates the practical value of the approach."
1301159,22457,20561,Discovery of Community Structures in a Heterogeneous Professional Online Network,2013,"Socio-technical networks that are heterogeneous in composition of actors and the media through which they interact are becoming common, but opportunities to study the emergent community structure of such networks are rare. We report a study of an international online network of educators involved in many forms of professional development and peer support, including sponsored and volunteer-driven activities taking place in both synchronous and asynchronous media, with participants from diverse career stages and occupations in education. A modularity-partitioning algorithm was applied to a directed, weighted, multimodal graph that represents associations between actors and the artifacts (chats, discussions and files) through which they interact. This analysis simultaneously detects cohesive subgroups of actors and artifacts, providing rich information about how communities are technologically embedded. Researchers deeply familiar with the network validated the interpretability of the partitions as corresponding to known activities, while also identifying new findings. The paper describes this interpretative validation, summarizes findings concerning the distribution and nature of communities and groups found within the larger heterogeneous network, and discusses open research questions and implications for practitioners."
2366518,22457,20561,Insight or ideas: escaping the idea centered Box defining creativity,2001,"The article is for those who are less than delighted by the state of the art in the various computer, Internet, and multimedia systems designed to enhance team creativity. It explores a hypothesis that certain common assumptions about team creativity and problem solving make it nearly impossible to develop systems which can measurably assist the richness and complexity of real world problem solving and design collaboration. Because creative success often results from recognizing that the original problem definition is hiding effective solutions, it may be advantageous to explore a definition of the creative event not as an idea that is newer and better but as a shift in perspective or belief that makes new possibilities obvious. In the classic phrase: don't raise the bridge, lower the water the creative event is seen as the shift of problem definition to getting the boats past, thus making a great many new possibilities obvious. This alternative perspective shifts the focus for deliberate creativity from out of the box thinking to better box thinking and validates the role of experience, expertise, and knowledge in the creative process. It is especially useful in understanding the more complex creative work of people like Einstein and Darwin, and in guiding the management of complex and cross functional creativity."
1511315,22457,20561,Fast Regulation Service Provision via Aggregation of Thermostatically Controlled Loads,2014,"Federal Energy Regulatory Commission (FERC) Order 755 requires scheduling coordinators to procure and compensate more for regulation resources with faster ramping rates. Thermostatically Controlled Loads (TCLs) are a tremendous demand-side resource for providing fast regulation service due to their population size and their ability of being turned ON or OFF simultaneously. In this paper, we consider modeling and control of a collection of TCLs to provide such regulation service. We first develop a non-uniform bin state transition model for aggregate modeling of a collection of TCLs. The non-uniform model presents a potential for more accurate prediction while requiring fewer number of bins (reducing the complexity of the model) than the existing uniform bin models. We also propose a randomized priority control strategy to manipulate the power consumption of TCLs to track a regulation signal, while preventing short cycling, and reducing wear and tear on the equipment. The proposed control strategy is decentralized in the sense that each TCL makes its own decision solely based on a common broadcast command signal. This framework reduces the communication and computational efforts required for implementing the control strategy. We provide illustrative simulations to show the accuracy of the developed non-uniform model and efficacy of the proposed control strategy."
1599855,22457,20561,Introduction to the enterprise content management minitrack,2003,"Enterprise content management (ECM) focuses on the management of textual and multimedia content across and between enterprises, emphasizing the coexistence of technical and social aspects within the content management. Methods and techniques applicable for managing textual and multimedia information with all sizes of content units, ranging from XML and database structures through web pages and documents to document collections, are studied as well as approaches focusing on specific content structures. In a piece of ECM research, multiple of the perspectives may be covered, or one of the perspectives is chosen as the major view to the area: • the technical perspective including the development of new kinds of hardware and software solutions and related standards for the management of content, or • the user perspective including requirements analysis, evaluation of existing or proposed solutions from the point of view of the users, and methods for personalization, or • the process perspective including the analysis and development of solutions to support business processes or work processes (choosing e.g. the approach of CSCW, eBusiness, or ERP), and analysis of the interaction of processes with the content elements, or • the content perspective, including issues on granularity of content, combination of content elements, modelling issues related to the content, and content on a special application area. The topics of ECM research can include: • content management in work processes • document and text databases • content personalization, internationalization, localization"
2082643,22457,20561,Online communities: a longitudinal analysis of communication activities,2003,"Online communities (OCs) are seen as an important stimulus to electronic business. However, surprisingly little is known about how the communication activity of their users develops and changes over time. A longitudinal study bears the potential to better elaborate the enabling and inhibiting factors of the users' communication activity in OCs. To explore these phenomena, we aim to develop a conceptual framework that serves as a foundation to guide an explorative data analysis of real OCs. The notions of common ground, information overload, interactivity and social loafing will be used to explain the communication activity of the users in online communities. The empirically explored framework will help organizations to support the development of OCs and utilize them in an economically successful way. Based on a literature review we develop a first conceptual framework. Then, we apply it to describe the development of the communication activity and its determinants in an OC hosted by a German financial service provider. The study examines over 33,000 participants and 1.03 million messages over a period of 3 years. We find a strong effect of external factors on the size of this OC. The size of the OC shows no direct influence on the communication activity of the users. But, in reaction to the increasing information load, communication strategies change and herewith influence the communication activity. The heterogeneity of the users' activity is growing over time and a small minority of users writes more and more of the postings."
2036332,22457,20561,From computer networks to agent networks,2003,"From the 1990s on, one of the most important challenges facing computer science researchers has been the design and construction of software tools to exploit Internet computing. At the same time, the development of agent technology has gone hand in hand with the explosion of the Internet. As worldwide network computing environments become more and more complex, software agents are believed to have the potential to help present and manage the Internet in an autonomous or semi-autonomous way. Yet, to date, a number of fundamental questions about the theory and practice of this new software engineering paradigm have remained unanswered. Here we explore the features that make the agent-based approach such an appealing and evolutionary computational model. In particular, we envision a global agent-based distributed computing architecture that provides a convenient programming abstraction and sufficient transparency. This paper gives a general introduction to the underlying concepts of our research and development both at the level of design philosophy and in practical implementation techniques. It is argued that the shift from computer networks to agent networks is a significant extension of network programming technology because agents are well suited to modeling, designing and implementing scalable, flexible and secure distributed systems over a worldwide computing environment."
2004861,22457,20561,Shifting perspectives on organizational memory: from storage to active remembering,1996,"This paper provides a critique of current conceptions of organizational memory as presented in a number of recent studies. It briefly reviews some of the rich and varied contributions from both administrative studies and information systems concerning this topic, while at the same time noting the vagueness of the term as it is commonly used. What is of interest is the pervasiveness and perseverance of this nebulous concept across a wide range of disciplinary endeavours. The paper provides an important reformulation of one aspect of memory that is implicit if not explicit in most current views (i.e. the notion of memory as a passive store), arguing instead for an active, constructive view of remembering that has a long, if forgotten history within psychology and other fields. Some implications of such an approach are discussed, paying particular attention to the need for empirical studies of memories in use and the need to focus on the active construction of common information spaces from information repositories and expanding the domain of discourse to include sociological as well as psychological perspectives on concepts such as memory, learning, remembering, talking, etc. in the content of organizations. This reformulation of the issues surrounding organizational memory has significant implications for the kinds of computer support for this phenomenon which might be possible or feasible."
2122719,22457,23836,An Effective Self-adaptive Load Balancing Algorithm for Peer-to-Peer Networks,2012,"The field of parallel and distributed computing has become increasingly significant as recent advances in electronic and integrated circuit technologies. Peer-to-Peer (P2P) cloud computing networks are the largest contributor of network traffic on the Internet. Measurement plays an important role in different P2P applications, we should enhance the measurement-based optimization of P2P networking and applications. In especial, to enhance the file sharing efficiency in P2P networks while reducing the inter-domain traffic, extensive schemes are proposed and file sharing is becoming seriously concerned. However, difference in ability, free-riding behavior and high churn have caused great unbalance on load degree between high speed network nodes. This paper presents a self-adaptive load balancing algorithm, where nodes create binary tree back-up node tables for their shared hot files automatically, and transfer extra query quest connection sent originally to heavy-load nodes and to back-up nodes. The experimental results reveal our algorithm can reduce load degree of heavy-load nodes and bring ideal balance between high speed network nodes, although under high churn, it also has balance effect and lower load degree of the whole network systems."
2702578,22457,20561,Enterprise BigGraph,2013,"Today, Big Data is drawing a lot of attention and popularity and is aspiring enterprises to utilise more efficiently their data to help them understand how to better function, grow and manage as a business. Enterprises are aware that to derive real business value from Big Data and seek competitive advantages, they need to have available the right tool to extract, capture and organize a wide variety of useful data and insights from different sources, and to be able to easily use and analyze it within the context of their data. In this paper we present Big Graph, a solution for enterprises to manage Big Data and facilitate data integration, making the enterprise data more accessible and easier to use externally. Big Graph provides the technology and expertise to build a data-centric enterprise architecture by enabling intuitive navigation, knowledge discovery, extensibility and social analysis. It offers 'social' capabilities that enable unified communications and collaborations to help enterprises to reduce the time and cost needed to analyze critical information and efficiently improve enterprise productivity. It is believed that Big Graph is a suitable tool capable of facilitating enterprises to create and link their data as a graph allowing information flow around their world and outside."
2438316,22457,20561,Decision support systems for improving the analytic capacity of decentralized routine health information systems in developing countries,2004,"Routine health information systems in most third world countries are woefully inadequate to provide the information support necessary for planning and management of the health services. In most countries they are centrally planned and managed. Indicators, data collection instruments, and reporting forms usually have been designed by centrally located epidemiologists, statisticians, and administrators (called data people), with minimal involvement of lower-level line managers and providers of the health services (called action people). Decentralized routine health information systems in developing countries allow health program managers at both peripheral (district and regional) and central (national) levels to better monitor and evaluate the health programs by making available at all levels the data necessary for decision making. Since information technology became increasingly affordable for developing countries, computerization of data processing and analysis has further contributed to the availability of quality and timely data. The decision support system (DSS) is a module added to an existing routine health information system that allows decision-makers to visualize health indicators and data elements collected by the system in graphical and geographical presentations. The user, after accessing the module, chooses a series of options to determine the specific analysis desired."
1497839,22457,20561,Cost Allocation in Ancillary Service Markets,2014,"Market designs for reserve capacity in power systems face new challenges in terms of demand side participation (DSP) and renewable energy in-feed. In order to enhance power system flexibility and to reduce the amounts required of reserve capacity two key issues have to be tackled: First, financial incentives for DSP to participate in Ancillary Service markets. Second, incentives for intermittent sources and demand to adhere to their forecasted in-feed schedule. Therefore, we consider the public good aspect of reliable electricity supply and treat deviations from the schedule in in-feed or consumption as negative externalities in electricity market operation. Our contributions are twofold: First, we present a novel methodology which incorporates the individual evaluation of reserves via a suitable cost allocation framework and therefore enhances DSP to ensure operational security. Second, we provide a framework to establish market based adaptive in-feed premiums for renewable energy sources and to assess investments in DSP and distributed storage in order to reduce the amount of reserve capacity procured by the System Operator. A simulation study shows that our approach leads to a Pareto-efficient reduction in the amount of procured reserves and hence social costs."
2317969,22457,20561,Audit-trail-based modelling of the decision-making process in Management and Accounting using sensitivity analysis,2005,"In a behavioural and organisational context, complex problems that reflect the multidimensional attributes of human activity inevitably arise and have to be addressed. In an attempt to model human decision-making behaviour, the vast number of potential parameters raises the question of how this complexity can be harnessed. This paper proposes a data-driven approach, with which dependencies or associations are extracted from the data itself. The complex and dynamic nature of modern business processes makes this approach more suitable, as the design of competent rule-based models or expert systems would be cumbersome, expensive or even infeasible. A hybrid behaviour-modelling method, based on both statistical component analysis and sensitivity analysis, is proposed to directly model decision behaviour. The derived model is the outcome of an optimisation process, where model-data matching is maximised in terms of known, pre-defined criteria. The implementation of the proposed intelligent system as an integral part of real-life business/accounting activity is discussed, and its capability to provide intelligent support to the decision making and internal control processes in management and accounting is demonstrated using realistic data from a business procurement application."
2095965,22457,20561,Evaluation of online assessment: the role of feedback in learner-centered e-learning,2004,"Advancement of the information and communication technologies enables the integration of technology with daily activities and education is not an exception. E-learning, which applies the concept of open and distance learning is learning through the Internet. It had been reviewed as an efficient knowledge transfer mechanism. E-learning is seen as a future application worldwide, promoting life long learning by enabling learners to learn anytime, anywhere and at the learner's pace. This paper presents the evaluation of an online test based on a case study of an e-commerce course offered by the Computation Department, University of Manchester Institute of Science and Technology (UMIST). The main aim of the online test is to provide 'rich' feedback to students, which is one of the requirements of the learner-centered learning paradigm. The online test, in the form of multiple choice questions, provides feedback through automatic grading, providing correct answers and referring the students to the learning content which explains the correct answers. Evaluation of the online test was based on two criteria: functionality and usability. In terms of functionality, evaluation was meant to get the students' view of the feedback provided by the system, while in terms of usability, the evaluation sought to ensure that the system not only functions as expected by the users but is also usable. Results show that the online test is suitable for online-learning and provides rich feedback."
469413,22457,20561,Expert versus novice use of the executive support systems: an empirical study,2001,"Expertise is essential in problem solving, particularly for executives. Much literature indicates that in solving daily problems, executives may employ both analytical thinking and intuition. To develop analytical thinking skills and to effectively apply intuition, company executives require expertise. Therefore, the use of executive support systems (ESS) may differ substantially between experts and novices. Previous ESS research has failed to address the effects of expertise on its use. Therefore, this study examines how professionals use ESS to address business-oriented tasks. The professionals were divided into two groups, depending on whether they were experts or novices in the business represented by those tasks. Results in this study can be summarized as follows: (1) Computer self-efficacy strongly influenced executive use of the ESS. (2) Both the main effects of expertise and interaction of expertise and task were insignificant on their perceived usefulness (PU) and user information satisfaction (UIS). (3) Experts felt the ESS was of greater rise when more powerful systems were employed, rather than less powerful systems, while the difference for novices between more and less powerful systems was insignificant. (4) For experts, the UIS score rated significantly higher when employing more powerful systems in both tasks. However novices rated significantly higher only when employing the systems that cognitively fit the performed task. Implications for further application and research are also discussed."
2428307,22457,20561,Classification framework for business components,2000,"Components and component orientation is often depicted as the next step after object orientation. A huge number of proposals and implementations of component models, frameworks, and standards are available nowadays, leading to many different definitions of the term software component. Additionally often the terms component, object, object framework, are not clearly distinguished. Moreover, if a component is defined, the definitions often vary. To achieve a clear understanding what the core features of a software component are, we provide a classification framework to classify each of the proposed models, frameworks, or standards. The goal of this classification is to obtain a consolidated and clear definition of what a component constitutes. As our focus lies in the application of components in the business application domain, we also clearly indicate the differences and additional characteristics of business components to generic software components. In addition, we extend the classification framework. This extended classification framework serves as a basis for the characterization of existing component oriented approaches in the business domain, like Enterprise JavaBeans, SanFrancisco, or SAP Business Objects. Component orientation is actually enlisted to solve the core problems of software development, like reuse, better integration of legacy systems, or software complexity. Thus, often leading to improper use of the term component oriented. The extended classification framework allows identification of any lack of properties of a given approach that claims to be component oriented."
1872475,22457,20561,Generalised reduction modified LR parsing for domain specific language prototyping,2002,"Domain specific languages should support syntax that is comfortable,for specialist users. We discuss the impact of the standard deterministic parsing techniques such as LALR(1) and LL(1) on the design of programming languages and the desirability of more flexible parsers in a development environment. We present a new bottom-up nondeterministic parsing algorithm (GRMLR) that combines a modified notion of reduction with a Tomita-style breadth-first search of parallel parsing stacks. We give experimental results,for standard programming language grammars and LR(0), SLR(1) and LR(1) tables; the weaker tables generate significant amounts of nondeterminism. We show that GRMLR parsing corrects errors in the standard Tomita algorithm without incurring the performance overheads associated with other published solutions. We also demonstrate that the performance of GRMLR is upper-bounded by the performance of Tomita's algorithm, and that,for once realistic language grammar GRMLR only needs to search around 74% of the nodes. Our heavily instrumented development version of the algorithm achieves parsing rates of around 4000-10000 tokens per second on a 400 MHz Pentium II processor. Proof of correctness and details of our implementation are omitted here for space reasons but are available in an accompanying technical report."
2508525,22457,20561,Towards an Intelligent Hospital Environment: Adaptive Workflow in the OR of the Future,2006,"Patients, providers, payers, and government demand more effective and efficient healthcare services, and the healthcare industry needs innovative ways to re-invent core processes. Business process reengineering (BPR) [14] showed adopting new hospital information systems can leverage this transformation and workflow management technologies can automate process management. Our research indicates workflow technologies in healthcare require real time patient monitoring, detection of adverse events, and adaptive responses to breakdown in normal processes [12]. Adaptive workflow systems are rarely implemented making current workflow implementations inappropriate for healthcare. The advent of evidence based medicine, guideline based practice, and better understanding of cognitive workflow combined with novel technologies including Radio Frequency Identification (RFID), mobile/wireless technologies, internet workflow, intelligent agents, and Service Oriented Architectures (SOA) opens up new and exciting ways of automating business processes. Total situational awareness of events, timing, and location of healthcare activities can generate self-organizing change in behaviors of humans and machines."
2509340,22457,20561,Towards an ontology for e-document management in public administration -the case of Schleswig-Holstein,2003,"An action research project in the state administration of Schleswig-Holstein (Germany) seeks to answer the following questions: How can we organize and present e-documents so that users will be able to retrieve the document needed, or at least the information indicating the document? And what is the most effective and adequate way to proceed in the given administrative environment? In search for an appropriate solution, existing approaches in other public administrations have been evaluated. Findings reveal that (1) employing an ambitious ontology-based approach requires the implementation of a set of interrelated elements to support this application, and (2) the necessary allocation of resources is associated with a number of risks which a state government cannot or may not want to bear. The appropriate strategy seems to take first steps in developing and using controlled vocabulary while this process should be accompanied by ongoing evaluation and by networking with other actors in this field to support a collective strategy. Drawing on these insights the state administration now develops a broader approach towards e-document management. In the conclusion, it is argued that research and practice should focus more on conditions of cross-organizational IT adoption in public administration, in particular on the power and ability to set up and control socio-technical infrastructures supporting the IT applications."
2272443,22457,20561,Computer-Based Training and Assessments: An Exploratory Study of Social Factors,2006,"This paper introduces an exploratory research program on different types of hybrid classes to answer those and other questions around its efficacy and applicability for training and education. Our objective is to develop and perform an initial test of a new model designed to trace the influence of individual and technical characteristics on learning outcomes through their effect on in-class and computer training phases of knowledge and skills acquisition and testing. The overall research question is: Which and how much do CBT, individual student, class, instructor, and CBA factors affect student learning outcomes? This paper proposes a research model based upon the Leidner and Jarvenpaa (2001) work where they introduce a research model that helps instructors determine the best teaching method depending on course content, available technology, an individual instructor, and student factors. Thirty-six questions were posed to over 400 students with direct and current experience using CBT and CBA for course credit. The findings show that there is a strong potential for student as well as corporate benefits in training using online assessment tools. Online assessment effectiveness should be given further research study given the explosive jump in reported learning."
2135147,22457,20561,Economic aspects of electronic commerce in financial services and advantageous steps to extended offers in Internet banking,1998,"In this paper we report on the results of two projects our research group is presently conducting. We start our with sketching preliminary results of a long-term government project geared to reveal efficiency conditions for successful electronic commerce particularly in the financial services field. We address questions relating to the innovative use of new channels for distributing financial services focusing on Internet banking. Our government research funds are devoted to help German financial services firms on their way into the digital economy and particularly to advise German banks in applying Internet technology in novel ways to new and promising applications. Thus, along with the research sketched above, we are engaged in a joint project with an innovative German bank, the Munich-based Advance Bank. This direct banking firm is currently extending its telephone banking technology simultaneously employing Internet communication for consultation-intensive customer processes such as mortgage loans (intelligently combined with other financial products). Based on our joint project, we present a brief case study of the bank's market and technology strategy and identify some problems encountered when employing Internet technology to open new markets successfully."
2390868,22457,20561,Customer relationship management for the Web-access challenged: inaccessibility of the Fortune 100 business Web sites,2002,"Companies employ the World Wide Web (Web) to gather and disseminate information to and from actual and potential customers and increasingly for end-consumer business transactions through electronic commerce (EC). Online barriers limit or eliminate Web accessibility for many potential customers with access challenges. It is difficult to establish, develop and manage relationships with potential customers if they cannot access the company's Web site for information, let alone to place orders or request services. The study evaluated the accessibility of the top 100 Fortune 500 company Web sites of 2001. An accessibility validation program quantified the number and severity of accessibility errors and problems for each site. Results indicated that the majority (71%) of the Fortune 100 Company Web sites had accessibility problems and that many of these problems were severe enough for those firms to consider it a high priority to correct them. Additionally, many errors and problems should be fixed as a matter of good programming style as well as general interface and usability principles. The bright side is there were actually few types of errors across all 100 Web sites and most can easily be amended to make sites more accessible and usable for all potential customers. The study illustrates the need for companies to examine the accessibility of their Web sites and bring them into compliance with ADA and other guidelines and requirements. Suggestions for improving the accessibility of Web sites are provided."
2393487,22457,20561,A real options approach for prioritization of a portfolio of information technology projects: a case study of a utility company,2004,"The valuation of information technology (IT) investments is particularly challenging because it is characterized by long payback periods, uncertainty, and changing business conditions. Corporate budgeting methods use accounting-based criteria like return on investment (ROT), internal rate of return (IRR), and payback period which were designed for projects with no option features. However, the uncertainties underlying IT investment decisions and the inability of traditional discounted cash flow (DCF) methods to incorporate the impact of flexibility on project valuation, force executives to rely on gut instinct when finalizing IT investment decisions. Real options analysis (ROA) has been suggested as a capital budgeting tool because it explicitly accounts for the value of future flexibility in management decision making. This paper deals with the application of a nested real options model to evaluate and prioritize a portfolio of information technology projects. It elaborate the valuation and prioritization of a real-world portfolio of IT initiatives under consideration for funding. It is illustrated using real world data from EnergyCo, a large utility facing challenges on many fronts due to uncertainties surrounding energy deregulation and Internet-based energy trading."
2104641,22457,20561,Evaluating and adopting application integration: the case of a multinational petroleum company,2002,"Many organisations use a diversity of information systems such as custom applications, e-business solutions and enterprise resource planning (ERP) to support their organisational and financial business processes. However, this diversity of heterogeneous and in many cases incompatible systems coupled with the absence of integrated enterprise architecture is considered a restricting factor in the automation of business processes and thus, cause a proliferation of integration problems. In attempting to overcome such issues, organisations are turning to a new category of integration software called application integration (AI), which results inflexible and manageable information systems (IS) and infrastructures. Application integration is achieved through the incorporation of functionality from disparate systems using a variety of integration technologies such as adapters and message brokers. In attempting to explore the area of AI, this paper discusses the adoption and the impact of application integration on organisations. In doing so, the case study of a multinational petroleum company that adopted an AI solution is presented. The case study presented in this paper shows that system design takes up to 60% of overall project time when integrating systems due to the reengineering of business processes. In addition, the majority of systems are phased out and the redundancy in functionality is significantly reduced."
2306326,22457,20561,A Petri net representation for dynamic programming problems in management applications,2004,"Dynamic programming (DP) is a very general optimization technique, which can be applied to numerous management decision problems. In order to develop a software system that automates many of the tasks a user encounters when attempting to solve an instance of an optimization problem with discrete DP an intermediate problem representation in the form of a Petri net (PN) turns out to be useful. The specialized PN model presented in this paper captures the essential components of a DP problem instance. It uses the standard semantics of place/transition nets, a low-level PN class, whereas previous work (Lew, 2002; Lew and Mauch, 2003; and Mikoljczak and Rumbut, 1997) relied on high-level PNs. This approach is illustrated by a simple financing example, but the methodology works for a wide range of management problems and can be applied to more complex instances. Among the benefits of this representation are the possibility to perform consistency checks on the PN level and the existence of a simple procedure to translate a model instance into executable code that could be integrated into existing solvers. Also, a software system currently under development automates the task of transforming a DP functional equation into the PN model suggested in this paper. Users need not construct the PN model directly."
2203742,22457,20561,Low-Bandwidth Topology Maintenance for Robustness in Structured Overlay Networks,2005,"Structured peer-to-peer systems have emerged as infrastructures for resource sharing in large-scale, distributed, and dynamic environments. One challenge in these systems is to efficiently maintain routing information in the presence of nodes joining, leaving, and failing. Many systems use costly periodic stabilization protocols to ensure that the routing information is up-to-date. In this paper, we present a novel technique called correction-on-change, which identifies and notifies all nodes that have outdated routing information as a result of a node joining, leaving, or failing. Effective failure handling is simplified as the detection of a failure triggers a correction-on-change which updates all the nodes that have a pointer to the failed node. The resulting system has increased robustness as nodes with stale routing information are immediately updated. We proof the correctness of the algorithms and evaluate its performance by means of simulation. Experimental results show that for the same amount of maintenance bandwidth correction-on-change makes the system by far more robust when compared to periodic stabilization. Moreover, compared to adaptive stabilization which adjusts its frequency to the dynamism in the system, correction-on-change gives the same performance but with considerably less maintenance bandwidth. As correction-on-change immediately updates incorrect routing entries the average lookup length is maintained close to the theoretical average in the presence of high dynamism. We show how the technique can be applied to our DKS system as well as the Chord system."
1282601,22457,20561,Building business from technology: the Sandia experience,1996,"The paper describes New Ventures, a new initiative at Sandia National Laboratories that encourages the creation of new businesses based on laboratory technology as a timely, efficient means of technology transfer. Sandia's New Ventures program has shown that a dedicated effort can produce significant results. In the three years prior to this program's launch, just two ventures per year on average were created based on laboratory technology. By comparison, the New Ventures program has enabled 20 new ventures in its first nine months of full operation. Our experience has yielded several lessons: most ventures result from Sandia entrepreneurs, from technologies that are well matched to market needs, and from laboratory projects that are ready for production; entrepreneurship issues are tremendously complex, requiring policy changes to reduce risk, manage intellectual property and licensing determinations, plan for potential conflicts of interest, and tailor other strategies; a new ventures program must advocate these policy changes, assist entrepreneurs, put significant effort into matching outside companies to inside technologies, and identify lab projects ready for manufacture; connection to the local business community is vital to good commercialization matches and to the development of Sandia entrepreneurs; lab employees are far more interested in pursuing Technology Transfer Leaves of Absence than anticipated."
1944675,22457,20561,A Max-Min Approach to the Output Evaluation of Knowledge Interaction,2009,"The concept of knowledge management has been flowering as information management matures. Nevertheless, up until now, more attention has been focused on knowledge management inside organizations and less on knowledge management across organizational boundaries. Attempting to fill this gap and address the problems of cross-boundary knowledge management, this research first identified key boundary objects in the context of knowledge management, and then studies how actors from different organizations interact through boundary objects. The result links the performance of collaborative acts to the frequency of boundary object encountering in the course of interaction. In this study, although the context is described with “actors” in mind, the unit of analysis is “knowledge” itself, rather than “actors,” and the interaction is termed “knowledge interaction”. Student assignments of information system projects serve as the cases of analysis. To analyze the performance of knowledge interactions, a max-min approach is applied, with one output factor, namely project performance, and four input factors, which are the frequencies of the encountering of four boundary objects. The result strongly suggests that identifying, creating, and facilitating useful boundary objects is the key to successful projects. Whether tacit knowledge is converted into explicit knowledge during the process is less important in achieving effective collaboration. Also, it is not always necessary to identify specific tacit knowledge in each organization."
1417881,22457,20561,The Wisdom of Reluctant Crowds,2010,"Estimating is difficult. This is true whether the task requires forecasting uncertain future events, or whether the estimation task is complex in itself and based on insufficient information. As a result, even perceived experts frequently estimate poorly. Surprisingly, recent research suggests that groups of non-experts can outperform individual experts, given certain conditions are met. The resulting capability has been described as collective intelligence or wisdom of crowds. Yet crowds (and individuals) do not necessarily like to make guesses, whether because it is cognitively hard, or emotionally undesirable. If crowd members prefer not to estimate, but instead seek to transfer this responsibility to others, are they able to identify good surrogates? We empirically tested these two aspects of collective intelligence. First, we explored whether collective intelligence was able to produce estimates that are significantly better than those of individuals, and second whether perceived experts as surrogate estimators were able to perform the task equally well. Our findings demonstrate good estimation ability for the crowd as well as its surrogates. We discuss implications for scenarios where estimates involve both beliefs and preferences, and where collective estimates thus have to be negotiated. Resulting requirements for information systems are outlined."
2478226,22457,20561,Organizational design of an IT-based knowledge system: the NetAcademy concept,1998,"The emergence of new media channels such as the World Wide Web has induced a profound growth in the publication of books, paper, pictures and hypertext documents. In addition to forming a large knowledge base, the NetAcademy (NA) is meant to provide a meeting place for the joint discussion of trends, the exchange of personal opinions and research results within a specific scientific field of research or interest. Building up a compound knowledge system does not only require an adequate design and good technological implementation, it involves also permanent engagement from a core of people responsible for news update, reviewing viewing and feedback response. A smooth integration and automation of processes is therefore a key prerequisite for the successful maintenance and continuous attractiveness of the system. The paper describes the realization of the NetAcademy platform, dealing with its template based design and the combination of different software tools such as e.g. Lotus Notes, InterNotes Web Publisher, Domino and Oracle/SQL. It illustrates the connections between the internal organization and the interaction with the knowledge medium, explaining how both can be optimized to mutually support each other."
2472231,22457,20561,Simulating the Deployment of Battery-Sensing Intrusion Protection Systems,2009,"This paper extends Battery-Sensing Intrusion Protection System (B-SIPS) research by utilizing network simulations for deployment validation and optimization. The primary simulation goal is to ensure that B-SIPS does not negatively affect external applications in the network, as any drastic throughput degradation would severely lower the probability of successful B-SIPS deployments. The research goal is accomplished goal by modeling the Virginia Tech wireless-cum-wired network and simulating various network sizes, external network loads, and B-SIPS application transmission settings. This research demonstrates that under reasonable network loads the B-SIPS application had little to no effect on the throughput of external applications. Additionally, the 1 second default transmission rate for B-SIPS was determined to cause the least application degradation for external applications and ensured B-SIPS reports were successfully transmitted in a saturated network environment. Next, the detection capabilities of B-SIPS are examined by conducting Bluetooth, Wi-Fi, and blended attacks against mobile devices. The ability of B-SIPS to detect multi-vector attacks provides application users with the ability to conserve battery charge life and retain device service significantly longer than devices undergoing similar attacks and not utilizing B-SIPS. The attacks used in this portion of the research should be applied to future network simulations of B-SIPS. These simulations will quantify network throughput and device battery usage in large scale network deployments that are, and are not, using B-SIPS."
1844959,22457,20561,Antecedents and Outcomes of Boundary Objects in Knowledge Interaction in the Context of Software Systems Analysis,2011,"Much of knowledge management research has focused on knowledge generation, translation and storage during interactions among knowledge workers, which has led to project success; however, less effort has been made to examine the effects of artifacts or boundary objects that such interactions yield. Thus, the study aimed to help fill this research gap by investigating, not only the categories and characteristics of boundary objects, but also the possible antecedents, taking into consideration the link between outcome and type of boundary object. In the information system field, system design and implementation is a continuous process of interactions between system analysts and end-users, with most interactions occurring in the stage of defining system requirements. Thus, this stage offers an appropriate context to study knowledge interaction. Based on data collected and codified from 82 records of knowledge interaction, the results showed that project performance could be highly enhanced by making use of syntactic, semantic, pragmatic and metaphoric boundary objects. In addition, higher atmosphere leads to a higher frequency of the occurrence of semantic boundary objects. Although the results may be inevitably linked to the context being investigated, the importance of the expected findings will trigger like studies in other contexts."
2504359,22457,20561,"The NetAcademy: a novel approach to domain-specific scientific knowledge accumulation, dissemination and review",1998,"Over the last decade the speed at which knowledge is generated has greatly accelerated, thus exacerbating the problem of finding the right information at the right time and posing new kinds of challenges to the management of an ever increasing pool of knowledge. Taking up the ideas of the ancient Greek concept of Academia, the NetAcademy is timing at providing a knowledge medium to aid in the creation, integration, reviewing and dissemination of domain specific knowledge in the scientific community, taking firm advantage of the unique characteristics of the Internet medium. The vision is to offer an open structure and management concept for virtually any kind of field of research in search of an intelligible organization of its contents. The paper emphasizes the motivation of the NetAcademy concept and its feasibility on the basis of available Internet technologies. The main part discusses the three key concepts which differentiate the NetAcademy from more traditional approaches to digital libraries: the system-imminent vocabulary allowing for the mediation of knowledge through powerful search mechanisms on a semantic level; an integrated system of roles that allows rights and duties to be assigned to agents interacting with the medium; and the modular, template based design."
1314364,22457,20561,Integrating Business Partners on Demand: The Effect on Capacity Planning for Cost Driven Support Processes,2012,Capacity planning for business processes is still a major challenge. Technology enabling on demand integration of business partners handling peak load at short notice may help. We model a three-stage supply chain with a service provider receiving demand from its customers usually executed by an in-house unit. Alternatively the demand can be routed to external business partners if these offer capacity and a preferable execution. Then the capacity planning problem of the service provider is examined: In what way does this on demand integration capability affect the optimal level of in-house capacity? The model consists of two separate queuing systems (in-house unit and external business partners) along with their relevant cost functions. Furthermore a routing algorithm is developed. It evaluates both systems for every incoming order and decides about routing to the preferable one. To derive results a discrete-event simulation is necessary performed within a case study of the securities trading and settlement process. Three insights are gained: There are situations where on demand integration leads to reduced optimal capacity. Furthermore the risk of allocating an inappropriate amount of capacity can be reduced as well as the total operating costs of the business process.
247576,22457,20561,3D-Visualization of Power System Data Using Triangulation and Subdivision Techniques,2009,"D surface visualizations of various power system operating quantities has always been challenging in terms of correctly capturing the changes of an arbitrary geographical shape power system. Triangulation methods offer promise for meaningful 3-D surface visualizations of such systems. In this paper we propose a scheme for such visualizations based on subdivision of triangle meshes. Input consists of various power system quantities such as voltage magnitude, voltage phase, reactive power flow, real power flow, electric current, etc. The data may be available from simulations or from real time streaming data from a model that is two-dimensional (geographic). We first perform a Delaunay Triangulation on the set of 2D sites and generate a triangle mesh. This triangle mesh is used to represent a coarse 3D surface. The height of this surface at a site is equal to the power system quantity at that site. This surface is refined using the butterfly subdivision scheme with an additional constraint that the heights of the interpolated vertices lie within the bounds of the original vertices from which they were interpolated. After each level of subdivision, we perform a modified Laplacian smoothing to compensate for the discontinuity introduced due to this bounding. The method is suitable for effective visualization of large geographic data. Example visualizations and performance indices are provided in the paper."
2241230,22457,20561,Strategic information technology management: the city of Anaheim technological initiatives,2004,"This paper reports the findings of an exploratory study investigating the role of IT in a municipal-owned and operated public utility. Through the use of case study methodology, the paper finds a confluence of contextual factors fostering changes in an IT management strategy aimed at increasing efficiency and effectiveness of service delivery and improving customer/citizen satisfaction. These factors include changes in the regulatory policy environment, advances in technology, increasing citizen and customer knowledge and sophistication about IT, and managerial and elected official commitment to an IT strategy. The paper begins by proposing a model of the IT strategic planning process that occurs in municipal environments and then details several IT initiatives of the municipality in relation to the proposed model. The study finds that the complex nature of technology and its financial risk due to quick obsolescence poses political risks for the organization attempting to manage the IT infrastructure, which changes at a far faster pace than the organization's other types of infrastructure. The strategic management of IT must take into account the differing value sets among its organizational and political members and how these differing motivations impact the management of the IT infrastructure."
2359911,22457,20561,A Distributed Power Management Game for Multi-Antenna Multiple-Access for Ad-Hoc Networks,2005,"This paper focuses on the competitively optimal power-control and signal-shaping for ad-hoc networks composed by Multiple-Antenna noncooperative transmit/receive terminals affected by spatially colored Multiple-Access Interference (MAI). For this purpose, the MAI-impaired network is modeled as a noncooperative strategic game, and sufficient conditions for the existence and uniqueness of the Nash Equilibrium are provided. Specifically, the following main results are achieved. First, we develop an iterative, fully decentralized, asynchronous and scalable power-control and signal-shaping algorithm that is competitively optimal and maximizes the information throughput sustained by links active over the network. Second, we test that the proposed decentralized access algorithm outperforms the (conventional) centralized orthogonal ones (as TDMA) in terms of aggregate network throughput. Third, we show that, when the throughput requested by the users are no sustainable by the network, the proposed algorithm converges to the allowable operating point at the minimum Euclidean distance from the requested one. Finally, we propose two fully decentralized Connection Admission Procedures (CAPs) that rely on the proposed decentralized access algorithm and optimize the tradeoff between aggregated networking throughput and users QoS requirements."
2453865,22457,20561,A commutative encrypted protocol for the privacy protection of watermarks in digital contents,2004,"Analysis by Forrester research revealed that 18% of global exports will flow online in 2004 and that the volume of e-commerce will surpass $400 billion. Digital rights protection is a major issue in the e-commerce of multimedia contents. Watermarking technology has been proposed as a promising enabling technology for the rights protection of multimedia digital contents. A unique watermark is embedded in each piece of multimedia contents before it is distributed to a customer. When unauthorized copies of a piece of contents are found, the customer who owns the contents can be readily identified by means of the embedded watermark. However, the unauthorized copies may also come from the content provider itself. It is therefore a challenging problem to determine whether an unauthorized copy is distributed by an unethical customer or by an unethical content provider. In this paper, we propose a watermarking protocol to address the problem using cryptographic technologies. Our protocol employs a commutative encryption algorithm to protect the privacy of watermarks. Information is doubly locked by two encryption keys kept separately by a customer and a content provider. In the protocol, a customer only gets a piece of watermarked multimedia contents in a transaction and the content provider has no idea how the watermark is formed. This facilitates the authority to determine the unethical party in case of unauthorized distribution of digital contents. We also discuss a couple of common attacks and show that our protocol can defend successfully against them."
2142818,22457,20561,A National Scientific Computing Environment for the Biological Sciences,1994,"A framework for developing a computing environment for researchers in the biological sciences which utilizes HPCC resources is described. This framework addresses the need to provide an organized network resource discovery and access capability for the genome researcher on a national scale. In particular, this framework addresses the issues of integrating autonomous computing tools, authenticating both users and the tools being accessed, dynamic and transparent tool location determination, application and network fault tolerance, and scalability. This framework is based, in part, on open-systems concepts and a distributed computing paradigm. on the network, providing support for highly reliable, fault tolerant service, and being scalable in large networking environments. As part of the US. Government’s High Performance Computing and Communication initiative (HPCC), a computing environment that addresses these issues on a national scale is being developed at the University of Missouri-Columbia (MU). As part of the development effort, a prototype system has been implemented which utilizes resources and services at the Pittsburgh Supercomputer Center (PSC), the National Library of Medicine (NLM), MU and elsewhere. The prototype system provides researchers in the biological sciences with a powerful capability to integrate a diverse set of resources that facilitate their research efforts."
381896,22457,20561,A Language-Based Approach to Construct Structured and Efficient,1997,"Classical object properties such as encapsulation easethe construction of distributed systems. The object paradigmsupports modeling of real world problems in a natural wayand delivers units of distribution to the resource managementlevel. To enhance the performance of distributed systems,more detailed application-specific information like potentialcommunication dependencies should be exploited.To fulfill this requirement, we propose a top-downdriven, language-based approach to construct structureddistributed systems. We introduce the object-based distributedprogramming language INSEL, that supports advancedstructuring concepts. Structural dependencies betweenpassive and active objects are determined at the applicationlevel and exploited by the resource managementsystem to transform INSEL programs into efficient executables."
1398732,22457,9896,Are computers merely supporting cooperative work: towards an ethnography of bot development,2013,"My dissertation investigates bots as a mode of software development. I am interested in how bots reconfigure relations in collaborative systems, particularly the production of alternative relations of power and agency between developers, users, platforms, and code. I am particularly interested in exploring whether bots require us to focus not on how computers 'support' the cooperative work of humans, but instead on how bots can be seen as active participants in collaborative communities. To this end, I propose a two-faced ethnography of bot development, relating first the subjective experiences of bot developers, then the subjective experiences of bots themselves."
1309181,22457,9896,Egalitarians at the gate: one-sided gatekeeping practices in social media,2010,"Although Wikipedia has increasingly attracted attention for its in-depth and timely coverage of breaking news stories, the social dynamics of how Wikipedia editors process breaking news items has not been systematically examined. Through a 3-month study of 161 deliberations over whether a news item should appear on Wikipedia's front page, we demonstrate that elite users fulfill a unique gatekeeping role that permits them to leverage their community position to block the promotion of inappropriate items. However, these elite users are unable to promote their supported news items more effectively than other types of editors. These findings suggest that one-sided gatekeeping may reflect a crucial stasis in social media where the community has to balance the experience of its elite users while encouraging contributions from non-elite users."
2920688,22457,10228,Joint throughput and channel aware (TCA) dynamic scheduling algorithm for emerging wearable applications,2016,"This paper addresses a reliability concern of the emerging wearable applications under dynamic and realistic conditions. We propose a new joint throughput and channel aware (TCA) dynamic scheduling algorithm for IEEE 802.15.6 standard to enhance the system performance while exploiting m-periodic scheduled access mechanism. First, various mobility patterns are generated with special emphasis on space and time varying links and their performance which are most vulnerable under dynamic environment. A deterministic pathloss values (as an estimate of the channel) are obtained from a set of training sequence which is generated using motion capture system and bio-mechanical modeling. Consequently, signal to noise (SNR), bit error rate (BER) and packet error rate (PER) are calculated. The TCA algorithm during the first phase uses this estimated PER to select the potential nodes for a time slot. Whereas in the second phase, based on the nodes priority and the data packets availability among the potential candidates, finally a slot is assigned to one node. This process is repeated by the coordinating node until the end of the super frame. This scheme has a significant gain over a reference scheme (i.e., without above adaptation). On average, 20-to-55 percent extra packets are received, along with 1-to-5 joules of energy savings though at the cost of higher delay ranging from 20-to-200 ms while operating at low power levels (i.e., 0 dBm, −5 dBm, −10 dBm)."
2667518,22457,20561,Success Factors of Online Petitions: Evidence from Change.org,2016,"Online petitions have emerged to become a powerful tool for the public to make positive impact on the society. This paper investigates what factors in the text content of online petitions influence their chance of success. Specifically, we examine moral, emotional, and cognitive elements in the petition language and identify their role in making online petitions successful. From the analysis of 12,808 online petitions from Change.org, we found that petitions containing positive emotions are more likely to be successful. In contrast to conventional beliefs, petitions containing heavier moral and cognitive elements are less likely to be successful. The findings have important implications to both petition websites and petitioners."
2140255,22457,20358,"Identifying, understanding and detecting recurring, harmful behavior patterns in collaborative Wikipedia editing: doctoral proposal",2013,"In this doctoral proposal, we describe an approach to identify recurring, collective behavioral mechanisms in the collaborative interactions of Wikipedia editors that have the potential to undermine the ideals of quality, neutrality and completeness of article content. We outline how we plan to parametrize these patterns in order to understand their emergence and evolution and measure their effective impact on content production in Wikipedia. On top of these results we intend to build end-user tools to increase the transparency of the evolution of articles and equip editors with more elaborated quality monitors. We also sketch out our evaluation plans and report on already accomplished tasks."
59622,22457,20332,Trust models and con-man agents: from mathematical to empirical analysis,2010,"Recent work has demonstrated that several trust and reputation models can be exploited by malicious agents with cyclical behaviour. In each cycle, the malicious agent with cyclical behaviour first regains a high trust value after a number of cooperations and then abuses its gained trust by engaging in a bad transaction. Using a game theoretic formulation, Salehi-Abari and White have proposed the AER model that is resistant to exploitation by cyclical behaviour. Their simulation results imply that FIRE, Regret, and a model due to Yu and Singh, can always be exploited with an appropriate value for the period of cyclical behaviour. Furthermore, their results demonstrate that this is not so for the proposed adaptive scheme. This paper provides a mathematical analysis of the properties of five trust models when faced with cyclical behaviour of malicious agents. Three main results are proven. First, malicious agents can always select a cycle period that allows them to exploit the four models of FIRE, Regret, Probabilistic models, and Yu and Singh indefinitely. Second, malicious agents cannot select a single, finite cycle period that allows them to exploit the AER model forever. Finally, the number of cooperations required to achieve a given trust value increases monotonically with each cycle. In addition to the mathematical analysis, this paper empirically shows how malicious agents can use the theorems proven in this paper to mount efficient attacks on trust models."
841867,22457,9896,"Quality control mechanisms for crowdsourcing: peer review, arbitration, & expertise at familysearch indexing",2013,"The FamilySearch Indexing project has enabled hundreds of thousands of volunteers to transcribe billions of records, making it one of the largest crowdsourcing initiatives in the world. Assuring high quality transcriptions (i.e., indexes) with a reasonable amount of volunteer effort is essential to keep pace with the mounds of newly digitized documents. Using historical data, we show the relationship between prior experience and native language on transcriber agreement. We then present a field experiment comparing the effectiveness (accuracy) and efficiency (time) of two quality control mechanisms: (1) Arbitration -- the existing mechanism wherein two volunteers independently transcribe records and disagreements go to an arbitrator, and (2) Peer Review -- a mechanism wherein one volunteer's work is reviewed by another volunteer. Peer Review is significantly more efficient, though not as effective for certain fields as Arbitration. Design suggestions for FamilySearch Indexing and related crowdsourcing initiatives are provided."
2724941,22457,20561,Developing a Shared Taxonomy of Workaround Behaviors for the Information Systems Field,2016,"This study offers a workaround taxonomy that is developed based on the input of Information Systems (IS) researchers and practitioners. We adopted a taxonomy development method from cognitive anthropology that includes: a card sorting exercise, consensus analysis using the Cultural Consensus Model (CCM), and residual analysis using Monte Carlo simulations. We identified the taxonomy structure via cluster analysis and interpreted the structural meaning via analysis of participants' explanations. Our primary contribution is a workaround taxonomy that is grounded on the shared consensus among participants. Our secondary contribution is to introduce and test the applicability of a systematic taxonomy development approach to the IS field. The taxonomy highlights the similarities of workaround behaviors within groups, and the similarities and differences between groups that are either on the same hierarchical level or adjacent levels. Researchers may use this taxonomy as a foundation for further theorization, practitioners as part of their diagnostic toolkit."
2704569,22457,20561,The Influence of Retweeting Robots During Brazilian Protests,2016,"Online Social Networks have been adopted by political groups in order to improve the reachability of protest movements. As such, these networks give us a rich data source for estimating the impact and participation on these events. In some situations, though, the organizers employ the use of bots to inflate the real impact of the event. These bots promote ideas while being disconnected from the political group social network. In this paper we investigate the dynamics of message sharing on the Twitter network during two contrastive protests that took place in Brazil in March of 2015. During the data collection, it was observed that some of the messages were massively shared by bots. The dynamics of message sharing, with and without the use of bots, were contrasted by means of different methodologies from the network science literature. It is observed that the use of bots indeed impacted on the network metrics, thus making it easier to detect such cases."
1699340,22457,9475,Convexification of Generalized Network Flow problem with application to power systems,2013,"This paper is concerned with the minimum-cost flow problem over an arbitrary flow network. In this problem, each node is associated with some possibly unknown injection, each line has two unknown flows at its ends related to each other via a nonlinear function, and all injections and flows need to satisfy certain box constraints. This problem, named generalized network flow (GNF), is highly non-convex due to its nonlinear equality constraints. Under the practical assumption of monotonicity and convexity of the flow and cost functions, a convex relaxation is proposed, which always finds the optimal injections. This relaxation may fail to find optimal flows because the mapping from injections to flows might lead to an exponential number of solutions. However, once optimal injections are found in polynomial time, other techniques can be used to find a feasible set of flows corresponding to the injections. A primary application of this work is in optimization over power networks. Recent work on the optimal power flow (OPF) problem has shown that this non-convex problem can be solved efficiently using semidefinite programming (SDP) after two approximations: relaxing angle constraints (by adding virtual phase shifters) and relaxing power balance equations to inequality constraints. The results of this work prove two facts for the OPF problem: (i) the second approximation (on balance equations) is not needed in practice under a very mild angle assumption, and (ii) if the SDP relaxation fails to find a rank-one solution, the optimal injections (and not flows) may still be recovered from an undesirable high-rank solution."
1484824,22457,9896,Harnessing the wisdom of crowds in wikipedia: quality through coordination,2008,"Wikipedia's success is often attributed to the large numbers of contributors who improve the accuracy, completeness and clarity of articles while reducing bias. However, because of the coordination needed to write an article collaboratively, adding contributors is costly. We examined how the number of editors in Wikipedia and the coordination methods they use affect article quality. We distinguish between explicit coordination, in which editors plan the article through communication, and implicit coordination, in which a subset of editors structure the work by doing the majority of it. Adding more editors to an article improved article quality only when they used appropriate coordination techniques and was harmful when they did not. Implicit coordination through concentrating the work was more helpful when many editors contributed, but explicit coordination through communication was not. Both types of coordination improved quality more when an article was in a formative stage. These results demonstrate the critical importance of coordination in effectively harnessing the wisdom of the crowd in online production environments."
3057658,22457,20561,Towards a Typology of Relevance,2017,"This essay presents a speculative work on making#N#distinctions among different equally valid types of#N#research relevance. The work is innovative not only#N#because it departs from the extant monistic#N#perspectives, where only narrow forms of relevance#N#are acknowledged, towards a pluralist perspective,#N#but also because it recognizes and accounts for the#N#plurality in the perceptions of relevance among#N#different stakeholder groups of the same research.#N#The pluralist perspective draws on the notion of#N#“empowerment,” widely employed in such domains#N#as education and social work, and suggests that#N#relevant research in fact can be understood as#N#empowering research to which different stakeholder#N#groups can relate in one way or another. Two#N#analytical dimensions are identified in relation to the#N#notion of “empowerment,” and are used in order to#N#demonstrate four general types of relevance that can#N#be achieved in IS research."
1624643,22457,9475,Concurrent learning adaptive identification of piecewise affine systems,2014,"In this paper, we enhance a recently proposed method for adaptive identification of piecewise affine systems by the use of concurrent learning. It is shown that the concurrent use of recorded and instantaneous data leads to exponential convergence of all subsystem parameters under verifiable conditions on the recorded data. A key advantage of the proposed method is that linear independence of the recorded data is sufficient, compared to the persistence of excitation assumed by previous adaptive parameter identifiers. Furthermore, the procedure tremendously improves the performance of adaptive identification for piecewise affine systems that previously suffered from slow convergence."
137360,22457,20332,Knowledge Encapsulation Framework for Collaborative Social Modeling,2009,"This paper describes the Knowledge Encapsulation Framework (KEF), a suite of tools to enable knowledge inputs (relevant, domain-specific facts) to modeling and simulation projects, as well as other domains that require effective collaborative workspaces for knowledge-based task. This framework can be used to capture evidence (e.g., trusted material such as journal articles and government reports), discover new evidence (covering both trusted and social media), enable discussions surrounding domain-specific topics and provide automatically generated semantic annotations for improved corpus investigation. The current KEF implementation is presented within a wiki environment, providing a simple but powerful collaborative space for team members to review, annotate, discuss and align evidence with their modeling frameworks. The novelty in this approach lies in the combination of automatically tagged and user-vetted resources, which increases user trust in the environment, leading to ease of adoption for the collaborative environment."
2062069,22457,9896,"Organizing without formal organization: group identification, goal setting and social modeling in directing online production",2012,"A challenge for many online production communities is to direct their members to accomplish tasks that are important to the group, even when these tasks may not match individual members' interests. Here we investigate how combining group identification and direction setting can motivate volunteers in online communities to accomplish tasks important to the success of the group as a whole. We hypothesize that group identity, the perception of belonging to a group, triggers in-group favoritism; and direction setting (including explicit direction from group goals and implicit direction from role models) focuses people's group-oriented motivation towards the group's important tasks. We tested our hypotheses in the context of Wikipedia's Collaborations of the Week (COTW), a group goal setting mechanism and a social event within Wikiprojects. Results demonstrate that 1) publicizing important group goals via COTW can have a strong motivating influence on editors who have voluntarily identified themselves as group members compared to those who have not self-identified; 2) the effects of goals spill over to non-goal related tasks; and 3) editors exposed to group role models in COTW are more likely to perform similarly to the models on group-relevant citizenship behaviors. Finally, we discuss design and managerial implications based on our findings."
1346518,22457,8228,Low Complexity Resource Allocation Algorithm by Multiple Attribute Weighing and User Ranking for OFDMA Systems,2006,"In this paper, we propose an effective subcarrier allocation scheme for multiuser orthogonal frequency division multiple access (OFDMA) system in the downlink transmission with low computational complexity. In the proposed scheme, by taking multiple attributes of a user channel, such as carrier gain decrease rate and variation from the mean channel gain of the system, to determine a rank for the user, subcarriers are then allocated depending on the individual users' rank. Different channel characteristics are used to better understand a users' need to subcarriers and hence determine a priority to user. We also adopt an attribute weighing scheme to enhance the performance of the proposed scheme. The scheme is efficiently computational, by avoiding using iterations for the algorithm convergence and also common water-filling calculations which might become complex with increasing system parameters. Low complexity is achieved by allocating subcarriers to users depending on their determined rank. Our proposed scheme is simulated in comparison with other mathematically efficient subcarrier allocation schemes as well as with a conventional greedy allocation scheme. It is shown that proposed method demonstrates better results than the simulated schemes."
2977859,22457,9475,Controlled link shedding for maximizing supportable demand of a disrupted power network,2016,"It is well-known that power networks are prone to cascading failures in the event of a network disruption. A traditional way to prevent such cascading failures is to shed some of the supportable demand from the network. Interestingly, due to the non-local nature of power flow distributions, further deliberate disconnection of lines in a disrupted power network can result in improvements in its supportable demand, the phenomenon resembling Braess' paradox. In this paper, we exploit this phenomenon to formulate a multi-stage control scheme using: a fast timescale, linear Network Stabilization Problem based on demand shedding; and a slow timescale, combinatorial Demand Maximization Problem based on link shedding. We provide a key example illustrating the paradox and some structural results demonstrating the limitations and potential of our control scheme. Using Simulated Annealing to tackle the large combinatorial problem, we also investigate the efficacy of our approach for the Polish power grid (which consists of 2383 buses and 2896 lines)."
140144,22457,20332,Contract enactment in virtual organizations: a commitment-based approach,2006,"A virtual organization (VO) is a dynamic collection of entities (individuals, enterprises, and information resources) collaborating on some computational activity. VOs are an emerging means to model, enact, and manage large-scale computations. VOs consist of autonomous, heterogeneous members, often dynamic exhibiting complex behaviors. Thus, VOs are best modeled via multiagent systems. An agent can be an individual such as a person, business partner, or a resource. An agent may also be a VO. A VO is an agent that comprises other agents.#R##N##R##N#Contracts provide a natural arms-length abstraction for modeling interaction among autonomous and heterogeneous agents. The interplay of contracts and VOs is the subject of this paper. The core of this paper is an approach to formalize VOs and contracts based on commitments.#R##N##R##N#Our main contributions are (1) a formalization of VOs, (2) a discussion of certain key properties of VOs, and (3) an identification of a variety of VO structures and an analysis of how they support contract enactment. We evaluate our approach with an analysis of several scenarios involving the handling of exceptions and conflicts in contracts."
1102567,22457,9896,Coordination and beyond: social functions of groups in open content production,2012,"We report on a study of the English edition of Wikipedia in which we used a mixed methods approach to understand how nested organizational structures called WikiProjects support collaboration. We first conducted two rounds of interviews with a total of 20 Wikipedians to understand how WikiProjects function and what it's like to participate in them from the perspective of Wikipedia editors. We then used a quantitative approach to further explore interpretations that arose from the qualitative data. Our analysis of these data together demonstrates how WikiProjects not only help Wikipedians coordinate tasks and produce articles, but also support community members and small groups of editors in important ways such as: providing a place to find collaborators, socialize and network; protecting editors' work; and structuring opportunities to contribute."
856683,22457,9896,Determinants of wikipedia quality: the roles of global and local contribution inequality,2010,"The success of Wikipedia and the relative high quality of its articles seem to contradict conventional wisdom. Recent studies have begun shedding light on the processes contributing to Wikipedia's success, highlighting the role of coordination and contribution inequality. In this study, we expand on these works in two ways. First, we make a distinction between global (Wikipedia-wide) and local (article-specific) inequality and investigate both constructs. Second, we explore both direct and indirect effects of these inequalities, exposing the intricate relationships between global inequality, local inequality, coordination, and article quality. We tested our hypotheses on a sample of a Wikipedia articles using structural equation modeling and found that global inequality exerts significant positive impact on article quality, while the effect of local inequality is indirect and is mediated by coordination"
2725330,22457,20561,BPMN4CP Revised -- Extending BPMN for Multi-perspective Modeling of Clinical Pathways,2016,"Clinical Pathways (CPs) can be seen as business processes of hospitals or clinical institutions. Modeling these pathways is an emerging field of research, as it provides promising benefits for systems integration, quality management and documentation. The Business Process Model and Notation (BPMN) provides a range of process-related concepts but naturally lacks in representing specific aspects from the CP domain. Therefore, the BPMN extension BPMN4CP was designed in a previous research project. In accordance with research guidelines from Design Science, the extension ran through an iteration based on its practical application within a telemedical project. Based on several new requirements, the extension was revised regarding to the integration of resources, documents, objectives and quality indicators. These concepts were assigned to particular perspectives and diagrams in order to support model complexity management and provide appropriate diagrams for respective stakeholders. In order to provide a commonly usable extension, these enhancements were implemented as BPMN meta model extension."
2641252,22457,20561,Geek Toys for Non-techies? Using Robots in Introductory Programming Courses for Computer Science Non-majors,2016,"While LEGO® MINDSTORMS® robots and Arduino boards are widely used today in high school education to stimulate pupils' interest for technologyrelated subjects or to introduce beginner computer science students to programming, it is interesting how these tools may be successfully used also in programming education of technology-agnostic noncomputer science majors. A possible lack of motivation as well as of practical IT skills to handle the development environments for these tools here form a specific challenge. Therefore, in this paper a learning environment and toolchain especially tailored for this target group is proposed and empirically evaluated in a classroom setting. Results indicate that with a proper setup and development environment these geek toys may be successfully used also for more technology-agnostic audiences."
2474555,22457,9896,Participation in an online mathematics community: differentiating motivations to add,2012,"Why do people contribute content to communities of question-answering, such as Yahoo! Answers? We investigated this issue on MathOverflow, a site dedicated to research-level mathematics, in which users ask and answer questions. MathOverflow is the first in a growing number of specialized Q&A sites using the Stack Exchange platform for scientific collaboration. In this study we combine responses to a survey with collected data on posting behavior on the site. User behavior suggests that building reputation is an important incentive, even though users do not report this in the survey. Level of expertise affects users' reported motivation to help others, but does not affect the importance of reputation building. We discuss the implications for the design of communities to target and encourage more contributions."
2096298,22457,369,QoS-Aware Load Balancing Algorithm for Joint Group Call Admission Control in Heterogeneous Networks,2012,"In heterogeneous network, it is likely that many mobile users send access requests at the same time. To avoid network congestion and provide users with good service experience, a novel joint group call admission control (JGCAC) algorithm is proposed. This algorithm includes two procedures: Firstly, the number of users allocated to each network is determined according to load balancing policy. Secondly, based on the evaluation values about network conditions and user requests, suitable users are admitted to each network by extended Hungary Algorithm. Simulation results indicate that the proposed algorithm can maintain load balancing among networks, reduce dropping rate and achieve a better user satisfaction."
1059729,22457,9896,HappyGo: a field trial of local group buying,2012,"Group buying is a business model where people with the same merchandise interests form a group and conduct the purchase together to achieve a discount. Third-party proxy websites negotiate with merchants for appealing deals and then provide them to end customers. We call it online group buying. Besides, there exists local group buying where the joiners, the initiator, and sometimes even the merchants are in the same local community. Such locality induces some interesting characteristics in group buying, which remain largely unexplored in the research community. This study attempts to reveal users' behaviors in group buying within the local context. We developed a mobile service called HappyGo that supports local group buying. We conducted a trial involving more than 300 users from a company office. From our findings, we believe that local group buying complements online group buying by creating a local economic circle while also providing users with social benefits."
2704646,22457,20561,Consumers' Expectations of Fair Data Collection and Usage -- A Mixed Method Analysis,2016,"Understanding consumers' expectations of fair data collection and usage (CEFD) in an online environment is critical in a time when the analysis of customer data is increasingly important for companies. Drawing on the psychological contract and justice theory, this study developed a holistic picture of customer expectations by applying a two-stage research design. In stage 1, in-depth interviews with customers and experts were conducted to gain an overview of customer expectations. In stage 2, results from an online survey among German consumers were analyzed. In general, customers expect a simplification of privacy statements and easier control options and are willing to switch to a competitor if it better fulfills expectations. Women and older respondents have higher expectations than men and younger respondents. A short field study of online retailing websites shows that companies are currently not fulfilling customer expectations. Managerial implica-tions are derived to improve this situation."
2100555,22457,9896,Searching for the goldilocks zone: trade-offs in managing online volunteer groups,2012,"Dedicated and productive members who actively contribute to community efforts are crucial to the success of online volunteer groups such as Wikipedia. What predicts member productivity? Do productive members stay longer? How does involvement in multiple projects affect member contribution to the community? In this paper, we analyze data from 648 WikiProjects to address these questions. Our results reveal two critical trade-offs in managing online volunteer groups. First, factors that increase member productivity, measured by the number of edits on Wikipedia articles, also increase likelihood of withdrawal from contributing, perhaps due to feelings of mission accomplished or burnout. Second, individual membership in multiple projects has mixed effects. It decreases the amount of work editors contribute to both the individual projects and Wikipedia as a whole. It increases withdrawal for each individual project yet reduces withdrawal from Wikipedia. We discuss how our findings expand existing theories to fit the online context and inform the design of new tools to improve online volunteer work."
920574,22457,9896,The Success and Failure of Quality Improvement Projects in Peer Production Communities,2015,"Peer production communities have been proven to be successful at creating valuable artefacts, with Wikipedia as a prime example. However, a number of studies have shown that work in these communities tends to be of uneven quality and certain content areas receive more attention than others. In this paper, we examine the efficacy of a range of targeted strategies to increase the quality of under-attended content areas in peer production communities. Mining data from five quality improvement projects in the English Wikipedia, the largest peer production community in the world, we show that certain types of strategies (e.g. creating artefacts from scratch) have better quality outcomes than others (e.g. improving existing artefacts), even if both are done by a similar cohort of participants. We discuss the implications of our findings for Wikipedia as well as other peer production communities."
361004,22457,8228,Integration of IEEE C37.118 and publish/subscribe communication,2015,"IEEE C37.118 is the current standard for synchrophasor measurements in power systems. It defines the measurement method and communication protocols for the entities in a synchrophasor network. The standard offers two different modes for client-server communication, but cannot be used unchanged over publish/subscribe communication architectures, whose major advantage is simplified and incremental integration of new applications. This work reviews the communication part of IEEE C37.118, and provides an adapter-based solution to easily connect and integrate entities in a synchrophasor network over a publish/subscribe communication architecture. The proposed adapters offer standard-compliant communication between the synchrophasor measurement network entities to facilitate the exchange of measurement data."
1586725,22457,9896,Readers are not free-riders: reading as a form of participation on wikipedia,2010,"The success of Wikipedia as a large-scale collaborative effort has spurred researchers to examine the motivations and behaviors of Wikipedia's participants. However, this research has tended to focus on active involvement rather than more common forms of participation such as reading. In this paper we argue that Wikipedia's readers should not all be characterized as free-riders -- individuals who knowingly choose to take advantage of others' effort. Furthermore, we illustrate how readers provide a valuable service to Wikipedia. Finally, we use the notion of legitimate peripheral participation to argue that reading is a gateway activity through which newcomers learn about Wikipedia. We find support for our arguments in the results of a survey of Wikipedia usage and knowledge. Implications for future research and design are discussed."
1672485,22457,20524,Model-based diagnosis of spreadsheet programs: a constraint-based debugging approach,2016,"Spreadsheet programs are probably the most successful example of end-user software development tools and are used for a variety of purposes. Like any type of software, they are prone to error, in particular as they are usually developed by non-programmers. While various techniques exist to support the developer in finding errors in procedural programs, the tool support for spreadsheet debugging is still limited. In this paper, we show how techniques from model-based diagnosis can be applied and extended for spreadsheet debugging by translating the relevant parts of a spreadsheet to a constraint satisfaction problem. We additionally propose both problem-specific and generalizable extensions to the classical diagnosis algorithms which help to detect potential problems in a spreadsheet based on user-provided test cases more efficiently. The proposed techniques were integrated into a modular framework for spreadsheet debugging and evaluated with respect to scalability based on a number of real-world and artificially created spreadsheets. An additional error detection exercise involving 24 subjects was performed to assess the general applicability of such advanced spreadsheet debugging techniques for end users."
1013312,22457,8806,Collaborative modeling of business processes: a comparative case study,2009,We study collaborative modeling of business processes with respect to the impact of tool support on the modeling process. For this purpose we compared model quality and modeling costs in two cases. The first was carried out with the help of a collaborative modeling tool; in the second case we kept all other parameters as closely as possible to the first one but conducted the modeling session in the usual way without tool support. We observed a marked increase in modeling time in the second case and a reduction in model quality.
2492590,22457,9896,Beyond Wikipedia: coordination and conflict in online production groups,2010,"Online production groups have the potential to transform the way that knowledge is produced and disseminated. One of the most widely used forms of online production is the wiki, which has been used in domains ranging from science to education to enterprise. We examined the development of and interactions between coordination and conflict in a sample of 6811 wiki production groups. We investigated the influence of four coordination mechanisms: intra-article communication, inter-user communication, concentration of workgroup structure, and policy and procedures. We also examined the growth of conflict, finding the density of users in an information space to be a significant predictor. Finally, we analyzed the effectiveness of the four coordination mechanisms on managing conflict, finding differences in how each scaled to large numbers of contributors. Our results suggest that coordination mechanisms effective for managing conflict are not always the same as those effective for managing task quality, and that designers must take into account the social benefits of coordination mechanisms in addition to their production benefits."
1755286,22457,20358,Volunteer computing: a model of the factors determining contribution to community-based scientific research,2010,"Volunteer computing is a powerful way to harness distributed resources to perform large-scale tasks, similarly to other types of community-based initiatives. Volunteer computing is based on two pillars: the first is computational - allocating and managing large computing tasks; the second is participative - making large numbers of individuals volunteer their computer resources to a project. While the computational aspects of volunteer computing received much research attention, the participative aspect remains largely unexplored. In this study we aim to address this gap: by drawing on social psychology and online communities research, we develop and test a three-dimensional model of the factors determining volunteer computing users' contribution. We investigate one of the largest volunteer computing projects - SETI@home - by linking survey data about contributors' motivations to their activity logs. Our findings highlight the differences between volunteer computing and other forms of community-based projects, and reveal the intricate relationship between individual motivations, social affiliation, tenure in the project, and resource contribution. Implications for research and practice are discussed."
2704664,22457,20561,Beyond the Border: A Comparative Literature Review on Communication Practices for Agile Global Outsourced Software Development Projects,2016,"Software development is increasingly heading in the direction of combining agile software development practices and outsourcing software development to external vendors worldwide. The resulting agile global outsourced software development (AGOSD) projects are characterized by applying agile methods to distributed environments, which results in several problems for collaboration and coordination. Specifically, communication between the project participants has been found to be a major challenge in distributed environment. Therefore, our study investigates the problem of improving communication in distributed settings by identifying suitable communication practices for usage within AGOSD projects. Based on an extensive literature review, our study (1) provides an overview of adequate practices for usage in AGOSD and (2) points out differences to traditional communication practices of agile software development (ASD) projects used in collocated, non-distributed environments."
770724,22457,9896,Social Loafing in Technology-Supported Teams,2008,"This study examines the occurrence of social loafing in technology-supported teams along with methods for diminishing loafing. A controlled laboratory experiment with a 3?×?2?×?2 factorial design is used. The independent variables --- feedback, anonymity, and group size --- are manipulated experimentally. It was expected that social loafing --- a widely observed phenomenon --- would indeed occur in technology supported teams. It was also expected that the traditional means of reducing social loafing (i.e., identifiability and feedback) within physical work environments would also have similar effects within technology-supported work environments. As expected, social loafing is found to occur in teams operating in a technology-driven realm. An unexpected finding is that social loafing is measurable only when participants are provided self-feedback. While other forms of feedback have a positive influence on productivity, they fail to reduce this phenomenon, and identifiability of group members is found to have no observable effect on social loafing."
1592597,22457,9896,"Network structure, position, ties and ICT use in distributed knowledge-intensive work",2008,"In this study, we develop a theoretical model based on social network theories and the social influence model to understand how knowledge professionals utilise technology for work and communication. We investigate the association between egocentric network properties (structure, position and tie) and information and communication technology (ICT) use of individuals in knowledge-intensive and geographically dispersed settings. Analysis from data collected using a reliable and validated questionnaire show that task-level ICT use is significantly associated with degree centrality and functional tie-diversity; and communication-level ICT use is negatively associated with efficiency. Implications of these associations for knowledge-intensive work are discussed in conclusion."
1790430,22457,20561,Understanding price volatility in electricity markets,2000,The paper illustrates notions of volatility associated with power systems spot prices for electricity. The paper demonstrates a frequency-domain method useful to separate out periodic price variations from random variations. It then uses actual observed price data to estimate parameters such as volatility and the coefficient of mean reversion associated with the random variation of prices. It also examines spatial volatility of prices.
2233908,22457,20561,Organizational Impacts of Cyber Security Provisions: A Sociotechnical Framework,2007,"In this paper, we outline a conceptual framework for linking cyber security provisions to business processes. The framework is presented for use in analyzing the cost and performance impacts of cyber security implementation on business processes in government agencies and other organizations. We argue that such an analysis should be based on a sociotechnical approach to understanding information security in the organizational context. The results of such analysis can be useful in government cyber security planning and investment decisions"
869967,22457,20561,The Development of a University-Based Forensics Training Center as a Regional Outreach and Service Activity,2007,This paper describes a university-based Forensics Training Center (FTC) established by a Department of Justice grant for the purpose of improving the ability of state and local law enforcement in the Southeastern part of the United States to address the rising incidence of computer based crime. The FTC effort is described along with supporting evidence of its need. Current and planned activities of the FTC are described
1963738,22457,20561,An integrated model on the adoption of Internet for commercial purposes,1998,"Internet commerce is fundamentally re-shaping the course of businesses. There is tremendous potential for enterprises to harness the power of Internet commerce to improve their productivity and sharpen their competitive edge in both local and international markets. It is therefore of importance that insight be gained into the factors affecting the adoption of the technology. This paper reviews models of adoption of electronic commerce in general, and proposes an integrated model for Internet commerce."
1986571,22457,20561,Electronic Medical Records: A Review Comparing the Challenges in Developed and Developing Countries,2008,"Studies on the adaptation of electronic medical and personal health records in developing countries are scarce. There are sharp differences between barriers to adaptation and implementation in developing countries to that of developed countries. This paper examines the challenges faced by developing countries toward the development, progression and sustainability of electronic medical records. The paper also provides a review of implementation of varying types of electronic medical data management systems in developing countries."
255186,22457,20561,Enhancing the Visualization of Big Data to Support Collaborative Decision-Making,2015,"This paper proposes the use of advanced data displays to promote the visualization of big data for supporting collaborative decision-making through enhanced synchronicity and team convergence. We review relevant literature and put forth propositions about the impact and interaction of task, data, and media attributes. We conclude by describing how the propositions can be empirically tested and highlighting the contributions of our work."
897597,22457,20561,Aligning IT Assets to Maximize Healthcare Organizational Performance,2013,"This study examines the impact of healthcare information technology assets on organizational efficiency. Using an econometric approach with data envelopment analysis, we examine the effect of IT asset clusters on organizational efficiency as measured relative to a peer group of healthcare organizations We observe that different IT asset clusters have varying effects on organizational efficiency based on the size of the organizations. The results of this study have implications for healthcare organizations in planning their investments across various IT asset clusters."
506028,22457,20561,The Impact of Electronic Commerce on the Travel Industry,1997,"This paper introduces an approach to analyzingthe impact of electronic commerce on an industry anddescribes how industry players can devise plans totake advantage of new business opportunities. We'llelaborate on this approach in the context of the travelindustry. This paper draws on our work on classifyingtechnologies used in electronic commerce, thebusiness value of electronic commerce, and a currentresearch project on the impact of electronic commerceon the travel industry."
1756300,22457,20561,The Interactive Digital Entertainment (IDE) Unification Framework: Creating a Taxonomy of IDE and Lifestyle Computing,2007,"In this paper, we create a taxonomy of interactive digital entertainment (IDE), which can be used to guide future research in IDE and direct the design of interactive entertainment. We start by defining and explaining the differences between IDE and lifestyle computing. We then review the major taxonomies on gaming that can illuminate research and practice with IDE. Given this review, we propose an overarching taxonomy called the IDE unification framework. Based on this framework, we then propose promising areas for future research"
868409,22457,20561,Culture Matters: Factors Affecting the Adoption of Telemedicine,2013,"The present research investigates the influence of culture on telemedicine adoption and patient information privacy, security, and policy. The results, based on the SEM analysis of the data collected in the United States, demonstrate that culture plays a significant role in telemedicine adoption. The results further show that culture also indirectly influences telemedicine adoption through information security, information privacy, and information policy. Our empirical results further indicate that information security, privacy, and policy impact telemedicine adoption."
2049235,22457,20561,"The Impact of Media Richness, Suspicion, and Perceived Truth Bias on Deception Detection",2005,"As new media channels, with varying degrees of richness, become more necessary to communicate efficiently, it is important to be able to detect deception in communication. This study is designed to look at the level of media richness and its resulting impact on the level of suspiciousness of the receiver. This suspiciousness in turn impacts one's tendency to use the truth-bias in assessing this communication. All of these relationships were found to be significant."
2433297,22457,20561,Identifying the dependent variables of IT personnel transition,2002,"This paper reports the initial findings from a National Science Foundation supported study of IT personnel transition. We used the revealed causal mapping method to elicit barriers, enablers, and examples of IT personnel transition. This paper reveals new knowledge and insight into the dependent variables of transition. The data is presented in the form of respondent quotes and interpretation of revealed causal maps from 83 respondents."
2090230,22457,20561,Extrinsic or Intrinsic Motivation of E-Negotiation Experiments' Participants,2011,"Motivation of the negotiation experiments participants affects their behavior and performance. We asked students participating in online experiments to assess the subjective importance of seven objectives associated with the negotiation. Based on the responses we identified three types of motivation. We also identified four participants' profiles which differ in the assessment of the significance of the motivations. The implications of the relationship between profiles, motivation, and the process and its results is discussed."
505717,22457,20561,Information Exchange and Use in GSS and Verbal Group Decision Making,1997,"The purpose of this study was to investigate the effectsof GSS use on the exchange and use of information ingroup decision making under two conditions: when therewas and was not a majority/minority split of opinion inthe group. When there was a distinct majority/minority,groups using a GSS exchanged more information, madebetter decisions, and took no more time than when theydid not use a GSS In the uniform treatment where therewas no majority/minority, groups using a GSS exchangedmore information, but made worse decisions, and tookmore time than when they did not use a GSS."
2471349,22457,20561,An organizational exchange model: theory and implementation,1996,"Organizational decision support systems (ODSSs) provide the organization with a powerful vehicle to represent to its members the circumstance of the organization through the models embedded in the ODSS. The paper proposes an organizational exchange modeling (OEM) paradigm. The paper discusses the importance of exchange to organizational processes, provides a graphical model to represent exchange features and relates the proposed model to several other models and frameworks."
256415,22457,20561,Improving Successful A+B Procurement Auctions with Negotiations,2015,"In A+B procurement auctions the buyer's utility is linear and the bidders' utility is assumed to be quasi-linear. If this assumption is met, then a successful auction may conclude with an efficient winning bid which maximizes both the buyer's utility and social welfare. If this assumption is not met, then an auction is either efficient and maximizes social welfare or it maximizes the buyer's utility. If the bidders are risk-averse, then a winning bid that maximizes the buyer's utility may be further improved through negotiations. It is possible to introduce side-payments which increase utility values of both the buyer and the seller."
355850,22457,20561,An Argument for Centralization of IT Governance in the Public Sector,2015,"Using a configurational crisp set Qualitative Comparative Analysis (csQCA) approach, we find that effective public sector IT governance is structured differently than in the private sector. While states adopt a variety of IT governance structures, it is unmistakable that centralized yields better organizational outcomes than decentralized. As such, this paper makes a case for additional research in public sector governance in order to understand and explain these differences."
1866985,22457,20561,Power-efficient delay-insensitive codes for data transmission,1995,Introduces and formalizes the notion of dynamic delay-insensitive codes for data communication. We describe several codes and protocols designed to optimize switching energy expended at the data pins during data transmission in asynchronous systems. These include adaptations of some existing communication methods as well as some new techniques for reducing energy used in dynamic data communication between delay-insensitive circuits. >
379632,22457,20561,What Is Complex About 273 Applications? Untangling Application Architecture Complexity in a Case of European Investment Banking,2009,"In this paper, we first derive propositions from the current literature addressing the causes and impacts of application architecture (AA) complexity. We then untangle AA complexity itself by differentiating four types of AA complexity that are mingled in extant literature: interdependency-, diversity-, deviation-, and overlap-related AA complexity. Based on this more differentiated view, we validate the propositions in the setting of a European Bank. Our findings suggest that only interdependency-related AA complexity behaves as currently assumed. Other types show partially opposite effects."
1039415,22457,8306,Remote operation and control of computer engineering laboratory experiments,2006,"We present a lab-in-a-box, a metal case needing only power supply and network access, to provide a complete infrastructure to establish a microprocessor laboratory for embedded applications in computer engineering. The laboratory is used in distance teaching and thus all instruments and devices are controlled and observed via the net. Our focus is on flexibility to setup experiments, and on scheduling access to such a laboratory."
2497490,22457,20561,Linking Technology and New Product Development,2009,"This study explores the linkage between technology development and new product development (NPD). Literature suggests that there is gap between technology development and product development. We develop a set of propositions through review of previous research and a case study from the semiconductor industry. We conclude that for successful integration of technologies into products, a formal technology integration process and technology portfolio management are highly recommended to prevent a misalignment between technology development and product development processes."
1476680,22457,20561,The Diffusion of Mobile Social Network Service in China: The Role of Habit and Social Influence,2013,"The present paper aims to investigate Chinese users' behavior toward adoption of mobile social network services. Based on a sample of 336 respondents who use the most popular mobile social network services (Tencent QQ) in China, structural equation modeling analysis suggests that, use context, habit, social influence, critical mass and ubiquitous ness of social network service make unique contributions to our understanding of mobile social network service acceptance behavior."
1869103,22457,20561,Spoken documents: creating searchable archives from continuous audio,2000,"Current search technologies for audio rely on the cataloguer of the data to provide additional keywords or metadata to enable retrieval. This can lead to haphazard cataloging and misleading searches, and provides the end user with no summarization, editing, or information extraction capabilities. One obvious way to tackle this problem is to transcribe the speech-based audio using automatic speech recognition technology."
2443506,22457,20561,Insider Threat Program Best Practices,2013,"Based on experiences with different organizations having insider threat programs, the components needed for an insider threat auditing and mitigation program and methods of program validation that agencies can use when both initiating a program and reviewing an existing program has been described. This paper concludes with descriptions of each of the best practices derived from the model program. This final section is meant to be a standalone section that readers can detach and incorporate into their insider threat mitigation program guidance."
1774848,22457,20561,A Typology of Requisite Skills for Information Technology Professionals,2011,"Based on qualitative and quantitative analysis of data gathered in structured interviews with 96 IT managers and executives, this paper proposes a typology of IT skills. The resulting typology is comprehensive enough to represent both current and future skills, concise enough to do so in a parsimonious and easily understood manner, consistent with general themes from prior research, and generalizable enough to accommodate future changes in the field."
714414,22457,20561,Creativity at the Margins: Exploring Social and Technical Marginality in Novel Idea Generation,2014,"If an individual on the edge of a problem's context can generate creative solutions to that problem, does this capacity emerge in spite of their marginality...or because of it? How can this marginality be leveraged in a collaborative context? The purpose of this paper is to explore the link between marginality and creativity through untangling of technical and social marginality. We advance the sociocognitive processes that lead marginal individuals, more so than those who are more embedded, to positively impact individual and group-level creative performance. We derive implications for a collaborative context."
1582942,22457,20561,Knowledge Management Success in Practice,2014,Knowledge management literature does not provide much guidance on how to measure the success or benefits of doing knowledge management. This paper discusses research that proposes a definition of knowledge management success and dimensions and measures that organizations can use to measure knowledge management success. A nuclear utility engineering organization and professional services firms in Europe are used as surrogate cases to illustrate how these dimensions and measures can be used to demonstrate the success of a knowledge management project.
1767513,22457,20561,Internet-based delivery and deployment of document management systems,2001,"In recent years, business on the Internet has exponentially increased. Consequently, the deployment and management of business applications on the Internet is becoming more and more complex, which requires the development of new Internet architectures suitable to efficiently run these business applications. The authors present a novel, revolutionary ASP (Application Service Provider) approach implemented by CyLex Systems in deploying document management systems."
3215295,22457,20561,MUDdling Through,1997,"The wOrlds project is concerned with developing next-generationcollaboration frameworks. We strongly believe thatreal progress in enhancing the usability of collaborativesystems hinges on improving our understanding of work,and applying the resulting insights to development of collaborativework support frameworks. We are investigatingthe thesis that appropriate bases for such an approach canbe drawn from existing results in sociology, specifically thework of sociologist Anselm Strauss, and his notion ofsocial worlds. In this paper we motivate and overviewwOrlds, the collaborative environment we have built inorder to explore our ideas and insights. We then critiquewOrlds (and, by implication, the class of systems known asMUDS of which it is a member), and point to future directionsfor investigation."
3137090,22457,10228,Analyzing Directional Modulation Techniques as Block Encryption Ciphers for Physical Layer Security,2017,"This paper presents a framework - PLR-Probe - consisting of two layers: (1) Mapping Layer and (2) Computing amp;amp; Decision Layer. In Mapping Layer (ML), the Directional Modulation Techniques (DMTs) are analyzed as block encryption ciphers by mapping their major components to the components of DMTs. The cryptographic strength of random stream of bits, received by eavesdropper in Physical Layer Security (PLS) techniques is explored and compared by Computing amp;amp; Decision Layer (CDL), with that of strong block ciphering algorithm (i.e. AES). To prove the effectiveness and relevance of the framework, we applied it on a recently proposed Antenna Subset Modulation (ASM) technique. We measured the cryptographic strength of the ASM technique by mapping it to a physical layer encryption method. The other major contribution is: using PLR-Probe, communication researchers can benchmark the cryptographic strength of any PLS technique with AES. In this paper, ASM is benchmarked against AES by using a novel metric (Physical Layer Randomness (PLR)). The analysis can be made comprehensive by considering PLR along with Symbol Error Rate (SER) and Secrecy Capacity (SC) as optimization parameters to improve the cryptographic strength of PLS techniques."
2699832,22457,9896,Encouraging Work in Citizen Science: Experiments in Goal Setting and Anchoring,2016,"This paper describes the results of an online i� eld exper-iment where we designed and analyzed the effects of a goal-setting tracker in an online citizen science project -Floating Forest. The design of our tracker was ini� uenced by psychology theories of anchoring and goal-setting. Our results of our experiment revealed: (1) setting goals increases annotations in a session; (2) numeric anchors ini� uence goals; and (3) participants in the treatment who saw a prompt but did not set a goal, contributed more an-notations than the participants in the control group. Our research shows how goal-setting and anchoring combine to increase work in online communities."
2236662,22457,20332,Towards A Role of Visualization in Social Modeling,2009,"The traditional role of visualization in large scale social modeling projects has mostly been relegated to presentation and reporting. While these projects see the potential of communicating information visually, the visualization component has too often been considered as the final stage of a long process, sometimes as a lastminute add-on. The result is that these visualization components are limited in capabilities, and often appear disjointed and forced from the rest of the project. In this paper, we propose that for visualization to be more commonly accepted, it needs to fit the role as an analytical tool on top of being a presentation component. We use our probe-based visualization as an example of how such cross-over can occur, and present some challenges in social modeling that can be addressed using visualization techniques. Visualization is becoming prevalent in our everyday lives. Popular websites such as Google Maps, the Visual Thesaurus, and Baby Name Voyager have increased the public’s awareness of how information can be efficiently communicated visually. In the past few years alone, visualization components are appearing with more frequency in the final products of large scale social modeling projects. However, a gap still remains between how the visualization community identifies itself and the perception of the role of visualization by the other disciplines. For too often visualization is considered to be the last step of a project, where visualization experts are asked to “make pretty pictures out of the final data” without having participated in the design or implementation of the overall system. We propose that for visualization to take a more integral part in these systems, it needs to fulfill both the roles of a presentation tool as well as an analytical tool. Not only does visualization need to deliver the “pretty pictures,” it also needs to provide the analytical capability that is difficult for non-visual components to deliver. As an example, we describe our probe-based visualization that supports interactive analysis and presentation of an agent-based simulation. We then propose additional challenges in social modeling that can be addressed by integrating a visualization component."
2816122,22457,20561,Using Context-Based Password Strength Meter to Nudge Users' Password Generating Behavior: A Randomized Experiment,2017,"Encouraging users to create stronger passwords has always been one of the key issues in password-based authentication. It is particularly important as passwords are still the most common user authentication method. Furthermore, prior works have highlighted that most passwords are significantly weak. In this paper, we seek to mitigate such an issue by proposing a context-based password strength meter and investigating its effectiveness on users' password generating behavior. We conduct a randomized experiment on Amazon MTurk involving hypothetical account creating scenarios. We observe the change in users' behavior in terms of the number of occasions where users change their password after seeing the warning message, the number of occasions where users want to learn more about creating stronger passwords, and the changes in password strength. We find that our proposed password strength meter is significantly effective. Users exposed to our password strength meter are more likely to change their password, and those new passwords are stronger. Furthermore, if the information is readily available, users are willing to invest their time to learn about creating a stronger password, even in a traditional password strength meter setting. Our findings suggest that simply incorporating a contextual information to password strength meters could be one of potential methods in promoting secure behaviors among end users."
1883965,22457,10228,Price Discount over Satellite Digital Multimedia Broadcast System Through a Demand Sensitive Model,2007,"This paper proposes a novel demand sensitive model (DSM) for tuning price service over SDMB (satellite digital multimedia broadcast) system offering a price discount to large amount of users while maintaining profit for the service provider. The discounted price is determined based on a marginal decision rule using a simple pseudo-linear function of the weight factor and the number of users. For testing the proposed model, an integrated satellite-terrestrial network architecture offering SDMB services to mobile users through the satellite or terrestrial UMTS segment, has been utilized. Simulations have been carried out to show the goodness of the proposed model within the system architecture; moreover the model, based on simple parameters, is very flexible and can be easily integrated in a price adapter module making the offered service attractive for end users and in the same time profitable for the satellite operator."
1597409,22457,8839,Poster -- SAfeDJ community: situation-aware in-car music delivery for safe driving,2014,"Driving is an integral part of our everyday lives, but it is also a time when people are uniquely vulnerable. Poor road condition, traffic congestion and long driving time may bring negative emotion to drivers and increase the chance of traffic accidents. We propose SAfeDJ, a situation-aware in-car music delivery application, which turns people's trips into pleasant journeys and driving into a safe and enjoyable activity. SAfeDJ aims at helping drivers to diminish fatigue and negative emotion. It is built on a vehicular healthcare platform that enables communications among drivers and integrates with multiple types of sensors to promote safe driving. Prototype implementation and initial results of SAfeDJ have demonstrated its desired functionality in drivers' daily lives and feasibility for real-world deployment."
2000080,22457,9704,Password Management for EPC Class 1 Generation 2 Transponders,2008,"RFID systems compliant to the widely-used standard EPC class 1 generation 2 lack effective security mechanisms. We show that passwords used to protect critical functionality can be obtained by attackers with only moderate effort. Since more capable systems are not likely to replace the current standard in the medium term, it is crucial to embed the deployment of RFID technology into IT-ecosystems that ensure a minimization of the potential damage caused by an attack. This objective can be achieved by using transponder-individual passwords. The associated challenge of an efficient and scalable password management remains one of most pressing problems of an enterprise-spanning RFID deployment, however. In this paper, we present two approaches for a password management infrastructure and describe their integration into a retailer's processes."
936574,22457,9896,Using edit sessions to measure participation in wikipedia,2013,"Many quantitative, log-based studies of participation and contribution in CSCW and CMC systems measure the activity of users in terms of output, based on metrics like posts to forums, edits to Wikipedia articles, or commits to code repositories. In this paper, we instead seek to estimate the amount of time users have spent contributing. Through an analysis of Wikipedia log data, we identify a pattern of punctuated bursts in editors' activity that we refer to as  edit sessions . Based on these edit sessions, we build a metric that approximates the labor hours of editors in the encyclopedia. Using this metric, we first compare labor-based analyses with output-based analyses, finding that the activity of many editors can appear quite differently based on the kind of metric used. Second, we use edit session data to examine phenomena that cannot be adequately studied with purely output-based metrics, such as the total number of labor hours for the entire project."
824163,22457,9896,Fairness in the division and completion of collaborative work,2013,"Fairness is often a concern when groups of people engage in collaborative tasks. Through the use of simple bargaining experiments, my PhD examines preferences for fairness during the allocation and completion of work. One goal of my work is to assess the applicability of existing theories about fairness to the context of CSCW. Overall, though, I aim to provoke discussion about how fairness preferences might be supported in the design of collaborative work tools."
2667612,22457,20561,Potential of Collaborative Mapping for Disaster Relief: A Case Study of OpenStreetMap in the Nepal Earthquake 2015,2016,"In the aftermath of a disaster, there is an urgent need for base maps to support relief efforts, especially in developing countries. In response to this, the OpenStreetMap project has been leveraged to produce maps of disaster-affected areas in a collaborative way. However, there has been little investigation aimed at explaining the collaborative mapping activity itself. This study presents an exploratory case study on how the collaborative mapping activities that followed the Nepal Earthquake in 2015 were coordinated and structured, i.e. how volunteers were organized, and what were the main outcomes of their activity in the context of disaster management. The results show that a large number of remote contributors spread across the world carried out concerted efforts to support the relief work. Moreover, coordination mechanisms were used by local actors to share their knowledge with remote mappers, and, hence, to improve the accuracy of the map."
1897994,22457,8806,Understanding and improving Wikipedia article discussion spaces,2011,"Wikipedia's article discussion spaces (Talk pages) form a large and growing proportion of the encyclopedia, used for collaboration and article improvement. So far there is no in-depth account of how article Talk pages are used, what is wrong with them, and how they can be improved. This paper reports on three contributions promoting the understanding of and improvement of these spaces: (1) Wikipedia editor interviews provide an increased understanding of readers' and editors' needs, (2) a large-scale comparative content analysis adds to knowledge of what kinds of discussions and coordination occur on Talk pages, (3) a prototype bookmarklet-based system, which we test in a formative user evaluation, integrates lightweight semantics."
2677450,22457,20561,"Introduction to the Cybercrimes, Cyber-Physical Innovations, and Emerging Investigation Challenges Minitrack",2016,"As technology is incorporated into more aspects of daily life, cybercrimes evolve and diversify, resulting in data intensive environments. Increasing smart-phone sales, increasing digital evidence requests in legal environments, the increasing generation and storage of digital transactions through the integration of the 'Internet of Things' (IOT), and the development of cyber-physical attacks all point to the broad societal impacts of technology. The dangers of cyber-physical threats are evidenced by a recent attack on a German steel mill that destroyed a blast furnace [1]."
2962954,22457,20561,One for All? Managing External and Internal Crowds through a Single Platform - A Case Study,2017,"Whereas crowdsourcing as a topic has often been addressed in recent literature, web-based crowdworking platforms that manage the interface between crowdsourcers and crowdworkers have not received much attention so far. Furthermore, most of these platforms focus on either the management of external or internal crowds; platforms that handle both groups are rare. This paper investigates such a provider: the German company Across Systems. It uses a hybrid model, offering an individual “mini crowdworking platform” that enables the simultaneous government of external and internal crowds as well as a more traditional marketplace crowdworking platform (crossMarket) where supply and demand meet. Using a single-case study approach, the main contribution of this paper is to shed light on a model that has the potential to change the current crowdworking platform market. We show that managing both external and internal crowds on one#R##N#platform can increase the acceptance, quality and speed of task completion."
2650464,22457,20561,Exploring a Systematic Approach to Malware Threat Assessment,2016,"Security incidents occur at an alarming rate with malicious software (malware) involved in a large number of these incidents. Current malware evaluation and handling practices in organizations are unstandardized and intelligence regarding threat levels often comes from vendors and peers, who lack a unified threat metric system. This paper explores a method to quantify malware threats systematically and proposes a quantitative malware threat metric system. The proposed method makes communicating the level of threat more effective and efficient, particularly for information sharing organizations."
920004,22457,9896,Awareness Support for Combining Individual and Collaborative Process Design in Co-located Meetings,2013,"The collaborative design of complex systems is a challenging task. It requires phases of linear as well as creativity oriented work. Also phases of collaborative work have to alternate with work in solitude, requiring a smooth transition between them. This in turn results in awareness becoming a crucial factor. Within the context of designing socio-technical processes through modeling we have developed tools and methods to integrate individual and collaborative creativity into modeling with special respect to awareness thus allowing for a smooth transition between phases of working in solitude and phases of collaboration. We have conducted multiple experiments on the subject following an action research approach which allowed for reflecting on the influence of awareness on collaborative process design in co-located meetings while also improving the socio-technical setting they were applied in. Derived from our findings we show requirements for further development of the socio-technical setting and show future directions such as the integration of the described setting into other areas of design."
2650844,22457,20561,Did You LINE Today? Strategies for Creating LINE Online to Offline Customer Experiences,2016,"The popularity smart phones, mobile applications (Apps) have exploded in recent years creating unlimited business opportunities. Today's customers desire to acquire not only software and products, but also memorable experiences. Using O2O (Online to Offline, Offline to Online) marketing strategies, customers interact with software and products in the real world that doing so will help them increase their imagination and enjoyment, providing them with different and memorable experiences. An exploratory qualitative study was undertaken using case study LINE&. Data were collected from secondary documents and interviews with customers about LINE's O2O services for creating customer experiences over the past three years. This study focuses on LINE's integration of online App-based services and offline real-world marketing, categorizes these services into five types of experiential strategy models based on their different characteristics. We conclude with several lessons related to the integration of the virtual and physical worlds to create customer O2O experiences."
2438687,22457,8228,Peer-to-Peer Mobility Management for all-IP Networks,2006,"With the increasing number of wireless devices, the importance of mobility management in future mobile networks is growing. Traditional mobility management approaches are based on client/server paradigms, and suffer from their well-known shortcomings (single point of failure, congestion, bottlenecks). With the success of P2P for file sharing applications, we believe that its benefits can be brought into new mobility management schemes to improve their scalability, robustness, availability, and performance. To the best of our knowledge, this paper is a first attempt to examine the potential of P2P concepts for mobility management. We perform experiments to quantify the performance of the proposed scheme, and compare it to traditional approaches such as Mobile IP."
3024533,22457,20561,"Effects of Color Appeal, Perceived Risk and Culture on User’s Decision in Presence of Warning Banner Message",2017,"Color is present in every aspect of human life, and color is driving our decisions. In the digital computer warning realm, in which a warning message is a communication mechanism, color represents an important design element, which aims at preventing the hazard and reducing negative outcomes from the user’s action. Interestingly, we are lacking the understanding of how color appeal influences behavioral intentions in culturally distinct countries when it comes to paying more attention to warning messages. We conducted a cross-cultural investigation by running an online experiment, followed by a survey of 258 participants from the United States and India. Supported by the color-in-context theory, we found that culture is an important dimension in the specific warning message context in which color appeal is a salient antecedent to behavioral intentions in culturally distinct countries. We derive several theoretical contributions and practitioners’ insights."
2556530,22457,9704,The Factors Affecting Institutionalisation of Enterprise Architecture in the Organisation,2009,"Abstract— Despite impressive technical advances in tools and methodologies and the organizational insights provided by many years of academic and business researches, the underperformance of Information Technology (IT) remains.In the past and even today, organizations experience difficulty in managing technology, changing from system to system, implementing new technology, maintaining compatibility with existing technologies, and changing from one business process to another. These problems impact significantly on business performance and will continue to do so if not addressed. As a result, many organizations have deployed EA in an attempt to address these challenges. However, the design and development of EA has proven to be easier than its institutionalization. The study explored the development and implementation of EA to determine the factors, which are barriers to its institutionalization. Two case studies were conducted."
1296902,22457,9475,Optimal control of cascading power grid failures,2011,"We study algorithms for computing optimal load shedding schedules in the event of a cascading power system failure. The algorithms compute an affine control at the onset of the cascade; the control is applied during the cascade as a function of observed state parameters such as line overloads. In the case of line outages that follow a deterministic rule, we obtain an efficient (polynomial time) algorithm for computing an optimal control. For the case of stochastic line outages we describe a stochastic gradients algorithm. We present computational experiments with a parallel implementation of our algorithms, tested on a snapshot of the U.S. Eastern Interconnect."
2118082,22457,8228,Research on the UI Integration Architecture of Service System,2008,"As researches of service science have gradually come into practical use, architecture of practical service system has arisen as an important problem. To solve this problem, the paper proposes a kind of service system integration architecture based on UI (user interface) integration technology. Important modules of this architecture and their constructing process are particularly introduced. In the end of this paper, the main characteristics of this architecture are enumerated to summarize the whole architecture."
2030179,22457,9704,Profitability Analysis of Workflow Management Systems,2009,"Workflow technology promises an increase in efficiency in the execution of business processes. The technology is widely accepted, but often the high costs exceed the promised benefits. Thus, it is desirable to calculate the profitability prior to investing into workflow technology. After an investment into workflow management systems (WFMS), it has to be verified whether the expected benefits have been realized or not. In this paper we present a method that covers both, the cost-benefit-ratio calculations specially customized for WFMS and the calculation of the realized savings. The profitability analysis is based on simple measurable performance indicators that consider the tangible calculation of costs as well as the quantitative and qualitative benefits. Long time practical experience in implementing and operating workflow management supported the design of the method. The method presented in this paper has been successfully used in the IT company of a banking corporation."
2182128,22457,422,Utilizing past relations and user similarities in a social matching system,2011,"Due to the higher expectation more and more online matching companies adopt recommender systems with content-based, collaborative filtering or hybrid techniques. However, these techniques focus on users explicit contact behaviors but ignore the implicit relationship among users in the network. This paper proposes a personalized social matching system for generating potential partners' recommendations that not only exploits users' explicit information but also utilizes implicit relationships among users. The proposed system is evaluated on the dataset collected from an online dating network. Empirical analysis shows the recommendation success rate has increased to 31% as compared to the baseline success rate of 19%."
2053172,22457,20561,The impact of message scheduling on a packet switching interconnect fabric,1996,"The impact of different message scheduling strategies on the performance of a packet-switched network is explored. We present a new scheduling technique, called Alpha scheduling, that can combine the bandwidth-fairness of round robin scheduling with nearly the optimal performance of shortest-first scheduling. We investigate the trade-off involved in using different routing strategies while intelligently scheduling the packets from various messages for injection into an interconnect."
1178743,22457,20561,A Pattern Language Approach to the Design of a Facilitation Reporting Database,2010,"The IAF Methods Database has 455 as of 29 August reported techniques used by facilitators divided into 3 levels: Applications, Methods and Models, and Interventions. Methods and Models are the same level of abstraction as ThinkLets. We use the ThinkLet pattern language to define requirements for a redesign of the database. We also discuss the implications for collaboration engineering and examine requirements for other levels of abstraction at the intervention and application level."
1826682,22457,20561,Smart Grid Infrastructure for Distribution Systems and Applications,2011,"This paper presents a new smart grid infrastructure for active distribution systems that will allow continuous and accurate monitoring of distribution system operations and customer utilization of electric power. The infrastructure allows a complete array of applications. The paper discusses four specific applications: (a) protection against downed conductors, (b) load levelization, (c) loss minimization and (d) reliability enhancement."
1821842,22457,20561,A branching time semantics for the Ada rendezvous mechanism,1996,"Branching-time semantics based on domains built upon tree structures have been proposed to model concurrent processes. However, the resulting models imposed severe restrictions to ensure monotonicity and compositionality. To address these issues, we construct a semantic domain without sacrificing these two properties. We also provide a simple and faithful semantics of the Ada rendezvous mechanism."
2316944,22457,20561,Standards Setting Consortia: A Transaction Cost Perspective,2005,"Consortiums are highly successful organizational systems for IT standard setting. However, it is not clear what advantages consortiums offer over the traditional approaches to standard-setting. We apply transaction cost economics to examine how and why consortiums are successful for standard-setting. We show that when standards are viewed as bundles of complementary patents, consortiums economize on transaction costs relative to the market. Further consortiums also economize on transaction costs relative to hierarchies, provided coordination costs are relatively lower than other types of transaction costs."
1534159,22457,20561,A Study on Preference Impartation and Decision Support in E-Negotiation,2010,"Decision support and the impartation of the principal's preferences to the agent may influence the negotiation outcome. A multi-attribute two-party contract e-negotiation was conducted in a controlled laboratory environment. The results indicate that the effectiveness of analytical support depends on the elicitation of the numerical preference values. When preference information is transmitted in qualitative terms to the negotiation agents, analytical support may be counterproductive."
1797710,22457,20561,Research and development in e-business on the Internet,2001,"The paper describes research and development projects in the field of system support for e-business on the Internet (EBI). The term EBI refers to a synergistic interaction of a number of disciplines, like electronic multimedia, electronic collaboration, electronic commerce, and appropriate business knowledge and intelligence infrastructure. There are several major infrastructure bottlenecks for efficient use of EBI. Some of the bottlenecks are in the hardware and others are in the software domain."
2246577,22457,20561,Accessing MEDLINE/PubMed with Handheld Devices: Developments and New Search Portals,2005,"We report on two new portals for searching MEDLINE/PubMed with handheld devices, PICO (Patient, Intervention, Comparison, Outcome) and a WAP (Wireless Application Protocol) browser interface. Early user evaluation and user feedback will be discussed. We also include an updated report of user evaluation of established search tools for handheld devices included in the first release."
2166828,22457,20561,An integrated multimedia environment for speech recognition using handwriting and written gestures,2003,"To provide a natural interface to the computer, we present an integrated speech, gesture, and handwriting recognition system. By integrating these technologies, we can easily accomplish all the tasks that are needed to use computers and their applications, including many tasks which neither technology can adequately perform by itself. This integrated environment not only makes it easier for novices to use computers but also increases the productivity of experienced computer users."
762302,22457,20561,The Whole Story: Building the Complete History of a Place,2012,"In this paper, we discuss how one can build a visual analytics system to comprehensively describe a place throughout its many interconnected histories. We discuss the needed 4D data structure, the analytics techniques, and the interactive visualizations. This combination of automated and interactive techniques can be brought together into a new, powerful capability. We focus on the example of Rome and, more specifically, on its architectural/cultural history."
2495752,22457,20561,Enterprise Architecture Management's Impact on Information Technology Success,2011,"Both practitioners and researchers put forward enterprise architecture management as a mean for achieving success with information technology. Many arguments have been put forward to support the benefits claimed to arise from mature enterprise architecture management and a considerable amount of literature describes the components of mature (successful) enterprise architecture management. However, few studies have empirically tested whether the enterprise architecture management activities impact organizations' success with information technology. This paper tests the relationship between organizations' success with information technology and enterprise architecture management activities. Significant correlations are found between these variables."
2053656,22457,20561,Users of Open Source Software - How Do They Get Help?,2009,"A study was conducted across multiple open source software online technical help communities. This paper presents the types of discussions that occur, the types of questions asked and the type of responses that are given. The implications for socio-technical design are considered, exploring how help requests and discussions can be used to improve future help-giving, documentation and interface and functionality redesign."
2228580,22457,20561,Work Design in Knowledge-Based Network Organizations: Facilitating Supply Chain Knowledge Flows via Network Entrepreneurship,2008,"We introduce social network theory as a way of understanding work design, which can facilitate knowledge flows in knowledge based network organizations (e.g. supply chain network). We introduce a typology of work design network to view work design as a strategic option of creating and recreating knowledge network; then we discuss what type of work design can facilitate more network entrepreneurial activities so that the resulting work networks can be more agile, adaptable and easy to achieve collective alignment."
1810527,22457,20561,Underlying technical issues in electricity deregulation,1997,"This paper reports on the results of an attempt by the Power Systems Engineering Research Center (Pserc) and EPRI to determine the technical tools missing in currently unfolding electric power restructuring scenarios. Needed tools have been divided into the functional categories of generation, transmission and distribution. In each category, there seems to be a common need to interface existing technical tools with the new economic unbundling."
2674397,22457,20561,Validating Scanned Foot Images and Designing Customized Insoles on the Cloud,2016,"People with foot problems need special healthcare: foot care. Customized insoles can provide this care. They are inserts that are placed in the shoes. They correct biomechanical and postural inaccuracies in foot. Insole production contains four phases: foot image scanning, image validation, insole design and insole manufacturing. Currently, image scanning and validation is separated in location and time, i.e. podiatrists take images and insole designers validate them at different location and at different time. A cloud-based solution, the CloudSME one-stop shop simulation platform, enables remote access to image validation and insole design service deployed and running on the Cloud. The remote access allows podiatrists validating scanned image while the patient is in their offices. The simulation platform also supports remote design of customized insoles."
2683298,22457,9475,Convex analysis of generalized flow networks,2015,"This paper is concerned with the generalized network flow (GNF) problem, which aims to find a minimum-cost solution for a generalized flow network. The objective is to determine the optimal injections at the nodes as well as optimal flows over the lines of the network. In this problem, each line is associated with two flows in opposite directions that are related to each other via a given nonlinear function. Under some monotonicity and convexity assumptions, we have shown in our recent work that a convexified generalized network flow (CGNF) problem always finds optimal injections for GNF, but may fail to find optimal flows. In this paper, we develop three results to explore the possibility of obtaining optimal flows. First, we show that CGNF yields optimal flows for GNF if the optimal injection vector is a Pareto point. Second, we show that if CGNF fails to find an optimal flow vector, then the graph can be decomposed into two subgraphs, where the lines between the subgraphs are congested at optimality and CGNF finds correct optimal flows over the lines of one of these subgraphs. Third, we fully characterize the set of all optimal flow vectors. In particular, we show that this non-convex set is a subset of the boundary of a convex set, and may include an exponential number of disconnected components."
2422268,22457,8494,Opcode encoding for low power embedded systems,2005,"In this paper, we propose two encoding schemes for reducing the amount of switching on the instruction memory, which is one of the biggest sources of power dissipation. We have targeted embedded systems with an external bus interface (EBI) unit with 16-bit and 8-bit external memory interface systems (such as mobile phones). Our schemes are based on instruction code field encoding. The major advantage of our encoding schemes stems from the fact that they only involve minor modifications to the EBI, and do not require any changes to the processor core."
1329815,22457,11104,Epidemic analysis and visualization based on Digital Earth spatio-temporal framework,2012,"Digital Earth provides an excellent means for the visualization and analysis of the epidemic data. Currently the most of the epidemic data analysis is done only based on the data attributes such as number of victims, time of occurrence, type or intensity of the epidemic, etc. Most of the visualization of the epidemic is done merely using maps. Visualization of the place of occurrence or hot spot is one of the major factors in the analysis of the epidemic data which seems to be lacking in the current research projects. So, we have introduced a China Star Epidemic data visualization and analysis tool which can do comprehensive and thorough analysis and visualization of epidemic data. The tool integrates most of the attributes of the epidemic data into one single solid system. As a case study, we have used a real disease data of Shenzhen, China for this research. It is demonstrated that Digital Earth can be an excellent platform for the visualization of the changing pattern of epidemic data both in space and time dimension. The developed prototype also represents a tool to implement a concept of ‘Thinking Spatially’ in 3D dimension especially in epidemic data analysis and visualization domain."
3000589,22457,9896,Knowledge Sharing in Online Discussion Threads: What Predicts the Ratings?,2017,"As an important category of user-generated content (UGC) community, Question and Answer (Q&A) community offers internet users opportunities to ask questions and share knowledge with others. In order to understand how the ratings of knowledge contribution quality correlate with the way knowledge is being shared in discussion threads, the study examines user behaviors and profiles in a large knowledge sharing community, /r/Techsupport, a discussion based Q&A site in Reddit.com concerning internet and technology problems. Negative binomial regressions and negative binomial mixed models are built to investigate the relationships among thread structure, level of user activity, user profiles and the ratings of threads and comments in the community. Results indicate that in the better rated threads, the structures tend to be more centralized with heterogeneous participants discussing the problem at a deeper level. Meanwhile, contributions with good ratings are more likely to be produced by users who are more engaged in commenting behaviors."
1400606,22457,9896,Jumpstarting relationships with online games: evidence from a laboratory investigation,2008,"The popularity of online games, particularly casual games, has increased tremendously in recent years. Often these game experiences involve partner-based or multi-player interactions. Previous work has shown that computer-mediated interactions and online activities with a stranger have the potential to impact attitudes and liking for that person. Can experiences in online games have a similar impact? This paper presents results from two experiments suggesting that cooperative online game experiences (even without any direct communication interactions) can significantly impact liking for another person and perceptions of that person's characteristics. Implications for the design of online team-building style game experiences are briefly discussed."
425929,22457,422,Composing Miners to Develop an Intrusion Detection Solution,2009,"Today, security is of strategic importance for many computer science applications. Unfortunately, an optimal solution does not exist and often system administrators are faced with new security problems when trying to protect computing resources within a reasonable time. Security applications that seem effective at first, could actually be unsuitable. This paper introduces a way of developing flexible computer security solutions which can allow system administrators to intervene rapidly on systems by adapting not only existing solutions but new ones as well. To this end, the study suggests considering the problem of intrusion detection as a Knowledge Discovery process and to describe it in terms of both e-services and miner building blocks. In addition, a definition of an intrusion detection process using Web content analysis generated by users is presented."
2344212,22457,9704,A Unified Framework for Outsourcing Governance,2007,"Outsourcing has become a trend for a business to pursue short-term operational efficiency and long-term strategic competency by delegating IT infrastructure, applications, and even business processes to external service providers. At the same time, new challenges are emerging along with outsourcing such as what are the right services that should be outsourced, how well these services get performed, what benefits outsourcing brings in, and so on. Thus, effective service governance and management mechanisms for both service outsourcers and service providers are essential to the success of outsourcing. However, current academic and industrial achievements cannot directly meet the requirements of governance in outsourcing. In this paper, a unified outsourcing governance framework not only for clients but also for providers is proposed, which provides a three-layer, three-perspective integrated governance model on three key dimensions of governance process, organizational structure, and measurement system. A typical call center outsourcing governance case study is illustrated to validate the framework. The future work and conclusion are discussed finally."
485686,22457,20561,"Introduction to the Big, Open, and Linked Data (BOLD), Analytics, and Interoperability Infrastructures in Government Minitrack",2015,"Open data in administration is a phenomenon in which public sector information is made available and can be used by everybody for what it seems an unlimited amount of purposes. As publicly available information can often be generated and provided in huge amounts and through multiple sources, specific needs for processing, curation, linking, visualization and maintenance result in the need for Big data and Linked data approaches."
2226102,22457,20561,How Students Search for Consumer Health Information on the Web,2009,"This study investigates how undergraduate and graduate students search the web for consumer health information. The 32 participants were asked to find answers to four health related topics. Data was collected through pre- and post search questionnaires, think-aloud protocol, and transaction logs. The results presented focus on the search process as a whole and by question and on the user satisfaction."
2417942,22457,20561,Escaping the Veil of Maya: Wisdom and the Organization,2006,"Though frequently considered desolate and distressing the philosophy of Arthur Schopenhauer provides a surprisingly appropriate framework through which to view the organization in order to investigate the existence of wisdom and how organizational wisdom can be achieved. This paper extends Schopenhauer's work so that it can be applied to current investigations related to wisdom creation, extraction and retention. Schopenhauer's work provides a platform upon which ramifications of wisdom creation and its effect on the organization can be assessed."
2302483,22457,20561,A tool for the capture and use of process knowledge in process tailoring,2003,"Software processes are critical assets of software development organizations. The knowledge about context in which a process is defined and tailored is typically lost during software development activities, making the processes difficult to understand, reuse and evolve. We present a framework that represents the process knowledge used in defining and tailoring a software process. Based on this model, we have developed a prototype tool to support the understanding, reuse and maintenance of this process knowledge."
677719,22457,20561,"Numbers, Governance, Health: A Norwegian Case of Statistics and Documentation Production",2013,"This paper follows the documents (texts, numbers) of a statistics system called IPLOS. IPLOS is intended to coordinate, control, standardize and stabilize municipal care services in Norway and generate statistical knowledge about the clients. We follow the production of IPLOS numbers, their movements through the interlocking organizations, and how IPLOS is understood, used, and interacts with service delivery. We find that rather than IPLOS numbers stabilizing the organization, the organization de-stabilizes the numbers."
1045141,22457,20561,The Impact of Local Loop Unbundling on DSL Service Diversity,2010,"This paper focuses on the impact of unbundling the local loops (LLU) policy on DSL service diversity through mediation roles played by inter-DSL and intra-technology market competition. This study provides another interesting perspective on the influence of LLU policy on DSL service diversity, which is a key consumer concern for DSL services, and is usually taken for granted by researchers. However, the linkage between LLU policy and DSL service diversity has not been found in extant literatures. Our empirical evidence, based on data from 9 countries, partly confirms the prediction of the role of LLU policy as the main driver of value-added DSL service diversity."
723544,22457,20561,Combining Phasor Measurements to Monitor Cutset Angles,2010,Power systems under stress can show large voltage angle differences between areas that can be monitored by wide area phasor measurements. One way to make this idea more specific is to choose a cutset of transmission lines that separates two power system areas and then define an angle difference across the cutset that is a suitable combination of the angle differences across lines of the cutset. We suggest that monitoring this cutset angle yields useful and specific information about power system stress.
1956795,22457,20561,The Chautauqua workflow system,1997,"Chautauqua is an exploratory workflow management system designed and implemented within the Collaboration Technology Research group (CTRG) at the University of Colorado. This system represents a tightly knit merger of workflow technology and groupware technology. Chautauqua has been in test usage at the University of Colorado since 1995. The article discusses Chautauqua-its motivation, its design, and its implementation. The emphasis is on its novel features, and the techniques for implementing these features."
1779023,22457,20561,A Model of Agile Evolution and Maintenance Process,2009,"Most of the agile methods mainly concentrate on the development phase. None of them however is explicitly dedicated to the evolution and maintenance domain. In this paper, we outline an agile evolution and maintenance process model and evaluate it within two Canadian software organizations. We do this by comparing current agile development process models to the industrial evolution and maintenance practice in order to find issues relevant for the evolution and maintenance domain. Our results show that some changes need be made in the current agile methods."
415822,22457,20561,The Impact of Interaction Anticipation and Incentive Type on Shared Leadership and Performance in Virtual Teams,2015,This research examines whether expectation of future interaction or team-based incentives can influence shared leadership and performance in virtual teams. The results of an experiment indicate that teams provided with team-based incentives generated higher levels of individual and team performance. Teams anticipating future interaction and incentivized by team-based incentives achieved the highest levels of performance. Our results indicate that anticipation of interaction and team-based incentives are useful methods for motivating shared leadership and achieving increased team performance for virtual teams.
2366114,22457,20561,Virtual Microscopy: Potential Applications in Medical Education and Telemedicine in Countries with Developing Economies,2005,"We evaluated the diagnostic accuracy of a virtual microscopy setup using surgical pathology specimens commonly encountered in a university hospital setting. The high quality images, Internet sharing and collaborative capability, interactivity, and ease of use suggested to us that this might have applications in countries with developing economies. We discuss the development process and its potential applications in medical education and telemedicine in countries with developing economies."
2361225,22457,20561,Cultural Impact on Intergroup Coordination in Software Development in China: A Qualitative Analysis,2006,"Intergroup coordination is critical for the success of software projects. This paper examines the impact of Chinese national culture on intergroup coordination success factors through qualitative analysis of semi-structured interviews with programmers from different sized companies. A comparison based on corporate culture, company size and related factors is conducted to analyze the differences among companies. Implications and directions for future research are discussed."
2144880,22457,20561,Social Media and Warning Response Impacts in Extreme Events: Results from a Naturally Occurring Experiment,2012,Our understanding of the impacts of social media on individuals who receive warnings of extreme events is limited. There is to date no uniform approach to integrating social media as part of emergency management strategies. This research addresses the question of the role of social media in the effectiveness of the warning response process in the context of a naturally occurring experiment. The results of the experiment contribute to our understanding of how social media complements as well as facilitates the warning response process.
2532435,22457,20561,Thread migration in the presence of pointers,1997,"Dynamic migration of lightweight threads supports both data locality and load balancing. However, migrating threads that contain pointers referencing data in both the stack and heap remains an open problem. We describe a technique by which threads with pointers referencing both stack and non shared heap data can be migrated such that the pointers remain valid after migration. As a result, threads containing pointers can now be migrated between processors in a homogeneous distributed memory environment."
2004834,22457,20561,Designing mobile information services: user requirements elicitation with GSS design and application of a repeatable process,2004,The main challenge in the first phase of designing mobile services is eliciting user requirements. We propose a repeatable process for eliciting user requirements based on the literature on requirements engineering and group support systems. We applied the repeatable process in three sessions to elicit user requirements for a mobile information service on a UMTS testbed. The sessions resulted in ideas for services that are highly valued by potential users and criteria for when they can or can not use the service.
1209480,22457,9896,Community-Building with Web-Based Systems -- Investigating a Hybrid Community of Students,2004,"This paper examines WiInf-Central, the 'virtual homeplace' of a student community (on Information Systems) at the University of Hamburg, and focuses on processes of social identity and community-building. Drawing on social-identity theory and communities of practice as our theoretical basis, we illustrate that the processes of identity-building and positive in-group evaluation triggered by WiInf-Central serve as a means for students of Information Systems to assert themselves against faculty members and students of other disciplines. While our study reveals strong mechanisms of social exclusion, inclusion mechanisms have to be assessed in a more differentiated way. In particular, our study shows the emergence of several 'subgroups', which appear largely closed to other community members. We ascribe this to both the self-organized and the hybrid -- half virtual, half real -- nature of the community based on WiInf-Central."
1030809,22457,9896,Socially immature organizations: a typology of social networking systems [SNS] with organizations as users [OAU],2012,This research conducts a survey of Social Networking Systems (SNS) literature and develops a Typology that challenges and identifies gaps in the basic questions thus far explored in SNS literature. The gap analysis exposes the previously unexplored opportunity for SNS with Organizations as Users (OAU) and deduces a framework for anticipating the emergence of full blown SNS with OAU that will rival the Facebooks of the world that thus far focus only on Individuals as Users.
2670245,22457,20561,"Tweeting Like Taylor Swift? Affordances, Status Production, and Online Platforms",2016,"This paper explores affordances of status production provided by Twitter as they are perceived and enacted under different institutional logics. We analyze tweets by IS academics (institutional logic of the IS academic profession) and celebrities (institutional logic of the popular music profession). We describe how the communicative features of Twitter are used to enhance identities and produce status in these two different fields. While we find evidence that both groups perceive and enact affordances of status production, we identify important differences in how these affordances are enacted: (1) certain affordances of status production are enacted under one institutional logic, while they are not under another, (2) the same affordance is enacted under different institutional logics with different intensity, and (3) different features afford the same opportunities of status production to different users. We explain the differences through the influence of offline cultural capital on online status production."
3033954,22457,9896,Problematizing and Addressing the Article-as-Concept Assumption in Wikipedia,2017,"Wikipedia-based studies and systems frequently assume that no two articles describe the same concept. However, in this paper, we show that this article-as-concept assumption is problematic due to editors' tendency to split articles into parent articles and sub-articles when articles get too long for readers (e.g. Portland, Oregon and History of Portland, Oregon in the English Wikipedia). In this paper, we present evidence that this issue can have significant impacts on Wikipedia-based studies and systems and introduce the sub-article matching problem. The goal of the sub-article matching problem is to automatically connect sub-articles to parent articles to help Wikipedia-based studies and systems retrieve complete information about a concept. We then describe the first system to address the sub-article matching problem. We show that, using a diverse feature set and standard machine learning techniques, our system can achieve good performance on most of our ground truth datasets, significantly outperforming baseline approaches."
691998,22457,8235,Managing escalation of collaboration processes in crisis mitigation situations,2000,"Processes for crisis mitigation must permit coordination flexibility and dynamic change to empower crisis mitigation coordinators and experts to deal with unexpected situations. However, such mitigation processes must also provide enough structure to prevent chaotic response and increase mitigation effectiveness. Such combination of structure and flexibility cannot be effectively supported by existing workflow or groupware technologies. In this paper, we introduce the Collaboration Management Infrastructure (CMI) and describe its capabilities for supporting crisis mitigation processes. CMI provides a comprehensive Collaboration Management Model (CMM) and a corresponding federated system. CMM supports process templates that provide the initial activities, control and data flow structure, and resources needed to start mitigating a variety of crisis situations. In the event of a crisis, the appropriate process template is selected and instantiated. Crisis mitigation is achieved by escalating the instantiated process template. Escalation involves selecting and adding new process templates, creating new activities, roles, and task forces as needed to deal with the current demands in the crisis, and delegating responsibilities to process participants and task forces. CMM provides advanced composable primitives that empower crisis mitigation coordinators and experts to escalate the process. We provide an overview of the implementation of a federated CMI system and discuss our initial experience with various applications in the area of crisis management."
197293,22457,20358,Comparing Smart Cities with different modeling approaches,2015,"Smart cities have attracted an extensive and increasing interest from both science and industry with an increasing number of international examples emerging from across the world. However, despite the significant role that smart cities can play to deal with recent urban challenges, the concept has been criticized for being influenced by vendor hype. There are various attempts to conceptualize smart cities and various benchmarking methods have been developed to evaluate their impact. In this paper the modelling and benchmarking approaches are systematically compared. There are six common dimensions among the approaches, namely people, government, economy, mobility, environment and living. This paper utilizes existing smart city analysis models in order to review three representative smart city cases and useful outcomes are extrapolated from this comparison."
2665696,22457,20561,Sustainability of ICTD Projects and Its Influencing Factors: A Comprehensive Literature Review,2016,"Sustainability is an important concern in ICTD literature because without a sustainable use of the technologies, less-developed countries will not be able to enjoy the promised benefits. This review has been conducted with the aim of bringing up-to-date discussion on the topic. Sustainability can be achieved if projects are delivered to satisfy the five aspects of sustainability: political/institutional, financial/economic, technological, cultural/social and environmental [1]. Apart from the technical challenges, it was found that effort to deliver sustainable ICTD has also been influenced by complexities that emerged from heterogeneous actors involved during the delivery process, these factors were identified in this review based on the five aspects of sustainability. There is still a limited discussion in the literature on how to fulfill the five aspects of sustainability in a coherent manner. It is expected that the results of the review will inform further studies on the topic of sustainability of ICTD."
2882939,22457,8494,An effective generator-allocating method to enhance the robustness of power grid,2016,"As renewable energy plants are becoming more widely accessible, one trend of power grids' evolution is decentralization which poses many challenges for grid management. In this paper, we propose a generator allocation method, based on community structure detection, for placing decentralized generators. We take node-generator distance (DG) as an indicator of optimal generators' locations and the underlying community structure is detected with a series of iterating steps. Simulation results show that our method can effectively achieve satisfying allocation solutions as well as enhance the robustness of power systems."
1162851,22457,9475,Model-based feedback control of distributed air-conditioning loads for fast demand-side ancillary services,2013,"Load control (LC) of distributed populations of air conditioners (ACs) can provide effective demand-side ancillary services while reducing emissions and network operating costs. Pilot trials with ACs typically deploy model-free, open-loop strategies, which cannot deliver the full potential of LC as a network resource. Seeking more advanced strategies, much research in recent years has targeted the development of accurate models and LC approaches for this type of loads. Most existing approaches, however, are restricted to scenarios involving large numbers of ACs, which may not work in small populations, or require two-way communications with the controlled devices, which may come at high costs in widely distributed populations. This paper exploits a previously developed dynamic model for the aggregate demand of populations of ACs to design a simple controller readily implementable in such LC scenarios. The proposed feedback scheme broadcasts thermostat set-point offset changes to the ACs, and requires no direct communications from the devices to the central controller, using instead readings of total aggregate demand from a common power distribution connection point, which may include demand of uncontrolled loads. The scheme is validated on a numerical case study constructed by simulating a distributed population of ACs using real power and temperature data from a 70-house residential precinct, and is shown to deliver robust fast load following performance. The simulation results highlight the practical potential of the proposed model and feedback control scheme for analysing and shaping demand response of ACs using standard control techniques."
2611877,22457,20358,Understanding Smart City Business Models: A Comparison,2015,"Smart cities have attracted the international scientific and business attention and a niche market is being evolved, which engages almost all the business sectors. In their attempt to empower and promote urban competitive advantages, local governments have approached the smart city context and they target habitants, visitors and investments. However, engaging the smart city context is not free-of-charge and corresponding investments are extensive and of high risk without the appropriate management. Moreover, investing in the smart city domain does not secure corresponding mission success and both governments and vendors require more effective instruments. This paper performs an investigation on the smart city business models and is a work in progress. Modeling can illustrate where corresponding profit comes from and how it flows, while a significant business model portfolio is eligible for smart city stakeholders."
1336434,22457,9099,Content-based retrieval of segmented images,1994,"Most general content-based image retrieval techniques use colour and texture as main retrieval indices. A recent technique uses colour pairs to model distinct object boundaries for retrieval. These techniques have been applied to overall image contents without taking into account the characteristics of individual objects. While the techniques work well for the retrieval of images with similar overall contents (including backgrounds), their accuracies are limited because they are unable to take advantage of individual object's visual characteristics, and to perform object-level retrieval. This paper looks specifically at the use of colour-pair technique for fuzzy object-level image retrieval. Three extensions are applied to the basic colour-pair technique: (a) the development of a similarity-based ranking formula for colour-pairs matching; (b) the use of segmented objects for object-level retrieval; and (c) the inclusion of perceptually similar colours for fuzzy retrieval. A computer-aided segmentation technique is developed to segment the images' contents. Experimental results indicate that the extensions have led to substantial improvements in the retrieval performance. These extensions are sufficiently general and can be applied to other content-based image retrieval techniques."
2056178,22457,9896,Comparing the use of social networking and traditional media channels for promoting citizen science,2013,"This paper examines how social networks can be used to recruit and promote a crowdsourced citizen science project and compares this recruiting method to the use of tradition-al media channels including press releases, news stories, and participation campaigns. The target studied is Creek Watch, a citizen science project that allows anyone with an iPhone to submit photos and observations of their local waterways to authorities who use the data for water management, environmental programs, and cleanup events. The results compare promotional campaigns using a traditional press release with news pickups, a participation campaign through local organizations, and a social networking campaign through Facebook and Twitter. Results also include the trial of a feature that allows users to post automatically to Facebook or Twitter. Social networking is found to be a worthwhile avenue for increasing awareness of the project, increasing the conversion rate from browsers to participants, but that targeting existing communities with a participation campaign was a more successful means for increasing the amount of data collected by volunteers."
1504964,22457,9475,Temperature-based Model-Predictive Cascade Mitigation in Electric Power Systems,2013,"This paper proposes a novel model-predictive control scheme which combines both economic and security objectives to mitigate the effects of severe disturbances in electrical power systems. A linear convex relaxation of the AC power flow is employed to model transmission line losses and conductor temperatures. Then, a receding-horizon model predictive control (MPC) strategy is developed to alleviate line temperature overloads and prevent the propagation of outages. The MPC strategy seeks to alleviate temperature overloads by rescheduling generation, energy storage and other network elements, subject to ramp-rate limits and network limitations. The MPC strategy is illustrated with simulations of the IEEE RTS-96 network augmented with energy storage and renewable generation."
2345360,22457,8385,BumbleBee: a refactoring environment for spreadsheet formulas,2014,"Spreadsheets are widely used in industry. It is estimated that end-user programmers outnumber regular programmers by a factor of 5. However, spreadsheets are error-prone: several reports exist of companies that have lost big sums of money due to spreadsheet errors. In previous work, spreadsheet smells have proven to be the cause of some of these errors. To that end, we have developed a tool that can apply refactorings to spreadsheet formulas, implementing our previous work on spreadsheet refactoring, which showed that spreadsheet formula smells are very common and that refactorings for them are widely applicable and that refactoring them with a tool is both quicker and less error-prone. Our new tool Bumblebee is able to execute refactorings originating from both these papers, by means of an extensible syntax, and can furthermore apply refactorings on entire groups of formulas, thus improving upon the existing tool RefBook. Finally, BumbleBee can also execute transformations other than refactorings."
2946106,22457,9475,Distributionally robust risk-constrained optimal power flow using moment and unimodality information,2016,"As we incorporate more random renewable energy into the power grid, power system operators need to ensure physical constraints, such as transmission line limits, are not violated despite uncertainty. Risk-constrained optimal power flow (RCOPF) based on the Conditional Value-at-Risk (CVaR) is a convenient modeling tool, ensuring that these constraints are satisfied with a high probability (e.g., 95%). However, in practice, it is often difficult to perfectly estimate the joint probability distribution of all uncertain variables, including renewable energy production and load consumption. In this paper, we propose a distributionally robust RCOPF approach by considering all possible probability distributions that share the same moment (e.g., mean and covariance) and unimodality properties. Moment and unimodality information can be estimated based on historical data, and so the proposed approach can be applied in a data-driven manner. In view of the computational challenges, we derive a conservative and a relaxed approximation of the problem. We reformulate these approximations as semidefinite programs (SDPs) facilitating the use of highly efficient off-the-shelf optimization solvers (e.g., CVX). We demonstrate the proposed approach based on a modified IEEE 9-bus power network."
1971611,22457,9896,We will never forget you [online]: an empirical investigation of post-mortem myspace comments,2011,"The proliferation of social network sites has resulted in an increasing number of profiles representing deceased users. In this paper, we present the results of a mixed-methods empirical study of 205,068 comments posted to 1,369 MySpace profiles of users who have died. Our results reveal interesting practices surrounding issues of authorship and audience, temporal patterns in posting, and continued social networking with the dead. These results suggest that post-mortem commenting behavior blends memorializing practices with existing practices and communication patterns for social network sites. We conclude by outlining future directions for research and implications for the understanding and use of social network sites in light of a deeper understanding of post-mortem comments."
463552,22457,369,Implementation of a Transparent Power Information System on Campus Using Existing Infrastructures,2015,"In numerous universities of Taiwan, students must pay an electricity bill for power consumption in their dormitories. In practice, the universities buy a contract capacity from a power company, and act as a middleman between the students and the power company. In this scenario, monitoring campus power consumption is essential so that actions such as load shifting can be taken when the overall power consumption approaches the contract capacity. Conventionally, monitoring the campus' power consumption is the duty of the university authorities. This study investigated the implementation of an online system that contains detailed information on power consumption. The system aims to provide students with transparent power information to make them aware of the amount of energy they consume. To avoid expensive hardware upgrades, the implementation is based on existing campus infrastructures. It involves the integration of hardware and software components, including an advanced metering infrastructure, a central server, servers and meters in dormitories, and a software system that collects, stores, and presents data in real time. This paper provides a framework for the proposed integration, which has various applications; for example, it can facilitate the creation of high-level smart features such as dynamic pricing and smart load scheduling on campus."
829714,22457,8235,A Stigmergic Guiding System to Facilitate the Group Decision Process,2012,"The paper presents a stigmergic approach to engineer a guiding system to facilitate the complex problem of designing the group decision processes. The system aims to provide contextual, actionable recommendations based on the knowledge and past experience of its users as recorded in a collaborative working environment implemented around the concept of stigmergic systems. Through an agent-based socio-simulation experiment we have demonstrated already the feasibility of this approach. The paper illustrates how the simulation results are transferred into a guiding system that facilitates the group decision process design through iterative queries reformulations for the identification, representation and manipulation of the relevant knowledge."
1994345,22457,20358,Open user profiles for adaptive news systems: help or harm?,2007,"Over the last five years, a range of projects have focused on progressively more elaborated techniques for adaptive news delivery. However, the adaptation process in these systems has become more complicated and thus less transparent to the users. In this paper, we concentrate on the application of open user models in adding transparency and controllability to adaptive news systems. We present a personalized news system, YourNews, which allows users to view and edit their interest profiles, and report a user study on the system. Our results confirm that users prefer transparency and control in their systems, and generate more trust to such systems. However, similar to previous studies, our study demonstrate that this ability to edit user profiles may also harm the system.s performance and has to be used with caution."
2674379,22457,20561,How Do Business Analytics and Business Intelligence Contribute to Improving Care Efficiency,2016,"The growth in volume, variety, and velocity of data has created new challenges and opportunities for healthcare contexts. Although Business Analytics (BA) technologies, techniques and tools are becoming recognised to improve the ability to analyse multi-spectral healthcare data, in and of themselves they are not sufficient to realise the full potential and benefits possible which can lead to optimal patient outcomes. In fact, it becomes a strategic necessity to develop a systematic and organising framework to apply BA technologies to a specific clinical context. Hence, this exploratory study is designed to investigate and thereby develop an appropriate organising framework and then a prototype to apply the benefits of the Business Analytics techniques to Healthcare contexts. The chosen clinical context is oncology and the study site is one of the largest private tertiary hospitals in Melbourne, Australia. Given the importance of cancer care, the cost of cancer treatments and the quantity and range of data elements that are generated during the care process, this case study is significant and important."
2311700,22457,8806,A requirements elicitation framework and tool for sourcing business-IT aligned e-services,2010,This paper describes a multiple perspectives goal-oriented requirements elicitation framework aimed at identifying IT service requirements for service sourcing in a service-oriented software marketplace (E-services marketplace). The framework is based on decomposing strategic goals into tactical and operational IT goals adopting a multiple perspectives elicitation approach that facilitates business-IT alignment in the elicitation/mapping of the service requirements and in the choice of the target service offerings. The framework is applicable in a scenario where there is a marketplace of software service providers (e.g. ASP's or web service yellow pages) and the sourcing organization is interested in developing service requirements and searching for services available in the marketplace that are aligned with the organizational goals. The framework is supported by a tool that helps the requirements analyst in the process of developing multiple perspectives service goal trees and also in the process of matching service goals to keywords describing service offerings available in the e-Service marketplace.
2651013,22457,20561,A New Outage Coordination: SMaRTS Model,2016,"The SMaRTS model, Scheduling Maintenance for Reliable Transmission Systems, is developed to schedule transmission line maintenance requests optimally and centrally at the central dispatcher (CD) level. The SMaRTS model promises up to 4% production cost savings by solely shifting the maintenance to an optimal time frame for the system. The model is developed to co-optimize generation unit commitment and transmission line outage coordination with N-1 reliability. The SMaRTS model is flexible enough to be converted to a security constrained unit commitment or to an optimal topology control problem, and its effectiveness is tested on a modified IEEE 30-bus system. The financial benefits of SMaRTS model are discussed in detail, and compared with those from Business-As-Usual (BU) model as adopted by the CDs."
2665598,22457,20561,Moving On: Predicting Continuance Intention on Social Networking Sites through Alternative Products,2016,"Social networking sites (SNS) have growing popularity and several sites compete with each other. This study examines three models to determine how competition between Facebook and other social networking sites may affect continuance intention on Facebook. The first model examines the relationship between having an account on four different SNSs and its impact on Facebook. Twitter users have lower intentions to continue using Facebook, Instagram users have higher intentions. The second model examines attitudes toward specific alternatives and found that users who felt alternatives were attractive have lower intentions to continue using Facebook. The third model examined general attitudes about alternative attractiveness and attitudes toward switching, this model explained a moderate to substantial amount of the variance in continuance intention. This study makes important contributions to both research and practice."
551055,22457,20358,A cross-cultural framework for protecting user privacy in online social media,2013,"Social media has become truly global in recent years. We argue that support for users' privacy, however, has not been extended equally to all users from around the world. In this paper, we survey existing literature on cross-cultural privacy issues, giving particular weight to work specific to online social networking sites. We then propose a framework for evaluating the extent to which social networking sites' privacy options are offered and communicated in a manner that supports diverse users from around the world. One aspect of our framework focuses on cultural issues, such as norms regarding the use of pseudonyms or posting of photographs. A second aspect of our framework discusses legal issues in cross-cultural privacy, including data-protection requirements and questions of jurisdiction. The final part of our framework delves into user expectations regarding the data-sharing practices and the communication of privacy information. The framework can enable service providers to identify potential gaps in support for user privacy. It can also help researchers, regulators, or consumer advocates reason systematically about cultural differences related to privacy in social media."
2445578,22457,8494,A high-performance low-power SoC for mobile one-time password applications,2013,"The presented SoC is an 8-bit MCU based processor with 32-bit encryption algorithm acceleration and special security mechanism dedicated to mobile one-time password (MOTP) applications. The encryption algorithm accelerator can perform several 32-bit key operations for hash function computation, with each in one clock cycle. The SoC also features protection mechanisms which can prevent attackers from stealing the algorithm program code or the secret key, or utilizing under-voltage attacks. The SoC chip, fabricated in 0.25 μm CMOS process, has more than 50% efficiency improvement on hash function computation if compared with those 8-bit general-purpose MCUs and consumes less than 7.2 μA current in average for typical MOTP applications."
2262573,22457,422,TurKit: tools for iterative tasks on mechanical Turk,2009,"Mechanical Turk (MTurk) is an increasingly popular web service for paying people small rewards to do human computation tasks. Current uses of MTurk typically post independent parallel tasks. We are exploring an alternative  iterative  paradigm, in which workers build on or evaluate each other's work. We describe TurKit, a new toolkit for deploying iterative tasks to MTurk, with a familiar imperative programming paradigm that effectively uses MTurk workers as subroutines."
2650482,22457,20561,Financial Transmission Rights in Changing Power Networks,2016,"Many restructured power markets rely on Financial Transmission Rights (FTRs). FTRs are financial contracts that entitle the holder to a stream of revenues (or charges) based on the day-ahead hourly congestion price difference across an FTR related energy path. Holders obtain FTRs through an auction mechanism relying on the solution of a specially formulated OPF problem. FTR holders then receive or make payments based on the outcome of Day Ahead (DA) energy market. Known FTR properties (revenue adequacy) [1] guarantee that if the auction OPF and the DA market have the same network topology, congestion rent collected in the DA market will be sufficient to pay all FTR holders. DA market topology almost always deviates from the auction topology. This may create underfunding problems. We propose a solution to topology-driven underfunding using Topology Reconfiguration Rights (TRRs) -- financial transactions corresponding to topology changes. Combinations of FTRs and TRRs guarantee revenue adequacy."
2328153,22457,507,An orthogonally persistent Java,1996,"The language Java is enjoying a rapid rise in popularity as an application programming language. For many applications an effective provision of database facilities is required. Here we report on a particular approach to providing such facilities, called “orthogonal persistence”. Persistence allows data to have lifetimes that vary from transient to (the best approximation we can achieve to) indefinite. It is orthogonal persistence if the available lifetimes are the same for all kinds of data. We aim to show that the programmer productivity gains and possible performance gains make orthogonal persistence a valuable augmentation of Java."
932326,22457,20411,Uncovering social spammers: social honeypots + machine learning,2010,"Web-based social systems enable new community-based opportunities for participants to engage, share, and interact. This community value and related services like search and advertising are threatened by spammers, content polluters, and malware disseminators. In an effort to preserve community value and ensure longterm success, we propose and evaluate a honeypot-based approach for uncovering social spammers in online social systems. Two of the key components of the proposed approach are: (1) The deployment of social honeypots for harvesting deceptive spam profiles from social networking communities; and (2) Statistical analysis of the properties of these spam profiles for creating spam classifiers to actively filter out existing and new spammers. We describe the conceptual framework and design considerations of the proposed approach, and we present concrete observations from the deployment of social honeypots in MySpace and Twitter. We find that the deployed social honeypots identify social spammers with low false positive rates and that the harvested spam data contains signals that are strongly correlated with observable profile features (e.g., content, friend information, posting patterns, etc.). Based on these profile features, we develop machine learning based classifiers for identifying previously unknown spammers with high precision and a low rate of false positives."
2396373,22457,11166,Genre Categorization of Web Pages,2007,"With the increase of the number of web pages, it is very difficult to find wanted information easily and quickly out of thousands of web pages retrieved by a search engine. To solve this problem, many researches propose to classify documents according to their genre, which is another criteria to classify documents different from the topic. Most of these works assign a document to only one genre. In this paper we propose a new flexible approach for document genre categorization. Flexibility means that our approach assigns a document to all predefined genres with different weights. The proposed approach is based on the combination of two homogenous classifiers: contextual and structural classifiers. The contextual classifier uses the URL, while the structural classifier uses the document structure. Both contextual and structural classifiers are centroid-based classifiers. Experimentations provide a micro-averaged breakeven point (BEP) more than 85%, which is better than those obtained by other categorization approaches."
1794866,22457,9475,Cascade mitigation in energy hub networks,2011,"The paper establishes a formulation for energy hub networks that is consistent with mixed-integer quadratic programming problems. Line outages and cascading failures can be considered within this framework. Power flows across transmission lines and pipelines are compared with flow bounds, and tripped when violations occur. The outaging of lines is achieved using a mixed-integer disjunctive model. A model predictive control (MPC) strategy is developed to mitigate cascading failures, and prevent propagation of outages from one energy-carrier network to another. The MPC strategy seeks to alleviate overloads by adjusting generation and storage schedules, subject to ramp-rate limits and governor action. If overloads cannot be eliminated by rescheduling alone, MPC determines the minimum amount of load that must be shed to restore system integrity. The MPC strategy is illustrated using a small 12 hub network and a much larger network that includes 132 energy hubs."
3048807,22457,20561,Catch Me If You Can: Technological Constraints/Affordances and Mindfulness during Collaborative Police Emergency Response,2017,"Nowadays, mobile technology plays an essential role during police emergency response duties. This article presents the result of an ethnographic research in progress. Police officers were shadowed during their shifts (70 hours of observation) in cases of timepressured incidents. We analyze the entanglement between the material and human agencies while the police officers were responding to two incidents (a holdup and a burglary). We assess the effect of technological constraints and affordances on human mindfulness. Mindfulness is important to achieve a successful collaborative response to an emergency where multiple High Reliability Teams are involved. When technology is not used to its full potential, our results show that it hinders collaboration between teams. Additionally, the results show the amount of time pressure affects the level of mindfulness among police officers."
229200,22457,8228,Secure mobile notifications of civilians in case of a disaster,2006,"Disaster management using mobile telecommunication networks provides a new and attractive possibility to save human lives in emergencies. With this contribution, we present a possible disaster management system based on mobile telecommunication. In order to use such a system in the real world, security requirements such as availability, accountability, integrity and confidentiality have to be ensured by the disaster management system (DMS). We summarize these requirements and propose ways of addressing them with a multilateral secure approach. Using electronic signatures based on SIM-cards, we assure integrity, accountability and confidentiality of the notification messages. We also discuss how availability could be increased."
1744123,22457,422,Extracting Consumers Needs for New Products - A Web Mining Approach,2010,"Here we introduce a web mining approach for automatically identifying new product ideas extracted from web logs. A web log - also known as blog - is a web site that provides commentary, news, and further information on a subject written by individual persons. We can find a large amount of web logs for nearly each topic where consumers present their needs for new products. These new product ideas probably are valuable for producers as well as for researchers and developers. This is because they can lead to a new product development process. Finding these new product ideas is a well-known task in marketing. Therefore, with this automatic approach we support marketing activities by extracting new and useful product ideas from textual information in internet logs. This approach is implemented by a web-based application named Product Idea Web Log Miner where users from the marketing department provide descriptions of existing products. As a result, new product ideas are extracted from the web logs and presented to the users."
2462127,22457,9438,Exploring RDF for Expertise Matching within an Organizational Memory,2002,"Organizations have realized that effective development and management of their organizational knowledge base is very important for their survival in todays competitive business environment. People, as a special knowledge asset, also attract the interest of many researchers because, only through people communicating with one another, can they really share their tacit knowledge and skills that can be more valuable than explicit documentation. The need to be able to quickly locate experts among the heterogeneous data sources stored in the organizational memory has been recognized by many researchers. This paper examines the advantages of using RDF (Resource Description Framework) for Expertise Matching. The major challenge is to semantically integrate heterogeneous data sources stored in the organizational memory and facilitate users to locate the right people. We present a practical application of this using a case study where PhD applicants can locate potential supervisors before they formally apply to a university."
290490,22457,20561,The Tangram DPE - A Distributed Processing Environment,1997,Within this paper we will describe the usage of a DistributedProcessing Environment based on CORBA 2 withrespect to distribution transparencies. We will sketch amultimedia telecommunication service (T-MMCS) basedon TINA-C concepts and our experience using CORBA 2implementations (Orbix and HPDST) as DPE for this application.At the moment the CORBA Scene is changing veryrapidly. New products are coming up and interoperabilitybetween products is increasing due to corrections in theimplementations. More and more CORBA Services aresupported. The CORBA Standards are also extended andmore services are defined. This changes will also happenin the time between submitting this paper and the time itwill be presented to the conference audience. Therefore wewill present the newest developments that took place andour newest experiences on the conference.
249832,22457,20561,Towards an optimal algorithm for recognizing Laman graphs,2009,"Ag raphJ withq vertices andp edges is aL aman graph, or equivalently a generically minimally rigid graph, ifp =2 q�3 and every induced subset ofn vertices spans at most 2n�3 edges. Laman graphs play a fundamental role in rigidity theory. We discuss the Veriocation problem: Given a graphJ withq vertices, decide if it is Laman. We present an algorithm that recognizes Laman graphs inR (Wvw(q )+ q logq) time, whereWvw(q) is the best time to extract two edge disjoint spanning trees from a graph withq vertices and 2q�2 edges, or decide no such trees exist. So far, it is known thatWvw(q) isR (q 3@2 s logq)="
2363425,22457,9896,'Is' to 'Was': Coordination and Commemoration in Posthumous Activity on Wikipedia Biographies,2015,"Following the deaths of notable people, Wikipedians incorporate this new knowledge by updating or creating biographical articles. Drawing on literature from death studies and peer production, we demonstrate how the creation of these wiki-bituaries requires complex coordination work and highlight processes of commemoration and memorialization within socio-technical systems. Using the corpus of 6,132 articles about people who died in 2012, we examine the network relationships and contribution dynamics of users who perform this work and identify behavioral and content dynamics on the biographical articles about the deceased. The collaborations that emerge from posthumous editing of these biographies are sites of significant activity that coalesce into complex but temporary collaborations. Based on these findings, we argue that Wikipedia has re-imagined the obituary into a genre for creating memory spaces in which the death of a subject prompts a form of death work involving the collective re-evaluation of article content and a transition into a new mode of data stewardship."
2807363,22457,20332,Developing Robots that Recognize When They Are Being Trusted,2013,"In previous work we presented a computational framework that allows a robot or agent to reason about whether it should trust an interactive partner or whether the interactive partner trusts the robot  (Wagner & Arkin, 2011). This article examines the use of this framework in a well-known situation for examining trust--the Investor-Trustee game (King-Casas, Tomlin, Anen, Camerer, Quartz, & Montague, 2005). Our experiment pits the robot against a person in this game and explores the impact of recognizing and responding to trust signals. Our results demonstrate that the recognition that a person has intentionally placed themselves at risk allows the robot to reciprocate and, by doing so, improve both individuals play in the game. This work has implications for home healthcare, search and rescue, and military applications."
2264676,22457,9475,Hybrid Minimal Control Synthesis identification of continuous piecewise linear systems,2009,"A novel identification strategy is presented in this paper for piecewise linear (PWL) dynamical systems. The strategy is based on the use of the Minimal Control Synthesis adaptive technique for PWL systems presented in [3]. After stating the general identification problem, the convergence of the novel algorithm is proved analytically in the case where the plant is PWL and the reference model is linear. Simulations are carried out on a representative example and are shown to be in perfect agreement with the theoretical derivations."
1392465,22457,9475,Power line control under uncertainty of ambient temperature,2013,"This paper discusses a control scheme for maintaining low tripping probability of a transmission system power line under thermal stress. We construct a stochastic differential equation to describe the temperature evolution in a line subject to randomness of the ambient temperature. When the distribution of the ambient temperature changes, so does the dependence of the tripping probability as a function of line current. The theory of extremes of Gaussian random fields is used to guide the size of the underlying frequency inspection so as to insure that current is effective for controlling the risk of overheating. In particular, we show that only when the change of temperature is suitably light-tailed (according to a precise definition discussed in the paper), the current provides a powerful enough mechanism to control tripping probabilities due to overheating. We then provide bounds that can be used to control the tripping probability in our stochastic model."
191721,22457,20358,Discriminative Models for Predicting Deception Strategies,2015,"Although a large body of work has previously investigated various cues predicting deceptive communications, especially as demonstrated through written and spoken language (e.g., [30]), little has been done to explore predicting kinds of de- ception. We present novel work to evaluate the use of textual cues to discriminate between deception strategies (such as exaggeration or falsification), concentrating on intention- ally untruthful statements meant to persuade in a social media context. We conduct human subjects experimenta- tion wherein subjects were engaged in a conversational task and then asked to label the kind(s) of deception they employed for each deceptive statement made. We then develop discriminative models to understand the difficulty between choosing between one and several strategies. We evaluate the models using precision and recall for strategy prediction among 4 deception strategies based on the most relevant psycholinguistic, structural, and data-driven cues. Our single strategy model results demonstrate as much as a 58% increase over baseline (random chance) accuracy and we also find that it is more difficult to predict certain kinds of de- ception than others."
2052553,22457,20358,Modulating video credibility via visualization of quality evaluations,2010,"In this work we develop and evaluate a method for the syndication and visualization of aggregate quality evaluations of informational video. We enable the sharing of knowledge between motivated media watchdogs and a wider population of casual users. We do this by developing simple visual cues which indicate aggregated activity levels and polarity of quality evaluations (i.e. positive / negative) which are presented in-line with videos as they play. In an experiment we show the potential of these visuals to engender constructive changes to the credibility of informational video under some circumstances. We discuss the limitations, and future work associated with this approach toward video credibility modulation."
2676611,22457,20561,Relational and Masspersonal Maintenance: Romantic Partners' Use of Social Network Websites,2016,"As social network websites (SNSs) occupy the intersection of both interpersonal and mass media communication, the current research examined how public, private, and masspersonal features of SNSs affect relational maintenance between romantic couples. In Study 1, a survey of 309 Facebook users revealed that increases in dyadic public and private maintenance, and network maintenance communication were associated with greater feelings of presence and satisfaction. However, public and private dyadic maintenance had opposite relationships with partner uncertainty. To further examine these patterns, Study 2 employed an in-depth content analysis of maintenance messages. Results from a sample of 94 Facebook users' maintenance messages indicated that selection of public and private SNS channels varied with respect to the valence and intimacy of the message."
3227606,22457,9896,"Video-based Evanescent, Anonymous, Asynchronous Social Interaction: Motivation and Adaption to Medium",2017,"Danmaku is an emerging socio-digital media paradigm that puts anonymous, asynchronous user-generated scrolling comments on videos. (How) can danmaku afford the illusion and realization of social interactions, if at all possible given its interactional incoherence nature? To answer this question, we collect Chinese danmaku users' reflection on their motivations to use this social service and explore the actual practices that meet the needs. According to a preliminary danmaku usage survey, users consider it as an information seeking and emotion venting channel. Through archival analysis of real-world data, we find that danmaku commentaries are relatively short, video-centric, saturated with emotions, and similar in syntactic and semantic features. Users have developed a set of mechanisms adapted to the medium, to leverage such text-based messages to foster interpersonal and hyperpersonal communication for sharing of facts, thoughts, and feelings."
1257958,22457,369,Systematic Model Driven Test of Vehicular Energy Management and Engine Control,2010,"The development of economic and hybrid vehicles is only possible with complex systems to control the energy management and engine. The amount of embedded electronics and software to realize these systems increases continuously, and hence the complexity of the integration. The functional validation and testing of these systems is of increasing importance, as these systems have an inreasing impact on other systems like comfort and safety functionalities. So there is a need for thourough testing. However, exhaustive testing is not possible as testing in industry is limited by time and resources. So a method is needed to derive systematically the most significant test cases in order to be able to assess the behavior of the system. We applied test models to accomplish this task. A Timed Usage Model served as a formal requirement specification and was the basis for following test activities. The model provides the possibility to describe timing and data dependencies of the system to be tested. The test planning and test case generation was supported by the models. The appliance of models allowed the systematic generation of test cases and the assessment of the significance of the conducted test activities with respect to the coverage of requirements."
360697,22457,20332,DataSift: An Expressive and Accurate Crowd-Powered Search Toolkit,2013,"Traditional information retrieval systems have limited functionality. For instance, they are not able to adequately support queries containing non-textual fragments such as images or videos, queries that are very long or ambiguous, or semantically-rich queries over non-textual corpora. In this paper, we present DataSift, an expressive and accurate crowd-powered search toolkit that can connect to any corpus. We provide a number of alternative configurations for DataSift using crowdsourced and automated components, and demonstrate gains of 2–3x on precision over traditional retrieval schemes using experiments on real corpora. We also present our results on determining suitable values for parameters in those configurations, along with a number of interesting insights learned along the way."
2576965,22457,20332,Addressing complexity in multi-issue negotiation via utility hypergraphs,2014,"There has been a great deal of interest about negotiations having interdependent issues and nonlinear utility spaces as they arise in many realistic situations. In this case, reaching a consensus among agents becomes more difficult as the search space and the complexity of the problem grow. Nevertheless, none of the proposed approaches tries to quantitatively assess the complexity of the scenarios in hand, or to exploit the topology of the utility space necessary to concretely tackle the complexity and the scaling issues. We address these points by adopting a representation that allows a modular decomposition of the issues and constraints by mapping the utility space into an issue-constraint hypergraph. Exploring the utility space reduces then to a message passing mechanism along the hyperedges by means of utility propagation. Adopting such representation paradigm will allow us to rigorously show how complexity arises in nonlinear scenarios. To this end, we use the concept of information entropy in order to measure the complexity of the hypergraph. Being able to assess complexity allows us to improve the message passing algorithm by adopting a low-complexity propagation scheme. We evaluated our model using parametrized random hyper- graphs, showing that it can optimally handle complex utility spaces while outperforming previous sampling approaches."
2467519,22457,65,Recognizing situations that demand trust,2011,"This article presents an investigation into the theoretical and computational aspects of trust as applied to robots. It begins with an in-depth review of the trust literature in search of a definition for trust suitable for implementation on a robot. Next we apply the definition to our interdependence framework for social action selection and develop an algorithm for determining if an interaction demands trust on the part of the robot. Finally, we apply our algorithm to several canonical social situations and review the resulting indications of whether or not the situation demands trust."
2658878,22457,20561,Institutional Barriers Against Innovation Diffusion: From the Perspective of Digital Health Startups,2016,"Growth in the applications market for many industries has been rapid, but appears much slower for healthcare-related applications. The purpose of this pilot study was to determine whether: (1) the healthcare field was perceived to be a slower adopter of digital solutions than other industries, (2) if so, what barriers contributed to this, and (3) what might mitigate these barriers? We conducted an exploratory qualitative study by interviewing six startup CEOs and conducting an ethnographic study at a digital health startup to answer these questions. The CEOs contended that compared with their prior ventures in non-healthcare settings, healthcare providers were slower adopters of novel innovations. Another key preliminary finding was the asymmetric impact of regulatory pressures. Even if the startup's product met regulatory requirements, healthcare providers were reluctant and risk adverse adopters. A last barrier was the need for multidisciplinary buy-in from other stakeholders, including payers and incumbent HIT vendors."
3013868,22457,20561,Analyzing Affordances of Digital Occupational Health Systems,2017,"This study adopts two distinct perspectives, employer and employee, to analyze the affordances of digital occupational health (DOH) systems and their appropriation. Data were collected in the context of a European collaborative research project that aims at developing a data integration infrastructure for con-text-aware health surveillance at the workplace. For employers the main affordance was to detect and prevent the health issues of their workforce. The main affordance from employee’s point of view was the possibility of being more self-conscious at work. However, the application of these systems might instigate several tensions, in particular those between privacy and security / wellbeing, between work and leisure activities, and between work and leisure roles. The findings of this study allow to direct future research on DOH systems to focus and eventually derive design principles that promise DOH systems to gain better acceptance and create higher added-value for all involved stake-holders."
1763267,22457,507,DataSift: a crowd-powered search toolkit,2014,"Traditional search engines are unable to support a large number of potential queries issued by users, for instance, queries containing non-textual fragments such as images or videos, queries that are very long, ambiguous, or those that require subjective judgment, or semantically-rich queries over non-textual corpora. We demonstrate DataSift, a crowd-powered search toolkit that can be instrumented over any corpus supporting a keyword search API, and supports efficient and accurate querying for a rich general class of queries, including those described previously. Our demonstration will allow conference attendees to issue live queries for image, video, and product search, as well as play back the results of a wide variety of prior queries issued on DataSift. Attendees will also be able to perform a side-by-side comparison between DataSift and traditional retrieval schemes."
1815816,22457,8228,A Development of Network Topology of Wireless Packet Communications for Disaster Situation with Genetic Algorithms or with Dijkstra's,2011,"This paper discusses the use of genetic algorithms (GAs) and Dijkstra's algorithm to optimize load network topologies in distributed packet communication systems. These algorithm is fully distributed in which information is dynamically updated at each movement of packet terminal almost realtime. Multiple distributed paradigms are adopted so that each terminal transmits information on the network topology throughout the wireless and satellite network. A GA model is effective when a network is configured with a sufficiently large number (N) of units. However, in marine applications or for use at a disaster site, the number (N) of units may be low, such as 7 or 8. In such cases, Dijkstra's algorithm is more efficient than genetic algorithms. With Dijkstra's algorithm, a system of 0 or 1 is not used in the adjacency matrix determinant, but each path can be assigned a weight (corresponding to the distance of each terminal). Based on field experiments, we will seek to manage network topologies by transmitting the adjacency matrix determinant bilaterally."
2670230,22457,20561,Analyzing the Concept of Affordances in Information Systems,2016,"The affordance concept has penetrated the Information Systems (IS) scholarship as a lens for theorizing the relationship between technology and its users. However, what exactly is it that the researchers are trying to capture when they use this concept? For this essay, we carefully read IS literature to reveal underlying assumptions behind this lens and how it has been adopted. This article reveals three assumptions: 1) whether affordances are identified as intended prior use or emerging in action, 2) whether affordances are functional or non-functional, and 3) whether affordances are potential or actual. We dig into these assumptions and suggest alternatives for further enquiry."
2705717,22457,20561,Diversified Recommendation Incorporating Item Content Information Based on MOEA/D,2016,"There has been an increasing awareness that accuracy is not the only criteria in the evaluation of recommender systems. Additional properties such as diversity, novelty and interpretability are playing more important roles in increasing satisfaction of users when interacting with the recommender systems. However, designing a recommendation algorithm that optimizes the abovementioned properties simultaneously is hard since these objectives are conflicting. In this paper, we propose a multi-objective evolutionary algorithm based on decomposition to recommend diversified recommendation lists to each user. Notably, the item content information are taken into account when devising the diversity objective function, which makes the recommendation lists highly explainable. Experimental results on the movie dataset demonstrate that the proposed algorithm can generate a more diversified and novel recommendation, without sacrificing the accuracy significantly."
2705872,22457,20561,Ambient Intelligence Based Context-Aware Assistive System to Improve Independence for People with Autism Spectrum Disorder,2016,"Individuals with Autism Spectrum Disorder (ASD) can face great challenges in learning and maintaining basic living skills. This not only reduces their possibilities of independent living and employment, but also continuously brings social and financial burdens to their caregivers/mentors. Although research has been proposed to help autism users, most of them focus on improving social and communication skills or providing help for emergency situations. In this paper, we propose a novel portable context-aware assistive system to help autism users in their daily activities such as cooking and cleaning. To make it easily accessible and cost effective, we employ mobile devices and cheap context sensors. Our care system has been implemented and tested under different settings, and a user study involving ten pairs of autism users and their caregiver/mentors has been carried out to evaluate our approach. User feedback is highly positive."
2702591,22457,20561,Attributes of Open Source Software Requirements -- The Effect of the External Environment and Internal Social Structure,2016,Popularity of open source software (OSS) projects has spiked an interest in the requirements engineering (RE) practices of such communities that are starkly different from those in traditional software development projects. Past work has focused on characterizing the main differences between OSS and traditional forms of software RE. In this effort we focus on differences in RE activity in OSS. RE is characterized as a socio-technical distributed cognitive (DCog) activity where multiple actors deploy artifacts to 'compute' requirements. To uncover how OSS projects configure the socio-technical distribution of cognitive processes to respond to varying attributes of incoming requirements we conduct a comparative analysis of four successful OSS projects. We observe that the volume of requirements faced by an OSS group dictates largely the nature of its social formation while the volatility experienced in the requirements dictates the overlap the project exhibits with the larger external community. Finally the velocity of change in technological requirements influence the project's documentation practices of requirements with the level of design consistency desired in the end product influencing the decision-making channels used in the development endeavor.
2704640,22457,20561,"Internet Usage, Physician Performances and Patient's Trust in Physician During Diagnoses: Investigating Both Pre-Use and Not-Use Internet Groups",2016,"Do patients' Internet searches of disease information and physician performances affect patients' trust in physicians during diagnoses? This study proposes a research model concerning the effect of whether patients use Internet and Internet usage on perceived physician performances (including perceived communication time, explanation quality and physician attitude) and on trust. Our empirical study of over 650 subjects in China suggests that for pre-use Internet patients, they feel longer communication time but less quality of physicians' explanation in diagnosis process. There is no significant discrepancy of perceived physician attitude between two sample groups. We also demonstrate that whether patients search healthcare information through the Internet impacts their trust in physicians through physicians' explanation quality as well as the communication time. Moreover, this study indicates that physician performances in a diagnosis process play a dominant role in gaining patients' trust, while the professional status of a physician (i.e. expert) will help improve trust when patients feel warm attitude from physicians. However, longer search time on the Internet will weaken the effect of communication time and explanation quality on trust. Overall, this study suggests that the impact of the physician performances and Internet search are not trivial to physician-patient trust, but even in the high-tech age, high-touch remains an important factor to physician-patient trust."
3041597,22457,20332,Interdependent multi-issue negotiation for energy exchange in remote communities,2013,"We present a novel negotiation protocol to facilitate energy exchange between off-grid homes that are equipped with renewable energy generation and electricity storage. Our protocol imposes restrictions over negotiation such that it reduces the complex interdependent multi-issue negotiation to one where agents have a strategy profile in subgame perfect Nash equilibrium. We show that our negotiation protocol is tractable, concurrent, scalable and leads to Pareto-optimal outcomes in a decentralised manner. We empirically evaluate our protocol and show that, in this instance, a society of agents can (i) improve the overall utilities by 14% and (ii) reduce their overall use of the batteries by 37%."
1856175,22457,9896,The Mind's Eye on Personal Profiles: A Cognitive Perspective on Profile Elements that Inform Initial Trustworthiness Assessments and Social Awareness in Virtual Project Teams,2013,"Collaboration in virtual project teams heavily relies on interpersonal trust, for which perceived professional trustworthiness is an important determinant. In face to face teams colleagues form a first impression of each others trustworthiness based on signs and signals that are `naturally' available. However, virtual project team members do not have the same opportunities to assess trustworthiness. This study provides insight in the information elements that virtual project team members value to assess professional trustworthiness in the initial phase of collaboration. The trustworthiness formed initially is highly influential on interpersonal trust formed during latter collaboration. We expect trustors in virtual teams to especially value information elements (= small containers for personal data stimulating the availability of specific information) that provide them with relevant cues of trust warranting properties of a trustee. We identified a list with fifteen information elements that were highly valued across trustors (n?=?226) to inform their trustworthiness assessments. We then analyzed explanations for preferences with the help of a theory-grounded coding scheme for perceived trustworthiness. Results show that respondents value those particular information elements that provide them with multiple cues (signaling multiple trust warranting properties) to assess the trustworthiness of a trustee. Information elements that provide unique cues (signaling for a specific trust warranting property) could not be identified. Insight in these information preferences can inform the design of artefacts, such as personal profile templates, to support acquaintanceships and social awareness especially in the initial phase of a virtual project team."
2724813,22457,20561,Visual Representation of Information as an Antecedent of Perceptive Efficiency: The Effect of Experience,2016,"Visual representation of information is ubiquitous, from traditional management reports via dynamic management cockpits to modern 3D and 4D visualizations of 'big data'. Little is known about how the perception in terms of efficiency of such a visual representation can be predicted ex-ante. The visualization/task complexity nexus is widely accepted to be a solid foundation of such a predictive model, although evidence points to a variety of additional factors, including data complexity, visual complexity, spatial ability, and experience. While most of these factors can be readily operationalized, the construct of experience is vastly under-researched in this context. In this paper we test the influence of the aforementioned factors on the perceptive efficiency of visualization -- given a certain task complexity -- by using experiments and structural equation modelling. In addition we look at four different conceptualizations of experience. The adjusted R2 of the model is 39% and all four proxies of experience are significant at the p"
534607,22457,20332,Genre classification of web documents,2005,"Retrieving relevant documents over the Web is an overwhelming task when search engines return thousands of Web documents. Sifting through these documents is time-consuming and sometimes leads to an unsuccessful search. One problem is that most search engines rely on matching a query to documents based solely on topical keywords. However, many users of search engines have a particular genre in mind for the desired documents. The genre of a document concerns aspects of the document such as the style or readability, presentation layout, and meta-content such as words in the title or the existence of graphs or photos. By including genre in Web searches, we hypothesize that Web document retrieval could greatly improve accuracy by better matching documents to the user's information needs. Before implementing a search engine capable of discriminating on both genre and topic, a feasibility analysis of genre classification is needed. Our previous research achieved 91% classification accuracy across ten genres, whereas similar research range between 60 and 85% accuracy. However, the ten genres used in our research were mostly distinct and only exemplar Web documents (consisting of only one genre) were chosen. This paper discusses our current work which involves an in-depth analysis of maintaining high accuracy rates among genres that are very similar."
1808151,22457,10228,QoS for Ad Hoc Networks Using an Empirical Model,2008,"Empirical models are a technique that has been used in research for a long time, and that proved to be capable of describe pseudo-random phenomena. In this paper, we present PREFAIRS, a protocol used to deploy QoS, and that was designed using empirical models. With our empirical model we are able to determine the available capacity of the ad hoc network and the maximum bandwidth of new flows to guarantee a specified QoS. We show that a combination of our network model, PREFAIRS and a empirical model is able to enforce fairness, predictability and stability in ad hoc networks."
2503188,22457,9704,A Semantic Based Framework for Supporting Negotiation in Service Oriented Architectures,2009,"Negotiation is required before invoking a service in order to identify how the invocation must occur in terms of functional and non-functional criteria. This process is possible when all the involved parties agree on the same negotiation protocol (e.g., bilateral negotiations). Considering a Service Oriented Architecture (SOA), this negotiation protocol cannot be predefined, but it must be selected by considering the negotiation capabilities of the involved services.In this work, we propose a semantic-based framework for supporting the negotiation in SOA. Specifically, the framework allows to express the negotiation capabilities of service requesters and providers and proposes a mechanism for discovering the negotiation protocols that can be enacted when a negotiation is required. To improve the flexibility of the framework, the concept of delegation is introduced to deal with the situation in which a party, that is not able to support the negotiation protocol, wants to participate in a negotiation. In this case, the negotiation can be fully or partially delegated to one or more other parties that, instead, are able to support the negotiation protocol."
2665629,22457,20561,Gender Differences in Online Dating: What Do We Know So Far? A Systematic Literature Review,2016,"With millions of users worldwide, online dating platforms strive to assert themselves as powerful tools to find dates and form romantic relationships. However, significant differences exist in male and female use of this mate-matching technology with respect to motivation, preferences, self-presentation, interaction and outcomes. While existing research has routinely reported on gender differences in online dating, these insights remain scattered across multiple studies. To gain a systematic insight into existing findings, in this study we conduct a meta-review of existing research. We find that evolutionary theory generally holds true in online dating: Users still follow natural stereotypes when it comes to choosing a mate online. Physical attractiveness is the key criteria for men, while women, being much more demanding, prioritize socio-economic attributes when choosing a male partner. Together, our structured findings offer a deeper insight into the underlying dynamics of gender differences in online dating."
2871609,22457,8494,On the modeling of blackouts in power networks,2016,"We describe a model of power networks which may be useful for studying power blackouts. The model is a combination of the admittance model of the network and the probabilistic model of faults of its components. To compute the probability of a power outage possible failure events are considered and in each case the possibility of a cascading failure is studied. Graph representation of the network is used to detect connected components in the network, and then network equations are solved separately in each component. We show how to use this model to compute the probability of a power blackout in power networks and how this model can be used to develop suggestions for improving power network designs. The IEEE 188 bus is considered to show the usefulness of this approach."
2850323,22457,20561,How Do Patients Expect Apps to Provide Drug Information,2017,"Patients use various sources to obtain information on pharmaceutical drugs they take. Mobile health care applications (apps) providing drug information to users are increasingly made available and of in-creasing importance for the health care domain. However, apps usually only offer functionality that medical professionals or developers consider useful for patients, although their expectations are not likely to meet patient expectations. In our mixed methods study, we identify 33 features patients expect in apps for drug information provision with interviews and empirically assess their perceived importance in an online survey. Results indicate that patients desire personalization features for provided information but not for the app interface. This work contributes to research and practice by identifying and empirically ranking drug information provision features patients find important. We furthermore establish a foundation for future research on effective mobile drug information provision and provide insights for practice on development of patient-centered mobile health apps."
1293462,22457,20358,Actions speak as loud as words: predicting relationships from social behavior data,2012,"In recent years, new studies concentrating on analyzing user personality and finding credible content in social media have become quite popular. Most such work augments features from textual content with features representing the user's social ties and the tie strength. Social ties are crucial in understanding the network the people are a part of. However, textual content is extremely useful in understanding topics discussed and the personality of the individual. We bring a new dimension to this type of analysis with methods to compute the type of ties individuals have and the strength of the ties in each dimension. We present a new genre of behavioral features that are able to capture the function of a specific relationship without the help of textual features. Our novel features are based on the statistical properties of communication patterns between individuals such as reciprocity, assortativity, attention and latency. We introduce a new methodology for determining how such features can be compared to textual features, and show, using Twitter data, that our features can be used to capture contextual information present in textual features very accurately. Conversely, we also demonstrate how textual features can be used to determine social attributes related to an individual."
2817397,22457,22113,A scalable interdependent multi-issue negotiation protocol for energy exchange,2015,"We present a novel negotiation protocol to facilitate energy exchange between off-grid homes that are equipped with renewable energy generation and electricity storage. Our protocol imposes restrictions over negotiation such that it reduces the complex interdependent multi-issue negotiation to one where agents have a strategy profile in subgame perfect Nash equilibrium. We show that our protocol is concurrent, scalable and; under certain conditions; leads to Pareto-optimal outcomes."
2702382,22457,20561,EPIC-OSM: A Software Framework for OpenStreetMap Data Analytics,2016,An important area of work in big data software engineering involves the design and development of software frameworks for data-intensive systems that perform large-scale data collection and analysis. We report on our work to design and develop a software framework for analyzing the collaborative editing behavior of OpenStreetMap users when working on the task of crisis mapping. Crisis mapping occurs after a disaster or humanitarian crisis and involves the coordination of a distributed set of users who collaboratively work to improve the quality of the map for the impacted area in support of emergency response efforts. Our paper presents the challenges related to the analysis of OpenStreetMap and how our software framework tackles those challenges to enable the efficient processing of gigabytes of OpenStreetMap data. Our framework has already been deployed to analyze crisis mapping efforts in 2015 and has an active development community.
2240023,22457,20358,Sub-event detection during natural hazards using features of social media data,2013,"Social networking sites such as Flickr, YouTube, Facebook, etc. contain a huge amount of user-contributed data for a variety of real-world events. These events can be some natural calamities such as earthquakes, floods, forest fires, etc. or some man-made hazards like riots. This work focuses on getting better knowledge about a natural hazard event using the data available from social networking sites. Rescue and relief activities in emergency situations can be enhanced by identifying sub-events of a particular event. Traditional topic discovery techniques used for event identification in news data cannot be used for social media data because social network data may be unstructured. To address this problem the features or metadata associated with social media data can be exploited. These features can be user-provided annotations (e.g., title, description) and automatically generated information (e.g., content creation time). Considerable improvement in performance is observed by using multiple features of social media data for sub-event detection rather than using individual feature. Proposed here is a two-step process. In the first step, clusters are formed from social network data using relevant features individually. Based on the significance of features weights are assigned to them. And in the second step all the clustering solutions formed in the first step are combined in a principal weighted manner to give the final clustering solution. Each cluster represents a sub-event for a particular natural hazard."
2963637,22457,20561,When are Decentralized Infrastructure Networks Preferable to Centralized Ones,2017,"Many infrastructure networks, such as power, water, and natural gas systems, have similar properties governing flows. However, these systems have distinctly different sizes and topological structures. This paper seeks to understand how these different features can emerge from relatively simple design principles. Specifically, we work to understand the conditions under which it is optimal to build small decentralized network infrastructures, such as a microgrid, rather than centralized ones, such as a large high-voltage power system. While our method is simple it is useful in explaining why sometimes, but not always, it is economical to build large, interconnected networks and in other cases it is preferable to use smaller, distributed systems. The results indicate that there is not a single set of infrastructure cost conditions that cause a transition from centralized networks being optimal, to decentralized architectures. Instead, as capital costs increase network sizes decrease gradually, according to a power-law. And, as the value of reliability increases, network sizes increase abruptly---there is a threshold at which large, highly interconnected networks are preferable to decentralized ones."
2909586,22457,11104,Spatial grid based Open Government Data mining,2016,"Then Open Government Data movement increases in recent years. The data has become an important part of Big Data. Data generated by different government agencies have different time and space coverages and are often focusing on various aspect of cities. These data could be co-registered in a unified spatial reference system for correlated analysis. This paper proposes a spatial grid based approach to manage government data and mine hidden information from it. The data is co-registered into spatial grids. Such data organization can facilitate the usage of array database technologies, which further introduce high performance in-database computing for data analysis. The open government data from Wuhan, China is used as a case to illustrate the applicability of the approach."
2715164,22457,20561,Idea Generation by Employees and External Participants in Innovation Competitions,2016,"Innovation competitions are considered to be an instrument by which companies can inspire customers and employees to generate value-added ideas. However, there is little research on how the quality contributions are made and by whom. In this paper, a case study-based analysis is carried out at a global telecommunications company. Through the analysis of log files, the participating users are categorized on the basis of their level of activity and membership of user groups. We differentiate between employees and external users. Our findings show that employees generated the best-rated ideas and that they provide more feedback for all other participants than external users. The data also indicate that external users created a higher number of valuable ideas in total. Our results extend the current theoretical discussion in the field of open innovation and provide valuable insights for managers as well."
1654110,22457,20358,Building a role search engine for social media,2012,"A social role is a set of characteristics that describe the behavior of individuals and their interactions between them within a social context. In this paper, we describe the architecture of a search engine for detecting roles in a social network. Our approach, based on indexed clusters, gives the user the possibility to define the roles interactively during a search session and retrieve the users for that role in milliseconds. We found that role selection strategies based on selecting people deviating from the average standards provides flexible query expressions and high quality results."
2711345,22457,20561,The Role of Agency Theory and Perceived Goal Divergence in IS Continuance: A Replication and Extension Study,2016,"Past literature recognizes the power of the well-established information systems continuance theory (ISCT) to explain information systems (IS) continuance. In this study, we integrate constructs from two additional perspectives and discuss their interdependencies with ISCT. We argue that the promising framework proposed by Sorebo et al. [1], which extends ISCT with self-determination theory (SDT), can increase its managerial relevance by adding the variables of users' perceptions of goal divergence and risk aversion, selected from agency theory. The empirical results support Sorebo et al.'s main findings and strongly support the impact of perceived goal divergence on e-learning continuance intention. By replicating and extending the main findings of the original target study, the results of the present study support the demand for an integrative perspective on IS continuance intention which includes ISCT, SDT and principal-agent theory (PAT)."
2667678,22457,20561,Towards a Conceptualization of Data Analytics Capabilities,2016,"Data analytics is an emerging domain in information systems literature and an increasing number of companies try to use data analytics to make sense out of their environment. Accordingly, the ability of companies to leverage digital data to explore new business opportunities becomes important to develop competitive advantage in digitalized world. Consequently, extant literature investigates different dimensions of data analytics, such as technical and organizational dimensions. In spite of all the insights provided and the practical relevance of the topic, extant literature does not provide a coherent view on data analytics and is relatively silent when it comes to measuring the effects. In this paper we conceptualize data analytics capabilities based on IT capabilities literature and provide a measurement instrument allowing to test effects of data analytics capabilities."
2248224,22457,20358,Computer-Supported Collaborative Knowledge Modeling in Ecology.,2007,"collaborative efforts between a knowledge representation team, a community of scientists, and scientific information managers in developing knowledge models for ecological and environmental sciences. Formal, structured approaches to knowledge representation used by the team (e.g., ontologies) can be informed by unstructured approaches to knowledge representation and semantic tagging already in use by the community. Observations about the process of collaboration between the team and the community are used to generate an interaction model for supporting software tools."
2833340,22457,8228,Research on Low-energy Consumption Tree Routing security for Wireless Sensor Networks,2015,"Safe and reliable Wireless Sensor Network (Wireless Sensor Networks, WSN) is an important branch of modern communication systems, and plays an important role in the life and production, especially in some critical fields. However, a large number of network attacks will threaten the data security, which will seriously affect network reliability and will greatly reduce the use value of wireless sensor networks. For network security issues, security model for Low-energy Consumption Tree Routing (LCTR) protocols has been proposed in this paper to provide reliable guarantee to achieve authentication and data integration using Message Authentication Code (MAC) or Digital Signature (DS) techniques. Research will devote to assess the implementation results and energy consumption of the common message authentication code and digital signature technology in tree routing protocol, so as to provide new option to security improvement for the wireless communication network."
3102200,22457,20561,A Semi-Automatic Approach for Eliciting Cloud Security and Privacy Requirements,2017,"Cloud computing provides a wide range of services to organisations in a flexible and cost efficient manner. Nevertheless, inherent cloud security issues make organisations hesitant towards the migration of their services to cloud. In parallel, the cloud service-oriented nature requires a specific and more demanding description of the business functional requirements intended for migration. Organisations need to transform their functional requirements based on a specific language, taking into account the respective non-functional requirements of the migrating services. Thus, the need for an approach that will holistically capture organisations' security and privacy requirements and transform them to cloud service requirements is immense. To this end, this paper presents an approach that takes as input abstract security and privacy requirements and produces through a semi-automatic process various alternative implementation options for cloud services. To achieve that a series of model transformations are utilised in order to create a mapping between the organisational and the operational level of the system's analysis."
1715819,22457,9896,A multi-level analysis of the impact of shared leadership in diverse virtual teams,2013,"Although organizations are using more virtual teams to accomplish work, they are finding it difficult to use traditional forms of leadership to manage these teams. Many organizations are encouraging a shared leadership approach over the traditional individual leader. Yet, there have been only a few empirical studies directly examining the effectiveness of such an approach and none have taken into account the team diversity. To address this gap, this paper reports the results of an empirical examination of the impacts of shared leadership in virtual teams. Results confirm the proposed research model. The impacts of shared leadership are multilevel and vary by race and gender. In addition, while shared leadership promotes team satisfaction despite prior assumptions, it actually reduces rather than increases team performance."
2659113,22457,20561,Implementation and Adoption of an Electronic Information System for Vaccine Inventory Management,2016,"In Canada, a national public health information system is being developed to support immunization and disease surveillance. This study aimed to evaluate the implementation and adoption of the first module of this system, targeting vaccine inventory management, in the province of Quebec. We conducted a two-phase mixed methods evaluation, using semi-structured interviews with key informants and an online survey among users at the local, regional and central levels. First, key informants identified some issues related to the system that slowed down its implementation. However, results from the second phase showed that the system was widely adopted and users were generally satisfied. Easy access to vaccine inventory supported better planning and the system could generate required reports. Usability issues, increased workload and complexity of the system were the main irritants identified. The widespread adoption of the vaccine inventory management module is the first step towards an integrated public health information system."
2677528,22457,20561,Consumer Trust towards an Online Vendor in High- vs. Low-Context Cultures,2016,"This study explores the effect of general disposition to trust on the perceived trustworthiness of an online vendor in high-and low-context cultures. A total sample of 616 responses from users of online bookstores was collected from China and Finland. The results show that the disposition to trust has a highly significant effect on the three dimensions of trustworthiness namely ability, integrity, and benevolence. However, the results of multigroup analysis indicate that these effects vary greatly between our country examples from high-and low-context cultures. We conclude that, while in China general disposition to trust has a highly significant effect on perceived trustworthiness of an online vendor, the effect is only marginal in Finland."
2676646,22457,20561,Residential Energy Efficiency and Electric Demand Response,2016,"Demand response programs, reduced air conditioner size, and improved thermal integrity all reduce the peak demand for residential air conditioning. All can also affect the comfort of residential occupants. A simulation of six hundred houses provides insight into the peak reductions available from each, and their effects on occupant comfort. Reduced air conditioner size and improved thermal integrity should always be evaluated whenever a demand response program, distributed generation, or energy storage are considered."
2655316,22457,20561,Seeking Technical Debt in Critical Software Development Projects: An Exploratory Field Study,2016,"In recent years, the metaphor of technical debt has received considerable attention, especially from the agile community. Still, despite the fact that agile practices are increasingly used in critical domains, to the best of our knowledge, there are no studies investigating the occurrence of technical debt in critical software development projects. The results of an exploratory field study conducted across several projects reveal that a variety of business and environmental factors cause the occurrence of technical debt in critical domains. Using Grounded Theory method, these factors are categorized as ambiguity of requirement, diversity of projects, inadequate knowledge management, and resource constraints to form a theoretical model. Following previous studies we suggest that integrating agile practices, such as iterative development, review meetings, and continuous testing, into common plan-driven processes enables development teams to better identify and manage technical debt."
2646814,22457,20561,A Study on the Clothes Recommendation for a Cold Region of Japan,2016,"This study presented the survey results of clothes recommendation based on Clo value for the clothes recommendation system based on weather information. The Clo value is an indicator of the clothing insulation and warmth. In general, the clothes recommendation services use the method to calculate the clothes recommendation based on the Clo value from weather information. However, there is no definition on how to calculate the optimal clothes recommendation based on Clo value in previous researches. Moreover, in Iwate, which is located in the cold district area of Japan, the Clo value is low, although the temperature is low during winter. In other words, people in Iwate are lightly dressed in winter. This research fills in the gap since there is no survey on clothes information and calculation for an optimal clothes recommendation based on Clo value has been conducted in the cold district area in Japan. Thus, in this study, we conducted surveys to collect the clothes information during winter and autumn in the cold district area. We also collect the information regarding what types of clothes people wear during these seasons. As a result, we conclude that the people in Iwate are lightly dressed and they wear coats, scarf and gloves. In winter, the rate of people wearing coats was increased regardless of the temperature and the Clo value."
1852073,22457,20411,A comparative study of statistical features of language in blogs-vs-splogs,2008,"Language usage in Blogs deviate from the language used in traditional corpora largely due to the noise from various causes like spelling errors, grammatical irregularity, overuse of abbreviations and symbolic characters like emoticons. Spam Blogs or Splogs comprise the subset of blogs, which are usually written to target specific audience for marketing promotions and are mostly generated by software that readily imitates Zipfian distribution of words. Therefore it becomes a difficult task to separate splogs from non-splogs using only frequentist distribution of unigrams. In this detailed comparative study we present and highlight several additional statistical features of language, which are hard to imitate and serve as good discriminator between splogs and blogs."
2548740,22457,9896,Mopping up: modeling wikipedia promotion decisions,2008,"This paper presents a model of the behavior of candidates for promotion to administrator status in Wikipedia. It uses a policy capture framework to highlight similarities and differences in the community's stated criteria for promotion decisions to those criteria actually correlated with promotion success. As promotions are determined by the consensus of dozens of voters with conflicting opinions and unwritten expectations, the results highlight the degree to which consensus is truly reached. The model is fast and easily computable on the fly, and thus could be applied as a self-evaluation tool for editors considering becoming administrators, as a dashboard for voters to view a nominee's relevant statistics, or as a tool to automatically search for likely future administrators. Implications for distributed consensus-building in online communities are discussed."
3039073,22457,20561,Controlling and Pricing Shareability,2017,"In the presence of a peer-to-peer economy, the option of sharing an item is valuable for consumers. By retaining control over the shareability of its products a monopolist can set a sharing tariff in conjunction with the purchase price of the product, in order to extract state-contingent surplus from consumers: the shareability rent. Using an overlapping-generations model with heterogeneous consumers, we determine the jointly optimal retail price and sharing tariff for durable products, and quantify the value for the control of shareability, thus defining the firm's financial boundary conditions for an investment in sharing-control technologies."
2256043,22457,9896,Coordinating donors on crowdfunding websites,2014,"Crowdfunding websites like Kickstarter, Spot.Us and Donor's Choose seek to fund multiple projects simultaneously by soliciting donations from a large number of donors. Crowdfunding site designers must decide what to do with donations to projects that don't reach their goal by the deadline. Some crowdfunding sites use an all-or-nothing return rule in which donations are returned to donors if a project doesn't meet its goal. Other sites use a direct donation structure where all donations are kept by the project even if the total is insufficient. We simulated a crowdfunding site using a threshold public goods game in which a set of donors tries to fund multiple projects that vary in riskiness. We find that the return rule mechanism leads to a marginal improvement in productivity of a site -- more money is donated in total -- by eliciting more donations. However, the return rule also leads to a potential loss in efficiency (percentage of projects funded) because donations become spread across too many projects and are not coordinated to achieve the maximum possible impact. The direct donation model, though, encourages donors to coordinate to creates a more efficient but slightly less productive marketplace."
2659444,22457,20561,SMGSC: Social-Level Macro-Governing Methodology for Cross-Management-Domain Service Collaboration Processes,2016,"In order to adapt to the accelerative open tendency of collaborations between enterprises, this paper proposes the cross-management-domain social-level macro-governing mode for regulating and controlling the social-level visible macro-behaviors of the social individuals participating in collaborations. Then this mode is achieved by creating Social-level Macro-Governing methodology for cross-management-domain Service Collaboration processes, called SMGSC, which consists of two levels of standalone and complementary technologies: the social -- level collaboration process norm system represented as social dependence norm sets and the rational agents whose macro-behaviors in collaboration processes conform to norms. Since the rational agents forming dynamically collaboration relationships can make their macro-behaviors governed by social dependence norms, SMGSC not only can remove effectively the uncontrollability hindrance confronted with by open social activities, but also enables cross-management-domain collaborations to be implemented by uniting the centralized controls of social individuals for respective social activities. Therefore, this paper provides a brand-new system construction mode to promote the convenient development and large-scale deployment of service collaborations."
2611072,22457,20332,Smart Homes or Smart Occupants? Reframing Computational Design Models for the Green Home.,2011,"A sustainable home is more than a green building: it is also a living experience that encourages occupants to use fewer resources more effectively. Research has shown that small changes in behaviour in how we use our homes can result in substantial energy and water savings. The design dialogue in the development of efficient buildings has largely focused on energy use simulations, smart automation of the building systems and components for optimal performance rather than on effectively supporting how people use them.  In this paper we propose that the challenge to computationally supporting sustainable home design lies in integrating more informative models of occupant behaviour and suggest three foci for developing these models drawn from case studies in sustainable home systems design."
1953857,22457,10228,A Vertical Handoff Decision Algorithm for Heterogeneous Wireless Networks,2007,"One of the major design issues in heterogeneous wireless networks is the support of vertical handoff. Vertical handoff occurs when a mobile terminal switches from one network to another (e.g., from WLAN to CDMA 1timesRTT). The objective of this paper is to determine the conditions under which vertical handoff should be performed. The problem is formulated as a Markov decision process. A link reward function and a signaling cost function are introduced to capture the tradeoff between the network resources utilized by the connection and the signaling and processing load incurred on the network. A stationary deterministic policy is obtained when the connection termination time is geometrically distributed. Numerical results show good performance of our proposed scheme over two other vertical handoff decision algorithms, namely: SAW (simple additive weighting) and GRA (grey relational analysis)."
2979409,22457,8385,Detecting table clones and smells in spreadsheets,2016,"Spreadsheets are widely used by end users for various business tasks, such as data analysis and financial reporting. End users may perform similar tasks by cloning a block of cells (table) in their spreadsheets. The corresponding cells in these cloned tables are supposed to keep the same or similar computational semantics. However, when spreadsheets evolve, thus cloned tables can become inconsistent due to ad-hoc modifications, and as a result suffer from smells. In this paper, we propose TableCheck to detect table clones and related smells due to inconsistency among them. We observe that two tables with the same header information at their corresponding cells are likely to be table clones. Inspired by existing fingerprint-based code clone detection techniques, we developed a detection algorithm to detect this kind of table clones. We further detected outliers among corresponding cells as smells in the detected table clones. We implemented our idea into TableCheck, and applied it to real-world spreadsheets from the EUSES corpus. Experimental results show that table clones commonly exist (21.8%), and 25.6% of the spreadsheets with table clones suffer from smells due to inconsistency among these clones. TableCheck detected table clones and their smells with a precision of 92.2% and 85.5%, respectively, while existing techniques detected no more than 35.6% true smells that TableCheck could detect."
145074,22457,9438,Strategic Alignment Maturity Model (SAMM) in a Cascading Balanced Scorecard (BSC) Environment: Utilization and Challenges,2012,"SAMM is a useful tool for measuring the maturity of business/IT alignment in an organization at the macro level. However, at the micro level, organizations use several frameworks including cascading BSC, ITIL, COBIT, etc. to align business and IT processes. The complexity of alignment increases with the existence of more than one tier of cascading and usage of different tools or frameworks. Studies have shown that measuring business/IT alignment at the micro level is difficult. Therefore, in order to accurately measure outcomes, mapping between metrics at all levels is required. It is also important to establish metrics that are aligned with those prescribed by SAMM. Using a multi-level cascading BSC that was previously published in BUSITAL by this author, this study attempts to apply the underlying components of SAMM and to establish relevant alignment metrics. It also highlights some applicability problems and suggests appropriate solutions for future implementations."
2659485,22457,20561,A Mathematical Programming Model for Matching Sequential Activities in Logistics Systems with Tolerance for Erroneous or Missing Data,2016,"We present a mathematical programming model that was constructed to match flight data from the FAA Air Traffic Control system with airline gate data maintained by an individual carrier. The purpose is to provide reliable data for calibrating realistic models of airport activity. Our technique also has potential value for other logistics and information systems where time stamps for sequential stages in a process are blended to impute time durations for activities, especially where observations are occasionally missing or imperfectly recorded."
2653647,22457,369,Towards Mobility-as-a-Service to Promote Smart Transportation,2015,"In this paper, we present a mobility cloud platform called CarCloud that has been designed to facilitate the real-world deployment of ubiquitous mobile telematic applications to promote smart transportation. CarCloud leverages the mobility, sensing and communication capacities of mobile devices, and collaborates with sensors embedded in vehicles (e.g., accessed via OBD-II) and cloud services to form a seamless platform. This platform orchestrates different mobility data in transportations to REST web service based mobility services that could be used for different mobile telematic applications (e.g., enabling traffic managers to monitor the behaviors of drivers) in intelligent transportation systems (ITS). Prototype implementation and preliminary experiments demonstrate the desired functionality of CarCloud for ITS and its feasibility for real-world deployment."
2698855,22457,20358,Smart Service Portfolios: Do the Cities Follow Standards?,2016,"Smart services concern the core element of a smart city, since they support the realization of urban intelligence in terms of people, economy, governance, environment, mobility and leaving. Smart services aim to enhance quality of life within a city and in this respect to improve livability. The types and purposes of smart services cannot be easily pre-defined, since they are the outcome of innovation, which cannot be pre-defined either, but instead it is the product of citizens' and businesses' creativity. However, standard bodies that work on smart city definition have described smart city portfolios, which are suggested to city policy makers and potential entrepreneurs. The aim of this paper is to validate whether standardized smart service portfolios are being followed by smart cities in practice. In this regard, a set of more than 70 smart cities are examined and their smart services are matched to these portfolios. The outcomes are extremely important and leave space for future research in this regard."
2708939,22457,20358,When do Recommender Systems Work the Best?: The Moderating Effects of Product Attributes and Consumer Reviews on Recommender Performance,2016,"We investigate the moderating effect of product attributes and consumer reviews on the efficacy of a collaborative filtering recommender system on an e-commerce site. We run a randomized field experiment on a top North American retailer's website with 184,375 users split into a recommender-treated group and a control group with 37,215 unique products in the dataset. By augmenting the dataset with Amazon Mechanical Turk tagged product attributes and consumer review data from the website, we study their moderating influence on recommenders in generating conversion. We first confirm that the use of recommenders increases the baseline conversion rate by 5.9%. We find that the recommenders act as substitutes for high average review ratings with the effect of using recommenders increasing the conversion rate as much as about 1.4 additional average star ratings. Additionally, we find that the positive impacts on conversion from recommenders are greater for hedonic products compared to utilitarian products while search-experience quality did not have any impact. We also find that the higher the price, the lower the positive impact of recommenders, while having lengthier product descriptions and higher review volumes increased the recommender's effectiveness. More findings are discussed in the Results.#R##N##R##N#For managers, we 1) identify the products and product attributes for which the recommenders work well, 2) show how other product information sources on e-commerce sites interact with recommenders. Additionally, the insights from the results could inform novel recommender algorithm designs that are aware of strength and shortcomings. From an academic standpoint, we provide insight into the underlying mechanism behind how recommenders cause consumers to purchase."
2119294,22457,20358,Statistical analysis of the social network and discussion threads in slashdot,2008,"We analyze the social network emerging from the user comment activity on the website Slashdot. The network presents common features of traditional social networks such as a giant component, small average path length and high clustering, but differs from them showing moderate reciprocity and neutral assortativity by degree. Using Kolmogorov-Smirnov statistical tests, we show that the degree distributions are better explained by log-normal instead of power-law distributions. We also study the structure of discussion threads using an intuitive radial tree representation. Threads show strong heterogeneity and self-similarity throughout the different nesting levels of a conversation. We use these results to propose a simple measure to evaluate the degree of controversy provoked by a post."
2813372,22457,8228,Personal health records as sources of productivity evidence,2016,"Capturing data from various data repositories and integrating them for productivity improvements is common in modern business organisations. With the well-accepted concept of achieving positive gains through investment in employee health and wellness, organisations have now started to capture both employee health and non-health data as Employer Sponsored electronic Personal Health Records (ESPHRs). However, non-health related data in ESPHRs has hardly been taken into consideration, with outcomes such as employee productivity potentially being suited for further validation and stimulation of ESPHR usage. Here we analyse selected employee demographic information (age, gender, marital status, and job grade) and employee health-related outcomes (absenteeism and presenteeism) to support evidence-based decision making. Our study considered demographic and health-related outcomes of 700 employees. Surprisingly, the analysis shows that employees with high sick leave rates are also high performers. A factor analysis shows 92% of the variance in the data can be explained by three factors, with the job grade capable of explaining 62% of the variance. Work responsibilities may drive employees to maintain high work performance despite signs of sickness, so ESPHRs should focus attention on high performers. This finding suggests new ways of extracting value from ESPHRs to support organisational health and wellness management to help assure sustainability in organisational productivity."
1839712,22457,9896,Perceptions of trustworthiness online: the role of visual and textual information,2010,"People increasingly rely on social networking websites to initiate personal and professional relationships. This requires that a considerable amount of trust be placed in strangers solely on the basis of their online profiles. This paper examines how the nature of online information affects how trustworthy online daters are perceived. Visual (i.e., photographs) and textual (i.e., about me section) information is considered. Results show that textual information elicits the highest ratings of trustworthiness, and that the addition of a photograph decreases daters' perceived trustworthiness. However, the accuracy of trustworthiness impressions is low regardless of the type of information available, because of a truth bias. Results are discussed in terms of (1) hyperpersonal impression formation and the nature of truth bias; and (2) practical implications for building trustworthiness online."
1377532,22457,8228,Mobile Data Transfer Scheduling with Uncertainty,2010,"Multi-interfaced mobile devices can connect to heterogeneous wireless access networks with different capabilities and constraints. Additionally, many bandwidth intensive applications have rather relaxed real time constraints allowing for alternative scheduling mechanisms which can take into account user preferences, network characteristics as well as future network resource availability to better exploit network heterogeneity. The current approaches either simply react to changes, or assume that availability predictions are perfect. In this paper, we propose a scheduling scheme based on stochastic modeling to account for prediction errors. The scheme optimizes overall user utility gain considering imperfect predictions taken over realistic time intervals while catering for different applications' needs. We use 60 days of real user data of many users to demonstrate that it consistently out-performs other non-stochastic and greedy approaches in typical networking environments."
2725110,22457,20561,Influential Aspects of the Smart City,2016,"Using millions of sensors in everyday objects, smart cities will generate petabytes of data, and it will be delivered to multiple users via networks. Multi-disciplinary inter-operability is essential. We propose system engineering management, with multidisciplinary teams as an effective way to deliver real change. Their goal is to develop intelligent and integrated services through the use of digital technologies and open collaboration. We also caution that the process cannot be entirely planned ahead of time, it must be allowed to evolve. New technology will change the game (where does a 3-D printer fit into a smart city?). Municipal planning means central planning -- not known for its sensitivity to reality. A successful smart city will include lots of feedback mechanisms for the citizenry."
1688539,22457,9475,A market-based mechanism for providing demand-side regulation service reserves,2011,"We develop a market-based mechanism that enables a building Smart Microgrid Operator (SMO) to offer regulation service reserves and meet the associated obligation of fast response to commands issued by the wholesale market Independent System Operator (ISO) who provides energy and purchases reserves. The proposed market-based mechanism allows the SMO to control the behavior of internal loads through price signals and to provide feedback to the ISO. A regulation service reserves quantity is transacted between the SMO and the ISO for a relatively long period of time (e.g., a one hour long time-scale). During this period the ISO repeatedly requests from the SMO to decrease or increase its consumption. We model the operational task of selecting an optimal short time-scale dynamic pricing policy as a stochastic dynamic program that maximizes average SMO and ISO utility. We then formulate an associated non-linear programming static problem that provides an upper bound on the optimal utility. We study an asymptotic regime in which this upper bound is tight and the static policy provides an efficient approximation of the dynamic pricing policy. We demonstrate, verify and validate the proposed approach through a series of Monte Carlo simulations of the controlled system time trajectories."
2641435,22457,20561,Decisions in Mobility Service Networks -- Coordinating Demand and Supply Using a Mechanism Design Approach,2016,"Passenger transportation has become more diverse in the recent past. New providers and transportation services are reeling up markets around the world. Together with the rise of the sharing economy, substantial ramifications for the transportation sector emerge. As a result of an increasing number of mobility options, the traveler can choose from a richer mobility menu. The difficulty of selecting the most appropriate mobility alternative, however, grows in the number of mobility options. Hence, without appropriate decision support, the full potential of mobility alternatives may remain locked from utilization. We leverage structurally similar observations from the domains of IT service management and cloud computing to address this issue. In particular, we introduce a formal model for matching supply and demand on graphs via a market platform. This platform allows for efficient matching and orchestration of a set of individual means of transportation with demand featuring heterogeneous user preferences. Our specific contribution comprises the formalization of complex mobility services and the corresponding optimization problem as well as the development of an incentive-compatible auction mechanism, the complex mobility service auction. A stylized example demonstrates the efficacy of our approach."
746317,22457,369,A Handoff Decision Algorithm in Heterogeneous Wireless Networks with Parallel Transmission Capability,2011,"To provide the seamless mobility in heterogeneous wireless networks, the handoff decision strategy is regarded as a significant and challenging issue. In this paper, we propose a handoff decision algorithm with the parallel transmission characteristic of the mobile multimode terminal in heterogeneous wireless networks. In our algorithm, the model of Markov decision process is used to determine the optimal handoff policy in order to maximize the expected total reward during the transmission. Simulation results show that compared to some existing handoff decision algorithms, the proposed algorithm outperforms in terms of the expected total reward, the expected number of handoffs and the probability of connection dropping."
2399379,22457,11166,Evaluating Fraud Detection Algorithms Using an Auction Data Generator,2012,"Online auction sites are a target for fraud. Researchers have developed fraud detection and prevention methods. However, there are difficulties when using either commercial or synthetic auction data to evaluate the effectiveness of these methods. When using commercial data, it is not possible to accurately identify cases of fraud. Using synthetic data, the conclusions drawn may not extend to the real world. The availability of realistic synthetic auction data, which models real auction data, will be invaluable for effective evaluation of fraud detection algorithms. We present an agent-based simulator that is capable of generating realistic English auction data. The agents and model are based on data collected from the Trade Me online auction site. We evaluate the generated data in two ways to show that it is similar to the Trade Me auction data we have collected. In addition, we demonstrate that the simulator can have additional agents added to simulate fraudulent behaviour, and be used to evaluate fraud detection algorithms: we implement three different fraud behaviours and three detection algorithms, and using the simulator, compare the ability of the detection algorithms to correctly identify fraudulent agents."
2589113,22457,20332,An Ontology of Socio-Cultural Time Expressions.,2010,"Time is a concept that highly depends on the socio-cultural context. Its perception by humans is primarily based on the cultures, nations and social environment they belong to. Hence, different socio-cultural contexts imply different understandings of time. This leads to communication problems when their members start interacting with each other. In a dynamic and multi-cultural environment like today’s Web, where both billions of people with different socio-cultural contexts and numerous context dependent software applications interact, similar communication and inter-operability problems are expected. Expressing socio-cultural temporal information in an unambiguous, explicit and machine processable way can, however, help reduce such communication conflicts. In this way, heterogeneous temporal Web application systems can share the same concept of time. In this paper we present an ontology of socio-cultural time expressions that attempts to formalize the notion of socio-cultural time. The resulting model can then be used in a Web based temporal applications such as automated appointment scheduling services or calendars to provide more context sensitive service to its users."
2985128,22457,20358,A Warm Welcome Matters! The Link Between Social Feedback and Weight Loss in /r/loseit,2017,"Social feedback has long been recognized as an important element of successful health-related behavior change. However, most of the existing studies look at the effect that offline social feedback has. This paper fills gaps in the literature by proposing a framework to study the causal effect that receiving social support in the form of comments in an online weight loss community has on (i) the probability of the user to return to the forum, and, more importantly, on (ii) the weight loss reported by the user. Using a matching approach for causal inference we observe a difference of 9 lbs lost between users who do or do not receive comments. Surprisingly, this effect is mediated by neither an increase in lifetime in the community nor by an increased activity level of the user. Our results show the importance that a warm welcome has when using online support forums to achieve health outcomes."
1331395,22457,9896,Network effects and valuing social network services,2013,"Models including network effects are often invoked to justify the high value of social network services like Facebook. Yet as time passes and user numbers grow, inevitably so does reach across social circles, creating online tension or, as we term it, mismatch of social display. This leads to reduced participation. Social network services respond with efforts to segment networks through efforts like separate 'friend lists'. We provide a conceptual framework and a visualization to incorporate these insights into models of network effects and social network value."
2670259,22457,20561,Establishing ICT Governance for Regional Information Infrastructures in Healthcare,2016,"Large-scale interconnected information systems frequently conceptualized as information infrastructures are very difficult to govern. In particular, healthcare contexts involving different collaborative institutions and departments that have diverging goals and policies make the situation even more complex. Based on information infrastructure theory and governance literature from the IS field, this paper contributes with empirical insight into the longitudinal and political process of establishing ICT governance in a heterogeneous healthcare context by focusing on the following research questions: What does it take to establish ICT governance in a heterogeneous healthcare environment? How do organizational politics and stakeholders' interest shape the process? Empirically, we report from one of Norway's largest ICT projects on healthcare, situated in the North Norway Regional Health Authority in 2012 -- 2016."
2717490,22457,20561,The Salesperson's Use of Global Customer Relationship Management Systems,2016,"We explore the factors affecting sales people's use of global Customer Relationship Management (CRM) systems. Previous research focusing on global CRM has largely explored the macro level issues of CRM and CRM system implementation at the company or industry level ignoring people who actually use the global CRM systems in their everyday work. Neglect of the behavior of sales people may have misled the entire CRM research field, which has looked at the issue from a perspective of economic and technological advancement, without realizing that the root cause for the conflicting research results can be traced to the individual level. Hence, we problematize the extant research and propose that cultural context and distance, Global Account Management Programs, and perceived customer information quality affect the sales person's use of global CRM systems. Our paper concludes with avenues for future research in the area."
3013483,22457,20561,Consumer Information Services in Intercultural Tourism: An Ethnographic Study of Chinese Outbound Backpackers,2017,"This paper reports the findings of an ethnographic study of Chinese outbound backpackers’ use and adoption of consumer information services (CIS) in an intercultural tourism setting. We apply McKenna et al.’s research model of consumers’ adoption of information services as the analytical lens for the interpretive qualitative study. The data gathering was conducted in four different countries. The findings of the study confirm linkages between four information service types and the use and adoption of CIS. The study also found that service types are more diversely linked than the earlier studies have predicted and therefore we propose a revised research model, which can be used for studying different CIS usage behaviour/patterns, but also to design of CIS for specific contexts."
627475,22457,20358,Understanding Twitter influence in the health domain: a social-psychological contribution,2014,"Twitter can be a powerful tool for the dissemination and discussion of public health information but how can we best describe its influence? In this paper we draw on social-psychological concepts such as social norms, social representations, emotions and rhetoric to explain how influence works both in terms of the spread of information and also its personal impact. Using tweets drawn from a range of health issues, we show that social psychological theory can be used in the qualitative analysis of Twitter data to further our understanding of how health behaviours can be affected by social media discourse."
2277841,22457,9704,A Business Service Network to Aid Collaboration between Small to Medium Enterprises,2006,Short term integration repeated multiple times in a year can create complex and potentially damaging integration architectures for the Small to Medium Enterprise (SME). The solution to this problem proposed in this paper is a model which involves building Business Service Networks (BSNs) based around a dynamic community approach to integration. The model is implemented using a grid service architecture and applies existing work on dynamic virtual organisations in the area of business to business integration.
2424731,22457,9896,Sounds good to me: effects of photo and voice profiles on gaming partner choice,2006,"In an empirical study we investigated how matchmaking for online gaming platforms could benefit from additional implicit information conveyed in profiles that include photos or voice recordings. We used 150 real online gamer profiles (50 text-only, 50 text & photo, 50 text & voice) to elicit gaming partner preferences from 267 online gamers. We found profiles with photos to lead to lower overall preference, indicating that people used them to reject potential partners. Voice recordings did not reduce overall preference but gave participants relevant information for gaming partner choice. We close with recommendations for the design of profile-based matchmaking systems."
1755876,22457,9896,Big Board: Teleconferencing Over Maps for Shared Situational Awareness,2014,"Collaborative technologies for information sharing are an invaluable resource for emergency managers to respond to and manage highly dynamic events such as natural disasters and other emergencies. However, many standard collaboration tools can be limited either because they provide passive presentation and dissemination of information, or because they are targeted towards highly specific usage scenarios that require considerable training to use the tools. We present a real-time gather and share system called Big Board which facilitates collaboration over maps. The Big Board is an open-source, web based, real time visual collaborative environment that runs on all modern web browsers and uses open-source web standards developed by the Open Geospatial Consortium (OGC) and WorldWideWeb Consortium (W3C). An evaluation of Big Board was conducted by school representatives in North Carolina for use in situational understanding for school closure decisions during winter weather events. The decision to close schools has major societal impacts and is one that is usually made based on how well a teenage driver could handle wintry precipitation on a road. Collecting information on the conditions of roads is especially critical, however gathering and sharing of this information within a county can be difficult. Participants in the study found the Big Board intuitive and useful for sharing real time information, such as road conditions and temperatures, leading up to and during a winter storm scenario. We have adapted the Big Board to manage risks and hazards during other types of emergencies such as tropical storm conditions."
1920673,22457,369,A Combined Design to Provide QoS for Mobile Ad Hoc Networks,2007,"To transmit real-time traffic in mobile ad hoc networks, a combined design of TDMA MAC and routing protocol was proposed. Most approaches proposed recently applied schemes in the routing protocol to provide QoS and paid no attention to the MAC design. Actually, the ability to provide QoS heavily depends on how well the resources are managed in the MAC layer. In our work, we try to focus on the design of MAC protocol and combine it with AODV to provide QoS. The QoS requirement of a certain session can be satisfied if all nodes in the route reserve slots with the corresponding frame length. It is convenient to manage slot assignment information and select a slot with a certain frame length in a binary tree structure. Simulation results are presented to verify the performance of the combined design."
1226642,22457,369,A Formal Methodology Applied to Secure Over-the-Air Automotive Applications,2011,"The expected high complexity in future automotive applications will require to frequently update electronic devices supporting those applications. Even if in-car devices are trusted, potential attacks on over the air exchanges impose stringent requirements on both safety and security. To address the formal verification of safety properties, we have previously introduced the AVATAR UML profile whose methodology covers requirement, analysis, design, and formal verification stages [1]. We now propose to extend AVATAR to support both safety and security during all methodological stages, and in the same models. The paper applies the extended AVATAR to an over the-air protocol for trusted firmware updates of in-car control units, with a special focus on design and formal verification stages."
1976592,22457,8228,Utility-based Intelligent Network Selection in Beyond 3G Systems,2006,Development in wireless access technologies and multihomed personal user devices is driving the way towards a heterogeneous wireless access network environment. Success in this arena will be reliant on the ability to offer an enhanced user experience. Users will plan to take advantage of the competition and always connect to the network which can best service their preferences for the current application. They will rely on intelligent network selection decision strategies to aid them in their choice. The contribution of this paper is to propose an intelligent utility-based strategy for network selection in this multi-access network scenario. A number of utility functions are examined which explore different user attitudes to risk for money and delay preferences related to their current application. For example we show that risk takers who are willing to pay more money get a better service.
823785,22457,9896,Open Education in the Wild: The Dynamics of Course Production in the Peer 2 Peer University,2015,"The Peer 2 Peer University (P2PU) is an online, open education platform where any user can create a course, contribute content, or join an existing course as a learner. P2PU represents an experiment in organizing the production of entirely user-generated, open education. However, the open model of P2PU rests on the critical assumption that members can successfully coordinate and produce a sufficient supply of courses and motivate others to join in. In this paper, we use log data from P2PU to describe the dynamics of organizers -- members who try to produce and launch open courses -- and explore the factors related to their ability to successfully create courses on this open platform. We find that a critical predictor of successful course development is quickly finding like-minded organizers to collaborate with, suggesting that creating new education systems based on open, social computing platforms requires facilitation of key aspects of social coordination beyond providing platform and content resources."
2724953,22457,20561,A Unified Model for System Security Engineering Support,2016,"In the course of performing their duties, system security engineers must develop a detailed understanding of cyber systems, the missions those systems support, the associated cyber threat, and the risk the threat poses to mission. They use this information to specify and track cyber requirements, security controls, and the architectural aspects that allow the controls to be coordinated and implemented across the cyber environment. When attempted manually, the process of gathering, interrelating, verifying, querying, analyzing, sharing, and reusing this information can be an overwhelming data management and cognitive challenge. While models exist that focus on isolated portions of the system security engineering process, this paper puts forward a unified model as a first step towards a common platform to manage this information. The model facilitates the development of analytics to assist with activities such as threat modeling, risk assessment, security requirements development, and control tracking and tailoring."
3227924,22457,9896,The Challenge of Enterprise Social Networking (Non-)Use at Work: A Case Study of How to Positively Influence Employees' Enterprise Social Networking Acceptanc,2017,"Enterprise social networking (ESN) platforms have been implemented by organizations to support employees' collaboration. However, there has been a reported lack of user participation on these platforms. This study focuses on interventions that can be used to overcome barriers of usage. A case study was conducted at IBM to investigate the effect of several interventions to positively influence ESN acceptance within IBM's Human Resources (HR) function. In this study we combined two rounds of interview data with activity log data. We interviewed the initiators of interventions, and we interviewed the employees targeted by those interventions. The activity logs allowed us to contrast actual usage of the ESN by employees from HR vs. other organizational functions. Compared to other ESN studies this study explicitly identifies factors driving or inhibiting ESN use, and shows how these factors can be addressed by interventions to significantly increase ESN use. Our results can inform and enable other organizations interested in the design of interventions to increase the use of ESN."
3089091,22457,20561,Challenges with smart cities initiatives – A municipal decision makers’ perspective,2017,"The European Nations foresee a growing population and a trending urbanization that pose significant environmental and social concerns. To manage these concerns municipal decision makers’ attempt to leverage the smart city concept with collaboration between external actors as a means to maintain the prepossessed living standard in the city.By developing a framework based on existing literature and validating it with municipal decision makers view on the framework, this paper attempts to further the discussion on the predominant challenges in smart city initiatives from the municipal decision makers’ perspective in mid-sized European cities.The study is based on a pre-study conducted via 39 interviews in 25 different EU-cities. This followed by interviews with 12 decision makers’ in 10 different cities. The results show that municipal decision makers mainly perceive challenges with non-technical issues such as collaboration, economical, governance and awareness of technology – however security is not perceived as a challenge. (Less)"
2212523,22457,9896,One piece at a time: why video-based communication is better for negotiation and conflict resolution,2012,"We compared the effects of three computer mediated communication (CMC) channels (text, audio, and video) on how people performed an appointment-scheduling task. The task involved a grounding and a conflict resolution component. The results showed that video conferencing supported participant dyads in reaching a consensus that had better balanced performance between the dyads only when task difficulty was high and when there were more inherent conflicts in the task. Participants across the three CMC conditions also demonstrated different patterns of conversation dynamics during information exchange and negotiation. Mediation analysis showed that in video-based communication, strategies of exchanging less information at a time predicted higher levels of negotiation, which in turn predicted smaller performance differences in high conflict conditions. The results suggested that the design and use of communication technologies for remote conflict resolution should promote the strategy of exchanging information in small pieces, which could better support subsequent negotiation and foster a sense of fairness."
2568867,22457,9475,Electrical centrality measures for electric power grid vulnerability analysis,2010,Centrality measures are used in network science to rank the relative importance of nodes and edges of a graph. Here we define new measures of centrality for power grid structure that are based on its functionality. We show that the relative importance analysis based on centrality in graph theory can be generalized to power grid network with its electrical parameters taken into account. In the paper we experiment with the proposed electrical centrality measures on the NYISO-2935 system and the IEEE 300-bus system. We analyze the centrality distribution in order to identify important nodes or branches in the system which are of essential importance in terms of system vulnerability. We also present and discuss a number of interesting discoveries regarding the importance rank of power grid nodes and branches.
348759,22457,9438,Augmenting CASE Tools with Hypertext: Desired Functionality and Implementation Issues,1997,"Information systems have become bigger and more complex as their support has expanded to cover larger business domains, communication and work. At the same time technical design options such as client/server architectures and graphical user interfaces have increased the size and complexity of applications. In addition, pressures to build better systems more quickly have motivated the use of integrated design environments, such as CASE. Several integration approaches such as process modeling, frameworks and hypertext technology have been proposed. Of these we consider the least analyzed, hypertext technology, in this paper. Because of the novelty of hypertext in CASE there are several unresolved issues related to this approach. Present hypertext technology has been mainly applied to non-structured representations such as text, which is radically different from complex structured representations such as the diagrams and matrices used in CASE. CASE tools also imply that a design object has both representational and conceptual aspect, which has not been investigated in relation to hypertext. In this paper we discuss how hypertext can be incorporated into a metaCASE tool which uses all the common representation paradigms: diagrams, matrices and tables. We also report the implementation and architecture of such an environment."
2011131,22457,422,Toward a multi-strategy and cooperative discovery system,1995,"We have been developing a methodology/system called GLS (Global Learning Scheme) for knowledge discovery in databases. The development of GLS has two main aspects. The first is to develop a multi-strategy system. That is, many kinds of discovery/learning methods are cooperatively used in multiple learning phases for performing multi-aspect intelligent data analysis as well as multi-level conceptual abstraction and learning. As a multi-strategy system, GLS is implemented as a toolkit composed of several sub-systems and optional parts with a multi-level structure. We have finished main parts belonging to this aspect, and have undertaken another aspect, i.e., extending GLS into a multi-agent, distributed and cooperative discovery system. We try to increase versatility and autonomy of GLS by multi-strategy and distributed cooperation. This paper briefly discusses these two aspects of GLS."
1498629,22457,9896,Microblogging after a major disaster in China: a case study of the 2010 Yushu earthquake,2011,"In this work, we conducted a case study of a popular Chinese microblogging site, Sina-Weibo, to investigate how Chinese netizens used microblogging in response to a major disaster: the 2010 Yushu Earthquake. We combined multiple analysis methods in this case study, including content analysis of microblog messages, trend analysis of different topics, and an analysis of the information spreading process. This study helped us understand the roles played by microblogging systems in response to major disasters and enabled us to gain insight into how to harness the power of microblogging to facilitate disaster response. In addition, this work supplements existing works with an exploration of a non-Western socio-cultural system: how Chinese Internet users used microblogging in disaster response."
1330273,22457,9896,Ad-itudes: twitter users & advertising,2012,"Advertising offline and online is pervasive. This study surveyed over 400 Internet users in the United States to assess current attitudes towards such advertisements. Preliminary results show that Twitter users have a more favorable view of advertisements, both online and offline, than non-users. As designers of Internet-based services introduce advertisements to fund their services, it is useful to understand users' attitudes towards such advertising. As researchers we should consider how advertisements and attitudes towards such advertisements impact how users interact and communicate with one another via these systems."
2579015,22457,20332,Scalable complex contract negotiation with structured search and agenda management,2014,"A large number of interdependent issues in complex contract negotiation poses a significant challenge for current approaches, which becomes even more apparent when negotiation problems scale up. To address this challenge, we present a structured anytime search process with an agenda management mechanism using a hierarchical negotiation model, where agents search at various levels during the negotiation with the guidance of a mediator. This structured negotiation process increases computational efficiency, making negotiations scalable for large number of interdependent issues. To validate the contributions of our approach, 1) we developed our proposed negotiation model using a hierarchical problem structure and a constraint-based preference model for real-world applications; 2) we defined a scenario matrix to capture various characteristics of negotiation scenarios and developed a scenario generator that produces test cases according to this matrix; and 3) we performed an extensive set of experiments to study the performance of this structured negotiation protocol and the influence of different scenario parameters, and investigated the Pareto efficiency and social welfare optimality of the negotiation outcomes. The experimental result supports the hypothesis that this hierarchical negotiation approach greatly improves scalability with the complexity of the negotiation scenarios."
